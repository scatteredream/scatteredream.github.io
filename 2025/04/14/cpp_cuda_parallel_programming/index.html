<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 5.4.2">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&family=Arvo:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&family=JetBrains+Mono:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"scatteredream.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":true,"version":"8.23.0","exturl":false,"sidebar":{"position":"right","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"flat"},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":false,"async":false},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="同一时刻，多条指令在一个CPU上同时执行，物理上和逻辑上都是同时执行的。分布式计算（Distributed computing）是并行计算的一个特例，它采用计算机网络来进行同步。 分类指令级并行，线程级并行，数据级并行区别？线程的概念是什么？ - 知乎  线程级并行 TLP线程级并发（Concurrency）  并发计算 - 维基百科，自由的百科全书 (wikipedia.org)  并发是一种现">
<meta property="og:type" content="article">
<meta property="og:title" content="多核并行编程(C++&amp;CUDA)">
<meta property="og:url" content="http://scatteredream.github.io/2025/04/14/cpp_cuda_parallel_programming/index.html">
<meta property="og:site_name" content="scatteredream&#39;s blog">
<meta property="og:description" content="同一时刻，多条指令在一个CPU上同时执行，物理上和逻辑上都是同时执行的。分布式计算（Distributed computing）是并行计算的一个特例，它采用计算机网络来进行同步。 分类指令级并行，线程级并行，数据级并行区别？线程的概念是什么？ - 知乎  线程级并行 TLP线程级并发（Concurrency）  并发计算 - 维基百科，自由的百科全书 (wikipedia.org)  并发是一种现">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/thumbnail_1280X720.jpg">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241029161108996.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241029164032833.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115220709073.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115220731029.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115220749864.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241119184759519.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241119185155274.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115221108488-1731681607112-1.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115222853277.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115220240060.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115225902890.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115230015703.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115230229087.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115231555912.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115230540760.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115231028700.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241116130720225.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241116002448557.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241116002705661.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241116003512855.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241116003914988.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241116004457236.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241116004534563.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241118150058492.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241221235324151.png">
<meta property="article:published_time" content="2025-04-13T16:00:00.000Z">
<meta property="article:modified_time" content="2025-05-15T04:05:25.230Z">
<meta property="article:author" content="碎梦">
<meta property="article:tag" content="排序算法">
<meta property="article:tag" content="cuda">
<meta property="article:tag" content="并发">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/thumbnail_1280X720.jpg">


<link rel="canonical" href="http://scatteredream.github.io/2025/04/14/cpp_cuda_parallel_programming/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://scatteredream.github.io/2025/04/14/cpp_cuda_parallel_programming/","path":"2025/04/14/cpp_cuda_parallel_programming/","title":"多核并行编程(C++&CUDA)"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>多核并行编程(C++&CUDA) | scatteredream's blog</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous" defer></script>
<script src="/js/third-party/search/local-search.js" defer></script>







  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">scatteredream's blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%88%86%E7%B1%BB"><span class="nav-number">1.</span> <span class="nav-text">分类</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BA%BF%E7%A8%8B%E7%BA%A7%E5%B9%B6%E8%A1%8C-TLP"><span class="nav-number">1.1.</span> <span class="nav-text">线程级并行 TLP</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BA%BF%E7%A8%8B%E7%BA%A7%E5%B9%B6%E5%8F%91%EF%BC%88Concurrency%EF%BC%89"><span class="nav-number">1.1.1.</span> <span class="nav-text">线程级并发（Concurrency）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BA%BF%E7%A8%8B%E7%BA%A7%E5%B9%B6%E8%A1%8C%EF%BC%88Parallelism%EF%BC%89"><span class="nav-number">1.1.2.</span> <span class="nav-text">线程级并行（Parallelism）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%B6%85%E7%BA%BF%E7%A8%8B%EF%BC%88Hyper-Threading-HT-SMT%EF%BC%89"><span class="nav-number">1.1.2.1.</span> <span class="nav-text">超线程（Hyper-Threading,HT&#x2F;SMT）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A4%9A%E6%A0%B8%E5%BF%83%EF%BC%88Multicore%EF%BC%89"><span class="nav-number">1.1.2.2.</span> <span class="nav-text">多核心（Multicore）</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8C%87%E4%BB%A4%E7%BA%A7%E5%B9%B6%E8%A1%8C-ILP%EF%BC%88Pipeline%EF%BC%89"><span class="nav-number">1.2.</span> <span class="nav-text">指令级并行 ILP（Pipeline）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E7%BA%A7%E5%B9%B6%E8%A1%8C-DLP%EF%BC%88SIMD%EF%BC%89"><span class="nav-number">1.3.</span> <span class="nav-text">数据级并行 DLP（SIMD）</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8F%91%E5%B1%95"><span class="nav-number">2.</span> <span class="nav-text">发展</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%B9%B6%E8%A1%8C%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80"><span class="nav-number">3.</span> <span class="nav-text">并行理论基础</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Thread-%E7%BA%BF%E7%A8%8B-%E5%B9%B6%E8%A1%8C%E6%9C%80%E5%B0%8F%E5%8D%95%E4%BD%8D"><span class="nav-number">3.1.</span> <span class="nav-text">Thread 线程 并行最小单位</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Process-%E8%BF%9B%E7%A8%8B"><span class="nav-number">3.1.1.</span> <span class="nav-text">Process 进程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Coroutine-%E5%8D%8F%E7%A8%8B"><span class="nav-number">3.1.2.</span> <span class="nav-text">Coroutine 协程</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Mutex-%E4%BA%92%E6%96%A5%E9%94%81"><span class="nav-number">3.2.</span> <span class="nav-text">Mutex 互斥锁</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#C-%E5%B9%B6%E8%A1%8C%E7%BC%96%E7%A8%8B"><span class="nav-number">4.</span> <span class="nav-text">C++ 并行编程</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BB%93%E6%9E%84%E5%8C%96%E5%B9%B6%E8%A1%8C%E7%BC%96%E7%A8%8B-fork-join"><span class="nav-number">4.1.</span> <span class="nav-text">结构化并行编程 fork-join</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF"><span class="nav-number">4.2.</span> <span class="nav-text">常见错误</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F"><span class="nav-number">4.3.</span> <span class="nav-text">Lambda表达式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A1%88%E4%BE%8B%EF%BC%9A%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95"><span class="nav-number">4.4.</span> <span class="nav-text">案例：矩阵乘法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%B6%E4%BB%96%E5%B9%B6%E5%8F%91%E5%BA%93"><span class="nav-number">4.5.</span> <span class="nav-text">其他并发库</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%B9%B6%E8%A1%8C%E7%AE%97%E6%B3%95"><span class="nav-number">5.</span> <span class="nav-text">并行算法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Bitonic-Sort"><span class="nav-number">5.1.</span> <span class="nav-text">Bitonic Sort</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Odd-Even-Sort"><span class="nav-number">5.2.</span> <span class="nav-text">Odd-Even Sort</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Prefix-Sum"><span class="nav-number">5.3.</span> <span class="nav-text">Prefix Sum</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Max-Subsequence-Sum"><span class="nav-number">5.4.</span> <span class="nav-text">Max Subsequence Sum</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Merge-Sort"><span class="nav-number">5.5.</span> <span class="nav-text">Merge Sort</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Quick-Sort"><span class="nav-number">5.6.</span> <span class="nav-text">Quick Sort</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Odd-Even-Merge"><span class="nav-number">5.7.</span> <span class="nav-text">Odd-Even Merge</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CUDA-%E5%B9%B6%E8%A1%8C%E7%BC%96%E7%A8%8B"><span class="nav-number">6.</span> <span class="nav-text">CUDA 并行编程</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%89%B9%E6%80%A7"><span class="nav-number">6.1.</span> <span class="nav-text">特性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BC%96%E7%A8%8B%E7%A4%BA%E4%BE%8B"><span class="nav-number">6.2.</span> <span class="nav-text">编程示例</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Memory-API"><span class="nav-number">6.3.</span> <span class="nav-text">Memory API</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5"><span class="nav-number">6.3.1.</span> <span class="nav-text">线程同步</span></a></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="碎梦"
      src="https://avatars.githubusercontent.com/u/62317679?s=400&v=4">
  <p class="site-author-name" itemprop="name">碎梦</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">78</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">125</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://scatteredream.github.io/2025/04/14/cpp_cuda_parallel_programming/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars.githubusercontent.com/u/62317679?s=400&v=4">
      <meta itemprop="name" content="碎梦">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="scatteredream's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="多核并行编程(C++&CUDA) | scatteredream's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          多核并行编程(C++&CUDA)
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-04-14 00:00:00" itemprop="dateCreated datePublished" datetime="2025-04-14T00:00:00+08:00">2025-04-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-05-15 12:05:25" itemprop="dateModified" datetime="2025-05-15T12:05:25+08:00">2025-05-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/juc/" itemprop="url" rel="index"><span itemprop="name">juc</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>同一时刻，多条指令在一个CPU上同时执行，物理上和逻辑上都是同时执行的。<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%88%86%E6%95%A3%E5%BC%8F%E8%A8%88%E7%AE%97">分布式计算</a>（Distributed computing）是<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/zh-cn/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97">并行计算</a>的一个特例，它采用计算机网络来进行同步。</p>
<h1 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h1><p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/21823699?sort=created">指令级并行，线程级并行，数据级并行区别？线程的概念是什么？ - 知乎</a> </p>
<h2 id="线程级并行-TLP"><a href="#线程级并行-TLP" class="headerlink" title="线程级并行 TLP"></a>线程级并行 TLP</h2><h3 id="线程级并发（Concurrency）"><a href="#线程级并发（Concurrency）" class="headerlink" title="线程级并发（Concurrency）"></a>线程级并发（Concurrency）</h3><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/thumbnail_1280X720.jpg" alt="thumbnail_1280X720"></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/zh-cn/%E5%B9%B6%E5%8F%91%E8%AE%A1%E7%AE%97">并发计算 - 维基百科，自由的百科全书 (wikipedia.org)</a></p>
<ul>
<li>并发是一种<strong>现象</strong>，比并行更加抽象，同时运行多个程序或多个任务需要被处理的现象。</li>
<li>它可以执行在单一<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%99%95%E7%90%86%E5%99%A8">处理器</a>上，将不同的执行步骤分散在不同<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%97%B6%E9%97%B4%E7%89%87">时间片</a>中执行，以非<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%B9%B3%E8%A1%8C%E9%81%8B%E7%AE%97">并行</a>方式循序运算，通过操作系统调度CPU快速切换执行上下文来实现宏观上的“并行”</li>
<li>它也可以用真正的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%B9%B3%E8%A1%8C%E8%A8%88%E7%AE%97">并行计算</a>来实现，将每个行程指定给处理器组中的某个处理器，以单片机<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%A4%9A%E8%99%95%E7%90%86%E5%99%A8">多处理器</a>平台，或是透过网络链接的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97">分散</a>平台来实做。</li>
</ul>
<p>coroutine就是典型的并发不并行</p>
</blockquote>
<p>操作系统通过时间片轮转调度，在不同的任务之间来回切换.</p>
<p>对cpu而言，这两个进程其实不是同时进行的；<br>对用户而言，由于P1和P2切换的速度非常快，所以用户觉得是“是同时进行的”。</p>
<h3 id="线程级并行（Parallelism）"><a href="#线程级并行（Parallelism）" class="headerlink" title="线程级并行（Parallelism）"></a>线程级并行（Parallelism）</h3><p>一个核心仍然无法处理多个线程</p>
<p>英特尔和AMD也意识到，当主频接近4GHz时，速度也会遇到自己的极限：那就是<strong>单靠主频提升，已经无法明显提升系统整体性能</strong>。因此迫切需要一个能支持同时处理2个线程以上的处理器，来提升CPU的瓶颈。需求推动了技术<strong>，线程级并行应运而生</strong>。主要由下面两种技术的支撑：</p>
<h4 id="超线程（Hyper-Threading-HT-SMT）"><a href="#超线程（Hyper-Threading-HT-SMT）" class="headerlink" title="超线程（Hyper-Threading,HT/SMT）"></a>超线程（Hyper-Threading,HT/SMT）</h4><p>2004年，奔腾4实现了Hyper-Threading（单核心双线程）</p>
<blockquote>
<p>超线程技术实现了单个物理核心同时两个线程，也就是别人常说的虚拟内核数。比如单物理核心实现的双线程，它同时可以处理两个线程，它的物理核心数其实是是1个，通过HyperThreading技术实现的<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=40117005&content_type=Answer&match_order=3&q=%E7%BA%BF%E7%A8%8B%E7%BA%A7%E5%B9%B6%E8%A1%8C&zhida_source=entity">线程级并行</a>(<code>Thread Lever Parallelism</code>)。至于技术细节的实现，这涉及到高速缓存的知识。</p>
</blockquote>
<p>Intel的SMT技术是我们认知最广泛的，早在2002年的Pentium 4上（应该是Pentium 4的E）和Xeon上，Intel就把SMT技术包装成Hyper Threading，并推向市场了。之后因为架构切换，在酷睿诞生初期暂停过一段时间，而自从Core i7 960这个划时代的酷睿后，就一直是Intel中高端CPU的标配了。 Intel的超线程一直都是SMT2，也就是一个物理核心虚拟出两个核心，也就是逻辑核心。 AMD最新的Zen系列CPU，也同样加入了SMT2的超线程，现在超线程技术可以说是PC和服务器CPU的标配了。</p>
<p>SMT是在指令级并行的基础上的扩展，可以在一个核上运行多个线程，多个线程共享执行单元，以便提高部件的利用率，提高吞吐量。SMT需要为每个线程单独保持状态，如程序计数器（PC），<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=61447789&content_type=Answer&match_order=1&q=%E5%AF%84%E5%AD%98%E5%99%A8%E5%A0%86&zhida_source=entity">寄存器堆</a>，重排序缓冲等。在一个CPU 的<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E6%97%B6%E9%92%9F%E5%91%A8%E6%9C%9F/1545064?fromModule=lemma_inlink">时钟周期</a>内能够执行来自多个线程的指令的硬件<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%8A%80%E6%9C%AF/5764231?fromModule=lemma_inlink">多线程技术</a>。本质上，同步多线程是一种将线程级<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86/8983963?fromModule=lemma_inlink">并行处理</a>（多CPU）转化为<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E6%8C%87%E4%BB%A4/3225201?fromModule=lemma_inlink">指令</a>级并行处理（同一CPU）的方法。 同步多线程是单个物理处理器从多个硬件线程上下文同时分派<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E6%8C%87%E4%BB%A4/3225201?fromModule=lemma_inlink">指令</a>的能力。</p>
<h4 id="多核心（Multicore）"><a href="#多核心（Multicore）" class="headerlink" title="多核心（Multicore）"></a>多核心（Multicore）</h4><p>物理核心数量的提升</p>
<ol>
<li><strong>多核处理器 (Multicore Processors)</strong></li>
</ol>
<ul>
<li><strong>描述</strong>：一个芯片上集成多个核心，每个核心可独立运行一个线程或任务。</li>
<li><strong>代表技术</strong>：Intel Core i7、AMD Ryzen。</li>
<li>特点：<ul>
<li>多个核心共享内存或缓存，提高线程并发能力。</li>
<li>适用于多线程应用和多任务环境。</li>
</ul>
</li>
</ul>
<ol>
<li>2005年，英特尔宣布他的第一个双核心 EM64T 处理器，和 Pentium D840(次年发布，双核心双线程，蹩脚双核)</li>
<li>2006年，Core 2（双核心双线程，但不支持HT技术）这大概才算真正意义上单芯片多核心处理器的诞生。（物理双核）</li>
<li>而2006后迎来了Multi-Core Processor多内核处理器时代，而且也伴随着多线程技术.<br>也就常说的几核几线程。核一般指的是物理核心的数目，线程是计算机能同时进行的线程。</li>
</ol>
<p><strong>多处理器系统 (Multi-Processor Systems)</strong></p>
<ul>
<li><strong>描述</strong>：多个物理 CPU 组成的系统，每个 CPU 拥有自己的内存或共享内存。</li>
<li>类型：<ol>
<li><strong>SMP（对称多处理）</strong>：所有处理器访问共享内存，共享操作系统资源。</li>
<li><strong>NUMA（非一致存储访问）</strong>：各处理器访问本地内存更快，远程内存访问更慢。</li>
</ol>
</li>
<li><strong>应用场景</strong>：大型服务器、高性能计算集群。</li>
</ul>
<p><strong>分布式计算 (Distributed Computing)</strong></p>
<ul>
<li><strong>描述</strong>：任务分布到多个计算节点，每个节点处理部分任务，并通过网络协调结果。</li>
<li><strong>典型框架</strong>：Hadoop、Spark、MPI。</li>
<li><strong>应用场景</strong>：数据挖掘、大规模仿真建模。</li>
</ul>
<p><strong>GPU 并行计算 (GPU Parallel Computing)</strong></p>
<ul>
<li><strong>描述</strong>：利用 GPU 的众多流处理器并行处理大量数据，适合数据密集型任务。</li>
<li>特点：<ul>
<li>专门用于图形渲染和 AI、机器学习任务。</li>
<li>框架：CUDA（NVIDIA）、OpenCL。</li>
</ul>
</li>
</ul>
<h2 id="指令级并行-ILP（Pipeline）"><a href="#指令级并行-ILP（Pipeline）" class="headerlink" title="指令级并行 ILP（Pipeline）"></a>指令级并行 ILP（<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%B5%81%E6%B0%B4%E7%BA%BF_(%E8%AE%A1%E7%AE%97%E6%9C%BA)">Pipeline</a>）</h2><blockquote>
<p>单核实现时间并行（指令流水）在并行性概念中引入时间因素，让多个处理过程在时间上相 互错开，轮流重叠地使用同一套硬件设备的各个部分，以加快硬件周转而赢得速度。 时间并行性概念的实现方式就是采用流水处理部件。这是一种非常经济而实用的并行 技术，能保证计算机系统具有较高的性能价格比。目前的高性能微型机几乎无一例外地使 用了流水技术。将计算机<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%8C%87%E4%BB%A4">指令</a>处理过程拆分为多个步骤，并通过多个硬件处理单元并行执行来加快指令执行速度，跟CPU核心数无关。</p>
</blockquote>
<p><strong>指令级并行（Instruction-Level Parallelism, ILP）</strong> 是指在<strong>单个处理器</strong>内部通过<strong>同时执行多条指令</strong>来提高程序运行速度的一种技术。它利用程序中指令之间的数据和控制独立性，使多条指令可以并行执行，从而提高性能。<strong>ILP 实质上是==时间级并行==的典型代表</strong>：</p>
<ul>
<li>利用流水线、超标量和乱序执行等技术，在一个核心内并行处理多条指令，但这些指令共享相同的计算资源，只是在不同阶段的时间上交错执行。</li>
<li>它依赖于执行单元复用，而不是多个物理核心并行处理任务。</li>
</ul>
<ol>
<li><p><strong>ILP 的核心思想</strong></p>
<ul>
<li><p><strong>并行性基础</strong>：程序中的指令并非严格依赖顺序执行，而是存在某些可以同时执行的指令。</p>
</li>
<li><p><strong>流水线技术</strong>：将指令分解为多个阶段（如取指、译码、执行、访存和写回），使得不同阶段的操作可以同时处理不同指令。</p>
</li>
<li><p><strong>硬件支持</strong>：依赖于高级处理器架构和控制逻辑来检测和管理指令依赖关系。</p>
</li>
</ul>
</li>
</ol>
<ol start="2">
<li><p><strong>ILP 的关键技术</strong></p>
<ul>
<li><p><strong>指令流水线 (Instruction Pipeline)</strong></p>
<ol>
<li>将指令分为多个阶段，每个阶段处理一部分操作，类似于生产线作业。</li>
<li>缺点：流水线可能因为数据依赖或控制依赖导致阻塞或停顿（称为流水线冒险）。</li>
</ol>
</li>
<li><p><strong>超标量处理 (Superscalar Execution)</strong></p>
<ol>
<li>在单个周期内执行多条指令，通过多个执行单元实现真正的并行执行。</li>
<li>例如：Intel Pentium 系列采用超标量设计，每周期可执行多条整数和浮点运算指令。</li>
</ol>
</li>
<li><p><strong>动态调度 (Dynamic Scheduling)</strong></p>
<ol>
<li>采用硬件动态调整指令顺序，绕过依赖性阻塞，提高指令吞吐量。</li>
<li>典型实现：Tomasulo 算法。</li>
</ol>
</li>
<li><p><strong>分支预测 (Branch Prediction)</strong></p>
<ol>
<li>解决控制依赖问题，预测程序分支方向，提前加载和执行指令。</li>
<li>精确的预测减少因分支跳转导致的流水线停顿。</li>
</ol>
</li>
<li><p><strong>乱序执行 (Out-of-Order Execution)</strong></p>
<ol>
<li>指令不按照程序编写顺序执行，而是根据依赖分析和资源调度动态调整执行顺序。</li>
<li>硬件负责结果重排序，确保程序语义正确性。</li>
</ol>
</li>
<li><p><strong>寄存器重命名 (Register Renaming)</strong></p>
<ol>
<li>通过给物理寄存器重新分配逻辑名称，避免写后读 (WAR) 和写后写 (WAW) 依赖冲突。</li>
</ol>
</li>
</ul>
</li>
<li><p><strong>ILP 的依赖分析</strong></p>
<ul>
<li><p><strong>数据依赖</strong>：</p>
<ol>
<li>**真实依赖 (RAW, Read After Write)**：指令需要前一指令的结果。</li>
<li>**反依赖 (WAR, Write After Read)**：后续指令会覆盖前面指令所需数据。</li>
<li>**输出依赖 (WAW, Write After Write)**：两个指令尝试写入同一位置。</li>
</ol>
</li>
<li><p><strong>控制依赖</strong>：</p>
<ol>
<li>指令执行取决于程序分支跳转结果，导致流水线停顿。</li>
</ol>
</li>
</ul>
</li>
<li><p><strong>ILP 的局限性</strong></p>
<ul>
<li><strong>数据依赖的限制</strong>：高度依赖指令本身的数据流特性，若指令相关性强，则并行度受限。</li>
<li><strong>控制流的限制</strong>：分支预测失败会导致流水线清空和指令重启，降低性能。</li>
<li><strong>硬件复杂度</strong>：超标量、乱序执行和动态调度需要大量硬件资源，功耗和成本较高。</li>
<li><strong>内存访问瓶颈</strong>：指令并行执行过程中，内存访问速度可能无法满足需求。</li>
</ul>
</li>
</ol>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241029161108996.png" alt="image-20241029161108996"></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241029164032833.png" alt="image-20241029164032833"></p>
<p><strong>内存级并行</strong>（英语：Memory-level parallelism，缩写为 MLP’），<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%B9%B3%E8%A1%8C%E8%A8%88%E7%AE%97">并行计算</a>技术的一种，是计算机体系结构的一种，能够同时进行数个存储器操作，特别是在<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/CPU%E5%BF%AB%E5%8F%96">缓存</a>未命中（cache miss），或<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%BD%89%E8%AD%AF%E5%BE%8C%E5%82%99%E7%B7%A9%E8%A1%9D%E5%8D%80">转译后备缓冲器</a>未命中（TLB miss）时。</p>
<p>在宏内核处理器架构下，内存级并行可以被视为是一种特殊的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%8C%87%E4%BB%A4%E5%B1%A4%E7%B4%9A%E5%B9%B3%E8%A1%8C">指令层级平行</a>（ILP）。它也经常在<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%B6%85%E7%B4%94%E9%87%8F">超标量</a>架构下出现。</p>
<h2 id="数据级并行-DLP（SIMD）"><a href="#数据级并行-DLP（SIMD）" class="headerlink" title="数据级并行 DLP（SIMD）"></a>数据级并行 DLP（SIMD）</h2><p>Flynn将计算机分为四类：</p>
<ul>
<li>SISD：单条指令操作一条数据，例如之前介绍的简单流水线</li>
<li>MISD：多条指令操作一条数据，很少</li>
<li>MIMD：多条指令操作多条数据，例如VLIW</li>
<li>SIMD：单条指令操作多条数据， 例如Vector Processor，GPU</li>
</ul>
<p>数据级并行就是指的SIMD，SIMD可以分为array processor和vector processor，array processor由多种ALU组成，成本更高，同一个时间可以有多个数据执行相同操作，vector processor每种硬件单元只有一个，同一个时间不同数据无法执行相同操作。</p>
<p>大型机多用于进行科学计算，为了更快的处理数据，它们使用了更多的寄存器，这样可以同时可以处理更多的操作数。<strong>单一指令运行多个<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=40117005&content_type=Answer&match_order=2&q=%E6%93%8D%E4%BD%9C%E6%95%B0&zhida_source=entity">操作数</a>并行计算</strong>。这里涉及到操作数的概念，如果你有汇编的基础应该会很好理解。我们考虑下面这个计算式子：(a+b)*(c+d)，该计算过程被分解为三步：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. e = a + b </span><br><span class="line">2. f = c + d</span><br><span class="line">3. m = e * f</span><br></pre></td></tr></table></figure>

<p>早期的计算机一次只能处理一条指令，它要先算步骤1（加法操作），再算步骤2（加法操作），最后算3（<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=40117005&content_type=Answer&match_order=1&q=%E4%B9%98%E6%B3%95%E6%93%8D%E4%BD%9C&zhida_source=entity">乘法操作</a>）。需要三步（花费三个指令）得到答案。</p>
<p>但是我们观察到：<br><strong>3的结果依赖于1和2，而1和2都单纯的加法操作，所以开始想办法让1和2同时计算，那么CPU只要两步得到答案，步骤1和2一次算出来的结果，直接进行乘法运算</strong>。</p>
<p>它运用了<code>SIMD</code>(Single -Instruction ,Multple -Data)<code>单指令多数据流</code>技术。一个指令执行了(a,b,c,d) 4个操作数。SIMD指令集可以提供更快的图像，声音，视频数据等运行速度。</p>
<h1 id="发展"><a href="#发展" class="headerlink" title="发展"></a>发展</h1><p><strong>单核编程</strong>：一开始是单核编程，优化算法也是在单核的基础上优化，为了更好的兼容性，发掘单核潜力</p>
<p><strong>多核编程</strong>：</p>
<p>摩尔定律，晶体管增长遥遥领先于指令执行。</p>
<p>能量消耗的问题，速度快了，能量消耗指数级上升，发热严重，影响计算速度，所以要进行散热，受制于经济原因，单核提升不上去</p>
<p>线路延迟问题，指令周期呈现缩短趋势，布线范围也呈缩短趋势，算得快但是来不及拿数，数据传递不过来，DRAM访问延迟，CPU 增长快于内存，一样的道理，拿不上数</p>
<p>收益递减diminishing returns：cpu性能提升难度陡增80s 流水线 90s 收益低于预期 00s 并行传输 </p>
<p>一个任务一个核，任务不够核消费，单个任务会有各种中断，不能有效利用核</p>
<h1 id="并行理论基础"><a href="#并行理论基础" class="headerlink" title="并行理论基础"></a>并行理论基础</h1><p>串行需要依赖，并行步骤之间不能有依赖，并行也分步骤，但是每一步的不同计算不能互相影响</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115220709073.png" alt="image-20241115220709073"></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115220731029.png" alt="image-20241115220731029"></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115220749864.png" alt="image-20241115220749864"></p>
<h2 id="Thread-线程-并行最小单位"><a href="#Thread-线程-并行最小单位" class="headerlink" title="Thread 线程 并行最小单位"></a>Thread 线程 并行最小单位</h2><p><strong>Parallel Unit</strong></p>
<ul>
<li>拥有自己的上下文</li>
<li>拥有调用堆栈</li>
<li>有PC</li>
<li>但是内存和同一个进程的其他线程共享（SHARED），发生竞态条件（RACE CONDITION）</li>
</ul>
<p>众所周知，CPU、内存、I/O 设备的速度是有极大差异的，为了合理利用 CPU 的高性能，平衡这三者的速度差异，计算机体系结构、操作系统、编译程序都做出了贡献，主要体现为:</p>
<ul>
<li>CPU 增加了缓存，以均衡与内存的速度差异；// 导致 <code>可见性</code>问题</li>
<li>操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I/O 设备的速度差异；// 导致 <code>原子性</code>问题</li>
<li>编译程序优化指令执行次序，使得缓存能够得到更加合理地利用。// 导致 <code>有序性</code>问题</li>
</ul>
<h3 id="Process-进程"><a href="#Process-进程" class="headerlink" title="Process 进程"></a>Process 进程</h3><p>进程就是程序的实例（就像面向对象编程中的类，类是静态的，只有实例化后才运行，且同一个类可以有多个实例）比如，你可以一边播放视频，一边编辑文档，每个程序都有自己的进程，互不干扰。即使它们都是同一份代码，但各自播放的内容和进度都可以不同。</p>
<p>进程（可以看成只有一个线程的进程）同时只能做一件事，如果将一个进程分成多个线程，这样就不会浪费时间空等了</p>
<p>进程间是完全独立的，互不干扰。而线程则共享同一个进程的资源，所以线程间交换数据更方便，几乎没有通讯损耗。</p>
<p>但进程间交换数据就麻烦多了，得通过一些通讯机制，比如管道、消息队列之类的（Inter-process Communication）</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241119184759519.png" alt="image-20241119184759519"></p>
<p>需要注意的是，线程各自拥有各自的栈</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241119185155274.png" alt="image-20241119185155274"></p>
<h3 id="Coroutine-协程"><a href="#Coroutine-协程" class="headerlink" title="Coroutine 协程"></a>Coroutine 协程</h3><p>线程在执行加载视频片段时，必须等待结果返回才能再次执行解码操作，如果引入多线程：加载本身是IO行为，CPU在等待结果返回期间几乎是在空等，浪费了CPU资源。当然，你可以让它休眠以释放 CPU 时间，但创建线程本身就有开销，线程切换同样有开销。</p>
<p>相比之下，协程（Coroutine）非常轻量，创建和切换的开销极小——它并非操作系统层面的东西，就不涉及内核调度。一般是由编程语言来实现（比如 Python 的 asyncio 标准库），它属于用户态的东西。</p>
<p>资源共享问题：线程的执行时机由操作系统调度，程序员无法控制，这正是多线程容易出现资源覆盖的主要原因。而协程的执行时机由程序自身控制，不受操作系统调度影响，因此可以完全避免这类问题。同一个线程内的多个协程共享同一个线程的 CPU 时间片资源，它们在 CPU 上的执行是有先后顺序的，不能并行执行。而线程是可以并行执行的</p>
<p>协程（coroutine），其实是一种特殊的子程序（subroutine，比如普通函数）。普通函数一旦执行就会从头到尾运行，然后返回结果，中间不会暂停。而协程则可以在执行到一半时暂停。利用这一特性，我们可以在遇到 I/O 这类不消耗 CPU 资源的操作时，将其挂起，继续执行其他计算任务，充分利用 CPU 资源。等 I/O 操作结果返回时，再恢复执行。在一个线程内并发执行多个任务</p>
<h2 id="Mutex-互斥锁"><a href="#Mutex-互斥锁" class="headerlink" title="Mutex 互斥锁"></a>Mutex 互斥锁</h2><p>案例：计算数组中3的个数。考虑将数组分成多个部分，每个部分由一个线程负责。</p>
<p><strong>V1 线程不安全</strong></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115221108488-1731681607112-1.png" alt="image-20241115221108488"></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">count3s_thread</span><span class="params">(<span class="type">int</span> id)</span> &#123;</span><br><span class="line">    <span class="type">int</span> length_per_thread = length / t;</span><br><span class="line">    <span class="type">int</span> start = id * length_per_thread;</span><br><span class="line">    <span class="keyword">for</span> (i = start; i &lt; start + length_per_thread; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">array</span>[i] == <span class="number">3</span>) </span><br><span class="line">        	count++;<span class="comment">//count++等价于count = count + 1，先读后写，不是原子操作，存在线程安全问题</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>V2 线程安全</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">mutex m;<span class="comment">//引入互斥锁，解决线程安全问题</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">count3s_thread</span><span class="params">(<span class="type">int</span> id)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> length_per_thread = length / t;</span><br><span class="line">    <span class="type">int</span> start = id * length_per_thread;</span><br><span class="line">    <span class="keyword">for</span> (i = start; i &lt; start + length_per_thread; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (array[i] == <span class="number">3</span>) &#123;</span><br><span class="line">        <span class="built_in">mutex_lock</span>(m);<span class="comment">//加互斥锁，count++只能串行执行</span></span><br><span class="line">        count++;</span><br><span class="line">        <span class="built_in">mutex_unlock</span>(m);<span class="comment">//解锁</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>V3 减少加锁次数 优化性能</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">private_count[MaxThreads];<span class="comment">//每个线程有自己的count变量，线程</span></span><br><span class="line">mutex x;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">count3s_thread</span><span class="params">(<span class="type">int</span> id)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> length_per_thread = length / t;</span><br><span class="line">    <span class="type">int</span> start = id * length_per_thread;</span><br><span class="line">    <span class="keyword">for</span> (i = start; i &lt; start + length_per_thread; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (array[i] == <span class="number">3</span>) </span><br><span class="line">        	private_count[id]++;</span><br><span class="line">	&#125;</span><br><span class="line">    <span class="built_in">mutex_lock</span>(m);</span><br><span class="line">    count += private_count[id];<span class="comment">//数完所有3再加，减少加锁的次数</span></span><br><span class="line">    <span class="built_in">mutex_unlock</span>(m);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>V4 针对硬件结构进行优化 避免伪共享</strong></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115222853277.png" alt="image-20241115222853277"></p>
<blockquote>
<p>在多线程程序中，如果不同线程访问的变量在同一个缓存行中，而其中一个线程修改了它所在缓存行的某个变量，其他线程即使访问不同的变量，也会因为缓存一致性协议（如 MESI 协议）而导致缓存失效，迫使这些线程频繁地从内存（RAM）中重新加载数据。</p>
<p>在大多数现代 CPU 上，一个缓存行通常是 64 字节。如果 <code>private_count</code> 数组的每个元素占用的空间小于 64 字节（例如一个 <code>int</code> 通常为 4 字节），多个 <code>private_count</code> 元素会共享同一个缓存行。这样一来，即使线程各自访问不同的 <code>private_count</code> 元素，它们的读写操作也会相互干扰。</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/31875174">细说Cache-L1/L2/L3/TLB - 知乎 (zhihu.com)</a></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">padded_int</span> &#123;</span><br><span class="line">    <span class="type">int</span> value;</span><br><span class="line">    <span class="type">char</span> padding[<span class="number">60</span>];</span><br><span class="line">&#125;private_count[MaxThreads];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">count3s_thread</span><span class="params">(<span class="type">int</span> id)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> length_per_thread = length / t;</span><br><span class="line">    <span class="type">int</span> start = id * length_per_thread;</span><br><span class="line">    <span class="keyword">for</span> (i = start; i &lt; start + length_per_thread; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (array[i] == <span class="number">3</span>) &#123;</span><br><span class="line">        	private_count[id]++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">mutex_lock</span>(m);</span><br><span class="line">    count += private_count[id].value;</span><br><span class="line">    <span class="built_in">mutex_unlock</span>(m);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<blockquote>
<ol>
<li>MESI 协议简介</li>
</ol>
<p>​    在 MESI 协议中，每个缓存行可以有以下四种状态：</p>
<ul>
<li><strong>Modified（M）</strong>：缓存行被当前处理器独占，并且内容已被修改，与主存不同步。</li>
<li><strong>Exclusive（E）</strong>：缓存行被当前处理器独占，且内容与主存同步。</li>
<li><strong>Shared（S）</strong>：缓存行在多个处理器的缓存中都有副本，且与主存同步。</li>
<li><strong>Invalid（I）</strong>：缓存行无效，即该缓存行内容与主存不同步，不能使用。</li>
</ul>
<ol start="2">
<li>判断缓存失效的机制</li>
</ol>
<p>缓存失效通常是通过<strong>监听总线上的操作</strong>来判断的。每个核心的缓存控制器都会监视其他核心发出的读写请求，这样它可以判断自己是否需要使某个缓存行失效。具体流程如下：</p>
<ol>
<li><p><strong>读操作</strong>：当一个处理器读取一个缓存行时，如果其他处理器的缓存中有该缓存行的修改版（Modified 状态），它会通知主存和其他缓存进行更新，使这个缓存行失效或进入共享状态。</p>
</li>
<li><p><strong>写操作（写失效）</strong>：当一个处理器要写入一个缓存行时，如果其他缓存有该缓存行的副本（处于 Shared 或 Exclusive 状态），它们会收到写入请求并将该缓存行标记为无效（Invalid）。这称为<strong>写失效</strong>。</p>
</li>
<li><p><strong>广播和探测</strong>：在缓存一致性协议中，当处理器对缓存行进行操作（如写操作）时，处理器会向其他核心或处理器发出<strong>广播</strong>或<strong>探测</strong>信号，要求其他缓存检查是否有该缓存行的副本。如果存在副本，这些副本会被标记为无效。</p>
</li>
<li><p>缓存失效的例子（基于 MESI 协议）</p>
</li>
</ol>
<p>假设处理器 P0 和 P1 都在各自的缓存中存有某个变量 <code>x</code>，且 <code>x</code> 的初始值为 0。以下是一个缓存失效的示例过程：</p>
<ul>
<li><strong>步骤 1</strong>：P0 读取 <code>x</code>，此时 <code>x</code> 在 P0 的缓存中处于 Shared 状态。</li>
<li><strong>步骤 2</strong>：P1 也读取 <code>x</code>，此时 <code>x</code> 在 P0 和 P1 的缓存中都是 Shared 状态。</li>
<li><strong>步骤 3</strong>：P0 对 <code>x</code> 进行写操作，将 <code>x</code> 修改为 1。<ul>
<li>P0 的缓存控制器会通知 P1 的缓存，将 <code>x</code> 在 P1 的缓存中标记为 Invalid。</li>
<li>P0 中的 <code>x</code> 变为 Modified 状态，与主存不同步。</li>
</ul>
</li>
<li><strong>步骤 4</strong>：当 P1 再次尝试读取 <code>x</code> 时，发现该缓存行是无效的（Invalid 状态），因此会触发一次从主存或 P0 缓存中的更新操作来同步数据。</li>
</ul>
<ol start="4">
<li>硬件实现的细节</li>
</ol>
<ul>
<li><strong>总线监听（Bus Snooping）</strong>：每个缓存控制器通过监听总线上其他处理器的内存访问请求来判断是否需要使缓存行失效。如果其他处理器发出了对自己缓存行的写请求，那么本地的缓存行会被标记为无效。</li>
<li><strong>目录协议（Directory-Based Protocol）</strong>：在一些系统中，每个内存块的状态由一个中央目录来管理。目录保存了该内存块在哪些缓存中有副本，哪个处理器在修改状态。当某个处理器要写数据时，目录会通知所有拥有该缓存行的处理器将其标记为无效。</li>
</ul>
<p>在伪共享中，不同线程访问不同变量，但这些变量在同一个缓存行中。当一个线程修改了它的变量，其他线程的缓存行会被标记为无效，迫使它们重新从内存中加载。这是因为缓存行是最小的一致性单位，即使只修改缓存行中的一个字节，整个缓存行都需要保持一致。</p>
<p>总结</p>
<p>缓存失效的判断是通过<strong>缓存一致性协议</strong>和<strong>硬件监听机制</strong>实现的。当一个缓存行被修改时，其他缓存中的相同缓存行会被标记为无效，从而保证所有处理器访问同一内存地址时的一致性。</p>
</blockquote>
<h1 id="C-并行编程"><a href="#C-并行编程" class="headerlink" title="C++ 并行编程"></a>C++ 并行编程</h1><p>HelloWorld：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thread&gt;</span><span class="comment">//引入并发包</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">func</span><span class="params">()</span>&#123;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;**Inside thread &quot;</span> &lt;&lt; <span class="built_in">std</span>::this_thread::get_id() &lt;&lt; <span class="string">&quot;!&quot;</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">  <span class="built_in">std</span>::thread  <span class="title function_">t</span><span class="params">( func )</span>;<span class="comment">//fork 创建子线程（主线程的分支）</span></span><br><span class="line">  t.join();<span class="comment">//把子线程合并到主线程中</span></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="结构化并行编程-fork-join"><a href="#结构化并行编程-fork-join" class="headerlink" title="结构化并行编程 fork-join"></a>结构化并行编程 fork-join</h2><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115220240060.png" alt="image-20241115220240060"></p>
<p>不能一创建子线程就join()，join的意思是让主线程等子线程执行完再继续，所以循环体内join就会阻塞其他子线程的创建，变成事实上的串行程序。因此应该全部创建完子线程后以后再统一join()，</p>
<h2 id="常见错误"><a href="#常见错误" class="headerlink" title="常见错误"></a>常见错误</h2><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115225902890.png" alt="image-20241115225902890"></p>
<p>不能让线程直接赋值，而是要用std::move(t)将t的上下文等信息转移到t2，然后t就变成了一个空壳，</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115230015703.png" alt="image-20241115230015703"></p>
<h2 id="Lambda表达式"><a href="#Lambda表达式" class="headerlink" title="Lambda表达式"></a>Lambda表达式</h2><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115230229087.png" alt="image-20241115230229087"></p>
<ul>
<li><code>[]</code>代表不传任何值</li>
<li><code>[&amp;]</code>代表把在进程内部但在函数外部的变量以引用的形式传递进去</li>
<li><code>[=]</code>代表把上述变量以值传递的形式传过去（传递副本）</li>
</ul>
<p>()表示参数，{}表示函数体</p>
<h2 id="案例：矩阵乘法"><a href="#案例：矩阵乘法" class="headerlink" title="案例：矩阵乘法"></a>案例：矩阵乘法</h2><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115231555912.png" alt="image-20241115231555912"></p>
<p><code>C[i][j]</code> 就是矩阵A的第i行和矩阵B的第j行的每一个数据相乘的和 </p>
<p>$C_{i,j}=\sum_{k=0}^N A_{i,k}B_{k,j}$   </p>
<p>并行版本：把总的任务拆分开。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115230540760.png" alt="image-20241115230540760"></p>
<p>优化：</p>
<blockquote>
<p><strong>数据结构、算法与应用</strong> C++语言描述（原书第2版）：第4章 性能测量 P88 矩阵乘法</p>
</blockquote>
<ul>
<li>一个循环体内部只对<code>C[i][j]</code>做一次赋值操作</li>
<li>优化嵌套的顺序：一共需要进行$N^3$次乘法，<code>A[i][k] B[k][j] C[i][j]</code>的元素都变成按行访问，有效利用了cache空间（因为同行的元素在内存中相邻，而同列的元素不是，如果数组长度过长，导致同列的元素无法同时存储在L2缓存中，使得缓存未命中必须从RAM中取，大大降低了效率）</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/he_nan/article/details/106169483">高速缓存与矩阵乘法(一)_矩阵乘法cache-CSDN博客</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/he_nan/article/details/106175159">高速缓存与矩阵乘法(二)_矩阵乘法的瓶颈-CSDN博客</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/he_nan/article/details/106181334">高速缓存与矩阵乘法(三)_clapack用法-CSDN博客</a> </p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115231028700.png" alt="image-20241115231028700"></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241116130720225.png" alt="image-20241116130720225"></p>
<h2 id="其他并发库"><a href="#其他并发库" class="headerlink" title="其他并发库"></a>其他并发库</h2><p><strong>Future Async 更舒适的开启线程方式</strong></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241116002448557.png" alt="image-20241116002448557"></p>
<p>async能实现异步开启一个线程的功能，并返回future，future最重要的是能够直接拿到返回值</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241116002705661.png" alt="image-20241116002705661"></p>
<p><strong>Mutex 解决RA</strong> </p>
<p>竞态条件(Race Condition)：</p>
<p>操作同一变量导致了竞态条件的发生，从上到下性能依次降低</p>
<blockquote>
<ul>
<li><em>redesign to eliminate (e.g. reduction)</em> 重新设计程序，尽量减少共享变量的次数</li>
<li><em>use thread-safe entities (e.g. parallel collections)</em> 比如java中的concurrentHashMap，比如原子变量（乐观锁）</li>
<li><em>use synchronization (e.g. locking)</em> 实在没办法只能加锁</li>
</ul>
</blockquote>
<p>因此要定义针对共享代码块的锁，也就是互斥锁Mutex</p>
<p><strong>Mutex</strong>: </p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241116003512855.png" alt="image-20241116003512855"></p>
<p><strong>Lock Guard</strong>: </p>
<p>直接使用mutex的加解锁，如果中间代码出现异常，就会出现死锁，那么显然就不能简单粗暴地直接调用锁。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241116003914988.png" alt="image-20241116003914988"></p>
<p>Java中的锁监视器（Monitor）和 <code>lock_guard</code> 确实有相似之处。它们都是用来管理资源的互斥访问，确保线程安全。<code>lock_guard</code> 是 C++ 中的一种 RAII 风格的锁实现，它在构造时加锁，在析构时自动解锁。锁监视器则是一个对象，包含加锁和解锁操作，通常通过 <code>synchronized</code> 关键字来实现。两者的核心思想都是在临界区自动管理锁的生命周期，避免死锁。</p>
<p><strong>Atomic</strong>: </p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241116004457236.png" alt="image-20241116004457236"></p>
<p>原子变量 只支持自增</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241116004534563.png" alt="image-20241116004534563"></p>
<p>将共享的变量去除，直接拿到异步future的返回值相加，完全避免了RA</p>
<h1 id="并行算法"><a href="#并行算法" class="headerlink" title="并行算法"></a>并行算法</h1><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241118150058492.png" alt="image-20241118150058492"></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thread&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;random&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="comment">//排序函数</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">parallelSort</span><span class="params">(vector&lt;<span class="type">int</span>&gt;&amp; arr)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> n = arr.<span class="built_in">size</span>();</span><br><span class="line">    <span class="type">int</span> rounds = <span class="built_in">log2</span>(n); <span class="comment">// 需要的轮数</span></span><br><span class="line">    <span class="keyword">auto</span> compareAndSwap = [&amp;](<span class="type">int</span> start,<span class="type">int</span> step) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = start; i &lt; n; i += <span class="number">2</span> * step) &#123;</span><br><span class="line">            <span class="keyword">if</span> (arr[i] &lt; arr[i + step]) &#123;</span><br><span class="line">                <span class="built_in">swap</span>(arr[i], arr[i + step]);</span><br><span class="line">            &#125;<span class="comment">//为什么不传start step的引用:因为线程创建以后，什么时候开始是不确定的，而start和step两个变量的值是随时间变化的，因此各个线程拿到的值是不确定的。</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> r = <span class="number">0</span>; r &lt; rounds; ++r) &#123;</span><br><span class="line">        <span class="type">int</span> step = <span class="number">1</span> &lt;&lt; r; <span class="comment">// 当前轮的步长</span></span><br><span class="line">        <span class="type">int</span> threadsCount = n / (<span class="number">2</span> * step); <span class="comment">// 每组分配一个线程</span></span><br><span class="line">        vector&lt;thread&gt; threads;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> t = <span class="number">0</span>; t &lt; threadsCount; ++t) &#123;</span><br><span class="line">            threads.<span class="built_in">emplace_back</span>(compareAndSwap, t * <span class="number">2</span> * step, step);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 等待所有线程完成</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; t : threads) &#123;</span><br><span class="line">            t.<span class="built_in">join</span>();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Bitonic-Sort"><a href="#Bitonic-Sort" class="headerlink" title="Bitonic Sort"></a>Bitonic Sort</h2><p>双调排序（Bitonic Sort）是一种并行排序算法，特别适用于多处理器系统。它通过递归方式构造双调序列（bitonic sequence），然后使用双调合并（bitonic merge）将其排序。以下是用C++和多线程实现双调排序的代码：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">bitonicSortKernel</span><span class="params">(<span class="type">int</span>* d_arr, <span class="type">int</span> n, <span class="type">int</span> stage, <span class="type">int</span> step)</span> </span>&#123;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> idx = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> pairIdx = idx ^ step;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 每个线程处理一个元素对</span></span><br><span class="line">    <span class="keyword">if</span> (pairIdx &gt; idx &amp;&amp; pairIdx &lt; n) &#123;</span><br><span class="line">        <span class="type">bool</span> ascending = ((idx &amp; stage) == <span class="number">0</span>); <span class="comment">// 根据 stage 决定升序或降序</span></span><br><span class="line">        <span class="keyword">if</span> ((d_arr[idx] &gt; d_arr[pairIdx]) == ascending) &#123;</span><br><span class="line">            <span class="comment">// 交换两个元素</span></span><br><span class="line">            <span class="type">int</span> temp = d_arr[idx];</span><br><span class="line">            d_arr[idx] = d_arr[pairIdx];</span><br><span class="line">            d_arr[pairIdx] = temp;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">bitonicSortCUDA</span><span class="params">(std::vector&lt;<span class="type">int</span>&gt;&amp; arr)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> n = arr.<span class="built_in">size</span>();</span><br><span class="line">    <span class="keyword">if</span> ((n &amp; (n - <span class="number">1</span>)) != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> std::<span class="built_in">runtime_error</span>(<span class="string">&quot;Array size must be a power of 2.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 分配设备内存</span></span><br><span class="line">    <span class="type">int</span>* d_arr;</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span>**)&amp;d_arr, n * <span class="built_in">sizeof</span>(<span class="type">int</span>));</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(d_arr, arr.<span class="built_in">data</span>(), n * <span class="built_in">sizeof</span>(<span class="type">int</span>), cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 设置线程块和网格维度</span></span><br><span class="line">    <span class="type">int</span> threadsPerBlock = <span class="number">256</span>;</span><br><span class="line">    <span class="type">int</span> blocksPerGrid = (n + threadsPerBlock - <span class="number">1</span>) / threadsPerBlock;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 执行排序算法</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> stage = <span class="number">2</span>; stage &lt;= n; stage *= <span class="number">2</span>) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> step = stage / <span class="number">2</span>; step &gt; <span class="number">0</span>; step /= <span class="number">2</span>) &#123;</span><br><span class="line">            bitonicSortKernel&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(d_arr, n, stage, step);</span><br><span class="line">            <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 拷贝结果回主机</span></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(arr.<span class="built_in">data</span>(), d_arr, n * <span class="built_in">sizeof</span>(<span class="type">int</span>), cudaMemcpyDeviceToHost);</span><br><span class="line">    <span class="built_in">cudaFree</span>(d_arr);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 初始化数据</span></span><br><span class="line">    std::vector&lt;<span class="type">int</span>&gt; arr = &#123;<span class="number">19</span>, <span class="number">7</span>, <span class="number">5</span>, <span class="number">3</span>, <span class="number">17</span>, <span class="number">13</span>, <span class="number">11</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">9</span>, <span class="number">4</span>, <span class="number">8</span>, <span class="number">6</span>, <span class="number">12</span>, <span class="number">10</span>, <span class="number">14</span>&#125;;</span><br><span class="line"></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Original array: &quot;</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> num : arr) &#123;</span><br><span class="line">        std::cout &lt;&lt; num &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    std::cout &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="built_in">bitonicSortCUDA</span>(arr);</span><br><span class="line">    &#125; <span class="built_in">catch</span> (<span class="type">const</span> std::exception&amp; e) &#123;</span><br><span class="line">        std::cerr &lt;&lt; e.<span class="built_in">what</span>() &lt;&lt; std::endl;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Sorted array: &quot;</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> num : arr) &#123;</span><br><span class="line">        std::cout &lt;&lt; num &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    std::cout &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol>
<li><strong><code>bitonicMerge</code></strong>:<ul>
<li>负责将双调序列合并为一个有序序列。</li>
<li>使用 <code>low</code> 和 <code>count</code> 参数确定操作范围，并通过 <code>ascending</code> 决定升序或降序。</li>
</ul>
</li>
<li><strong><code>bitonicSort</code></strong>:<ul>
<li>构造双调序列并调用 <code>bitonicMerge</code> 完成排序。</li>
</ul>
</li>
<li><strong><code>parallelBitonicSort</code></strong>:<ul>
<li>通过多线程加速排序过程。</li>
<li>根据线程数分配工作，递归调用 <code>parallelBitonicSort</code>。</li>
</ul>
</li>
<li><strong><code>main</code></strong>:<ul>
<li>验证数组大小为 2 的幂。</li>
<li>使用多线程完成排序，并输出结果。</li>
</ul>
</li>
</ol>
<ul>
<li>输入数组大小必须是 2 的幂。如果不是，可以填充为下一个最近的 2 的幂。</li>
<li>适当调整线程数量，以避免因过多线程导致上下文切换开销。</li>
<li><code>std::thread::hardware_concurrency()</code> 获取系统支持的最大线程数。</li>
</ul>
<p>运行结果会显示原始数组和排序后的数组，从而验证算法正确性和并行效果。</p>
<h2 id="Odd-Even-Sort"><a href="#Odd-Even-Sort" class="headerlink" title="Odd-Even Sort"></a>Odd-Even Sort</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;cuda_runtime.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;device_launch_parameters.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="comment">// 每个块的线程数量</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> BLOCK_SIZE 1024</span></span><br><span class="line"><span class="comment">// 设备内核函数：执行奇偶交换</span></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">odd_even_sort_step</span><span class="params">(<span class="type">int</span>* data, <span class="type">int</span> size, <span class="type">int</span> phase)</span> &#123;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> i = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> index = <span class="number">2</span> * i + (phase % <span class="number">2</span>); <span class="comment">// 控制奇偶阶段</span></span><br><span class="line">    <span class="comment">// 确保不越界</span></span><br><span class="line">    <span class="keyword">if</span> (index &lt; size - <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (data[index] &gt; data[index + <span class="number">1</span>]) &#123;</span><br><span class="line">            <span class="comment">// 交换数据</span></span><br><span class="line">            <span class="type">int</span> temp = data[index];</span><br><span class="line">            data[index] = data[index + <span class="number">1</span>];</span><br><span class="line">            data[index + <span class="number">1</span>] = temp;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 启动CUDA奇偶排序</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">odd_even_sort</span><span class="params">(<span class="type">int</span>* data, <span class="type">int</span> size)</span> &#123;</span><br><span class="line">    <span class="type">int</span>* d_data;</span><br><span class="line">    <span class="comment">// 在设备上分配内存</span></span><br><span class="line">    cudaMalloc((<span class="type">void</span>**)&amp;d_data, size * <span class="keyword">sizeof</span>(<span class="type">int</span>));</span><br><span class="line">    cudaMemcpy(d_data, data, size * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyHostToDevice);</span><br><span class="line">    <span class="comment">// 计算块和线程的配置</span></span><br><span class="line">    <span class="type">int</span> threads_per_block = BLOCK_SIZE / <span class="number">2</span>;  <span class="comment">// 每个块的线程数量</span></span><br><span class="line">    <span class="type">int</span> num_blocks = (size / <span class="number">2</span> + threads_per_block - <span class="number">1</span>) / threads_per_block;</span><br><span class="line">    <span class="comment">// 每一轮奇偶排序</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> phase = <span class="number">0</span>; phase &lt; size; phase++) &#123;</span><br><span class="line">        odd_even_sort_step &lt;&lt; &lt;num_blocks, threads_per_block &gt;&gt; &gt; (d_data, size, phase);</span><br><span class="line">        cudaDeviceSynchronize(); <span class="comment">// 确保所有线程完成</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 将数据从设备复制回主机</span></span><br><span class="line">    cudaMemcpy(data, d_data, size * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyDeviceToHost);</span><br><span class="line">    cudaFree(d_data); <span class="comment">// 释放设备内存</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// CUDA内核：奇数阶段排序</span></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">oddEvenSortKernel</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> n, <span class="type">int</span> phase)</span> &#123;</span><br><span class="line">    <span class="type">int</span> index = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (phase % <span class="number">2</span> == <span class="number">0</span>) &#123; <span class="comment">// 偶数阶段：比较偶数索引和下一个奇数索引</span></span><br><span class="line">        <span class="keyword">if</span> (index % <span class="number">2</span> == <span class="number">0</span> &amp;&amp; index &lt; n - <span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (arr[index] &gt; arr[index + <span class="number">1</span>]) &#123;</span><br><span class="line">                <span class="comment">// 交换</span></span><br><span class="line">                <span class="type">int</span> temp = arr[index];</span><br><span class="line">                arr[index] = arr[index + <span class="number">1</span>];</span><br><span class="line">                arr[index + <span class="number">1</span>] = temp;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123; <span class="comment">// 奇数阶段：比较奇数索引和下一个偶数索引</span></span><br><span class="line">        <span class="keyword">if</span> (index % <span class="number">2</span> == <span class="number">1</span> &amp;&amp; index &lt; n - <span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (arr[index] &gt; arr[index + <span class="number">1</span>]) &#123;</span><br><span class="line">                <span class="comment">// 交换</span></span><br><span class="line">                <span class="type">int</span> temp = arr[index];</span><br><span class="line">                arr[index] = arr[index + <span class="number">1</span>];</span><br><span class="line">                arr[index + <span class="number">1</span>] = temp;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> numElements = <span class="number">1024</span>;</span><br><span class="line">    <span class="type">int</span> h_input[numElements];</span><br><span class="line">    <span class="type">int</span> *d_input;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 初始化输入数据</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; numElements; i++) &#123;</span><br><span class="line">        h_input[i] = rand() % <span class="number">1000</span>;  <span class="comment">// 生成随机数</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cudaMalloc((<span class="type">void</span>**)&amp;d_input, numElements * <span class="keyword">sizeof</span>(<span class="type">int</span>));</span><br><span class="line">    cudaMemcpy(d_input, h_input, numElements * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 假设每个线程块有512个线程</span></span><br><span class="line">    <span class="type">int</span> blockSize = <span class="number">512</span>;</span><br><span class="line">    <span class="type">int</span> numBlocks = (numElements + blockSize - <span class="number">1</span>) / blockSize;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 进行多个阶段的排序</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> phase = <span class="number">0</span>; phase &lt; numElements; phase++) &#123;</span><br><span class="line">        oddEvenSortKernel&lt;&lt;&lt;numBlocks, blockSize&gt;&gt;&gt;(d_input, numElements, phase);</span><br><span class="line">        cudaDeviceSynchronize();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将排序结果从设备复制回主机</span></span><br><span class="line">    cudaMemcpy(h_input, d_input, numElements * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 打印排序结果</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; numElements; i++) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, h_input[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line"></span><br><span class="line">    cudaFree(d_input);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Prefix-Sum"><a href="#Prefix-Sum" class="headerlink" title="Prefix Sum"></a>Prefix Sum</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thread&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;functional&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;mutex&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">parallel_prefix_sum</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> k = <span class="number">3</span>;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> n = <span class="number">1</span> &lt;&lt; k; <span class="comment">// 数组大小为 2^k</span></span><br><span class="line">    std::vector&lt;<span class="type">int</span>&gt; elements = &#123;<span class="number">7</span>, <span class="number">3</span>, <span class="number">15</span>, <span class="number">10</span>, <span class="number">13</span>, <span class="number">18</span>, <span class="number">6</span>, <span class="number">4</span>&#125;;</span><br><span class="line">    <span class="function">std::vector&lt;<span class="type">int</span>&gt; <span class="title">tree_top</span><span class="params">(<span class="number">2</span> * n, <span class="number">0</span>)</span>, <span class="title">tree_left</span><span class="params">(n, <span class="number">0</span>)</span></span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 初始化 tree_top，前 n 个元素为原数组</span></span><br><span class="line">    std::<span class="built_in">copy</span>(elements.<span class="built_in">begin</span>(), elements.<span class="built_in">end</span>(), tree_top.<span class="built_in">begin</span>() + n);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">auto</span> reduce_layer = [&amp;](<span class="type">int</span> i) &#123;</span><br><span class="line">        <span class="type">int</span> layer_size = <span class="number">1</span> &lt;&lt; (k - i - <span class="number">1</span>); <span class="comment">// 当前层的节点数</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; layer_size; ++j) &#123;</span><br><span class="line">            <span class="type">int</span> idx = (<span class="number">1</span> &lt;&lt; (k - i - <span class="number">1</span>)) + j; <span class="comment">// 当前节点索引</span></span><br><span class="line">            tree_top[idx] = tree_top[<span class="number">2</span> * idx] + tree_top[<span class="number">2</span> * idx + <span class="number">1</span>]; <span class="comment">// 左右子节点求和</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="keyword">auto</span> expand_layer = [&amp;](<span class="type">int</span> i) &#123;</span><br><span class="line">        <span class="type">int</span> layer_size = <span class="number">1</span> &lt;&lt; i; <span class="comment">// 当前层的节点数</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; layer_size; ++j) &#123;</span><br><span class="line">            <span class="type">int</span> idx = (<span class="number">1</span> &lt;&lt; i) + j; <span class="comment">// 当前节点索引</span></span><br><span class="line">            <span class="keyword">if</span> (idx % <span class="number">2</span> == <span class="number">0</span>) &#123;</span><br><span class="line">                tree_left[idx] = tree_left[idx / <span class="number">2</span>]; <span class="comment">// 左孩子继承父节点的前缀和</span></span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                tree_left[idx] = tree_left[idx / <span class="number">2</span>] + tree_top[idx - <span class="number">1</span>]; <span class="comment">// 右孩子加上左兄弟节点的值</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="comment">// ====== 归约阶段（从叶子向根方向）======</span></span><br><span class="line">    <span class="comment">// 多线程执行归约</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; k; ++i) &#123;</span><br><span class="line">        <span class="type">int</span> thread_count = <span class="number">1</span> &lt;&lt; (k - i - <span class="number">1</span>); <span class="comment">// 当前层线程数</span></span><br><span class="line">        std::vector&lt;std::thread&gt; threads;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; thread_count; ++j) &#123;</span><br><span class="line">            threads.<span class="built_in">emplace_back</span>(reduce_layer, i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> &amp;t : threads) t.<span class="built_in">join</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ====== 扩展阶段（从根向叶方向）======</span></span><br><span class="line">    tree_left[<span class="number">0</span>] = <span class="number">0</span>; <span class="comment">// 根的左前缀和为 0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 多线程执行扩展</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; k; ++i) &#123;</span><br><span class="line">        <span class="type">int</span> thread_count = <span class="number">1</span> &lt;&lt; i; <span class="comment">// 当前层线程数</span></span><br><span class="line">        std::vector&lt;std::thread&gt; threads;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; thread_count; ++j) &#123;</span><br><span class="line">            threads.<span class="built_in">emplace_back</span>(expand_layer, i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> &amp;t : threads) t.<span class="built_in">join</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>归约阶段</strong>：</p>
<ul>
<li>利用线程池对每一层的节点进行并行处理。</li>
<li><code>reduce_layer</code> 是一个 lambda 函数，用于计算每一层的节点累积值。</li>
</ul>
<p><strong>扩展阶段</strong>：</p>
<ul>
<li>同样使用线程池完成每一层的前缀和传播。</li>
<li><code>expand_layer</code> 是一个 lambda 函数，计算每个节点的前缀和。</li>
</ul>
<p><strong>线程池管理</strong>：</p>
<ul>
<li>每层节点的数量决定了需要启动的线程数。</li>
<li><code>std::thread</code> 管理每个线程，<code>join</code> 确保主线程等待所有子线程完成。</li>
</ul>
<hr>
<h2 id="Max-Subsequence-Sum"><a href="#Max-Subsequence-Sum" class="headerlink" title="Max Subsequence Sum"></a>Max Subsequence Sum</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// CUDA内核：计算最大子段和</span></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">maxSubarraySumKernel</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> *result, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="keyword">extern</span> __shared__ <span class="type">int</span> sharedData[];</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="type">int</span> start = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (start &lt; n) &#123;</span><br><span class="line">        sharedData[tid] = arr[start];</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        sharedData[tid] = <span class="number">0</span>;  <span class="comment">// 边界处理</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 进行归并操作，合并子数组求和</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> stride = <span class="number">1</span>; stride &lt;= blockDim.x / <span class="number">2</span>; stride *= <span class="number">2</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (tid % (<span class="number">2</span> * stride) == <span class="number">0</span> &amp;&amp; tid + stride &lt; blockDim.x) &#123;</span><br><span class="line">            sharedData[tid] += sharedData[tid + stride];</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 线程0将每个块的结果存储到result数组中</span></span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>) &#123;</span><br><span class="line">        result[blockIdx.x] = sharedData[<span class="number">0</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> numElements = <span class="number">1024</span>;</span><br><span class="line">    <span class="type">int</span> h_input[numElements];</span><br><span class="line">    <span class="type">int</span> *d_input, *d_result;</span><br><span class="line">    <span class="type">int</span> h_result[<span class="number">32</span>];  <span class="comment">// 假设最多32个块</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 初始化输入数据</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; numElements; i++) &#123;</span><br><span class="line">        h_input[i] = rand() % <span class="number">100</span> - <span class="number">50</span>;  <span class="comment">// 生成[-50, 50]之间的随机数</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cudaMalloc((<span class="type">void</span>**)&amp;d_input, numElements * <span class="keyword">sizeof</span>(<span class="type">int</span>));</span><br><span class="line">    cudaMalloc((<span class="type">void</span>**)&amp;d_result, <span class="number">32</span> * <span class="keyword">sizeof</span>(<span class="type">int</span>));  <span class="comment">// 假设最多32个块</span></span><br><span class="line"></span><br><span class="line">    cudaMemcpy(d_input, h_input, numElements * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 启动kernel：假设我们使用32个线程块，每个线程块处理32个元素</span></span><br><span class="line">    maxSubarraySumKernel&lt;&lt;&lt;<span class="number">32</span>, <span class="number">32</span>, <span class="number">32</span> * <span class="keyword">sizeof</span>(<span class="type">int</span>)&gt;&gt;&gt;(d_input, d_result, numElements);</span><br><span class="line"></span><br><span class="line">    cudaMemcpy(h_result, d_result, <span class="number">32</span> * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 在主机上进一步合并各个线程块的结果</span></span><br><span class="line">    <span class="type">int</span> maxSum = h_result[<span class="number">0</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; <span class="number">32</span>; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (h_result[i] &gt; maxSum) &#123;</span><br><span class="line">            maxSum = h_result[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;最大子段和: %d\n&quot;</span>, maxSum);</span><br><span class="line"></span><br><span class="line">    cudaFree(d_input);</span><br><span class="line">    cudaFree(d_result);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Merge-Sort"><a href="#Merge-Sort" class="headerlink" title="Merge Sort"></a>Merge Sort</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// CUDA内核：归并操作</span></span><br><span class="line">__device__ <span class="type">void</span> <span class="title function_">merge</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> left, <span class="type">int</span> mid, <span class="type">int</span> right)</span> &#123;</span><br><span class="line">    <span class="type">int</span> n1 = mid - left + <span class="number">1</span>;</span><br><span class="line">    <span class="type">int</span> n2 = right - mid;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> *L = new <span class="type">int</span>[n1];</span><br><span class="line">    <span class="type">int</span> *R = new <span class="type">int</span>[n2];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n1; i++) &#123;</span><br><span class="line">        L[i] = arr[left + i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n2; i++) &#123;</span><br><span class="line">        R[i] = arr[mid + <span class="number">1</span> + i];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> i = <span class="number">0</span>, j = <span class="number">0</span>, k = left;</span><br><span class="line">    <span class="keyword">while</span> (i &lt; n1 &amp;&amp; j &lt; n2) &#123;</span><br><span class="line">        <span class="keyword">if</span> (L[i] &lt;= R[j]) &#123;</span><br><span class="line">            arr[k++] = L[i++];</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            arr[k++] = R[j++];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span> (i &lt; n1) &#123;</span><br><span class="line">        arr[k++] = L[i++];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span> (j &lt; n2) &#123;</span><br><span class="line">        arr[k++] = R[j++];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    delete[] L;</span><br><span class="line">    delete[] R;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// CUDA内核：并行归并排序</span></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">mergeSortKernel</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> left, <span class="type">int</span> right)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (left &lt; right) &#123;</span><br><span class="line">        <span class="type">int</span> mid = left + (right - left) / <span class="number">2</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 对左右部分递归排序</span></span><br><span class="line">        <span class="keyword">if</span> (threadIdx.x == <span class="number">0</span>) &#123;</span><br><span class="line">            mergeSortKernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;(arr, left, mid);  <span class="comment">// 排序左半部分</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (threadIdx.x == <span class="number">1</span>) &#123;</span><br><span class="line">            mergeSortKernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;(arr, mid + <span class="number">1</span>, right); <span class="comment">// 排序右半部分</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 合并两个已排序的部分</span></span><br><span class="line">        merge(arr, left, mid, right);  <span class="comment">// 合并两部分</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> numElements = <span class="number">1024</span>;</span><br><span class="line">    <span class="type">int</span> h_input[numElements];</span><br><span class="line">    <span class="type">int</span> *d_input;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 初始化输入数据</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; numElements; i++) &#123;</span><br><span class="line">        h_input[i] = rand() % <span class="number">1000</span>;  <span class="comment">// 生成随机数</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cudaMalloc((<span class="type">void</span>**)&amp;d_input, numElements * <span class="keyword">sizeof</span>(<span class="type">int</span>));</span><br><span class="line">    cudaMemcpy(d_input, h_input, numElements * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 启动归并排序内核：使用多个线程块</span></span><br><span class="line">    mergeSortKernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">2</span>&gt;&gt;&gt;(d_input, <span class="number">0</span>, numElements - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将排序结果从设备复制回主机</span></span><br><span class="line">    cudaMemcpy(h_input, d_input, numElements * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 打印排序结果</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; numElements; i++) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, h_input[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line"></span><br><span class="line">    cudaFree(d_input);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Quick-Sort"><a href="#Quick-Sort" class="headerlink" title="Quick Sort"></a>Quick Sort</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// CUDA内核：执行快速排序的分区操作</span></span><br><span class="line">__device__ <span class="type">int</span> <span class="title function_">partition</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> low, <span class="type">int</span> high)</span> &#123;</span><br><span class="line">    <span class="type">int</span> pivot = arr[high]; <span class="comment">// 选择最右边的元素作为基准</span></span><br><span class="line">    <span class="type">int</span> i = low - <span class="number">1</span>;  <span class="comment">// i是小于基准元素的子数组的最后一个元素的索引</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> j = low; j &lt; high; j++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (arr[j] &lt;= pivot) &#123;</span><br><span class="line">            i++;</span><br><span class="line">            <span class="comment">// 交换arr[i]和arr[j]</span></span><br><span class="line">            <span class="type">int</span> temp = arr[i];</span><br><span class="line">            arr[i] = arr[j];</span><br><span class="line">            arr[j] = temp;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 将基准元素放到正确的位置</span></span><br><span class="line">    <span class="type">int</span> temp = arr[i + <span class="number">1</span>];</span><br><span class="line">    arr[i + <span class="number">1</span>] = arr[high];</span><br><span class="line">    arr[high] = temp;</span><br><span class="line">    <span class="keyword">return</span> i + <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// CUDA内核：快速排序</span></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">quickSortKernel</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> low, <span class="type">int</span> high)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (low &lt; high) &#123;</span><br><span class="line">        <span class="comment">// 分区</span></span><br><span class="line">        <span class="type">int</span> pi = partition(arr, low, high);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 使用多个线程并行处理子数组</span></span><br><span class="line">        <span class="keyword">if</span> (threadIdx.x == <span class="number">0</span>) &#123;</span><br><span class="line">            quickSortKernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;(arr, low, pi - <span class="number">1</span>);  <span class="comment">// 排序左子数组</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (threadIdx.x == <span class="number">1</span>) &#123;</span><br><span class="line">            quickSortKernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;(arr, pi + <span class="number">1</span>, high); <span class="comment">// 排序右子数组</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> numElements = <span class="number">1024</span>;</span><br><span class="line">    <span class="type">int</span> h_input[numElements];</span><br><span class="line">    <span class="type">int</span> *d_input;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 初始化输入数据</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; numElements; i++) &#123;</span><br><span class="line">        h_input[i] = rand() % <span class="number">1000</span>;  <span class="comment">// 生成随机数</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cudaMalloc((<span class="type">void</span>**)&amp;d_input, numElements * <span class="keyword">sizeof</span>(<span class="type">int</span>));</span><br><span class="line">    cudaMemcpy(d_input, h_input, numElements * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 启动快速排序内核：使用多个线程块</span></span><br><span class="line">    quickSortKernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">2</span>&gt;&gt;&gt;(d_input, <span class="number">0</span>, numElements - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将排序结果从设备复制回主机</span></span><br><span class="line">    cudaMemcpy(h_input, d_input, numElements * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 打印排序结果</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; numElements; i++) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, h_input[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line"></span><br><span class="line">    cudaFree(d_input);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Odd-Even-Merge"><a href="#Odd-Even-Merge" class="headerlink" title="Odd-Even Merge"></a>Odd-Even Merge</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdlib&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;ctime&gt;</span></span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// CUDA 奇偶归并排序核函数</span></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">oddEvenMergeSortKernel</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> n, <span class="type">int</span> step, <span class="type">int</span> halfStep)</span> &#123;</span><br><span class="line">    <span class="type">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 确保线程索引不越界</span></span><br><span class="line">    <span class="keyword">if</span> (i &lt; n / <span class="number">2</span>) &#123;</span><br><span class="line">        <span class="type">int</span> index = i * step; <span class="comment">// 当前线程处理的起始位置</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 找到比较的索引</span></span><br><span class="line">        <span class="type">int</span> first = index;</span><br><span class="line">        <span class="type">int</span> second = index + halfStep;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 比较并交换</span></span><br><span class="line">        <span class="keyword">if</span> (second &lt; n &amp;&amp; arr[first] &gt; arr[second]) &#123;</span><br><span class="line">            <span class="type">int</span> temp = arr[first];</span><br><span class="line">            arr[first] = arr[second];</span><br><span class="line">            arr[second] = temp;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// CUDA 主排序函数</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">cudaOddEvenMergeSort</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="type">int</span> *d_arr;</span><br><span class="line">    <span class="type">size_t</span> size = n * <span class="keyword">sizeof</span>(<span class="type">int</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 申请设备内存</span></span><br><span class="line">    cudaMalloc((<span class="type">void</span>**)&amp;d_arr, size);</span><br><span class="line">    cudaMemcpy(d_arr, arr, size, cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// CUDA 并行处理</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> step = <span class="number">2</span>; step &lt;= n; step &lt;&lt;= <span class="number">1</span>) &#123;          <span class="comment">// 步长从 2 开始，每次翻倍</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> halfStep = step &gt;&gt; <span class="number">1</span>; halfStep &gt; <span class="number">0</span>; halfStep &gt;&gt;= <span class="number">1</span>) &#123; <span class="comment">// 半步</span></span><br><span class="line">            <span class="type">int</span> threadsPerBlock = <span class="number">256</span>;</span><br><span class="line">            <span class="type">int</span> numBlocks = (n / <span class="number">2</span> + threadsPerBlock - <span class="number">1</span>) / threadsPerBlock;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 调用核函数进行并行比较和交换</span></span><br><span class="line">            oddEvenMergeSortKernel&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(d_arr, n, step, halfStep);</span><br><span class="line">            cudaDeviceSynchronize(); <span class="comment">// 同步确保所有线程完成</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将结果拷回主机</span></span><br><span class="line">    cudaMemcpy(arr, d_arr, size, cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 释放设备内存</span></span><br><span class="line">    cudaFree(d_arr);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 打印数组</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">printArray</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; arr[i] &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 主函数</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> n = <span class="number">8</span>; <span class="comment">// 数组大小</span></span><br><span class="line">    <span class="type">int</span> arr[n] = &#123;<span class="number">9</span>, <span class="number">7</span>, <span class="number">3</span>, <span class="number">8</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">2</span>&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;排序前: &quot;</span>;</span><br><span class="line">    printArray(arr, n);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 执行 CUDA 奇偶归并排序</span></span><br><span class="line">    cudaOddEvenMergeSort(arr, n);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;排序后: &quot;</span>;</span><br><span class="line">    printArray(arr, n);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="CUDA-并行编程"><a href="#CUDA-并行编程" class="headerlink" title="CUDA 并行编程"></a>CUDA 并行编程</h1><h2 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h2><p><strong>Terminology</strong>:</p>
<ul>
<li><em>==Host==</em>:The CPU and its memory (host memory)</li>
<li><em>==Device==</em>: The GPU and its memory (device memory)</li>
</ul>
<p><strong>函数元关键字</strong>：</p>
<ul>
<li><code>__global__</code>: 一组由 CPU 调用、GPU 执行的并行计算任务<ul>
<li><code>__global__</code> 必须采用 <code>void</code> 返回值类型</li>
<li><code>__global__</code> 函数是异步的，这意味着函数未执行完就返回了控制权。因此，测量内核函数的时间需要同步操作才能获得准确的结果</li>
</ul>
</li>
</ul>
 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> *a, <span class="type">int</span> *b, <span class="type">int</span> *c)</span> &#123;</span><br><span class="line">		*c = *a + *b;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><p><code>__device__</code>: 只能由 GPU 调用的函数</p>
</li>
<li><p><code>__host__</code>: 原来 CPU 调用的函数</p>
</li>
</ul>
<p><strong>函数超参数</strong>：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add&lt;&lt;&lt;gridDim, blockDim&gt;&gt;&gt;(pa, pb, pc);</span><br></pre></td></tr></table></figure>

<p>GPU 结构：Grid -&gt; Block -&gt; Thread</p>
<p>这个 <code>add</code> 函数执行在 Grid，<code>gridDim</code> 就是 Block 数目，<code>blockDim</code> 为 Thread 数目，最基本的并行单位是 Thread，下面的 idx 是全局的线程号， <code>threadIdx</code> 为块内的线程序号，<code>blockIdx</code> 为Grid内的块序号</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241221235324151.png" alt="image-20241221235324151"></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> *a, <span class="type">int</span> *b, <span class="type">int</span> *c)</span> &#123;</span><br><span class="line">		<span class="type">unsigned</span> <span class="type">int</span> idx = threadIdx + blockIdx * blockDim;</span><br><span class="line">    	*c[idx] = *a[idx] + *b[idx];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="编程示例"><a href="#编程示例" class="headerlink" title="编程示例"></a>编程示例</h2><p><code>add&lt;&lt;&lt;(N + M-1) / M,M&gt;&gt;&gt;(d_a, d_b, d_c, N)</code> 保证能够除尽</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// CUDA 内核函数</span></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">vectorAdd</span><span class="params">(<span class="type">const</span> <span class="type">float</span>* A, <span class="type">const</span> <span class="type">float</span>* B, <span class="type">float</span>* C, <span class="type">int</span> N)</span> &#123;</span><br><span class="line">    <span class="comment">// 计算线程索引</span></span><br><span class="line">    <span class="type">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 确保索引在范围内</span></span><br><span class="line">    <span class="keyword">if</span> (i &lt; N) &#123;</span><br><span class="line">        C[i] = A[i] + B[i];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">int</span> N = <span class="number">1000</span>; <span class="comment">// 向量长度</span></span><br><span class="line">    <span class="type">size_t</span> size = N * <span class="keyword">sizeof</span>(<span class="type">float</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 在主机 (CPU) 上分配内存</span></span><br><span class="line">    <span class="type">float</span> *h_A, *h_B, *h_C;</span><br><span class="line">    h_A = (<span class="type">float</span>*)<span class="built_in">malloc</span>(size);</span><br><span class="line">    h_B = (<span class="type">float</span>*)<span class="built_in">malloc</span>(size);</span><br><span class="line">    h_C = (<span class="type">float</span>*)<span class="built_in">malloc</span>(size);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 初始化数据</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++) &#123;</span><br><span class="line">        h_A[i] = i * <span class="number">0.1f</span>;</span><br><span class="line">        h_B[i] = i * <span class="number">0.2f</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 在设备 (GPU) 上分配内存</span></span><br><span class="line">    <span class="type">float</span> *d_A, *d_B, *d_C;</span><br><span class="line">    cudaMalloc((<span class="type">void</span>**)&amp;d_A, size);</span><br><span class="line">    cudaMalloc((<span class="type">void</span>**)&amp;d_B, size);</span><br><span class="line">    cudaMalloc((<span class="type">void</span>**)&amp;d_C, size);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将数据从主机拷贝到设备</span></span><br><span class="line">    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);</span><br><span class="line">    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 设置线程布局</span></span><br><span class="line">    <span class="type">int</span> threadsPerBlock = <span class="number">256</span>; <span class="comment">// 每个线程块包含 256 个线程</span></span><br><span class="line">    <span class="type">int</span> blocksPerGrid = (N + threadsPerBlock - <span class="number">1</span>) / threadsPerBlock; <span class="comment">// 总块数</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 调用 CUDA 内核函数</span></span><br><span class="line">    vectorAdd&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(d_A, d_B, d_C, N);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将结果从设备拷贝回主机</span></span><br><span class="line">    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 验证结果</span></span><br><span class="line">    <span class="type">bool</span> success = <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">fabs</span>(h_C[i] - (h_A[i] + h_B[i])) &gt; <span class="number">1e-5</span>) &#123;</span><br><span class="line">            success = <span class="literal">false</span>;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (success) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Test PASSED!\n&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Test FAILED!\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 清理资源</span></span><br><span class="line">    <span class="built_in">free</span>(h_A);</span><br><span class="line">    <span class="built_in">free</span>(h_B);</span><br><span class="line">    <span class="built_in">free</span>(h_C);</span><br><span class="line">    cudaFree(d_A);</span><br><span class="line">    cudaFree(d_B);</span><br><span class="line">    cudaFree(d_C);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Memory-API"><a href="#Memory-API" class="headerlink" title="Memory API"></a>Memory API</h2><ol>
<li><code>cudaError_t cudaMalloc(void **ptr, size_t size)</code>: 在 GPU 上动态分配内存<ul>
<li><code>ptr</code>: <code>devicePtr</code> 指向显存，通过<code>ptr</code> 修改 <code>devicePtr</code> <ul>
<li><code>malloc</code> 直接返回一个内存指针，而 <code>cudaMalloc</code> 不返回指针，需要传入一个指向 <code>devicePtr</code> 的二级指针 <code>ptr</code>，分配空间后通过 <code>ptr</code>  修改 <code>devicePtr</code></li>
</ul>
</li>
<li><code>size</code>: 分配空间大小，类似 <code>malloc</code> </li>
</ul>
</li>
<li><code>cudaError_t cudaMemcpy(void *dst, const void *src, size_t size, enum cudaMemcpyKind kind)</code>: <ul>
<li><code>dst</code>: 指向拷贝的目的地指针；</li>
<li><code>src</code>: 拷贝源头指针；</li>
<li><code>size</code>: 空间大小；</li>
<li><code>kind</code>: 枚举，拷贝的类型，<code>cudaMemcpyHostToHost</code> <code>cudaMemcpyHostToDevice</code> <code>cudaMemcpyDeviceToHost</code> <code>cudaMemcpyDeviceToDevice</code> 分别表示从主机到主机、从主机到设备、从设备到主机和从设备到设备的拷贝。</li>
</ul>
</li>
<li><code>cudaError_tcudaFree(void *devicePtr)</code>: 释放内存</li>
</ol>
<p>先分配，然后把数据拷贝到GPU，开始调用，调用完拷贝回 CPU</p>
<h3 id="线程同步"><a href="#线程同步" class="headerlink" title="线程同步"></a>线程同步</h3><p><strong>块内同步</strong>：<code>__syncthreads()</code>:</p>
<p><code>__syncthreads()</code> 是 CUDA 编程中的一个同步原语，它用于确保在某个线程块中的所有线程都已完成它们之前的所有指令，然后才能继续执行<code>__syncthreads()</code>之后的指令。这个函数只能在设备代码中使用，例如CUDA内核</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> <span class="title function_">example</span><span class="params">(<span class="type">int</span> *data)</span> &#123;</span><br><span class="line">    <span class="type">int</span> i = threadIdx.x;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 修改共享数据</span></span><br><span class="line">    data[i] += <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 同步所有线程</span></span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 使用其他线程更新的数据</span></span><br><span class="line">    <span class="keyword">if</span> (i &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        data[i] += data[i - <span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><code>__syncthreads()</code>的关键点</p>
<ul>
<li><strong>作用域</strong>：它只对一个线程块内的线程起作用，不会同步整个网格的所有线程。</li>
<li><strong>使用场景</strong>： 当线程写入共享内存，并且这些数据将被线程块中的其他线程读取时，通常需要一个__syncthreads()调用来确保写入完成。 当线程块内的线程可能同时写入同一个位置（导致不确定的结果）或在其他线程完成某些操作之前需要读取数据时，使用__syncthreads()可以避免竞态条件。</li>
<li><strong>注意事项</strong>： 不要在分支条件下不均匀地调用__syncthreads()，这可能会导致死锁。 不要在循环中过度使用__syncthreads()，因为它会阻止线程并行地执行。 CUDA本身不提供跨线程块的同步机制。为了在全网格范围内实现同步，程序员通常需要结束当前的kernel执行并启动一个新的kernel，因为kernel启动之间存在隐式的全局同步。</li>
</ul>
<p><strong>设备同步</strong>：<code>cudaDeviceSynchronize()</code></p>
<p>CUDA 中的线程块（Block）之间<strong>不能直接通信</strong>，即使使用 <code>__syncthreads()</code> 也只对<strong>同一个线程块内部</strong>有效。因此：</p>
<ul>
<li>不同线程块之间的数据依赖需要通过<strong>全局内存</strong>传递，并通过内核（kernel）调用之间进行同步：</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cudaMemcpy(); <span class="comment">// 数据传递</span></span><br><span class="line">cudaDeviceSynchronize(); <span class="comment">// 保证设备执行完前一个 kernel</span></span><br></pre></td></tr></table></figure>

<p>如果线程之间完全没有数据依赖，比如前面提到的<strong>向量加法</strong>示例，每个线程独立计算一个元素，互不干扰，那么不需要任何同步操作：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> <span class="title function_">vectorAdd</span><span class="params">(<span class="type">const</span> <span class="type">float</span>* A, <span class="type">const</span> <span class="type">float</span>* B, <span class="type">float</span>* C, <span class="type">int</span> N)</span> &#123;</span><br><span class="line">    <span class="type">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="keyword">if</span> (i &lt; N) &#123;</span><br><span class="line">        C[i] = A[i] + B[i]; <span class="comment">// 独立计算，无需同步</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/" rel="tag"># 排序算法</a>
              <a href="/tags/cuda/" rel="tag"># cuda</a>
              <a href="/tags/%E5%B9%B6%E5%8F%91/" rel="tag"># 并发</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2025/02/03/rpc-interpretation/" rel="prev" title="基于 Netty 的 RPC 框架">
                  <i class="fa fa-angle-left"></i> 基于 Netty 的 RPC 框架
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2025/05/01/review-4-30-%E5%8D%8E%E4%B8%BA%E4%B8%80%E9%9D%A2/" rel="next" title="4.30 华为一面+主管面">
                  4.30 华为一面+主管面 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2023 – 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">碎梦</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/scatteredream" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
