<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 5.4.2">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&family=Arvo:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&family=JetBrains+Mono:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"scatteredream.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":true,"version":"8.23.0","exturl":false,"sidebar":{"position":"right","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"flat"},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":false,"async":false,"duration":100,"transition":{"menu_item":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js" defer></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="scatteredream&#39;s blog">
<meta property="og:url" content="http://scatteredream.github.io/default/page/2/index.html">
<meta property="og:site_name" content="scatteredream&#39;s blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="碎梦">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://scatteredream.github.io/default/page/2/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"default/page/2/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>scatteredream's blog</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous" defer></script>
<script src="/js/third-party/search/local-search.js" defer></script>







  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">scatteredream's blog</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="碎梦"
      src="https://avatars.githubusercontent.com/u/62317679?s=400&v=4">
  <p class="site-author-name" itemprop="name">碎梦</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">78</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">125</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://scatteredream.github.io/2025/05/01/review-4-30-%E5%8D%8E%E4%B8%BA%E4%B8%80%E9%9D%A2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars.githubusercontent.com/u/62317679?s=400&v=4">
      <meta itemprop="name" content="碎梦">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="scatteredream's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | scatteredream's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/05/01/review-4-30-%E5%8D%8E%E4%B8%BA%E4%B8%80%E9%9D%A2/" class="post-title-link" itemprop="url">4.30 华为一面+主管面</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-05-01 00:00:00" itemprop="dateCreated datePublished" datetime="2025-05-01T00:00:00+08:00">2025-05-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-05-03 23:32:20" itemprop="dateModified" datetime="2025-05-03T23:32:20+08:00">2025-05-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/review/" itemprop="url" rel="index"><span itemprop="name">review</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><strong>华为 半导体业务部 通用软件开发工程师 暑期实习</strong> </p>
<p>3.28投递 4.9笔试 4.30 一面 主管面</p>
<p>一面：</p>
<ul>
<li>自我介绍。</li>
<li>介绍一下项目中遇到的难点？答得不好。</li>
<li>数组和链表的区别？</li>
<li>队列和栈的区别？两个队列能否实现栈？</li>
<li>手撕（寻找缺失的第一个正整数）</li>
<li>复盘笔试</li>
<li>c语言宏定义的求两个数之间的大数怎么办？（c语言忘得差不多了）</li>
<li>反问：</li>
<li>实习生如何培养的？</li>
<li>部门主要用什么语言开发的？（c，不过都会有对应的培训）</li>
<li>您对我的面试有什么建议？（处女面，太紧张了脱口而出，不然没话聊了）</li>
</ul>
<p>主管面：</p>
<ul>
<li>你们专业主要学什么？</li>
<li>绩点排名怎样？保研还是考研？</li>
<li>英语水平怎么样？</li>
<li>现在数学是不是比以前难很多？</li>
<li>反问</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://scatteredream.github.io/2025/04/14/cpp_cuda_parallel_programming/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars.githubusercontent.com/u/62317679?s=400&v=4">
      <meta itemprop="name" content="碎梦">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="scatteredream's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | scatteredream's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/04/14/cpp_cuda_parallel_programming/" class="post-title-link" itemprop="url">多核并行编程(C++&CUDA)</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-04-14 00:00:00" itemprop="dateCreated datePublished" datetime="2025-04-14T00:00:00+08:00">2025-04-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-05-15 12:05:25" itemprop="dateModified" datetime="2025-05-15T12:05:25+08:00">2025-05-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/juc/" itemprop="url" rel="index"><span itemprop="name">juc</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>同一时刻，多条指令在一个CPU上同时执行，物理上和逻辑上都是同时执行的。<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%88%86%E6%95%A3%E5%BC%8F%E8%A8%88%E7%AE%97">分布式计算</a>（Distributed computing）是<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/zh-cn/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97">并行计算</a>的一个特例，它采用计算机网络来进行同步。</p>
<h1 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h1><p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/21823699?sort=created">指令级并行，线程级并行，数据级并行区别？线程的概念是什么？ - 知乎</a> </p>
<h2 id="线程级并行-TLP"><a href="#线程级并行-TLP" class="headerlink" title="线程级并行 TLP"></a>线程级并行 TLP</h2><h3 id="线程级并发（Concurrency）"><a href="#线程级并发（Concurrency）" class="headerlink" title="线程级并发（Concurrency）"></a>线程级并发（Concurrency）</h3><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/thumbnail_1280X720.jpg" alt="thumbnail_1280X720"></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/zh-cn/%E5%B9%B6%E5%8F%91%E8%AE%A1%E7%AE%97">并发计算 - 维基百科，自由的百科全书 (wikipedia.org)</a></p>
<ul>
<li>并发是一种<strong>现象</strong>，比并行更加抽象，同时运行多个程序或多个任务需要被处理的现象。</li>
<li>它可以执行在单一<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%99%95%E7%90%86%E5%99%A8">处理器</a>上，将不同的执行步骤分散在不同<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%97%B6%E9%97%B4%E7%89%87">时间片</a>中执行，以非<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%B9%B3%E8%A1%8C%E9%81%8B%E7%AE%97">并行</a>方式循序运算，通过操作系统调度CPU快速切换执行上下文来实现宏观上的“并行”</li>
<li>它也可以用真正的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%B9%B3%E8%A1%8C%E8%A8%88%E7%AE%97">并行计算</a>来实现，将每个行程指定给处理器组中的某个处理器，以单片机<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%A4%9A%E8%99%95%E7%90%86%E5%99%A8">多处理器</a>平台，或是透过网络链接的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97">分散</a>平台来实做。</li>
</ul>
<p>coroutine就是典型的并发不并行</p>
</blockquote>
<p>操作系统通过时间片轮转调度，在不同的任务之间来回切换.</p>
<p>对cpu而言，这两个进程其实不是同时进行的；<br>对用户而言，由于P1和P2切换的速度非常快，所以用户觉得是“是同时进行的”。</p>
<h3 id="线程级并行（Parallelism）"><a href="#线程级并行（Parallelism）" class="headerlink" title="线程级并行（Parallelism）"></a>线程级并行（Parallelism）</h3><p>一个核心仍然无法处理多个线程</p>
<p>英特尔和AMD也意识到，当主频接近4GHz时，速度也会遇到自己的极限：那就是<strong>单靠主频提升，已经无法明显提升系统整体性能</strong>。因此迫切需要一个能支持同时处理2个线程以上的处理器，来提升CPU的瓶颈。需求推动了技术<strong>，线程级并行应运而生</strong>。主要由下面两种技术的支撑：</p>
<h4 id="超线程（Hyper-Threading-HT-SMT）"><a href="#超线程（Hyper-Threading-HT-SMT）" class="headerlink" title="超线程（Hyper-Threading,HT/SMT）"></a>超线程（Hyper-Threading,HT/SMT）</h4><p>2004年，奔腾4实现了Hyper-Threading（单核心双线程）</p>
<blockquote>
<p>超线程技术实现了单个物理核心同时两个线程，也就是别人常说的虚拟内核数。比如单物理核心实现的双线程，它同时可以处理两个线程，它的物理核心数其实是是1个，通过HyperThreading技术实现的<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=40117005&content_type=Answer&match_order=3&q=%E7%BA%BF%E7%A8%8B%E7%BA%A7%E5%B9%B6%E8%A1%8C&zhida_source=entity">线程级并行</a>(<code>Thread Lever Parallelism</code>)。至于技术细节的实现，这涉及到高速缓存的知识。</p>
</blockquote>
<p>Intel的SMT技术是我们认知最广泛的，早在2002年的Pentium 4上（应该是Pentium 4的E）和Xeon上，Intel就把SMT技术包装成Hyper Threading，并推向市场了。之后因为架构切换，在酷睿诞生初期暂停过一段时间，而自从Core i7 960这个划时代的酷睿后，就一直是Intel中高端CPU的标配了。 Intel的超线程一直都是SMT2，也就是一个物理核心虚拟出两个核心，也就是逻辑核心。 AMD最新的Zen系列CPU，也同样加入了SMT2的超线程，现在超线程技术可以说是PC和服务器CPU的标配了。</p>
<p>SMT是在指令级并行的基础上的扩展，可以在一个核上运行多个线程，多个线程共享执行单元，以便提高部件的利用率，提高吞吐量。SMT需要为每个线程单独保持状态，如程序计数器（PC），<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=61447789&content_type=Answer&match_order=1&q=%E5%AF%84%E5%AD%98%E5%99%A8%E5%A0%86&zhida_source=entity">寄存器堆</a>，重排序缓冲等。在一个CPU 的<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E6%97%B6%E9%92%9F%E5%91%A8%E6%9C%9F/1545064?fromModule=lemma_inlink">时钟周期</a>内能够执行来自多个线程的指令的硬件<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%8A%80%E6%9C%AF/5764231?fromModule=lemma_inlink">多线程技术</a>。本质上，同步多线程是一种将线程级<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86/8983963?fromModule=lemma_inlink">并行处理</a>（多CPU）转化为<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E6%8C%87%E4%BB%A4/3225201?fromModule=lemma_inlink">指令</a>级并行处理（同一CPU）的方法。 同步多线程是单个物理处理器从多个硬件线程上下文同时分派<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E6%8C%87%E4%BB%A4/3225201?fromModule=lemma_inlink">指令</a>的能力。</p>
<h4 id="多核心（Multicore）"><a href="#多核心（Multicore）" class="headerlink" title="多核心（Multicore）"></a>多核心（Multicore）</h4><p>物理核心数量的提升</p>
<ol>
<li><strong>多核处理器 (Multicore Processors)</strong></li>
</ol>
<ul>
<li><strong>描述</strong>：一个芯片上集成多个核心，每个核心可独立运行一个线程或任务。</li>
<li><strong>代表技术</strong>：Intel Core i7、AMD Ryzen。</li>
<li>特点：<ul>
<li>多个核心共享内存或缓存，提高线程并发能力。</li>
<li>适用于多线程应用和多任务环境。</li>
</ul>
</li>
</ul>
<ol>
<li>2005年，英特尔宣布他的第一个双核心 EM64T 处理器，和 Pentium D840(次年发布，双核心双线程，蹩脚双核)</li>
<li>2006年，Core 2（双核心双线程，但不支持HT技术）这大概才算真正意义上单芯片多核心处理器的诞生。（物理双核）</li>
<li>而2006后迎来了Multi-Core Processor多内核处理器时代，而且也伴随着多线程技术.<br>也就常说的几核几线程。核一般指的是物理核心的数目，线程是计算机能同时进行的线程。</li>
</ol>
<p><strong>多处理器系统 (Multi-Processor Systems)</strong></p>
<ul>
<li><strong>描述</strong>：多个物理 CPU 组成的系统，每个 CPU 拥有自己的内存或共享内存。</li>
<li>类型：<ol>
<li><strong>SMP（对称多处理）</strong>：所有处理器访问共享内存，共享操作系统资源。</li>
<li><strong>NUMA（非一致存储访问）</strong>：各处理器访问本地内存更快，远程内存访问更慢。</li>
</ol>
</li>
<li><strong>应用场景</strong>：大型服务器、高性能计算集群。</li>
</ul>
<p><strong>分布式计算 (Distributed Computing)</strong></p>
<ul>
<li><strong>描述</strong>：任务分布到多个计算节点，每个节点处理部分任务，并通过网络协调结果。</li>
<li><strong>典型框架</strong>：Hadoop、Spark、MPI。</li>
<li><strong>应用场景</strong>：数据挖掘、大规模仿真建模。</li>
</ul>
<p><strong>GPU 并行计算 (GPU Parallel Computing)</strong></p>
<ul>
<li><strong>描述</strong>：利用 GPU 的众多流处理器并行处理大量数据，适合数据密集型任务。</li>
<li>特点：<ul>
<li>专门用于图形渲染和 AI、机器学习任务。</li>
<li>框架：CUDA（NVIDIA）、OpenCL。</li>
</ul>
</li>
</ul>
<h2 id="指令级并行-ILP（Pipeline）"><a href="#指令级并行-ILP（Pipeline）" class="headerlink" title="指令级并行 ILP（Pipeline）"></a>指令级并行 ILP（<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%B5%81%E6%B0%B4%E7%BA%BF_(%E8%AE%A1%E7%AE%97%E6%9C%BA)">Pipeline</a>）</h2><blockquote>
<p>单核实现时间并行（指令流水）在并行性概念中引入时间因素，让多个处理过程在时间上相 互错开，轮流重叠地使用同一套硬件设备的各个部分，以加快硬件周转而赢得速度。 时间并行性概念的实现方式就是采用流水处理部件。这是一种非常经济而实用的并行 技术，能保证计算机系统具有较高的性能价格比。目前的高性能微型机几乎无一例外地使 用了流水技术。将计算机<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%8C%87%E4%BB%A4">指令</a>处理过程拆分为多个步骤，并通过多个硬件处理单元并行执行来加快指令执行速度，跟CPU核心数无关。</p>
</blockquote>
<p><strong>指令级并行（Instruction-Level Parallelism, ILP）</strong> 是指在<strong>单个处理器</strong>内部通过<strong>同时执行多条指令</strong>来提高程序运行速度的一种技术。它利用程序中指令之间的数据和控制独立性，使多条指令可以并行执行，从而提高性能。<strong>ILP 实质上是==时间级并行==的典型代表</strong>：</p>
<ul>
<li>利用流水线、超标量和乱序执行等技术，在一个核心内并行处理多条指令，但这些指令共享相同的计算资源，只是在不同阶段的时间上交错执行。</li>
<li>它依赖于执行单元复用，而不是多个物理核心并行处理任务。</li>
</ul>
<ol>
<li><p><strong>ILP 的核心思想</strong></p>
<ul>
<li><p><strong>并行性基础</strong>：程序中的指令并非严格依赖顺序执行，而是存在某些可以同时执行的指令。</p>
</li>
<li><p><strong>流水线技术</strong>：将指令分解为多个阶段（如取指、译码、执行、访存和写回），使得不同阶段的操作可以同时处理不同指令。</p>
</li>
<li><p><strong>硬件支持</strong>：依赖于高级处理器架构和控制逻辑来检测和管理指令依赖关系。</p>
</li>
</ul>
</li>
</ol>
<ol start="2">
<li><p><strong>ILP 的关键技术</strong></p>
<ul>
<li><p><strong>指令流水线 (Instruction Pipeline)</strong></p>
<ol>
<li>将指令分为多个阶段，每个阶段处理一部分操作，类似于生产线作业。</li>
<li>缺点：流水线可能因为数据依赖或控制依赖导致阻塞或停顿（称为流水线冒险）。</li>
</ol>
</li>
<li><p><strong>超标量处理 (Superscalar Execution)</strong></p>
<ol>
<li>在单个周期内执行多条指令，通过多个执行单元实现真正的并行执行。</li>
<li>例如：Intel Pentium 系列采用超标量设计，每周期可执行多条整数和浮点运算指令。</li>
</ol>
</li>
<li><p><strong>动态调度 (Dynamic Scheduling)</strong></p>
<ol>
<li>采用硬件动态调整指令顺序，绕过依赖性阻塞，提高指令吞吐量。</li>
<li>典型实现：Tomasulo 算法。</li>
</ol>
</li>
<li><p><strong>分支预测 (Branch Prediction)</strong></p>
<ol>
<li>解决控制依赖问题，预测程序分支方向，提前加载和执行指令。</li>
<li>精确的预测减少因分支跳转导致的流水线停顿。</li>
</ol>
</li>
<li><p><strong>乱序执行 (Out-of-Order Execution)</strong></p>
<ol>
<li>指令不按照程序编写顺序执行，而是根据依赖分析和资源调度动态调整执行顺序。</li>
<li>硬件负责结果重排序，确保程序语义正确性。</li>
</ol>
</li>
<li><p><strong>寄存器重命名 (Register Renaming)</strong></p>
<ol>
<li>通过给物理寄存器重新分配逻辑名称，避免写后读 (WAR) 和写后写 (WAW) 依赖冲突。</li>
</ol>
</li>
</ul>
</li>
<li><p><strong>ILP 的依赖分析</strong></p>
<ul>
<li><p><strong>数据依赖</strong>：</p>
<ol>
<li>**真实依赖 (RAW, Read After Write)**：指令需要前一指令的结果。</li>
<li>**反依赖 (WAR, Write After Read)**：后续指令会覆盖前面指令所需数据。</li>
<li>**输出依赖 (WAW, Write After Write)**：两个指令尝试写入同一位置。</li>
</ol>
</li>
<li><p><strong>控制依赖</strong>：</p>
<ol>
<li>指令执行取决于程序分支跳转结果，导致流水线停顿。</li>
</ol>
</li>
</ul>
</li>
<li><p><strong>ILP 的局限性</strong></p>
<ul>
<li><strong>数据依赖的限制</strong>：高度依赖指令本身的数据流特性，若指令相关性强，则并行度受限。</li>
<li><strong>控制流的限制</strong>：分支预测失败会导致流水线清空和指令重启，降低性能。</li>
<li><strong>硬件复杂度</strong>：超标量、乱序执行和动态调度需要大量硬件资源，功耗和成本较高。</li>
<li><strong>内存访问瓶颈</strong>：指令并行执行过程中，内存访问速度可能无法满足需求。</li>
</ul>
</li>
</ol>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241029161108996.png" alt="image-20241029161108996"></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241029164032833.png" alt="image-20241029164032833"></p>
<p><strong>内存级并行</strong>（英语：Memory-level parallelism，缩写为 MLP’），<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%B9%B3%E8%A1%8C%E8%A8%88%E7%AE%97">并行计算</a>技术的一种，是计算机体系结构的一种，能够同时进行数个存储器操作，特别是在<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/CPU%E5%BF%AB%E5%8F%96">缓存</a>未命中（cache miss），或<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%BD%89%E8%AD%AF%E5%BE%8C%E5%82%99%E7%B7%A9%E8%A1%9D%E5%8D%80">转译后备缓冲器</a>未命中（TLB miss）时。</p>
<p>在宏内核处理器架构下，内存级并行可以被视为是一种特殊的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%8C%87%E4%BB%A4%E5%B1%A4%E7%B4%9A%E5%B9%B3%E8%A1%8C">指令层级平行</a>（ILP）。它也经常在<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%B6%85%E7%B4%94%E9%87%8F">超标量</a>架构下出现。</p>
<h2 id="数据级并行-DLP（SIMD）"><a href="#数据级并行-DLP（SIMD）" class="headerlink" title="数据级并行 DLP（SIMD）"></a>数据级并行 DLP（SIMD）</h2><p>Flynn将计算机分为四类：</p>
<ul>
<li>SISD：单条指令操作一条数据，例如之前介绍的简单流水线</li>
<li>MISD：多条指令操作一条数据，很少</li>
<li>MIMD：多条指令操作多条数据，例如VLIW</li>
<li>SIMD：单条指令操作多条数据， 例如Vector Processor，GPU</li>
</ul>
<p>数据级并行就是指的SIMD，SIMD可以分为array processor和vector processor，array processor由多种ALU组成，成本更高，同一个时间可以有多个数据执行相同操作，vector processor每种硬件单元只有一个，同一个时间不同数据无法执行相同操作。</p>
<p>大型机多用于进行科学计算，为了更快的处理数据，它们使用了更多的寄存器，这样可以同时可以处理更多的操作数。<strong>单一指令运行多个<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=40117005&content_type=Answer&match_order=2&q=%E6%93%8D%E4%BD%9C%E6%95%B0&zhida_source=entity">操作数</a>并行计算</strong>。这里涉及到操作数的概念，如果你有汇编的基础应该会很好理解。我们考虑下面这个计算式子：(a+b)*(c+d)，该计算过程被分解为三步：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. e = a + b </span><br><span class="line">2. f = c + d</span><br><span class="line">3. m = e * f</span><br></pre></td></tr></table></figure>

<p>早期的计算机一次只能处理一条指令，它要先算步骤1（加法操作），再算步骤2（加法操作），最后算3（<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=40117005&content_type=Answer&match_order=1&q=%E4%B9%98%E6%B3%95%E6%93%8D%E4%BD%9C&zhida_source=entity">乘法操作</a>）。需要三步（花费三个指令）得到答案。</p>
<p>但是我们观察到：<br><strong>3的结果依赖于1和2，而1和2都单纯的加法操作，所以开始想办法让1和2同时计算，那么CPU只要两步得到答案，步骤1和2一次算出来的结果，直接进行乘法运算</strong>。</p>
<p>它运用了<code>SIMD</code>(Single -Instruction ,Multple -Data)<code>单指令多数据流</code>技术。一个指令执行了(a,b,c,d) 4个操作数。SIMD指令集可以提供更快的图像，声音，视频数据等运行速度。</p>
<h1 id="发展"><a href="#发展" class="headerlink" title="发展"></a>发展</h1><p><strong>单核编程</strong>：一开始是单核编程，优化算法也是在单核的基础上优化，为了更好的兼容性，发掘单核潜力</p>
<p><strong>多核编程</strong>：</p>
<p>摩尔定律，晶体管增长遥遥领先于指令执行。</p>
<p>能量消耗的问题，速度快了，能量消耗指数级上升，发热严重，影响计算速度，所以要进行散热，受制于经济原因，单核提升不上去</p>
<p>线路延迟问题，指令周期呈现缩短趋势，布线范围也呈缩短趋势，算得快但是来不及拿数，数据传递不过来，DRAM访问延迟，CPU 增长快于内存，一样的道理，拿不上数</p>
<p>收益递减diminishing returns：cpu性能提升难度陡增80s 流水线 90s 收益低于预期 00s 并行传输 </p>
<p>一个任务一个核，任务不够核消费，单个任务会有各种中断，不能有效利用核</p>
<h1 id="并行理论基础"><a href="#并行理论基础" class="headerlink" title="并行理论基础"></a>并行理论基础</h1><p>串行需要依赖，并行步骤之间不能有依赖，并行也分步骤，但是每一步的不同计算不能互相影响</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115220709073.png" alt="image-20241115220709073"></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115220731029.png" alt="image-20241115220731029"></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115220749864.png" alt="image-20241115220749864"></p>
<h2 id="Thread-线程-并行最小单位"><a href="#Thread-线程-并行最小单位" class="headerlink" title="Thread 线程 并行最小单位"></a>Thread 线程 并行最小单位</h2><p><strong>Parallel Unit</strong></p>
<ul>
<li>拥有自己的上下文</li>
<li>拥有调用堆栈</li>
<li>有PC</li>
<li>但是内存和同一个进程的其他线程共享（SHARED），发生竞态条件（RACE CONDITION）</li>
</ul>
<p>众所周知，CPU、内存、I/O 设备的速度是有极大差异的，为了合理利用 CPU 的高性能，平衡这三者的速度差异，计算机体系结构、操作系统、编译程序都做出了贡献，主要体现为:</p>
<ul>
<li>CPU 增加了缓存，以均衡与内存的速度差异；// 导致 <code>可见性</code>问题</li>
<li>操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I/O 设备的速度差异；// 导致 <code>原子性</code>问题</li>
<li>编译程序优化指令执行次序，使得缓存能够得到更加合理地利用。// 导致 <code>有序性</code>问题</li>
</ul>
<h3 id="Process-进程"><a href="#Process-进程" class="headerlink" title="Process 进程"></a>Process 进程</h3><p>进程就是程序的实例（就像面向对象编程中的类，类是静态的，只有实例化后才运行，且同一个类可以有多个实例）比如，你可以一边播放视频，一边编辑文档，每个程序都有自己的进程，互不干扰。即使它们都是同一份代码，但各自播放的内容和进度都可以不同。</p>
<p>进程（可以看成只有一个线程的进程）同时只能做一件事，如果将一个进程分成多个线程，这样就不会浪费时间空等了</p>
<p>进程间是完全独立的，互不干扰。而线程则共享同一个进程的资源，所以线程间交换数据更方便，几乎没有通讯损耗。</p>
<p>但进程间交换数据就麻烦多了，得通过一些通讯机制，比如管道、消息队列之类的（Inter-process Communication）</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241119184759519.png" alt="image-20241119184759519"></p>
<p>需要注意的是，线程各自拥有各自的栈</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241119185155274.png" alt="image-20241119185155274"></p>
<h3 id="Coroutine-协程"><a href="#Coroutine-协程" class="headerlink" title="Coroutine 协程"></a>Coroutine 协程</h3><p>线程在执行加载视频片段时，必须等待结果返回才能再次执行解码操作，如果引入多线程：加载本身是IO行为，CPU在等待结果返回期间几乎是在空等，浪费了CPU资源。当然，你可以让它休眠以释放 CPU 时间，但创建线程本身就有开销，线程切换同样有开销。</p>
<p>相比之下，协程（Coroutine）非常轻量，创建和切换的开销极小——它并非操作系统层面的东西，就不涉及内核调度。一般是由编程语言来实现（比如 Python 的 asyncio 标准库），它属于用户态的东西。</p>
<p>资源共享问题：线程的执行时机由操作系统调度，程序员无法控制，这正是多线程容易出现资源覆盖的主要原因。而协程的执行时机由程序自身控制，不受操作系统调度影响，因此可以完全避免这类问题。同一个线程内的多个协程共享同一个线程的 CPU 时间片资源，它们在 CPU 上的执行是有先后顺序的，不能并行执行。而线程是可以并行执行的</p>
<p>协程（coroutine），其实是一种特殊的子程序（subroutine，比如普通函数）。普通函数一旦执行就会从头到尾运行，然后返回结果，中间不会暂停。而协程则可以在执行到一半时暂停。利用这一特性，我们可以在遇到 I/O 这类不消耗 CPU 资源的操作时，将其挂起，继续执行其他计算任务，充分利用 CPU 资源。等 I/O 操作结果返回时，再恢复执行。在一个线程内并发执行多个任务</p>
<h2 id="Mutex-互斥锁"><a href="#Mutex-互斥锁" class="headerlink" title="Mutex 互斥锁"></a>Mutex 互斥锁</h2><p>案例：计算数组中3的个数。考虑将数组分成多个部分，每个部分由一个线程负责。</p>
<p><strong>V1 线程不安全</strong></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115221108488-1731681607112-1.png" alt="image-20241115221108488"></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">count3s_thread</span><span class="params">(<span class="type">int</span> id)</span> &#123;</span><br><span class="line">    <span class="type">int</span> length_per_thread = length / t;</span><br><span class="line">    <span class="type">int</span> start = id * length_per_thread;</span><br><span class="line">    <span class="keyword">for</span> (i = start; i &lt; start + length_per_thread; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">array</span>[i] == <span class="number">3</span>) </span><br><span class="line">        	count++;<span class="comment">//count++等价于count = count + 1，先读后写，不是原子操作，存在线程安全问题</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>V2 线程安全</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">mutex m;<span class="comment">//引入互斥锁，解决线程安全问题</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">count3s_thread</span><span class="params">(<span class="type">int</span> id)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> length_per_thread = length / t;</span><br><span class="line">    <span class="type">int</span> start = id * length_per_thread;</span><br><span class="line">    <span class="keyword">for</span> (i = start; i &lt; start + length_per_thread; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (array[i] == <span class="number">3</span>) &#123;</span><br><span class="line">        <span class="built_in">mutex_lock</span>(m);<span class="comment">//加互斥锁，count++只能串行执行</span></span><br><span class="line">        count++;</span><br><span class="line">        <span class="built_in">mutex_unlock</span>(m);<span class="comment">//解锁</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>V3 减少加锁次数 优化性能</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">private_count[MaxThreads];<span class="comment">//每个线程有自己的count变量，线程</span></span><br><span class="line">mutex x;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">count3s_thread</span><span class="params">(<span class="type">int</span> id)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> length_per_thread = length / t;</span><br><span class="line">    <span class="type">int</span> start = id * length_per_thread;</span><br><span class="line">    <span class="keyword">for</span> (i = start; i &lt; start + length_per_thread; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (array[i] == <span class="number">3</span>) </span><br><span class="line">        	private_count[id]++;</span><br><span class="line">	&#125;</span><br><span class="line">    <span class="built_in">mutex_lock</span>(m);</span><br><span class="line">    count += private_count[id];<span class="comment">//数完所有3再加，减少加锁的次数</span></span><br><span class="line">    <span class="built_in">mutex_unlock</span>(m);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>V4 针对硬件结构进行优化 避免伪共享</strong></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115222853277.png" alt="image-20241115222853277"></p>
<blockquote>
<p>在多线程程序中，如果不同线程访问的变量在同一个缓存行中，而其中一个线程修改了它所在缓存行的某个变量，其他线程即使访问不同的变量，也会因为缓存一致性协议（如 MESI 协议）而导致缓存失效，迫使这些线程频繁地从内存（RAM）中重新加载数据。</p>
<p>在大多数现代 CPU 上，一个缓存行通常是 64 字节。如果 <code>private_count</code> 数组的每个元素占用的空间小于 64 字节（例如一个 <code>int</code> 通常为 4 字节），多个 <code>private_count</code> 元素会共享同一个缓存行。这样一来，即使线程各自访问不同的 <code>private_count</code> 元素，它们的读写操作也会相互干扰。</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/31875174">细说Cache-L1/L2/L3/TLB - 知乎 (zhihu.com)</a></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">padded_int</span> &#123;</span><br><span class="line">    <span class="type">int</span> value;</span><br><span class="line">    <span class="type">char</span> padding[<span class="number">60</span>];</span><br><span class="line">&#125;private_count[MaxThreads];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">count3s_thread</span><span class="params">(<span class="type">int</span> id)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> length_per_thread = length / t;</span><br><span class="line">    <span class="type">int</span> start = id * length_per_thread;</span><br><span class="line">    <span class="keyword">for</span> (i = start; i &lt; start + length_per_thread; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (array[i] == <span class="number">3</span>) &#123;</span><br><span class="line">        	private_count[id]++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">mutex_lock</span>(m);</span><br><span class="line">    count += private_count[id].value;</span><br><span class="line">    <span class="built_in">mutex_unlock</span>(m);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<blockquote>
<ol>
<li>MESI 协议简介</li>
</ol>
<p>​    在 MESI 协议中，每个缓存行可以有以下四种状态：</p>
<ul>
<li><strong>Modified（M）</strong>：缓存行被当前处理器独占，并且内容已被修改，与主存不同步。</li>
<li><strong>Exclusive（E）</strong>：缓存行被当前处理器独占，且内容与主存同步。</li>
<li><strong>Shared（S）</strong>：缓存行在多个处理器的缓存中都有副本，且与主存同步。</li>
<li><strong>Invalid（I）</strong>：缓存行无效，即该缓存行内容与主存不同步，不能使用。</li>
</ul>
<ol start="2">
<li>判断缓存失效的机制</li>
</ol>
<p>缓存失效通常是通过<strong>监听总线上的操作</strong>来判断的。每个核心的缓存控制器都会监视其他核心发出的读写请求，这样它可以判断自己是否需要使某个缓存行失效。具体流程如下：</p>
<ol>
<li><p><strong>读操作</strong>：当一个处理器读取一个缓存行时，如果其他处理器的缓存中有该缓存行的修改版（Modified 状态），它会通知主存和其他缓存进行更新，使这个缓存行失效或进入共享状态。</p>
</li>
<li><p><strong>写操作（写失效）</strong>：当一个处理器要写入一个缓存行时，如果其他缓存有该缓存行的副本（处于 Shared 或 Exclusive 状态），它们会收到写入请求并将该缓存行标记为无效（Invalid）。这称为<strong>写失效</strong>。</p>
</li>
<li><p><strong>广播和探测</strong>：在缓存一致性协议中，当处理器对缓存行进行操作（如写操作）时，处理器会向其他核心或处理器发出<strong>广播</strong>或<strong>探测</strong>信号，要求其他缓存检查是否有该缓存行的副本。如果存在副本，这些副本会被标记为无效。</p>
</li>
<li><p>缓存失效的例子（基于 MESI 协议）</p>
</li>
</ol>
<p>假设处理器 P0 和 P1 都在各自的缓存中存有某个变量 <code>x</code>，且 <code>x</code> 的初始值为 0。以下是一个缓存失效的示例过程：</p>
<ul>
<li><strong>步骤 1</strong>：P0 读取 <code>x</code>，此时 <code>x</code> 在 P0 的缓存中处于 Shared 状态。</li>
<li><strong>步骤 2</strong>：P1 也读取 <code>x</code>，此时 <code>x</code> 在 P0 和 P1 的缓存中都是 Shared 状态。</li>
<li><strong>步骤 3</strong>：P0 对 <code>x</code> 进行写操作，将 <code>x</code> 修改为 1。<ul>
<li>P0 的缓存控制器会通知 P1 的缓存，将 <code>x</code> 在 P1 的缓存中标记为 Invalid。</li>
<li>P0 中的 <code>x</code> 变为 Modified 状态，与主存不同步。</li>
</ul>
</li>
<li><strong>步骤 4</strong>：当 P1 再次尝试读取 <code>x</code> 时，发现该缓存行是无效的（Invalid 状态），因此会触发一次从主存或 P0 缓存中的更新操作来同步数据。</li>
</ul>
<ol start="4">
<li>硬件实现的细节</li>
</ol>
<ul>
<li><strong>总线监听（Bus Snooping）</strong>：每个缓存控制器通过监听总线上其他处理器的内存访问请求来判断是否需要使缓存行失效。如果其他处理器发出了对自己缓存行的写请求，那么本地的缓存行会被标记为无效。</li>
<li><strong>目录协议（Directory-Based Protocol）</strong>：在一些系统中，每个内存块的状态由一个中央目录来管理。目录保存了该内存块在哪些缓存中有副本，哪个处理器在修改状态。当某个处理器要写数据时，目录会通知所有拥有该缓存行的处理器将其标记为无效。</li>
</ul>
<p>在伪共享中，不同线程访问不同变量，但这些变量在同一个缓存行中。当一个线程修改了它的变量，其他线程的缓存行会被标记为无效，迫使它们重新从内存中加载。这是因为缓存行是最小的一致性单位，即使只修改缓存行中的一个字节，整个缓存行都需要保持一致。</p>
<p>总结</p>
<p>缓存失效的判断是通过<strong>缓存一致性协议</strong>和<strong>硬件监听机制</strong>实现的。当一个缓存行被修改时，其他缓存中的相同缓存行会被标记为无效，从而保证所有处理器访问同一内存地址时的一致性。</p>
</blockquote>
<h1 id="C-并行编程"><a href="#C-并行编程" class="headerlink" title="C++ 并行编程"></a>C++ 并行编程</h1><p>HelloWorld：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thread&gt;</span><span class="comment">//引入并发包</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">func</span><span class="params">()</span>&#123;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;**Inside thread &quot;</span> &lt;&lt; <span class="built_in">std</span>::this_thread::get_id() &lt;&lt; <span class="string">&quot;!&quot;</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">  <span class="built_in">std</span>::thread  <span class="title function_">t</span><span class="params">( func )</span>;<span class="comment">//fork 创建子线程（主线程的分支）</span></span><br><span class="line">  t.join();<span class="comment">//把子线程合并到主线程中</span></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="结构化并行编程-fork-join"><a href="#结构化并行编程-fork-join" class="headerlink" title="结构化并行编程 fork-join"></a>结构化并行编程 fork-join</h2><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115220240060.png" alt="image-20241115220240060"></p>
<p>不能一创建子线程就join()，join的意思是让主线程等子线程执行完再继续，所以循环体内join就会阻塞其他子线程的创建，变成事实上的串行程序。因此应该全部创建完子线程后以后再统一join()，</p>
<h2 id="常见错误"><a href="#常见错误" class="headerlink" title="常见错误"></a>常见错误</h2><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115225902890.png" alt="image-20241115225902890"></p>
<p>不能让线程直接赋值，而是要用std::move(t)将t的上下文等信息转移到t2，然后t就变成了一个空壳，</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115230015703.png" alt="image-20241115230015703"></p>
<h2 id="Lambda表达式"><a href="#Lambda表达式" class="headerlink" title="Lambda表达式"></a>Lambda表达式</h2><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115230229087.png" alt="image-20241115230229087"></p>
<ul>
<li><code>[]</code>代表不传任何值</li>
<li><code>[&amp;]</code>代表把在进程内部但在函数外部的变量以引用的形式传递进去</li>
<li><code>[=]</code>代表把上述变量以值传递的形式传过去（传递副本）</li>
</ul>
<p>()表示参数，{}表示函数体</p>
<h2 id="案例：矩阵乘法"><a href="#案例：矩阵乘法" class="headerlink" title="案例：矩阵乘法"></a>案例：矩阵乘法</h2><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115231555912.png" alt="image-20241115231555912"></p>
<p><code>C[i][j]</code> 就是矩阵A的第i行和矩阵B的第j行的每一个数据相乘的和 </p>
<p>$C_{i,j}=\sum_{k=0}^N A_{i,k}B_{k,j}$   </p>
<p>并行版本：把总的任务拆分开。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115230540760.png" alt="image-20241115230540760"></p>
<p>优化：</p>
<blockquote>
<p><strong>数据结构、算法与应用</strong> C++语言描述（原书第2版）：第4章 性能测量 P88 矩阵乘法</p>
</blockquote>
<ul>
<li>一个循环体内部只对<code>C[i][j]</code>做一次赋值操作</li>
<li>优化嵌套的顺序：一共需要进行$N^3$次乘法，<code>A[i][k] B[k][j] C[i][j]</code>的元素都变成按行访问，有效利用了cache空间（因为同行的元素在内存中相邻，而同列的元素不是，如果数组长度过长，导致同列的元素无法同时存储在L2缓存中，使得缓存未命中必须从RAM中取，大大降低了效率）</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/he_nan/article/details/106169483">高速缓存与矩阵乘法(一)_矩阵乘法cache-CSDN博客</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/he_nan/article/details/106175159">高速缓存与矩阵乘法(二)_矩阵乘法的瓶颈-CSDN博客</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/he_nan/article/details/106181334">高速缓存与矩阵乘法(三)_clapack用法-CSDN博客</a> </p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241115231028700.png" alt="image-20241115231028700"></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241116130720225.png" alt="image-20241116130720225"></p>
<h2 id="其他并发库"><a href="#其他并发库" class="headerlink" title="其他并发库"></a>其他并发库</h2><p><strong>Future Async 更舒适的开启线程方式</strong></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241116002448557.png" alt="image-20241116002448557"></p>
<p>async能实现异步开启一个线程的功能，并返回future，future最重要的是能够直接拿到返回值</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241116002705661.png" alt="image-20241116002705661"></p>
<p><strong>Mutex 解决RA</strong> </p>
<p>竞态条件(Race Condition)：</p>
<p>操作同一变量导致了竞态条件的发生，从上到下性能依次降低</p>
<blockquote>
<ul>
<li><em>redesign to eliminate (e.g. reduction)</em> 重新设计程序，尽量减少共享变量的次数</li>
<li><em>use thread-safe entities (e.g. parallel collections)</em> 比如java中的concurrentHashMap，比如原子变量（乐观锁）</li>
<li><em>use synchronization (e.g. locking)</em> 实在没办法只能加锁</li>
</ul>
</blockquote>
<p>因此要定义针对共享代码块的锁，也就是互斥锁Mutex</p>
<p><strong>Mutex</strong>: </p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241116003512855.png" alt="image-20241116003512855"></p>
<p><strong>Lock Guard</strong>: </p>
<p>直接使用mutex的加解锁，如果中间代码出现异常，就会出现死锁，那么显然就不能简单粗暴地直接调用锁。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241116003914988.png" alt="image-20241116003914988"></p>
<p>Java中的锁监视器（Monitor）和 <code>lock_guard</code> 确实有相似之处。它们都是用来管理资源的互斥访问，确保线程安全。<code>lock_guard</code> 是 C++ 中的一种 RAII 风格的锁实现，它在构造时加锁，在析构时自动解锁。锁监视器则是一个对象，包含加锁和解锁操作，通常通过 <code>synchronized</code> 关键字来实现。两者的核心思想都是在临界区自动管理锁的生命周期，避免死锁。</p>
<p><strong>Atomic</strong>: </p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241116004457236.png" alt="image-20241116004457236"></p>
<p>原子变量 只支持自增</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241116004534563.png" alt="image-20241116004534563"></p>
<p>将共享的变量去除，直接拿到异步future的返回值相加，完全避免了RA</p>
<h1 id="并行算法"><a href="#并行算法" class="headerlink" title="并行算法"></a>并行算法</h1><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241118150058492.png" alt="image-20241118150058492"></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thread&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;random&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="comment">//排序函数</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">parallelSort</span><span class="params">(vector&lt;<span class="type">int</span>&gt;&amp; arr)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> n = arr.<span class="built_in">size</span>();</span><br><span class="line">    <span class="type">int</span> rounds = <span class="built_in">log2</span>(n); <span class="comment">// 需要的轮数</span></span><br><span class="line">    <span class="keyword">auto</span> compareAndSwap = [&amp;](<span class="type">int</span> start,<span class="type">int</span> step) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = start; i &lt; n; i += <span class="number">2</span> * step) &#123;</span><br><span class="line">            <span class="keyword">if</span> (arr[i] &lt; arr[i + step]) &#123;</span><br><span class="line">                <span class="built_in">swap</span>(arr[i], arr[i + step]);</span><br><span class="line">            &#125;<span class="comment">//为什么不传start step的引用:因为线程创建以后，什么时候开始是不确定的，而start和step两个变量的值是随时间变化的，因此各个线程拿到的值是不确定的。</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> r = <span class="number">0</span>; r &lt; rounds; ++r) &#123;</span><br><span class="line">        <span class="type">int</span> step = <span class="number">1</span> &lt;&lt; r; <span class="comment">// 当前轮的步长</span></span><br><span class="line">        <span class="type">int</span> threadsCount = n / (<span class="number">2</span> * step); <span class="comment">// 每组分配一个线程</span></span><br><span class="line">        vector&lt;thread&gt; threads;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> t = <span class="number">0</span>; t &lt; threadsCount; ++t) &#123;</span><br><span class="line">            threads.<span class="built_in">emplace_back</span>(compareAndSwap, t * <span class="number">2</span> * step, step);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 等待所有线程完成</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; t : threads) &#123;</span><br><span class="line">            t.<span class="built_in">join</span>();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Bitonic-Sort"><a href="#Bitonic-Sort" class="headerlink" title="Bitonic Sort"></a>Bitonic Sort</h2><p>双调排序（Bitonic Sort）是一种并行排序算法，特别适用于多处理器系统。它通过递归方式构造双调序列（bitonic sequence），然后使用双调合并（bitonic merge）将其排序。以下是用C++和多线程实现双调排序的代码：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">bitonicSortKernel</span><span class="params">(<span class="type">int</span>* d_arr, <span class="type">int</span> n, <span class="type">int</span> stage, <span class="type">int</span> step)</span> </span>&#123;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> idx = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> pairIdx = idx ^ step;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 每个线程处理一个元素对</span></span><br><span class="line">    <span class="keyword">if</span> (pairIdx &gt; idx &amp;&amp; pairIdx &lt; n) &#123;</span><br><span class="line">        <span class="type">bool</span> ascending = ((idx &amp; stage) == <span class="number">0</span>); <span class="comment">// 根据 stage 决定升序或降序</span></span><br><span class="line">        <span class="keyword">if</span> ((d_arr[idx] &gt; d_arr[pairIdx]) == ascending) &#123;</span><br><span class="line">            <span class="comment">// 交换两个元素</span></span><br><span class="line">            <span class="type">int</span> temp = d_arr[idx];</span><br><span class="line">            d_arr[idx] = d_arr[pairIdx];</span><br><span class="line">            d_arr[pairIdx] = temp;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">bitonicSortCUDA</span><span class="params">(std::vector&lt;<span class="type">int</span>&gt;&amp; arr)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> n = arr.<span class="built_in">size</span>();</span><br><span class="line">    <span class="keyword">if</span> ((n &amp; (n - <span class="number">1</span>)) != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> std::<span class="built_in">runtime_error</span>(<span class="string">&quot;Array size must be a power of 2.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 分配设备内存</span></span><br><span class="line">    <span class="type">int</span>* d_arr;</span><br><span class="line">    <span class="built_in">cudaMalloc</span>((<span class="type">void</span>**)&amp;d_arr, n * <span class="built_in">sizeof</span>(<span class="type">int</span>));</span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(d_arr, arr.<span class="built_in">data</span>(), n * <span class="built_in">sizeof</span>(<span class="type">int</span>), cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 设置线程块和网格维度</span></span><br><span class="line">    <span class="type">int</span> threadsPerBlock = <span class="number">256</span>;</span><br><span class="line">    <span class="type">int</span> blocksPerGrid = (n + threadsPerBlock - <span class="number">1</span>) / threadsPerBlock;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 执行排序算法</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> stage = <span class="number">2</span>; stage &lt;= n; stage *= <span class="number">2</span>) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> step = stage / <span class="number">2</span>; step &gt; <span class="number">0</span>; step /= <span class="number">2</span>) &#123;</span><br><span class="line">            bitonicSortKernel&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(d_arr, n, stage, step);</span><br><span class="line">            <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 拷贝结果回主机</span></span><br><span class="line">    <span class="built_in">cudaMemcpy</span>(arr.<span class="built_in">data</span>(), d_arr, n * <span class="built_in">sizeof</span>(<span class="type">int</span>), cudaMemcpyDeviceToHost);</span><br><span class="line">    <span class="built_in">cudaFree</span>(d_arr);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 初始化数据</span></span><br><span class="line">    std::vector&lt;<span class="type">int</span>&gt; arr = &#123;<span class="number">19</span>, <span class="number">7</span>, <span class="number">5</span>, <span class="number">3</span>, <span class="number">17</span>, <span class="number">13</span>, <span class="number">11</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">9</span>, <span class="number">4</span>, <span class="number">8</span>, <span class="number">6</span>, <span class="number">12</span>, <span class="number">10</span>, <span class="number">14</span>&#125;;</span><br><span class="line"></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Original array: &quot;</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> num : arr) &#123;</span><br><span class="line">        std::cout &lt;&lt; num &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    std::cout &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="built_in">bitonicSortCUDA</span>(arr);</span><br><span class="line">    &#125; <span class="built_in">catch</span> (<span class="type">const</span> std::exception&amp; e) &#123;</span><br><span class="line">        std::cerr &lt;&lt; e.<span class="built_in">what</span>() &lt;&lt; std::endl;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Sorted array: &quot;</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> num : arr) &#123;</span><br><span class="line">        std::cout &lt;&lt; num &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    std::cout &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol>
<li><strong><code>bitonicMerge</code></strong>:<ul>
<li>负责将双调序列合并为一个有序序列。</li>
<li>使用 <code>low</code> 和 <code>count</code> 参数确定操作范围，并通过 <code>ascending</code> 决定升序或降序。</li>
</ul>
</li>
<li><strong><code>bitonicSort</code></strong>:<ul>
<li>构造双调序列并调用 <code>bitonicMerge</code> 完成排序。</li>
</ul>
</li>
<li><strong><code>parallelBitonicSort</code></strong>:<ul>
<li>通过多线程加速排序过程。</li>
<li>根据线程数分配工作，递归调用 <code>parallelBitonicSort</code>。</li>
</ul>
</li>
<li><strong><code>main</code></strong>:<ul>
<li>验证数组大小为 2 的幂。</li>
<li>使用多线程完成排序，并输出结果。</li>
</ul>
</li>
</ol>
<ul>
<li>输入数组大小必须是 2 的幂。如果不是，可以填充为下一个最近的 2 的幂。</li>
<li>适当调整线程数量，以避免因过多线程导致上下文切换开销。</li>
<li><code>std::thread::hardware_concurrency()</code> 获取系统支持的最大线程数。</li>
</ul>
<p>运行结果会显示原始数组和排序后的数组，从而验证算法正确性和并行效果。</p>
<h2 id="Odd-Even-Sort"><a href="#Odd-Even-Sort" class="headerlink" title="Odd-Even Sort"></a>Odd-Even Sort</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;cuda_runtime.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;device_launch_parameters.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="comment">// 每个块的线程数量</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> BLOCK_SIZE 1024</span></span><br><span class="line"><span class="comment">// 设备内核函数：执行奇偶交换</span></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">odd_even_sort_step</span><span class="params">(<span class="type">int</span>* data, <span class="type">int</span> size, <span class="type">int</span> phase)</span> &#123;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> i = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> index = <span class="number">2</span> * i + (phase % <span class="number">2</span>); <span class="comment">// 控制奇偶阶段</span></span><br><span class="line">    <span class="comment">// 确保不越界</span></span><br><span class="line">    <span class="keyword">if</span> (index &lt; size - <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (data[index] &gt; data[index + <span class="number">1</span>]) &#123;</span><br><span class="line">            <span class="comment">// 交换数据</span></span><br><span class="line">            <span class="type">int</span> temp = data[index];</span><br><span class="line">            data[index] = data[index + <span class="number">1</span>];</span><br><span class="line">            data[index + <span class="number">1</span>] = temp;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 启动CUDA奇偶排序</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">odd_even_sort</span><span class="params">(<span class="type">int</span>* data, <span class="type">int</span> size)</span> &#123;</span><br><span class="line">    <span class="type">int</span>* d_data;</span><br><span class="line">    <span class="comment">// 在设备上分配内存</span></span><br><span class="line">    cudaMalloc((<span class="type">void</span>**)&amp;d_data, size * <span class="keyword">sizeof</span>(<span class="type">int</span>));</span><br><span class="line">    cudaMemcpy(d_data, data, size * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyHostToDevice);</span><br><span class="line">    <span class="comment">// 计算块和线程的配置</span></span><br><span class="line">    <span class="type">int</span> threads_per_block = BLOCK_SIZE / <span class="number">2</span>;  <span class="comment">// 每个块的线程数量</span></span><br><span class="line">    <span class="type">int</span> num_blocks = (size / <span class="number">2</span> + threads_per_block - <span class="number">1</span>) / threads_per_block;</span><br><span class="line">    <span class="comment">// 每一轮奇偶排序</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> phase = <span class="number">0</span>; phase &lt; size; phase++) &#123;</span><br><span class="line">        odd_even_sort_step &lt;&lt; &lt;num_blocks, threads_per_block &gt;&gt; &gt; (d_data, size, phase);</span><br><span class="line">        cudaDeviceSynchronize(); <span class="comment">// 确保所有线程完成</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 将数据从设备复制回主机</span></span><br><span class="line">    cudaMemcpy(data, d_data, size * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyDeviceToHost);</span><br><span class="line">    cudaFree(d_data); <span class="comment">// 释放设备内存</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// CUDA内核：奇数阶段排序</span></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">oddEvenSortKernel</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> n, <span class="type">int</span> phase)</span> &#123;</span><br><span class="line">    <span class="type">int</span> index = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (phase % <span class="number">2</span> == <span class="number">0</span>) &#123; <span class="comment">// 偶数阶段：比较偶数索引和下一个奇数索引</span></span><br><span class="line">        <span class="keyword">if</span> (index % <span class="number">2</span> == <span class="number">0</span> &amp;&amp; index &lt; n - <span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (arr[index] &gt; arr[index + <span class="number">1</span>]) &#123;</span><br><span class="line">                <span class="comment">// 交换</span></span><br><span class="line">                <span class="type">int</span> temp = arr[index];</span><br><span class="line">                arr[index] = arr[index + <span class="number">1</span>];</span><br><span class="line">                arr[index + <span class="number">1</span>] = temp;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123; <span class="comment">// 奇数阶段：比较奇数索引和下一个偶数索引</span></span><br><span class="line">        <span class="keyword">if</span> (index % <span class="number">2</span> == <span class="number">1</span> &amp;&amp; index &lt; n - <span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (arr[index] &gt; arr[index + <span class="number">1</span>]) &#123;</span><br><span class="line">                <span class="comment">// 交换</span></span><br><span class="line">                <span class="type">int</span> temp = arr[index];</span><br><span class="line">                arr[index] = arr[index + <span class="number">1</span>];</span><br><span class="line">                arr[index + <span class="number">1</span>] = temp;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> numElements = <span class="number">1024</span>;</span><br><span class="line">    <span class="type">int</span> h_input[numElements];</span><br><span class="line">    <span class="type">int</span> *d_input;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 初始化输入数据</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; numElements; i++) &#123;</span><br><span class="line">        h_input[i] = rand() % <span class="number">1000</span>;  <span class="comment">// 生成随机数</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cudaMalloc((<span class="type">void</span>**)&amp;d_input, numElements * <span class="keyword">sizeof</span>(<span class="type">int</span>));</span><br><span class="line">    cudaMemcpy(d_input, h_input, numElements * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 假设每个线程块有512个线程</span></span><br><span class="line">    <span class="type">int</span> blockSize = <span class="number">512</span>;</span><br><span class="line">    <span class="type">int</span> numBlocks = (numElements + blockSize - <span class="number">1</span>) / blockSize;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 进行多个阶段的排序</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> phase = <span class="number">0</span>; phase &lt; numElements; phase++) &#123;</span><br><span class="line">        oddEvenSortKernel&lt;&lt;&lt;numBlocks, blockSize&gt;&gt;&gt;(d_input, numElements, phase);</span><br><span class="line">        cudaDeviceSynchronize();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将排序结果从设备复制回主机</span></span><br><span class="line">    cudaMemcpy(h_input, d_input, numElements * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 打印排序结果</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; numElements; i++) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, h_input[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line"></span><br><span class="line">    cudaFree(d_input);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Prefix-Sum"><a href="#Prefix-Sum" class="headerlink" title="Prefix Sum"></a>Prefix Sum</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thread&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;functional&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;mutex&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">parallel_prefix_sum</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> k = <span class="number">3</span>;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> n = <span class="number">1</span> &lt;&lt; k; <span class="comment">// 数组大小为 2^k</span></span><br><span class="line">    std::vector&lt;<span class="type">int</span>&gt; elements = &#123;<span class="number">7</span>, <span class="number">3</span>, <span class="number">15</span>, <span class="number">10</span>, <span class="number">13</span>, <span class="number">18</span>, <span class="number">6</span>, <span class="number">4</span>&#125;;</span><br><span class="line">    <span class="function">std::vector&lt;<span class="type">int</span>&gt; <span class="title">tree_top</span><span class="params">(<span class="number">2</span> * n, <span class="number">0</span>)</span>, <span class="title">tree_left</span><span class="params">(n, <span class="number">0</span>)</span></span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 初始化 tree_top，前 n 个元素为原数组</span></span><br><span class="line">    std::<span class="built_in">copy</span>(elements.<span class="built_in">begin</span>(), elements.<span class="built_in">end</span>(), tree_top.<span class="built_in">begin</span>() + n);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">auto</span> reduce_layer = [&amp;](<span class="type">int</span> i) &#123;</span><br><span class="line">        <span class="type">int</span> layer_size = <span class="number">1</span> &lt;&lt; (k - i - <span class="number">1</span>); <span class="comment">// 当前层的节点数</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; layer_size; ++j) &#123;</span><br><span class="line">            <span class="type">int</span> idx = (<span class="number">1</span> &lt;&lt; (k - i - <span class="number">1</span>)) + j; <span class="comment">// 当前节点索引</span></span><br><span class="line">            tree_top[idx] = tree_top[<span class="number">2</span> * idx] + tree_top[<span class="number">2</span> * idx + <span class="number">1</span>]; <span class="comment">// 左右子节点求和</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="keyword">auto</span> expand_layer = [&amp;](<span class="type">int</span> i) &#123;</span><br><span class="line">        <span class="type">int</span> layer_size = <span class="number">1</span> &lt;&lt; i; <span class="comment">// 当前层的节点数</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; layer_size; ++j) &#123;</span><br><span class="line">            <span class="type">int</span> idx = (<span class="number">1</span> &lt;&lt; i) + j; <span class="comment">// 当前节点索引</span></span><br><span class="line">            <span class="keyword">if</span> (idx % <span class="number">2</span> == <span class="number">0</span>) &#123;</span><br><span class="line">                tree_left[idx] = tree_left[idx / <span class="number">2</span>]; <span class="comment">// 左孩子继承父节点的前缀和</span></span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                tree_left[idx] = tree_left[idx / <span class="number">2</span>] + tree_top[idx - <span class="number">1</span>]; <span class="comment">// 右孩子加上左兄弟节点的值</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="comment">// ====== 归约阶段（从叶子向根方向）======</span></span><br><span class="line">    <span class="comment">// 多线程执行归约</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; k; ++i) &#123;</span><br><span class="line">        <span class="type">int</span> thread_count = <span class="number">1</span> &lt;&lt; (k - i - <span class="number">1</span>); <span class="comment">// 当前层线程数</span></span><br><span class="line">        std::vector&lt;std::thread&gt; threads;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; thread_count; ++j) &#123;</span><br><span class="line">            threads.<span class="built_in">emplace_back</span>(reduce_layer, i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> &amp;t : threads) t.<span class="built_in">join</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ====== 扩展阶段（从根向叶方向）======</span></span><br><span class="line">    tree_left[<span class="number">0</span>] = <span class="number">0</span>; <span class="comment">// 根的左前缀和为 0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 多线程执行扩展</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; k; ++i) &#123;</span><br><span class="line">        <span class="type">int</span> thread_count = <span class="number">1</span> &lt;&lt; i; <span class="comment">// 当前层线程数</span></span><br><span class="line">        std::vector&lt;std::thread&gt; threads;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; thread_count; ++j) &#123;</span><br><span class="line">            threads.<span class="built_in">emplace_back</span>(expand_layer, i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> &amp;t : threads) t.<span class="built_in">join</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>归约阶段</strong>：</p>
<ul>
<li>利用线程池对每一层的节点进行并行处理。</li>
<li><code>reduce_layer</code> 是一个 lambda 函数，用于计算每一层的节点累积值。</li>
</ul>
<p><strong>扩展阶段</strong>：</p>
<ul>
<li>同样使用线程池完成每一层的前缀和传播。</li>
<li><code>expand_layer</code> 是一个 lambda 函数，计算每个节点的前缀和。</li>
</ul>
<p><strong>线程池管理</strong>：</p>
<ul>
<li>每层节点的数量决定了需要启动的线程数。</li>
<li><code>std::thread</code> 管理每个线程，<code>join</code> 确保主线程等待所有子线程完成。</li>
</ul>
<hr>
<h2 id="Max-Subsequence-Sum"><a href="#Max-Subsequence-Sum" class="headerlink" title="Max Subsequence Sum"></a>Max Subsequence Sum</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// CUDA内核：计算最大子段和</span></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">maxSubarraySumKernel</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> *result, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="keyword">extern</span> __shared__ <span class="type">int</span> sharedData[];</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="type">int</span> start = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (start &lt; n) &#123;</span><br><span class="line">        sharedData[tid] = arr[start];</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        sharedData[tid] = <span class="number">0</span>;  <span class="comment">// 边界处理</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 进行归并操作，合并子数组求和</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> stride = <span class="number">1</span>; stride &lt;= blockDim.x / <span class="number">2</span>; stride *= <span class="number">2</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (tid % (<span class="number">2</span> * stride) == <span class="number">0</span> &amp;&amp; tid + stride &lt; blockDim.x) &#123;</span><br><span class="line">            sharedData[tid] += sharedData[tid + stride];</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 线程0将每个块的结果存储到result数组中</span></span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>) &#123;</span><br><span class="line">        result[blockIdx.x] = sharedData[<span class="number">0</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> numElements = <span class="number">1024</span>;</span><br><span class="line">    <span class="type">int</span> h_input[numElements];</span><br><span class="line">    <span class="type">int</span> *d_input, *d_result;</span><br><span class="line">    <span class="type">int</span> h_result[<span class="number">32</span>];  <span class="comment">// 假设最多32个块</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 初始化输入数据</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; numElements; i++) &#123;</span><br><span class="line">        h_input[i] = rand() % <span class="number">100</span> - <span class="number">50</span>;  <span class="comment">// 生成[-50, 50]之间的随机数</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cudaMalloc((<span class="type">void</span>**)&amp;d_input, numElements * <span class="keyword">sizeof</span>(<span class="type">int</span>));</span><br><span class="line">    cudaMalloc((<span class="type">void</span>**)&amp;d_result, <span class="number">32</span> * <span class="keyword">sizeof</span>(<span class="type">int</span>));  <span class="comment">// 假设最多32个块</span></span><br><span class="line"></span><br><span class="line">    cudaMemcpy(d_input, h_input, numElements * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 启动kernel：假设我们使用32个线程块，每个线程块处理32个元素</span></span><br><span class="line">    maxSubarraySumKernel&lt;&lt;&lt;<span class="number">32</span>, <span class="number">32</span>, <span class="number">32</span> * <span class="keyword">sizeof</span>(<span class="type">int</span>)&gt;&gt;&gt;(d_input, d_result, numElements);</span><br><span class="line"></span><br><span class="line">    cudaMemcpy(h_result, d_result, <span class="number">32</span> * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 在主机上进一步合并各个线程块的结果</span></span><br><span class="line">    <span class="type">int</span> maxSum = h_result[<span class="number">0</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; <span class="number">32</span>; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (h_result[i] &gt; maxSum) &#123;</span><br><span class="line">            maxSum = h_result[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;最大子段和: %d\n&quot;</span>, maxSum);</span><br><span class="line"></span><br><span class="line">    cudaFree(d_input);</span><br><span class="line">    cudaFree(d_result);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Merge-Sort"><a href="#Merge-Sort" class="headerlink" title="Merge Sort"></a>Merge Sort</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// CUDA内核：归并操作</span></span><br><span class="line">__device__ <span class="type">void</span> <span class="title function_">merge</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> left, <span class="type">int</span> mid, <span class="type">int</span> right)</span> &#123;</span><br><span class="line">    <span class="type">int</span> n1 = mid - left + <span class="number">1</span>;</span><br><span class="line">    <span class="type">int</span> n2 = right - mid;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> *L = new <span class="type">int</span>[n1];</span><br><span class="line">    <span class="type">int</span> *R = new <span class="type">int</span>[n2];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n1; i++) &#123;</span><br><span class="line">        L[i] = arr[left + i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n2; i++) &#123;</span><br><span class="line">        R[i] = arr[mid + <span class="number">1</span> + i];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> i = <span class="number">0</span>, j = <span class="number">0</span>, k = left;</span><br><span class="line">    <span class="keyword">while</span> (i &lt; n1 &amp;&amp; j &lt; n2) &#123;</span><br><span class="line">        <span class="keyword">if</span> (L[i] &lt;= R[j]) &#123;</span><br><span class="line">            arr[k++] = L[i++];</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            arr[k++] = R[j++];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span> (i &lt; n1) &#123;</span><br><span class="line">        arr[k++] = L[i++];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span> (j &lt; n2) &#123;</span><br><span class="line">        arr[k++] = R[j++];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    delete[] L;</span><br><span class="line">    delete[] R;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// CUDA内核：并行归并排序</span></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">mergeSortKernel</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> left, <span class="type">int</span> right)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (left &lt; right) &#123;</span><br><span class="line">        <span class="type">int</span> mid = left + (right - left) / <span class="number">2</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 对左右部分递归排序</span></span><br><span class="line">        <span class="keyword">if</span> (threadIdx.x == <span class="number">0</span>) &#123;</span><br><span class="line">            mergeSortKernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;(arr, left, mid);  <span class="comment">// 排序左半部分</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (threadIdx.x == <span class="number">1</span>) &#123;</span><br><span class="line">            mergeSortKernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;(arr, mid + <span class="number">1</span>, right); <span class="comment">// 排序右半部分</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 合并两个已排序的部分</span></span><br><span class="line">        merge(arr, left, mid, right);  <span class="comment">// 合并两部分</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> numElements = <span class="number">1024</span>;</span><br><span class="line">    <span class="type">int</span> h_input[numElements];</span><br><span class="line">    <span class="type">int</span> *d_input;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 初始化输入数据</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; numElements; i++) &#123;</span><br><span class="line">        h_input[i] = rand() % <span class="number">1000</span>;  <span class="comment">// 生成随机数</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cudaMalloc((<span class="type">void</span>**)&amp;d_input, numElements * <span class="keyword">sizeof</span>(<span class="type">int</span>));</span><br><span class="line">    cudaMemcpy(d_input, h_input, numElements * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 启动归并排序内核：使用多个线程块</span></span><br><span class="line">    mergeSortKernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">2</span>&gt;&gt;&gt;(d_input, <span class="number">0</span>, numElements - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将排序结果从设备复制回主机</span></span><br><span class="line">    cudaMemcpy(h_input, d_input, numElements * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 打印排序结果</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; numElements; i++) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, h_input[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line"></span><br><span class="line">    cudaFree(d_input);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Quick-Sort"><a href="#Quick-Sort" class="headerlink" title="Quick Sort"></a>Quick Sort</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// CUDA内核：执行快速排序的分区操作</span></span><br><span class="line">__device__ <span class="type">int</span> <span class="title function_">partition</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> low, <span class="type">int</span> high)</span> &#123;</span><br><span class="line">    <span class="type">int</span> pivot = arr[high]; <span class="comment">// 选择最右边的元素作为基准</span></span><br><span class="line">    <span class="type">int</span> i = low - <span class="number">1</span>;  <span class="comment">// i是小于基准元素的子数组的最后一个元素的索引</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> j = low; j &lt; high; j++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (arr[j] &lt;= pivot) &#123;</span><br><span class="line">            i++;</span><br><span class="line">            <span class="comment">// 交换arr[i]和arr[j]</span></span><br><span class="line">            <span class="type">int</span> temp = arr[i];</span><br><span class="line">            arr[i] = arr[j];</span><br><span class="line">            arr[j] = temp;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 将基准元素放到正确的位置</span></span><br><span class="line">    <span class="type">int</span> temp = arr[i + <span class="number">1</span>];</span><br><span class="line">    arr[i + <span class="number">1</span>] = arr[high];</span><br><span class="line">    arr[high] = temp;</span><br><span class="line">    <span class="keyword">return</span> i + <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// CUDA内核：快速排序</span></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">quickSortKernel</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> low, <span class="type">int</span> high)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (low &lt; high) &#123;</span><br><span class="line">        <span class="comment">// 分区</span></span><br><span class="line">        <span class="type">int</span> pi = partition(arr, low, high);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 使用多个线程并行处理子数组</span></span><br><span class="line">        <span class="keyword">if</span> (threadIdx.x == <span class="number">0</span>) &#123;</span><br><span class="line">            quickSortKernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;(arr, low, pi - <span class="number">1</span>);  <span class="comment">// 排序左子数组</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (threadIdx.x == <span class="number">1</span>) &#123;</span><br><span class="line">            quickSortKernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;(arr, pi + <span class="number">1</span>, high); <span class="comment">// 排序右子数组</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> numElements = <span class="number">1024</span>;</span><br><span class="line">    <span class="type">int</span> h_input[numElements];</span><br><span class="line">    <span class="type">int</span> *d_input;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 初始化输入数据</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; numElements; i++) &#123;</span><br><span class="line">        h_input[i] = rand() % <span class="number">1000</span>;  <span class="comment">// 生成随机数</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cudaMalloc((<span class="type">void</span>**)&amp;d_input, numElements * <span class="keyword">sizeof</span>(<span class="type">int</span>));</span><br><span class="line">    cudaMemcpy(d_input, h_input, numElements * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 启动快速排序内核：使用多个线程块</span></span><br><span class="line">    quickSortKernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">2</span>&gt;&gt;&gt;(d_input, <span class="number">0</span>, numElements - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将排序结果从设备复制回主机</span></span><br><span class="line">    cudaMemcpy(h_input, d_input, numElements * <span class="keyword">sizeof</span>(<span class="type">int</span>), cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 打印排序结果</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; numElements; i++) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, h_input[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line"></span><br><span class="line">    cudaFree(d_input);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Odd-Even-Merge"><a href="#Odd-Even-Merge" class="headerlink" title="Odd-Even Merge"></a>Odd-Even Merge</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdlib&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;ctime&gt;</span></span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// CUDA 奇偶归并排序核函数</span></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">oddEvenMergeSortKernel</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> n, <span class="type">int</span> step, <span class="type">int</span> halfStep)</span> &#123;</span><br><span class="line">    <span class="type">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 确保线程索引不越界</span></span><br><span class="line">    <span class="keyword">if</span> (i &lt; n / <span class="number">2</span>) &#123;</span><br><span class="line">        <span class="type">int</span> index = i * step; <span class="comment">// 当前线程处理的起始位置</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 找到比较的索引</span></span><br><span class="line">        <span class="type">int</span> first = index;</span><br><span class="line">        <span class="type">int</span> second = index + halfStep;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 比较并交换</span></span><br><span class="line">        <span class="keyword">if</span> (second &lt; n &amp;&amp; arr[first] &gt; arr[second]) &#123;</span><br><span class="line">            <span class="type">int</span> temp = arr[first];</span><br><span class="line">            arr[first] = arr[second];</span><br><span class="line">            arr[second] = temp;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// CUDA 主排序函数</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">cudaOddEvenMergeSort</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="type">int</span> *d_arr;</span><br><span class="line">    <span class="type">size_t</span> size = n * <span class="keyword">sizeof</span>(<span class="type">int</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 申请设备内存</span></span><br><span class="line">    cudaMalloc((<span class="type">void</span>**)&amp;d_arr, size);</span><br><span class="line">    cudaMemcpy(d_arr, arr, size, cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// CUDA 并行处理</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> step = <span class="number">2</span>; step &lt;= n; step &lt;&lt;= <span class="number">1</span>) &#123;          <span class="comment">// 步长从 2 开始，每次翻倍</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> halfStep = step &gt;&gt; <span class="number">1</span>; halfStep &gt; <span class="number">0</span>; halfStep &gt;&gt;= <span class="number">1</span>) &#123; <span class="comment">// 半步</span></span><br><span class="line">            <span class="type">int</span> threadsPerBlock = <span class="number">256</span>;</span><br><span class="line">            <span class="type">int</span> numBlocks = (n / <span class="number">2</span> + threadsPerBlock - <span class="number">1</span>) / threadsPerBlock;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 调用核函数进行并行比较和交换</span></span><br><span class="line">            oddEvenMergeSortKernel&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(d_arr, n, step, halfStep);</span><br><span class="line">            cudaDeviceSynchronize(); <span class="comment">// 同步确保所有线程完成</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将结果拷回主机</span></span><br><span class="line">    cudaMemcpy(arr, d_arr, size, cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 释放设备内存</span></span><br><span class="line">    cudaFree(d_arr);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 打印数组</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">printArray</span><span class="params">(<span class="type">int</span> *arr, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; arr[i] &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 主函数</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> n = <span class="number">8</span>; <span class="comment">// 数组大小</span></span><br><span class="line">    <span class="type">int</span> arr[n] = &#123;<span class="number">9</span>, <span class="number">7</span>, <span class="number">3</span>, <span class="number">8</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">2</span>&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;排序前: &quot;</span>;</span><br><span class="line">    printArray(arr, n);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 执行 CUDA 奇偶归并排序</span></span><br><span class="line">    cudaOddEvenMergeSort(arr, n);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">&quot;排序后: &quot;</span>;</span><br><span class="line">    printArray(arr, n);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="CUDA-并行编程"><a href="#CUDA-并行编程" class="headerlink" title="CUDA 并行编程"></a>CUDA 并行编程</h1><h2 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h2><p><strong>Terminology</strong>:</p>
<ul>
<li><em>==Host==</em>:The CPU and its memory (host memory)</li>
<li><em>==Device==</em>: The GPU and its memory (device memory)</li>
</ul>
<p><strong>函数元关键字</strong>：</p>
<ul>
<li><code>__global__</code>: 一组由 CPU 调用、GPU 执行的并行计算任务<ul>
<li><code>__global__</code> 必须采用 <code>void</code> 返回值类型</li>
<li><code>__global__</code> 函数是异步的，这意味着函数未执行完就返回了控制权。因此，测量内核函数的时间需要同步操作才能获得准确的结果</li>
</ul>
</li>
</ul>
 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> *a, <span class="type">int</span> *b, <span class="type">int</span> *c)</span> &#123;</span><br><span class="line">		*c = *a + *b;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><p><code>__device__</code>: 只能由 GPU 调用的函数</p>
</li>
<li><p><code>__host__</code>: 原来 CPU 调用的函数</p>
</li>
</ul>
<p><strong>函数超参数</strong>：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add&lt;&lt;&lt;gridDim, blockDim&gt;&gt;&gt;(pa, pb, pc);</span><br></pre></td></tr></table></figure>

<p>GPU 结构：Grid -&gt; Block -&gt; Thread</p>
<p>这个 <code>add</code> 函数执行在 Grid，<code>gridDim</code> 就是 Block 数目，<code>blockDim</code> 为 Thread 数目，最基本的并行单位是 Thread，下面的 idx 是全局的线程号， <code>threadIdx</code> 为块内的线程序号，<code>blockIdx</code> 为Grid内的块序号</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241221235324151.png" alt="image-20241221235324151"></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> *a, <span class="type">int</span> *b, <span class="type">int</span> *c)</span> &#123;</span><br><span class="line">		<span class="type">unsigned</span> <span class="type">int</span> idx = threadIdx + blockIdx * blockDim;</span><br><span class="line">    	*c[idx] = *a[idx] + *b[idx];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="编程示例"><a href="#编程示例" class="headerlink" title="编程示例"></a>编程示例</h2><p><code>add&lt;&lt;&lt;(N + M-1) / M,M&gt;&gt;&gt;(d_a, d_b, d_c, N)</code> 保证能够除尽</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// CUDA 内核函数</span></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">vectorAdd</span><span class="params">(<span class="type">const</span> <span class="type">float</span>* A, <span class="type">const</span> <span class="type">float</span>* B, <span class="type">float</span>* C, <span class="type">int</span> N)</span> &#123;</span><br><span class="line">    <span class="comment">// 计算线程索引</span></span><br><span class="line">    <span class="type">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 确保索引在范围内</span></span><br><span class="line">    <span class="keyword">if</span> (i &lt; N) &#123;</span><br><span class="line">        C[i] = A[i] + B[i];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">int</span> N = <span class="number">1000</span>; <span class="comment">// 向量长度</span></span><br><span class="line">    <span class="type">size_t</span> size = N * <span class="keyword">sizeof</span>(<span class="type">float</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 在主机 (CPU) 上分配内存</span></span><br><span class="line">    <span class="type">float</span> *h_A, *h_B, *h_C;</span><br><span class="line">    h_A = (<span class="type">float</span>*)<span class="built_in">malloc</span>(size);</span><br><span class="line">    h_B = (<span class="type">float</span>*)<span class="built_in">malloc</span>(size);</span><br><span class="line">    h_C = (<span class="type">float</span>*)<span class="built_in">malloc</span>(size);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 初始化数据</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++) &#123;</span><br><span class="line">        h_A[i] = i * <span class="number">0.1f</span>;</span><br><span class="line">        h_B[i] = i * <span class="number">0.2f</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 在设备 (GPU) 上分配内存</span></span><br><span class="line">    <span class="type">float</span> *d_A, *d_B, *d_C;</span><br><span class="line">    cudaMalloc((<span class="type">void</span>**)&amp;d_A, size);</span><br><span class="line">    cudaMalloc((<span class="type">void</span>**)&amp;d_B, size);</span><br><span class="line">    cudaMalloc((<span class="type">void</span>**)&amp;d_C, size);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将数据从主机拷贝到设备</span></span><br><span class="line">    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);</span><br><span class="line">    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 设置线程布局</span></span><br><span class="line">    <span class="type">int</span> threadsPerBlock = <span class="number">256</span>; <span class="comment">// 每个线程块包含 256 个线程</span></span><br><span class="line">    <span class="type">int</span> blocksPerGrid = (N + threadsPerBlock - <span class="number">1</span>) / threadsPerBlock; <span class="comment">// 总块数</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 调用 CUDA 内核函数</span></span><br><span class="line">    vectorAdd&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(d_A, d_B, d_C, N);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将结果从设备拷贝回主机</span></span><br><span class="line">    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 验证结果</span></span><br><span class="line">    <span class="type">bool</span> success = <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">fabs</span>(h_C[i] - (h_A[i] + h_B[i])) &gt; <span class="number">1e-5</span>) &#123;</span><br><span class="line">            success = <span class="literal">false</span>;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (success) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Test PASSED!\n&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Test FAILED!\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 清理资源</span></span><br><span class="line">    <span class="built_in">free</span>(h_A);</span><br><span class="line">    <span class="built_in">free</span>(h_B);</span><br><span class="line">    <span class="built_in">free</span>(h_C);</span><br><span class="line">    cudaFree(d_A);</span><br><span class="line">    cudaFree(d_B);</span><br><span class="line">    cudaFree(d_C);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Memory-API"><a href="#Memory-API" class="headerlink" title="Memory API"></a>Memory API</h2><ol>
<li><code>cudaError_t cudaMalloc(void **ptr, size_t size)</code>: 在 GPU 上动态分配内存<ul>
<li><code>ptr</code>: <code>devicePtr</code> 指向显存，通过<code>ptr</code> 修改 <code>devicePtr</code> <ul>
<li><code>malloc</code> 直接返回一个内存指针，而 <code>cudaMalloc</code> 不返回指针，需要传入一个指向 <code>devicePtr</code> 的二级指针 <code>ptr</code>，分配空间后通过 <code>ptr</code>  修改 <code>devicePtr</code></li>
</ul>
</li>
<li><code>size</code>: 分配空间大小，类似 <code>malloc</code> </li>
</ul>
</li>
<li><code>cudaError_t cudaMemcpy(void *dst, const void *src, size_t size, enum cudaMemcpyKind kind)</code>: <ul>
<li><code>dst</code>: 指向拷贝的目的地指针；</li>
<li><code>src</code>: 拷贝源头指针；</li>
<li><code>size</code>: 空间大小；</li>
<li><code>kind</code>: 枚举，拷贝的类型，<code>cudaMemcpyHostToHost</code> <code>cudaMemcpyHostToDevice</code> <code>cudaMemcpyDeviceToHost</code> <code>cudaMemcpyDeviceToDevice</code> 分别表示从主机到主机、从主机到设备、从设备到主机和从设备到设备的拷贝。</li>
</ul>
</li>
<li><code>cudaError_tcudaFree(void *devicePtr)</code>: 释放内存</li>
</ol>
<p>先分配，然后把数据拷贝到GPU，开始调用，调用完拷贝回 CPU</p>
<h3 id="线程同步"><a href="#线程同步" class="headerlink" title="线程同步"></a>线程同步</h3><p><strong>块内同步</strong>：<code>__syncthreads()</code>:</p>
<p><code>__syncthreads()</code> 是 CUDA 编程中的一个同步原语，它用于确保在某个线程块中的所有线程都已完成它们之前的所有指令，然后才能继续执行<code>__syncthreads()</code>之后的指令。这个函数只能在设备代码中使用，例如CUDA内核</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> <span class="title function_">example</span><span class="params">(<span class="type">int</span> *data)</span> &#123;</span><br><span class="line">    <span class="type">int</span> i = threadIdx.x;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 修改共享数据</span></span><br><span class="line">    data[i] += <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 同步所有线程</span></span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 使用其他线程更新的数据</span></span><br><span class="line">    <span class="keyword">if</span> (i &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        data[i] += data[i - <span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><code>__syncthreads()</code>的关键点</p>
<ul>
<li><strong>作用域</strong>：它只对一个线程块内的线程起作用，不会同步整个网格的所有线程。</li>
<li><strong>使用场景</strong>： 当线程写入共享内存，并且这些数据将被线程块中的其他线程读取时，通常需要一个__syncthreads()调用来确保写入完成。 当线程块内的线程可能同时写入同一个位置（导致不确定的结果）或在其他线程完成某些操作之前需要读取数据时，使用__syncthreads()可以避免竞态条件。</li>
<li><strong>注意事项</strong>： 不要在分支条件下不均匀地调用__syncthreads()，这可能会导致死锁。 不要在循环中过度使用__syncthreads()，因为它会阻止线程并行地执行。 CUDA本身不提供跨线程块的同步机制。为了在全网格范围内实现同步，程序员通常需要结束当前的kernel执行并启动一个新的kernel，因为kernel启动之间存在隐式的全局同步。</li>
</ul>
<p><strong>设备同步</strong>：<code>cudaDeviceSynchronize()</code></p>
<p>CUDA 中的线程块（Block）之间<strong>不能直接通信</strong>，即使使用 <code>__syncthreads()</code> 也只对<strong>同一个线程块内部</strong>有效。因此：</p>
<ul>
<li>不同线程块之间的数据依赖需要通过<strong>全局内存</strong>传递，并通过内核（kernel）调用之间进行同步：</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cudaMemcpy(); <span class="comment">// 数据传递</span></span><br><span class="line">cudaDeviceSynchronize(); <span class="comment">// 保证设备执行完前一个 kernel</span></span><br></pre></td></tr></table></figure>

<p>如果线程之间完全没有数据依赖，比如前面提到的<strong>向量加法</strong>示例，每个线程独立计算一个元素，互不干扰，那么不需要任何同步操作：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> <span class="title function_">vectorAdd</span><span class="params">(<span class="type">const</span> <span class="type">float</span>* A, <span class="type">const</span> <span class="type">float</span>* B, <span class="type">float</span>* C, <span class="type">int</span> N)</span> &#123;</span><br><span class="line">    <span class="type">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="keyword">if</span> (i &lt; N) &#123;</span><br><span class="line">        C[i] = A[i] + B[i]; <span class="comment">// 独立计算，无需同步</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://scatteredream.github.io/2025/02/03/rpc-interpretation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars.githubusercontent.com/u/62317679?s=400&v=4">
      <meta itemprop="name" content="碎梦">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="scatteredream's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | scatteredream's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/02/03/rpc-interpretation/" class="post-title-link" itemprop="url">基于 Netty 的 RPC 框架</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-02-03 00:00:00" itemprop="dateCreated datePublished" datetime="2025-02-03T00:00:00+08:00">2025-02-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-05-11 18:41:37" itemprop="dateModified" datetime="2025-05-11T18:41:37+08:00">2025-05-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E9%A1%B9%E7%9B%AE/" itemprop="url" rel="index"><span itemprop="name">项目</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="基于-Netty-的-RPC-框架"><a href="#基于-Netty-的-RPC-框架" class="headerlink" title="基于 Netty 的 RPC 框架"></a>基于 Netty 的 RPC 框架</h1><p>实现要点： </p>
<ul>
<li>实现了 Netty <a href="#%E5%BF%83%E8%B7%B3%E6%9C%BA%E5%88%B6">心跳机制</a>，保持连接。客户端<a href="#%E6%8C%87%E6%95%B0%E9%80%80%E9%81%BF">指数退避</a>重试连接，服务端用线程池处理请求。可选 HTTP 和 Socket。</li>
<li>实现了自定义 RPC <a href="#protocol">通信协议</a>，<a href="#codec">自定义编解码器和拆包解码器</a>解决粘包和半包，实现了 Kryo 等5种<a href="#serialization">序列化方式</a>。</li>
<li><a href="#center">注册中心</a>支持 Nacos 与 Zookeeper，服务发现支持本地缓存、实时监听。除利用健康检查机制外，下线服务还会主动通知注册中心注销，实现优雅下线。支持一致性哈希等3种<a href="#loadbalance">负载均衡</a>算法。</li>
<li>集成 SpringBoot。通过<a href="#annotation">自定义注解</a>，提供者自动扫描并注册服务 Bean，消费者自动注入<a href="#proxy">代理对象</a>。自定义 starter 实现<a href="#autoconfig">自动装配</a>。</li>
<li>参考 Dubbo 实现 <a href="#spi">SPI</a>，支持<a href="#spi1">序列化</a>、<a href="#spi2">服务发现</a>等的动态扩展，实现与类型解耦的<a href="#cache">单例缓存</a>，减少大量冗余的对象创建。</li>
</ul>
<h2 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h2><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/项目架构图.png" alt="项目架构图" style="zoom:67%;" />

<p><code>consumer</code>模块：服务的消费者，依赖于 <code>rpc-client-spring-boot-starter</code> 模块；</p>
<p><code>provider-api</code>模块：服务提供者暴露的API；</p>
<p><code>provider</code>模块：服务的提供者，依赖于 <code>rpc-server-spring-boot-starter</code> 模块：</p>
<p><code>rpc-client-spring-boot</code>模块：rpc 客户端模块，封装客户端发起的请求过程，提供服务发现、动态代理，网络通信等功能；</p>
<p><code>rpc-client-spring-boot-stater</code>模块：是<code>rpc-client-spring-boot</code>的stater模块，负责引入相应依赖进行自动配置；</p>
<p><code>rpc-framework-core</code>模块：是rpc核心依赖，提供负载均衡、服务注册发现、消息协议、消息编码解码、序列化算法；</p>
<p><code>rpc-server-spring-boot</code>模块：rpc 服务端模块，负责启动服务，接受和处理RPC请求，提供服务发布、反射调用等功能；</p>
<p><code>rpc-server-spring-boot-stater</code>模块：是<code>rpc-server-spring-boot</code>的stater模块，负责引入相应依赖进行自动配置；</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/02/03/rpc-interpretation/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://scatteredream.github.io/2025/01/24/408-OS-%E5%B9%B6%E5%8F%91/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars.githubusercontent.com/u/62317679?s=400&v=4">
      <meta itemprop="name" content="碎梦">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="scatteredream's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | scatteredream's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/01/24/408-OS-%E5%B9%B6%E5%8F%91/" class="post-title-link" itemprop="url">并发</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-01-24 00:00:00" itemprop="dateCreated datePublished" datetime="2025-01-24T00:00:00+08:00">2025-01-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-05-05 11:43:28" itemprop="dateModified" datetime="2025-05-05T11:43:28+08:00">2025-05-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/OS/" itemprop="url" rel="index"><span itemprop="name">OS</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h1><h2 id="Thread-A-New-Executor"><a href="#Thread-A-New-Executor" class="headerlink" title="Thread: A New Executor"></a>Thread: A New Executor</h2><h3 id="Different-from-Process"><a href="#Different-from-Process" class="headerlink" title="Different from Process"></a>Different from Process</h3><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241221230956042.png" alt="image-20241221230956042"></p>
<p>线程和进程最大的区别是，线程之间可以共享地址空间，因此线程的上下文切换不需要切换页表，但是每个线程都有独立的执行栈，它们分散在整个地址空间中，任何有关线程执行相关的信息都存在线程的执行栈——线程本地存储(TLS, Thread Local Storage)中。</p>
<ol>
<li><strong>进程是容器</strong>：一个进程可以包含<strong>一个或多个线程</strong>。线程依赖于进程，不能独立存在。</li>
<li><strong>线程属于进程</strong>：线程是进程的一部分，所有线程共享该进程的资源，如代码段、数据段和打开的文件等。</li>
<li><strong>进程管理资源，线程执行任务</strong>：进程管理资源和环境，而线程负责实际计算和操作。</li>
</ol>
<h3 id="Why-Threads"><a href="#Why-Threads" class="headerlink" title="Why Threads?"></a>Why Threads?</h3><p>事实证明，您应该使用线程至少有两个主要原因。</p>
<p>第一个很简单：==并行性==。想象一下，您正在编写一个对非常大的数组执行操作的程序，例如，将两个大数组相加，或者将数组中每个元素的值增加一定量。如果仅在单个处理器上运行，则任务很简单：只需执行每个操作即可完成。 如果在具有多个处理器的系统上执行程序，则可以通过使用每个处理器执行一部分工作来显著加快此过程。将标准单线程程序转换为在多个 CPU 上执行此类工作的程序的任务称为并行化，并且使用每个 CPU 的线程来执行此工作是使程序运行的自然而典型的方法在现代硬件上速度更快。</p>
<p>第二个原因有点微妙：避免由于 I/O 缓慢而**==阻塞程序进度==**。想象一下，您正在编写一个执行不同类型 I/O 的程序：等待发送或接收消息、等待显式磁盘 I/O 完成，甚至（隐式）等待页面错误完成。您的程序可能不想等待，而是希望做其他事情，包括利用 CPU 执行计算，甚至发出进一步的 I/O 请求。使用线程是避免阻塞的自然方法；当程序中的一个线程等待时（即被阻塞等待 I/O），CPU 调度程序可以切换到其他线程，这些线程已准备好运行并执行一些有用的操作。线程允许 I/O 与单个程序中的其他活动重叠，就像多道程序设计对跨程序的进程所做的那样；因此，许多现代基于服务器的应用程序（Web 服务器、数据库管理系统等）在其实现中都使用了线程。</p>
<p>当然，在上述任何一种情况下，您都可以使用多个进程而不是线程。然而，**==线程共享地址空间==<strong>，因此可以轻松共享数据，因此是构建这些类型的程序时的自然选择，</strong>==线程更加轻量==**，切换成本没有那么高。对于逻辑上独立的任务来说，进程是一个更合理的选择，因为这些任务几乎不需要共享内存中的数据结构。</p>
<h3 id="Problems"><a href="#Problems" class="headerlink" title="Problems"></a>Problems</h3><p>一、不可控调度引发的问题：</p>
<ol>
<li>临界区(critical section): 多个任务共享的一片区域</li>
<li>竞态条件(race condition): 多个任务几乎同时读取一片区域，并做了修改，结果不符合预期</li>
<li>不确定性(indeterminate)：多个竞态条件组成程序，导致结果不确定</li>
<li>解决方案：注重原子性<ul>
<li>线程使用互斥(mutex exclusion)原语，保证同时只有一个任务进入临界区修改，避免竞态</li>
<li>原语：若干条指令组成的程序段，用来实现某个特定功能，在执行过程中不可被中断</li>
<li>在<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/192?fromModule=lemma_inlink">操作系统</a>中，某些被进程调用的操作，如队列操作、对信号量的操作、检查启动外设操作等，一旦开始执行，就不能被中断，否则就会出现操作错误，造成系统混乱。</li>
</ul>
</li>
</ol>
<p>二、任务之间应该如何唤醒对方？</p>
<h2 id="POSIX-Thread-API"><a href="#POSIX-Thread-API" class="headerlink" title="POSIX Thread API"></a>POSIX Thread API</h2><h3 id="Structured-“fork-join”-Parallelism"><a href="#Structured-“fork-join”-Parallelism" class="headerlink" title="Structured (“fork-join”) Parallelism"></a>Structured (“fork-join”) Parallelism</h3><h4 id="Compile-and-Run-pthread"><a href="#Compile-and-Run-pthread" class="headerlink" title="Compile and Run: -pthread"></a>Compile and Run: <code>-pthread</code></h4><p>在链接行上，您还必须通过添加 <code>-pthread</code> 标志来显式动态链接 pthreads 库。</p>
<p><code>prompt&gt; gcc -o thread thread.c -Wall -pthread</code> </p>
<p><code>prompt&gt; gcc thread.c -o thread -lpthread</code> </p>
<p>并且要在源码中加入 <code>pthread.h</code></p>
<h4 id="Creation-pthread-create"><a href="#Creation-pthread-create" class="headerlink" title="Creation: pthread_create()"></a>Creation: <code>pthread_create()</code></h4><p><code>create</code>:</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">pthread_create</span><span class="params">(<span class="type">pthread_t</span> *thread,</span></span><br><span class="line"><span class="params">                   <span class="type">const</span> <span class="type">pthread_attr_t</span> *attr,</span></span><br><span class="line"><span class="params">                   <span class="type">void</span> *(*start_routine)(<span class="type">void</span>*),</span></span><br><span class="line"><span class="params">                   <span class="type">void</span> *arg)</span>;</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>参数说明</strong>：<ul>
<li><code>thread</code> 是一个 <code>pthread_t</code> 类型的指针，也就是待初始化的线程指针</li>
<li><code>attr</code> 用来配置这个线程的属性，比如栈大小，线程调度优先级，默认可以为 <code>NULL</code></li>
<li><code>start_routine</code> 是函数指针,,前面是返回值类型，后面是参数类型及个数</li>
<li><code>void *</code> 可以代表任何类型的参数/返回值， <code>arg</code> 和 <code>start_routine</code> 参数类型一致</li>
</ul>
</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    <span class="type">int</span> a;</span><br><span class="line">    <span class="type">int</span> b;</span><br><span class="line">&#125; <span class="type">myarg_t</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> *<span class="title function_">mythread</span><span class="params">(<span class="type">void</span> *arg)</span> &#123;</span><br><span class="line">    <span class="type">myarg_t</span> *args = (<span class="type">myarg_t</span> *) arg;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d %d\n&quot;</span>, args-&gt;a, args-&gt;b);</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *argv[])</span> &#123;</span><br><span class="line">    <span class="type">pthread_t</span> p;</span><br><span class="line">    <span class="type">myarg_t</span> args = &#123; <span class="number">10</span>, <span class="number">20</span> &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> rc = pthread_create(&amp;p, <span class="literal">NULL</span>, mythread, &amp;args);</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们只是创建一个传递两个参数的线程，并将其打包成我们自己定义的单个类型（<code>myarg t</code>）</p>
<p>线程一旦创建，就可以简单地将其参数转换为它期望的类型，从而根据需要解压参数。</p>
<p>创建线程后，您实际上拥有另一个实时的执行实体，具有自己的调用堆栈，与程序中所有当前现有线程在同一地址空间中运行。 </p>
<h4 id="Completion-pthread-join"><a href="#Completion-pthread-join" class="headerlink" title="Completion: pthread_join()"></a>Completion: <code>pthread_join()</code></h4><p><strong><code>join</code></strong>:</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">pthread_join</span><span class="params">(<span class="type">pthread_t</span> thread, <span class="type">void</span> **value_ptr)</span>;</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>参数说明</strong>：<ul>
<li> <code>thread</code> 用于指定要等待哪个线程。该变量由线程创建例程初始化（当您将指向它的指针作为参数传递给 <code>pthread_create()</code> 时）；如果保留，则可以使用它等待线程终止。</li>
<li> <code>value_ptr</code> 是指向 指向期望返回值的指针 的二级指针，因为还没返回，只能传进去一个指针变量，<code>join</code>修改指针就需要传二级指针</li>
</ul>
</li>
</ul>
<p>Usage: </p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span> <span class="type">int</span> a; <span class="type">int</span> b; &#125; <span class="type">myarg_t</span>;</span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span> <span class="type">int</span> x; <span class="type">int</span> y; &#125; <span class="type">myret_t</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> *<span class="title function_">mythread</span><span class="params">(<span class="type">void</span> *arg)</span> &#123;</span><br><span class="line">    <span class="comment">// 这里用的是包装函数，首字母大写，用来应对可能发生的异常</span></span><br><span class="line">    <span class="type">myret_t</span> *rvals = Malloc(<span class="keyword">sizeof</span>(<span class="type">myret_t</span>));</span><br><span class="line">    rvals-&gt;x = <span class="number">1</span>;</span><br><span class="line">    rvals-&gt;y = <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">return</span> (<span class="type">void</span> *) rvals;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *argv[])</span> &#123;</span><br><span class="line">    <span class="type">pthread_t</span> p;</span><br><span class="line">    <span class="type">myret_t</span> *rvals;</span><br><span class="line">    <span class="type">myarg_t</span> args = &#123; <span class="number">10</span>, <span class="number">20</span> &#125;;</span><br><span class="line">    <span class="comment">// 这里用的是包装函数，首字母大写，用来应对可能发生的异常</span></span><br><span class="line">    Pthread_create(&amp;p, <span class="literal">NULL</span>, mythread, &amp;args);</span><br><span class="line">    Pthread_join(p, (<span class="type">void</span> **) &amp;rvals);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;returned %d %d\n&quot;</span>, rvals-&gt;x, rvals-&gt;y);</span><br><span class="line">    <span class="built_in">free</span>(rvals);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在代码中，再次创建单个线程，并通过 <code>myarg_t</code> 结构传递几个参数。要返回值，请使用 <code>myret_t</code> 类型。一旦线程完成运行，一直在 <code>pthread_join()</code> 例程1内等待的主线程就会返回，我们可以访问从线程返回的值，即 <code>myret_t</code> 中的任何内容。 </p>
<p>关于这个例子有几点需要注意：</p>
<ol>
<li><p>首先，很多时候我们不必进行所有这些痛苦的参数打包和拆包。例如，如果我们只是创建一个不带参数的线程，则可以在创建线程时将 <code>NULL</code> 作为参数传入。类似地，如果我们不关心返回值，我们可以将 <code>NULL</code> 传递给 <code>pthread_join()</code>。</p>
</li>
<li><p>```c<br>void *mythread(void *arg) {</p>
<pre><code>long long int value = (long long int) arg;
printf(&quot;%lld\n&quot;, value);
return (void *) (value + 1);
</code></pre>
<p>}<br>int main(int argc, char *argv[]) {</p>
<pre><code>pthread_t p;
long long int rvalue;
Pthread_create(&amp;p, NULL, mythread, (void *) 100);
Pthread_join(p, (void **) &amp;rvalue);
printf(&quot;returned %lld\n&quot;, rvalue);
return 0;
</code></pre>
<p>}</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">   如上图，如果我们只是传递单个值（例如，`long long int`），则不必将其打包为参数。在这种情况下，我们不必将参数和返回值打包在结构体内部。  </span><br><span class="line"></span><br><span class="line">3. ```c</span><br><span class="line">   void *mythread(void *arg) &#123;</span><br><span class="line">       myarg_t *args = (myarg_t *) arg;</span><br><span class="line">       printf(&quot;%d %d\n&quot;, args-&gt;a, args-&gt;b);</span><br><span class="line">       myret_t oops; // ALLOCATED ON STACK: BAD!</span><br><span class="line">       oops.x = 1;</span><br><span class="line">       oops.y = 2;</span><br><span class="line">       return (void *) &amp;oops;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<p>如上图，必须非常小心线程的返回值，永远不要**<u>返回指向线程栈上分配的内容的指针</u>**，因为栈随着函数返回，空间也会自动释放，<code>oops</code>返回的指针指向的是一片不确定区域。</p>
</li>
<li><p>这种 fork-join 式的多线程编程方式是较为普遍的结构化编程方法。但我们应该注意，并非所有多线程代码都使用 <code>join</code> 例程。例如，多线程 Web 服务器可能会创建多个工作线程，然后使用主线程无限期地接受请求并将它们传递给工作线程。因此，此类长期计划可能不需要加入。然而，创建线程来执行特定任务（并行）的并行程序可能会使用 <code>join</code> 来确保所有此类工作在退出或进入下一个计算阶段之前完成。</p>
</li>
</ol>
<h4 id="Mutex-lock-unlock"><a href="#Mutex-lock-unlock" class="headerlink" title="Mutex: lock() unlock()"></a>Mutex: <code>lock()</code> <code>unlock()</code></h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">pthread_mutex_t</span> lock;  <span class="comment">// lock is here</span></span><br><span class="line">pthread_mutex_lock(&amp;lock);  <span class="comment">// LOCK</span></span><br><span class="line">... <span class="comment">// critical section</span></span><br><span class="line">pthread_mutex_unlock(&amp;lock);<span class="comment">// UNLOCK</span></span><br></pre></td></tr></table></figure>

<p>整体结构如上，但是缺乏正确的初始化和各种细节：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">pthread_mutex_t</span> lock = PTHREAD_MUTEX_INITIALIZER;<span class="comment">// 宏，设置为默认的值</span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> rc = pthread_mutex_init(&amp;lock, <span class="literal">NULL</span>);</span><br><span class="line">assert(rc == <span class="number">0</span>); <span class="comment">// always check success!</span></span><br><span class="line">Pthread_mutex_lock(lock);</span><br><span class="line">...</span><br><span class="line">Pthread_mutex_unlock(lock);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Keeps code clean; only use if exit() OK upon failure 包装</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">Pthread_mutex_lock</span><span class="params">(<span class="type">pthread_mutex_t</span> *mutex)</span> &#123;</span><br><span class="line">    <span class="type">int</span> rc = pthread_mutex_lock(mutex);</span><br><span class="line">    assert(rc == <span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><code>int pthread_mutex_init(pthread_mutex_t *mutex, pthread_mutexattr_t)</code>: <ul>
<li><code>pthread_mutexattr_t</code>: 具体的参数设置，可以使用 <code>NULL</code> 作为缺省选项</li>
</ul>
</li>
<li><code>int pthread_mutex_destroy(pthread_mutex_t *mutex)</code>: <ul>
<li>销毁一个已经初始化但未上锁的互斥锁是安全的。</li>
<li>使用完锁资源需要释放 (RAII 的思想) ，只能是被释放，不再被争抢，不再被需要时才可以</li>
</ul>
</li>
</ul>
<p>改进：增加适当的检测错误机制，健壮的程序需要能够应对调用失败的情况（断言）</p>
<p><strong>还有其他与锁交互的例程</strong>：</p>
<ul>
<li><code>int pthread_mutex_trylock(pthread_mutex_t *mutex)</code> 只尝试一次，non-blocking</li>
<li><code>int pthread_mutex_timedlock(pthread_mutex_t *mutex, timespec *tsptr)</code> 尝试一段时间，如果等一段时间获取不到锁就直接返回 <code>ETIMEOUT</code> </li>
</ul>
<h4 id="Condition-Variables-wait-signal"><a href="#Condition-Variables-wait-signal" class="headerlink" title="Condition Variables: wait() signal()"></a>Condition Variables: <code>wait()</code> <code>signal()</code></h4><h5 id="Thread-Interaction"><a href="#Thread-Interaction" class="headerlink" title="Thread Interaction"></a>Thread Interaction</h5><p><code>int pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex)</code></p>
<ul>
<li>使调用的线程休眠，等待唤醒(通常是在程序中的某些内容发生更改，使某个条件发生了变化，而使得 wait 处于的 while 循环条件发生了变化)</li>
<li>您可能会注意到等待调用将 <code>mutex</code> 作为其第二个参数，而 <code>signal</code> 不需要。造成这种差异的原因是 wait 调用除了使调用线程进入睡眠状态之外，还使调用者进入睡眠状态时释放锁。<ul>
<li>进入 wait 状态就会自动 release mutex。当其他线程通过<code>pthread_cond_signal()</code>或<code>pthread_cond_broadcast</code>，把该线程唤醒，之后需要重新获取 mutex 来进行之后的操作</li>
<li>1.将线程加入等待队列 2.将线程持有的锁先释放 这两个步骤必须是原子的</li>
</ul>
</li>
<li>被唤醒之后，从<code>wait</code>返回之前，还应该重新获取锁，防止竞态条件的发生</li>
</ul>
<p><code>int pthread_cond_signal(pthread_cond_t *cond)</code> </p>
<ul>
<li>一旦条件满足，**<code>pthread_cond_signal</code>** 函数可以被用来唤醒至少一个等待该条件(ready ==0)的线程，如果有多个线程阻塞在条件变量上，它们被唤醒的顺序由调度策略决定。</li>
<li>如果没有线程在条件变量上阻塞，调用 <strong><code>pthread_cond_signal</code></strong> ==将不会有任何效果==。</li>
<li>在实际应用中，**<code>pthread_cond_signal</code>** 通常用于<strong>生产者-消费者</strong>问题，其中生产者在添加了新项目后会通知消费者线程。此外，它也用于实现读写锁，以及在两阶段提交算法中通知所有客户端即将提交事务。</li>
<li><code>pthread_cond_broadcast()</code> 用于唤醒当前全部等待的线程</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">pthread_mutex_t</span> mutex = PTHREAD_MUTEX_INITIALIZER;</span><br><span class="line"><span class="type">pthread_cond_t</span> cond = PTHREAD_COND_INITIALIZER;</span><br><span class="line"><span class="type">int</span> ready = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 符合特定条件，进入睡眠</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">thread_function</span><span class="params">(<span class="type">void</span> *arg)</span> &#123;</span><br><span class="line">    pthread_mutex_lock(&amp;mutex);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (!ready) &#123;<span class="comment">//循环检查条件	</span></span><br><span class="line">    	pthread_cond_wait(&amp;cond, &amp;mutex);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 执行当条件满足时的操作</span></span><br><span class="line">    execute_task();</span><br><span class="line">    pthread_mutex_unlock(&amp;mutex);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/***************************************************/</span></span><br><span class="line"><span class="comment">// 改变条件之后，唤起正在等待的线程</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">signal_condition</span><span class="params">()</span> &#123;</span><br><span class="line">    pthread_mutex_lock(&amp;mutex);</span><br><span class="line">    </span><br><span class="line">    ready = <span class="number">1</span>;</span><br><span class="line">    pthread_cond_signal(&amp;cond);</span><br><span class="line">    </span><br><span class="line">    pthread_mutex_unlock(&amp;mutex);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="Simple-Flags"><a href="#Simple-Flags" class="headerlink" title="Simple Flags"></a>Simple Flags</h5><p>请注意，有时很容易使用简单的标志在两个线程之间发出信号，而不是使用条件变量和关联的锁。 例如，我们可以重写上面的等待代码，使其在等待代码中看起来更像这样：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// wait code:</span></span><br><span class="line"><span class="keyword">while</span> (ready == <span class="number">0</span>)</span><br><span class="line">; <span class="comment">// spin</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// notify code:</span></span><br><span class="line">ready = <span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<p><strong>永远不要这样做，原因如下</strong>:</p>
<p>首先，它在很多情况下表现不佳（长时间自旋浪费 CPU 周期）。</p>
<p>其次，容易出错。正如最近的研究表明 ，使用 FLAG 在线程之间进行同步时非常容易出错；在那项研究中，这些临时同步的使用中大约有一半是有问题的！不要偷懒；即使您认为不这样做也可以逃脱，也要使用条件变量。</p>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li><p>Keep simple. 任何在线程之间锁定或发出信号的代码都应该尽可能简单，避免复杂的线程交互</p>
</li>
<li><p><strong>最大限度减少线程交互方式</strong>，尝试将线程交互方式的数量保持在最低限度</p>
</li>
<li><p><strong>初始化</strong>锁和条件变量 (mutex and condition variables) <code>INITIALIZER</code></p>
</li>
<li><p>始终<strong>使用条件变量</strong>在线程之间发出信号。虽然使用简单的 <strong>FLAG</strong> 通常很诱人，但不要这样做</p>
</li>
<li><p>检查函数的<strong>返回码</strong>，比如断言失败导致的返回码会异常</p>
</li>
<li><p>如何向线程传递参数以及线程的返回值。比如<strong>不要返回 指向栈上变量的指针</strong> </p>
</li>
<li><p>每个线程都有<strong>自己的栈</strong>。如果线程正在执行的某个函数内部有一个局部分配的变量，那么它本质上是该<strong>线程私有</strong>的(Thread-Local)；没有其他线程可以（轻松）访问它。要在线程之间共享数据，值必须位于<strong>堆</strong>中或其他可全局访问的区域设置中。  </p>
</li>
</ul>
<h1 id="Locks"><a href="#Locks" class="headerlink" title="Locks"></a>Locks</h1><p>锁——程序员在 OS 调度的基础上实现对调度的最小控制，使调度的混乱状态变得更加可控</p>
<h2 id="Efficient-Lock"><a href="#Efficient-Lock" class="headerlink" title="Efficient Lock"></a>Efficient Lock</h2><ol>
<li>最基本的互斥(<strong>mut</strong>ual <strong>ex</strong>clusion)：能否在 OS 调度下，阻止多个线程同时进入临界区？</li>
<li>公平性(fairness)：是否会有线程始终无法竞争到锁(starvation)?</li>
<li>性能(performance)：在有竞争与没有竞争的情况下，抢锁、释放锁的开支如何？</li>
</ol>
<h2 id="Implementations"><a href="#Implementations" class="headerlink" title="Implementations"></a>Implementations</h2><ul>
<li>完全由软件实现的锁（✕）</li>
<li>硬件支持有更强大的原子指令 + 操作系统调用支持（✓）</li>
</ul>
<h3 id="Control-Interrupts"><a href="#Control-Interrupts" class="headerlink" title="Control Interrupts"></a>Control Interrupts</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">lock</span><span class="params">()</span> &#123;</span><br><span class="line">	DisableInterrupts();</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">unlock</span><span class="params">()</span> &#123;</span><br><span class="line">	EnableInterrupts();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>加锁：关中断</p>
<p>释放锁：开中断</p>
<ul>
<li><p>优点：实现简单，操作系统本身可能会采用这种方式保证访问自己数据结构的原子性</p>
</li>
<li><p>缺点</p>
</li>
</ul>
<ol>
<li>性能开销大：开关中断的指令耗时较长</li>
<li>丢失中断：关中断导致一些中断没有及时被 CPU 接收</li>
<li>调度失效：恶意程序一直运行，而时钟中断被屏蔽，操作系统的抢占式调度失效</li>
</ol>
<h3 id="Spin-Locks"><a href="#Spin-Locks" class="headerlink" title="Spin Locks"></a>Spin Locks</h3><h4 id="Set-flag-after-check"><a href="#Set-flag-after-check" class="headerlink" title="Set flag after check"></a>Set flag <strong>after</strong> check</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> __<span class="title">lock_t</span> &#123;</span> <span class="type">int</span> flag; &#125; <span class="type">lock_t</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">init</span><span class="params">(<span class="type">lock_t</span> *mutex)</span> &#123;</span><br><span class="line">    <span class="comment">// 0 -&gt; lock is available, 1 -&gt; held</span></span><br><span class="line">    mutex-&gt;flag = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// LOCK GAIN</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">lock</span><span class="params">(<span class="type">lock_t</span> *mutex)</span> &#123;</span><br><span class="line">    <span class="keyword">while</span> (mutex-&gt;flag == <span class="number">1</span>) <span class="comment">// TEST the flag</span></span><br><span class="line">    	; <span class="comment">// spin-wait (do nothing)</span></span><br><span class="line">    mutex-&gt;flag = <span class="number">1</span>; <span class="comment">// now SET it!</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">unlock</span><span class="params">(<span class="type">lock_t</span> *mutex)</span> &#123;</span><br><span class="line">    mutex-&gt;flag = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面是简单的 flag 实现的，先检验 FLAG 是否为 1，如果不是就将其设置为 1，否则就自旋等待</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241222220609945.png" alt="image-20241222220609945"></p>
<p>线程1第一次检验到锁是空闲的，于是想将flag设为1，但与此同时也已耗尽时间片，切换到线程2以后线程2依然试图获取锁，结果获取成功，耗尽时间片回到线程1，线程1竟然也成功获取到了锁！</p>
<h4 id="Test-and-Set-TAS"><a href="#Test-and-Set-TAS" class="headerlink" title="Test-and-Set(TAS)"></a>Test-and-Set(<strong>TAS)</strong></h4><p>导致失败的主要原因是检验Test与赋值Set这两个操作并不是原子化的，会出现只执行一半的情况</p>
<p>因此应该改进锁的实现，使用一个硬件原语：TAS(Atomic Exchange)</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">TestAndSet</span><span class="params">(<span class="type">int</span> *old_ptr, <span class="type">int</span> new)</span> &#123;</span><br><span class="line">    <span class="type">int</span> old = *old_ptr; <span class="comment">// fetch old value at old_ptr</span></span><br><span class="line">    *old_ptr = new; <span class="comment">// store ’new’ into old_ptr</span></span><br><span class="line">    <span class="keyword">return</span> old; <span class="comment">// return the old value</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">lock</span><span class="params">(<span class="type">lock_t</span> *lock)</span> &#123;</span><br><span class="line">	<span class="keyword">while</span> (TestAndSet(&amp;lock-&gt;flag, <span class="number">1</span>) == <span class="number">1</span>)</span><br><span class="line">		; <span class="comment">// spin-wait (do nothing)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其中 <code>TestAndSet()</code> 是一个原子命令，功能是：获取旧值，将其设置为新值，然后返回旧值。这三个一定会在一次操作内完成。如果检测到锁被占用，就会<strong>自旋</strong>等待，一旦锁被释放，检测返回值为0的同时将其设置为1，成功获取锁，原子命令要么全部成功要么全部失败。自旋锁（spin lock）需要抢占式调度，通过时钟进行线程的中断。</p>
<h4 id="CAS-LL-SC-and-FAA"><a href="#CAS-LL-SC-and-FAA" class="headerlink" title="CAS, LL-SC and FAA"></a><strong>CAS</strong>, LL-SC and FAA</h4><p><strong>Compare-And-Swap(CAS)</strong></p>
<p>x86 中也叫 Compare-And-Exchange(cmpxchg)</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">CompareAndSwap</span><span class="params">(<span class="type">int</span> *ptr, <span class="type">int</span> expected, <span class="type">int</span> new)</span>&#123;</span><br><span class="line">	<span class="type">int</span> actual = *ptr;</span><br><span class="line">	<span class="keyword">if</span> (actual == expected)&#123;</span><br><span class="line">		*ptr = new;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> actual;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">lock</span><span class="params">(<span class="type">lock_t</span> *lock)</span>&#123;</span><br><span class="line">    <span class="keyword">while</span>(CompareAndSwap(&amp;lock-&gt;flag, <span class="number">0</span>, <span class="number">1</span>) == <span class="number">1</span>)</span><br><span class="line">        ; <span class="comment">// spin-wait (do nothing)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>Load-Linked, Store-Conditional(LL-SC)</strong></p>
<p>MIPS, PowerPC, Alpha, ARM 都有类似功能的指令</p>
<figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Load_Linked(address): <span class="comment">// 读取某地址的值并将该地址标记为“保留地址”</span></span><br><span class="line">    value ← *address          <span class="comment">// 从地址中加载值</span></span><br><span class="line">    LL_reserved ← address      <span class="comment">// 设置保留的地址</span></span><br><span class="line">    <span class="keyword">return</span> value               <span class="comment">// 返回加载的值</span></span><br><span class="line">    </span><br><span class="line">Store_Conditional(address, value): </span><br><span class="line"><span class="comment">// 尝试将值存入地址，但前提是自 LL 设置保留后，该地址未被其他线程修改。</span></span><br><span class="line">    <span class="keyword">if</span> (LL_reserved == address) then  <span class="comment">// 检查是否仍然保留该地址</span></span><br><span class="line">        *address ← value              <span class="comment">// 将值存储到地址中</span></span><br><span class="line">        LL_reserved ← NULL            <span class="comment">// 清除保留状态</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>                      <span class="comment">// 存储成功</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>                      <span class="comment">// 存储失败</span></span><br></pre></td></tr></table></figure>

<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">lock</span><span class="params">(<span class="type">lock_t</span> *lock)</span>&#123;</span><br><span class="line">	<span class="keyword">do</span> &#123;</span><br><span class="line">        <span class="keyword">while</span>(LL(&amp;lock-&gt;flag) == <span class="number">1</span>);  <span class="comment">// 首先加载当前值并标记保留</span></span><br><span class="line">                 ; <span class="comment">//spin-wait</span></span><br><span class="line">    &#125; <span class="keyword">while</span> (SC(&amp;lock-&gt;flag, <span class="number">1</span>) == <span class="number">0</span>);  <span class="comment">// 如果存储失败，则重试</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">lock_boolean_short_circuiting</span><span class="params">(<span class="type">lock_t</span> *lock)</span>&#123;</span><br><span class="line">    <span class="keyword">while</span>(LL(&amp;lock-&gt;flag) || !SC(&amp;lock-&gt;flag, <span class="number">1</span>))  </span><br><span class="line">                 ; <span class="comment">//spin-wait</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol>
<li>A 和 B 都执行 <strong>LL</strong>，地址相同，但状态保存在各自寄存器中。</li>
<li>假设 A 先执行 <strong>SC</strong> 并成功，硬件会==清除== B 的保留状态。</li>
<li>B 执行 <strong>SC</strong> 时发现状态无效，返回失败并进入重试。</li>
</ol>
<p><strong>Fetch-and-Add(FAA)</strong></p>
<figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">FAA(address):</span><br><span class="line">    old_value = *address             <span class="comment">// 读取当前值</span></span><br><span class="line">    *address = old_value + <span class="number">1</span>         <span class="comment">// 增加指定值</span></span><br><span class="line">    <span class="keyword">return</span> old_value                 <span class="comment">// 返回旧值</span></span><br></pre></td></tr></table></figure>

<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">lock_t</span>&#123;</span></span><br><span class="line">    <span class="type">int</span> ticket;<span class="comment">//初始化为0</span></span><br><span class="line">    <span class="type">int</span> turn;<span class="comment">//初始化为0</span></span><br><span class="line">&#125; <span class="type">lock_t</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">lock</span><span class="params">(<span class="type">lock_t</span> *lock)</span>&#123;</span><br><span class="line">    <span class="type">int</span> myturn = FAA(&amp;lock-&gt;ticket);</span><br><span class="line">	<span class="keyword">while</span>(lock-&gt;turn != myturn)</span><br><span class="line">		;   <span class="comment">// spin-wait	</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">unlock</span><span class="params">(<span class="type">lock_t</span> *lock)</span>&#123;</span><br><span class="line">    FAA(&amp;lock-&gt;turn);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol>
<li>每个线程通过 <strong>FAA</strong> 获取一个唯一的排队号 (<strong>myturn</strong>)。</li>
<li>当前服务号 (<strong>ticket</strong>)表示哪个线程正在被服务。</li>
<li>线程不断检查自己的排队号是否等于当前服务号，只有匹配时才能获得锁。</li>
<li>解锁时，将服务号递增，以便下一个线程继续执行。</li>
<li>特性：实现了<strong>公平性</strong>，每个线程最终都有机会被服务，类似排队机制，按照来的先后顺序排队</li>
</ol>
<h4 id="Evaluating-Spin-Locks"><a href="#Evaluating-Spin-Locks" class="headerlink" title="Evaluating Spin Locks"></a>Evaluating Spin Locks</h4><ol>
<li><strong>正确性</strong>: 能够实现最基本的互斥功能，不会被操作系统的调度影响</li>
<li><strong>公平性</strong>: 实际上并不能保证一个竞争的线程一定能够拿到锁，可能会有饥饿的现象发生</li>
<li><strong>性能</strong>: 单核性能差，只有一个执行的单位，如果一个获取锁的线程刚进入临界区就被抢占，那么直到此线程再次被调度之前，其他的等待者必须轮流自旋一整个时间片；而多核环境下，由于是各个线程物理上并行执行(parallel)，因此获取到锁的线程很快就会执行完并释放锁给别人。</li>
</ol>
<h5 id="Priority-Inversion"><a href="#Priority-Inversion" class="headerlink" title="Priority Inversion"></a>Priority Inversion</h5><p>自旋锁适合<strong>短时间的临界区操作</strong>，但不适合长时间持有锁的场景。在等待锁释放时，线程会<strong>忙等待（busy-waiting）</strong>，一直循环检查锁状态，而不会主动放弃 CPU。</p>
<p><strong>高优先级线程 A</strong>：需要自旋锁资源。</p>
<p><strong>低优先级线程 C</strong>：当前持有自旋锁资源。</p>
<p><strong>中优先级线程 B</strong>：占用 CPU 时间，导致 C 无法执行。</p>
<ol>
<li><strong>C 获得锁</strong>并进入临界区，但是此时被更高优先级的 A 抢占。</li>
<li><strong>A 尝试获取锁</strong>，但由于 C 持有锁，A 进入自旋状态忙等待。</li>
<li><strong>B 开始运行</strong>，其优先级高于 C，导致 C 仍然无法继续执行，因此也无法释放锁。</li>
<li><strong>A 等待 C 释放锁，但 C 被 B 抢占</strong> </li>
<li><strong>结果：高优先级的 A 无法执行，但是更低优先级的 B 反而能够顺利执行，优先级反转发生。</strong></li>
</ol>
<p><strong>解决方案：</strong></p>
<p><strong>(1) 优先级继承机制</strong>(Priority inheritance)</p>
<ul>
<li><strong>原理：</strong> 当低优先级线程持有锁，而高优先级线程请求锁时，系统会<strong>临时提高低优先级线程的优先级</strong>到高优先级线程的级别。</li>
<li><strong>效果：</strong> 确保低优先级线程尽快运行并释放锁，防止高优先级线程长期等待。</li>
<li><strong>应用：</strong> 常用于<strong>互斥锁 (mutex)</strong> 中，但自旋锁通常不支持该机制。</li>
</ul>
<p><strong>(2) 使用互斥锁替代自旋锁</strong></p>
<ul>
<li><strong>互斥锁会主动挂起等待线程</strong>，释放 CPU 给其他任务，提高资源调度效率。</li>
<li>适合可能存在较长等待时间的临界区操作，避免忙等待浪费资源。</li>
</ul>
<p><strong>(3) 控制自旋时间或自旋次数</strong></p>
<ul>
<li>设置自旋锁的最大等待时间或循环次数，超过后将线程挂起，而不是一直忙等待。</li>
<li>在 Linux 内核中，可通过**<code>spin_trylock()</code><strong>或</strong>自旋锁超时机制**控制。</li>
</ul>
<p><strong>(4) 避免中间优先级线程干扰，或取消优先级差异</strong></p>
<h3 id="Sleep"><a href="#Sleep" class="headerlink" title="Sleep"></a>Sleep</h3><h4 id="Yield"><a href="#Yield" class="headerlink" title="Yield"></a>Yield</h4><p>改进自旋锁：如果获取不到锁就立即让出 CPU (yield)</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">init</span><span class="params">()</span> &#123;</span><br><span class="line">	flag = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">lock</span><span class="params">()</span> &#123;</span><br><span class="line">	<span class="keyword">while</span> (TestAndSet(&amp;flag, <span class="number">1</span>) == <span class="number">1</span>)</span><br><span class="line">		yield(); <span class="comment">// give up the CPU</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">unlock</span><span class="params">()</span> &#123;</span><br><span class="line">	flag = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>缺点</strong>: <strong>容易受操作系统的调度影响</strong>，可能导致有线程被饿死，并且如果锁的拥有者在进入临界区之后被调度走，其他程序必须反复执行 运行-&gt;让出 的循环，上下文切换成本也不容忽视</p>
<h4 id="Queue-amp-Park-Solaris"><a href="#Queue-amp-Park-Solaris" class="headerlink" title="Queue &amp; Park(Solaris)"></a>Queue &amp; Park(Solaris)</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> __<span class="title">lock_t</span> &#123;</span></span><br><span class="line">    <span class="type">int</span> flag;</span><br><span class="line">    <span class="type">int</span> guard;</span><br><span class="line">    <span class="type">queue_t</span> *q;</span><br><span class="line">&#125; <span class="type">lock_t</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">lock_init</span><span class="params">(<span class="type">lock_t</span> *m)</span> &#123;</span><br><span class="line">    m-&gt;flag = <span class="number">0</span>;</span><br><span class="line">    m-&gt;guard = <span class="number">0</span>;</span><br><span class="line">    queue_init(m-&gt;q);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">lock</span><span class="params">(<span class="type">lock_t</span> *m)</span> &#123;</span><br><span class="line">    <span class="keyword">while</span> (TestAndSet(&amp;m-&gt;guard, <span class="number">1</span>) == <span class="number">1</span>)</span><br><span class="line">    		; <span class="comment">//acquire guard lock by spinning</span></span><br><span class="line">    <span class="keyword">if</span> (m-&gt;flag == <span class="number">0</span>) &#123;</span><br><span class="line">        m-&gt;flag = <span class="number">1</span>; <span class="comment">// lock is acquired</span></span><br><span class="line">        m-&gt;guard = <span class="number">0</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        queue_add(m-&gt;q, gettid());</span><br><span class="line">        m-&gt;guard = <span class="number">0</span>;</span><br><span class="line">        park(); <span class="comment">// sleep here!</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">unlock</span><span class="params">(<span class="type">lock_t</span> *m)</span> &#123;</span><br><span class="line">    <span class="keyword">while</span> (TestAndSet(&amp;m-&gt;guard, <span class="number">1</span>) == <span class="number">1</span>)</span><br><span class="line">    		; <span class="comment">//acquire guard lock by spinning</span></span><br><span class="line">    <span class="keyword">if</span> (queue_empty(m-&gt;q))</span><br><span class="line">        m-&gt;flag = <span class="number">0</span>; <span class="comment">// let go of lock; no one wants it</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        unpark(queue_remove(m-&gt;q)); <span class="comment">// hold lock</span></span><br><span class="line">    								<span class="comment">// (for next thread!)</span></span><br><span class="line">    m-&gt;guard = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>锁外面套了一层 guard 锁，基本思想是，既然不能直接休眠，那就尽量减小自旋等待的范围，原来需要反复自旋获取 flag 锁，并且临界区是整个lock到unlock的区域，现在只需要先自旋获取 guard，临界区只需要获取锁(flag 设置为 1)或者休眠等待锁的释放(唤醒后直接返回，意为锁被上一个线程让了出来)</p>
<p><strong>加锁逻辑</strong>：</p>
<ul>
<li>自旋等待获取 <code>guard</code> </li>
<li>获取 <code>guard</code> 之后，如果 <code>flag</code> 未被占用，则直接获取 lock；</li>
<li>如果 <code>flag</code> 被占用，此时不要直接放弃，而是将自己加入等待队列中，释放 <code>guard</code>，并将自己休眠。先休眠后释放一定会造成死锁</li>
</ul>
<p><strong>释放锁逻辑</strong>：（可控调度的关键）</p>
<ul>
<li><p>自旋等待获取 <code>guard</code> </p>
</li>
<li><p>获取 <code>guard</code> 之后，如果队列为空，直接将 lock 释放，因为没有人正在等待                                                                                               </p>
</li>
<li><p><strong>如果队列不为空，唤醒队头线程，不能将 lock 释放，因为要为下一个要执行的线程保管好锁</strong></p>
</li>
<li><p>被唤醒的线程之前一直阻塞在 <code>park()</code> ，被唤醒之后依然符合 <code>flag == 1</code> 的条件，直接返回，进入临界区。</p>
<ul>
<li><p><code>wakeup race</code>: 如果在 <code>park()</code> 之前切换到了另一个线程（例如，持有锁的线程）可能会导致麻烦，例如，如果该线程随后释放了锁，就会试图唤醒队头线程并FIFO，但是此时线程并没有处于休眠状态，因此唤醒信号丢失，这个线程将永远挂起</p>
</li>
<li><p><strong>解决方案</strong>：Solaris 通过添加第三个系统调用来解决此问题：<code>setpark()</code> 通过调用此例程，线程A可以指示它即将停止(about to park)。如果A随后恰好被中断，并且另一个线程B在A实际调用 park 之前调用了 unpark，则后续 park 会立即返回而不是 sleep</p>
</li>
<li><p>```c<br>void lock(lock_t *m) {</p>
<pre><code>while (TestAndSet(&amp;m-&gt;guard, 1) == 1)
        ; //acquire guard lock by spinning
if (m-&gt;flag == 0) &#123;
    m-&gt;flag = 1; // lock is acquired
    m-&gt;guard = 0;
&#125; else &#123;
    queue_add(m-&gt;q, gettid());
    setpark(); // be about to sleep, ready to receive SIGWAKEUP
    m-&gt;guard = 0; // release guard
    park(); // return immediately if received SIGWAKEUP
&#125;
</code></pre>
<p>}</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 最后返回之前将 `guard` 释放</span><br><span class="line"></span><br><span class="line">也可以将 guard 放入内核中，这样就能保持原子的释放</span><br><span class="line"></span><br><span class="line">#### **Futex**(Linux)</span><br><span class="line"></span><br><span class="line">Linux 提供了一个类似于 Solaris 接口的 futex(**F**ast **U**serspace mu**TEX**)，但提供更多 in-kernel 功能。具体来说，每个 futex 与特定的物理内存位置以及每个 futex 内核队列相关联（**SLAB Allocator**）</span><br><span class="line"></span><br><span class="line">```c</span><br><span class="line">void mutex_lock (int *mutex) &#123;</span><br><span class="line">    int v;</span><br><span class="line">    // Bit 31 was clear(0), we got the mutex (fastpath, no SYSCALL)</span><br><span class="line">    // Set bit 31 to 1, variable mutex is negative now </span><br><span class="line">    if (atomic_bit_test_set (mutex, 31) == 0)</span><br><span class="line">    	return;</span><br><span class="line">    // Not free </span><br><span class="line">    atomic_increment (mutex);</span><br><span class="line">    while (1) &#123;</span><br><span class="line">        // If bit 31 is still 0, there is no contention, acquire the mutex</span><br><span class="line">        if (atomic_bit_test_set (mutex, 31) == 0) &#123;</span><br><span class="line">            atomic_decrement (mutex);</span><br><span class="line">            return;</span><br><span class="line">    	&#125; </span><br><span class="line">        /* </span><br><span class="line">        	First to make sure futex value</span><br><span class="line">        	we are monitoring is negative (locked).</span><br><span class="line">        */ </span><br><span class="line">        v = *mutex;</span><br><span class="line">        if (v &gt;= 0)</span><br><span class="line">            continue;</span><br><span class="line">        futex_wait (mutex, v);// immediately return if v!= *mutex</span><br><span class="line"> 							  // otherwise sleep	</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void mutex_unlock (int *mutex) &#123;</span><br><span class="line">    /* Adding 0x80000000 to counter results in 0 if and</span><br><span class="line">       only if there are not other interested threads </span><br><span class="line">       returns (new_mutex == 0)*/</span><br><span class="line">    if (atomic_add_zero (mutex, 0x80000000))</span><br><span class="line">    	return;</span><br><span class="line"></span><br><span class="line">    // There are other threads waiting for this mutex,</span><br><span class="line">    // wake one of them up.</span><br><span class="line">    futex_wake (mutex);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<blockquote>
<p>它使用单个整数来跟踪锁是否被持有（整数最高位）以及锁上的等待者数量（所有其他位）。 如果整数为负，则保持该锁定（因为设置了高位，并且该位确定整数的符号）</p>
<p>加锁：</p>
<ol>
<li>整数的最高位用来标记锁是否被占用，其余位用来标记等待者数量</li>
<li>如果获取锁失败，说明锁被占用，则低位自增，等待者 + 1</li>
<li>随后再次尝试获取锁（spin for one time，Phase 1）<ul>
<li>如果成功，则低位自减，等待者 - 1</li>
<li>如果失败，即将进入下个阶段(Phase 2)</li>
</ul>
</li>
<li>再次检查锁的状态（避免竞态条件，如果在这期间锁被释放就应该重新尝试获取锁）</li>
</ol>
<p>解锁：</p>
<ol>
<li>检测低位等待者的同时，清除最高位，如果结果不为0，则返回false</li>
<li>false，唤醒等待的线程</li>
</ol>
</blockquote>
<blockquote>
<p><strong>Function Signature</strong>: <code>int futex_wait(int *uaddr, int val)</code></p>
<p><strong>Purpose</strong>: If the <strong>futex word</strong> equals to <strong>val</strong>, the thread is put to sleep. The thread remains asleep until another thread calls <code>futex_wake</code> on the same futex word, signaling that the condition has changed.</p>
<p><strong>Parameters</strong>:</p>
<ul>
<li><code>uaddr</code>: Pointer to the futex word in user space.</li>
<li><code>val</code>: The expected value of the futex word.</li>
</ul>
<p><strong>Return Value</strong>: Returns 0 on success, or an error code on failure.</p>
</blockquote>
<blockquote>
<p><strong>Function Signature</strong>: <code>int futex_wake(int *uaddr, int val)</code></p>
<p><strong>Parameters</strong>:</p>
<ul>
<li><code>uaddr</code>: Pointer to the futex word in user space.</li>
<li><code>val</code>: The number of threads to wake up.</li>
</ul>
<p><strong>Return Value</strong>: Returns the number of threads that were woken up, or an error code on failure.</p>
</blockquote>
<blockquote>
<p><strong>Function Signature</strong>: <code>int atomic_bit_test_set(int *ptr, int bit)</code></p>
<p><strong>Parameters</strong>:</p>
<ul>
<li><code>ptr</code>: Pointer to the integer variable.</li>
<li><code>bit</code>: The bit position to be tested and set.</li>
</ul>
<p><strong>Return Value</strong>: Returns the previous value of the bit (0 or 1).</p>
</blockquote>
<blockquote>
<p><strong>Function Signature</strong>: <code>bool atomic_add_zero(int *ptr, int value)</code></p>
<p><strong>Parameters</strong>:</p>
<ul>
<li><code>ptr</code>: Pointer to the integer variable.</li>
<li><code>value</code>: Value to be added.</li>
</ul>
<p><strong>Return Value</strong>: Returns <code>true</code> if the result is zero, otherwise <code>false</code>.</p>
</blockquote>
<p>一般来说，内核态同步机制需要调用系统调用，来确保只有一个线程能进入互斥区，但如果根本没有竞争对象，则系统调用浪费了性能。</p>
<p>Futex 是一种用户态和内核态混合的同步机制。首先，同步的进程间通过 mmap <strong>共享一段内存</strong>，futex 变量就位于这段共享的内存中，且操作是原子的，当进程尝试进入互斥区<code>lock()</code>或者退出互斥区<code>unlock()</code>的时候，先去查看共享内存中的 futex 变量，如果没有竞争发生，则只修改 futex，而不用再执行系统调用了。当通过访问 futex 变量告诉进程有竞争发生，则还是得执行系统调用去完成相应的处理（<code>wait</code> 或者 <code>wake</code>）</p>
<p>简单的说，futex 就是通过在用户态的检查，如果了解到当前没有竞争就不用陷入内核了，大大提高了低竞争情况下的效率。</p>
<p>假设地址处的值等于预期，对 <code>futex_wait(address,expected) </code>的调用将使调用线程进入睡眠状态。如果不相等，则调用立即返回。对例程 <code>futex_wake(address)</code> 的调用会唤醒正在队列中等待的一个线程。</p>
<ol>
<li><p>Futex 变量的特征：</p>
<p>1）位于共享的用户空间中；</p>
<p>2）是一个32位的整型；</p>
<p>3）对它的操作是原子的。</p>
</li>
<li><p>Futex 在程序 low-contention 的时候能获得比传统同步机制更好的性能。</p>
</li>
<li><p>不要直接使用 Futex 系统调用。</p>
</li>
<li><p>Futex 同步机制可以用于进程间同步，也可以用于线程间同步。</p>
</li>
</ol>
<h5 id="Two-Phase-Locks"><a href="#Two-Phase-Locks" class="headerlink" title="Two-Phase Locks"></a>Two-Phase Locks</h5><p>两阶段锁中，自旋被看作可能很有用，特别是在锁即将被释放的情况下。在 Phase 1，会自旋一段时间，希望能够获取到锁。 如果在 Phase 1 没有获取锁，则进入 Phase 2，调用者将进入睡眠状态，只有在锁稍后释放时才会被唤醒。</p>
<p>上面的 Linux Futex 实现的 Mutex 就是这种锁的一种形式，但它只<strong>自旋一次</strong>；更常见的是在循环中自旋固定的（fixed）次数</p>
<h2 id="Thread-Safe-Data-Structures"><a href="#Thread-Safe-Data-Structures" class="headerlink" title="Thread-Safe Data Structures"></a>Thread-Safe Data Structures</h2><h3 id="Concurrent-Counter"><a href="#Concurrent-Counter" class="headerlink" title="Concurrent Counter"></a>Concurrent Counter</h3><p><strong>Basic Mutex</strong></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241224125018845.png" alt="image-20241224125018845"></p>
<p>简单给访问临界区加锁完全能够保证绝对的线程安全(thread safe)，但是锁的开销非常大</p>
<p><strong>Scalable Counting</strong></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241224134929698.png" alt="image-20241224134929698"></p>
<p>近似计数器：每个CPU有一个局部计数器(local)，所有CPU共享一个全局计数器(global)，局部计数器加到全局计数器上的时候才加给全局计数器加锁，这就显著减少了加锁解锁的次数。</p>
<p>另外，局部锁也是需要的，因为我们假设每个核心上可能有多个线程。相反，如果每个核心上仅运行一个线程，则不需要局部所锁。</p>
<p>为了使全局计数器保持最新（如果线程希望读取其值），通过获取全局锁并将其增加局部计数器的值，局部值会定期传输到全局计数器；然后局部计数器归零。 这种局部到全局传输发生的频率由阈值 S 决定，当局部计数器达到 S 就向全局计数器写入。S 越小，计数器的行为就越像上面的不可扩展计数器； S 越大，计数器的可扩展性就越高，但全局值可能与实际计数相差越远。人们可以简单地获取所有局部锁和全局锁（以指定的顺序，以避免死锁）来获得精确的值，但这是不可扩展的：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241224135017601.png" alt="image-20241224135017601"></p>
<p>图 29.6 显示了阈值 S 的重要性，其中有四个线程，每个线程在四个 CPU 上将计数器递增 100 万次。如果 S 较低，则性能较差（但全局计数总是相当准确）； 如果 S 较高，则性能出色，但全局计数滞后（最多为 CPU 数量乘以 S）。这种准确性/性能权衡正是近似计数器所实现的。</p>
<h3 id="Concurrent-Linked-List"><a href="#Concurrent-Linked-List" class="headerlink" title="Concurrent Linked List"></a>Concurrent Linked List</h3><p><strong>Basic Mutex</strong></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// basic list structure (one used per list)</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> __<span class="title">list_t</span> &#123;</span><span class="type">node_t</span> *head; <span class="type">pthread_mutex_t</span> lock;&#125; <span class="type">list_t</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">List_Insert</span><span class="params">(<span class="type">list_t</span> *L, <span class="type">int</span> key)</span> &#123;</span><br><span class="line">    <span class="type">node_t</span> *new = <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="type">node_t</span>));</span><br><span class="line">    <span class="keyword">if</span> (new == <span class="literal">NULL</span>) &#123;</span><br><span class="line">        perror(<span class="string">&quot;malloc&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span>; <span class="comment">// fail</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    new-&gt;key = key;</span><br><span class="line">    pthread_mutex_lock(&amp;L-&gt;lock);  <span class="comment">// lock</span></span><br><span class="line">    new-&gt;next = L-&gt;head;</span><br><span class="line">    L-&gt;head = new;</span><br><span class="line">    pthread_mutex_unlock(&amp;L-&gt;lock);<span class="comment">// unlock</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">List_Lookup</span><span class="params">(<span class="type">list_t</span> *L, <span class="type">int</span> key)</span> &#123;</span><br><span class="line">    <span class="type">int</span> rv = <span class="number">-1</span>;</span><br><span class="line">    pthread_mutex_lock(&amp;L-&gt;lock);</span><br><span class="line">    <span class="type">node_t</span> *curr = L-&gt;head;</span><br><span class="line">    <span class="keyword">while</span> (curr) &#123;</span><br><span class="line">        <span class="keyword">if</span> (curr-&gt;key == key) &#123;</span><br><span class="line">            rv = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    	curr = curr-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">    pthread_mutex_unlock(&amp;L-&gt;lock); <span class="comment">// failure</span></span><br><span class="line">	<span class="keyword">return</span> rv; <span class="comment">// rv = -1: </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>尽量缩小锁涵盖的范围（临界区大小）如果没有涉及到访问共享区域的就不要纳入范围</li>
<li>使用单一返回路径，减少代码中需要获取、释放锁的地方，降低了返回前忘记释放锁的可能</li>
</ul>
<p><strong>Lock and Control flow</strong>：</p>
<p>在并发编程中，函数通常在开始时获取锁或分配资源、更改状态。如果发生错误，函数必须在退出之前释放锁或释放资源。这个过程很容易出错，因为它需要仔细管理状态。为了避免这些问题，最好以一种尽量<strong>减少撤消状态更改</strong>的方式构建代码。这可以通过以下方式实现：</p>
<ul>
<li><strong>集中错误处理</strong>：谨慎处理导致函数返回、退出或其他停止执行的错误情况的更改，在函数中使用单个退出点来处理所有清理操作。 </li>
<li><strong>最小化模式</strong>：构造代码以尽量减少撤消状态更改的需要，从而降低出错风险。</li>
<li><strong>避免过早返回</strong>：减少函数中的返回语句数量，以确保执行所有必要的清理。 </li>
<li><strong>使用 RAII（资源获取即初始化）</strong>：在支持它的语言中，使用 RAII 自动管理资源。 </li>
</ul>
<p><strong>Hand-over-hand Locking</strong>: </p>
<p>每个节点都有一个锁，替代之前链表的整个链表一个锁，遍历链表时首先抢占下一个节点的锁，然后释放当前节点的锁，一定程度上增加了链表的并发能力，但是开销很大，</p>
<h3 id="Concurrent-Queue"><a href="#Concurrent-Queue" class="headerlink" title="Concurrent Queue"></a>Concurrent Queue</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> __<span class="title">queue_t</span> &#123;</span></span><br><span class="line">	<span class="type">node_t</span> *head; <span class="type">node_t</span> *tail; </span><br><span class="line">    <span class="type">pthread_mutex_t</span> head_lock, tail_lock;</span><br><span class="line">&#125;<span class="type">queue_t</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">Queue_Init</span><span class="params">(<span class="type">queue_t</span> *q)</span> &#123;</span><br><span class="line">    <span class="type">node_t</span> *tmp = <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="type">node_t</span>));</span><br><span class="line">    tmp-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">    q-&gt;head = q-&gt;tail = tmp;</span><br><span class="line">    pthread_mutex_init(&amp;q-&gt;head_lock, <span class="literal">NULL</span>);</span><br><span class="line">    pthread_mutex_init(&amp;q-&gt;tail_lock, <span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">Queue_Enqueue</span><span class="params">(<span class="type">queue_t</span> *q, <span class="type">int</span> value)</span> &#123;</span><br><span class="line">    <span class="type">node_t</span> *tmp = <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="type">node_t</span>));</span><br><span class="line">    assert(tmp != <span class="literal">NULL</span>);</span><br><span class="line">    tmp-&gt;value = value;</span><br><span class="line">    tmp-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    pthread_mutex_lock(&amp;q-&gt;tail_lock);<span class="comment">//在队尾加锁</span></span><br><span class="line">    q-&gt;tail-&gt;next = tmp;</span><br><span class="line">    q-&gt;tail = tmp;</span><br><span class="line">    pthread_mutex_unlock(&amp;q-&gt;tail_lock);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">Queue_Dequeue</span><span class="params">(<span class="type">queue_t</span> *q, <span class="type">int</span> *value)</span> &#123;</span><br><span class="line">    pthread_mutex_lock(&amp;q-&gt;head_lock);</span><br><span class="line">    <span class="type">node_t</span> *tmp = q-&gt;head;</span><br><span class="line">    <span class="type">node_t</span> *new_head = tmp-&gt;next;</span><br><span class="line">    <span class="keyword">if</span> (new_head == <span class="literal">NULL</span>) &#123;</span><br><span class="line">        pthread_mutex_unlock(&amp;q-&gt;head_lock);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>; <span class="comment">// queue was empty</span></span><br><span class="line">    &#125;</span><br><span class="line">    *value = new_head-&gt;value;</span><br><span class="line">    q-&gt;head = new_head;</span><br><span class="line">    pthread_mutex_unlock(&amp;q-&gt;head_lock);</span><br><span class="line">    <span class="built_in">free</span>(tmp);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>队列的加锁特点：</p>
<ul>
<li><p>入队只访问 <code>tail_lock</code> 出队只访问 <code>head_lock</code></p>
</li>
<li><p>在初始化阶段添加了 dummy node 假节点，不然空队列的情况需要同时处理 tail 和 head：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">Queue_Enqueue</span><span class="params">(<span class="type">queue_t</span> *q, <span class="type">int</span> value)</span> &#123;</span><br><span class="line">    <span class="type">node_t</span> *tmp = <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="type">node_t</span>));</span><br><span class="line">    assert(tmp != <span class="literal">NULL</span>);</span><br><span class="line">    tmp-&gt;value = value;</span><br><span class="line">    tmp-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    pthread_mutex_lock(&amp;q-&gt;tail_lock);</span><br><span class="line">    <span class="keyword">if</span> (q-&gt;tail == <span class="literal">NULL</span>) &#123;<span class="comment">// additional if-else!!!</span></span><br><span class="line">        q-&gt;head = q-&gt;tail = tmp;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        q-&gt;tail-&gt;next = tmp;</span><br><span class="line">        q-&gt;tail = tmp;</span><br><span class="line">    &#125;</span><br><span class="line">    pthread_mutex_unlock(&amp;q-&gt;tail_lock);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">Queue_Dequeue</span><span class="params">(<span class="type">queue_t</span> *q, <span class="type">int</span> *value)</span> &#123;</span><br><span class="line">    pthread_mutex_lock(&amp;q-&gt;head_lock);</span><br><span class="line">    <span class="keyword">if</span> (q-&gt;head == <span class="literal">NULL</span>) &#123;<span class="comment">// additional if-else!!!</span></span><br><span class="line">        pthread_mutex_unlock(&amp;q-&gt;head_lock);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>; <span class="comment">// queue was empty</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">node_t</span> *tmp = q-&gt;head;</span><br><span class="line">    <span class="type">node_t</span> *new_head = tmp-&gt;next;</span><br><span class="line">    <span class="keyword">if</span> (new_head == <span class="literal">NULL</span>) &#123;</span><br><span class="line">        pthread_mutex_unlock(&amp;q-&gt;head_lock);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>; <span class="comment">// queue was empty</span></span><br><span class="line">    &#125;</span><br><span class="line">    *value = new_head-&gt;value;</span><br><span class="line">    q-&gt;head = new_head;</span><br><span class="line">    pthread_mutex_unlock(&amp;q-&gt;head_lock);</span><br><span class="line">    <span class="built_in">free</span>(tmp);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="Concurrent-Hash-Table"><a href="#Concurrent-Hash-Table" class="headerlink" title="Concurrent Hash Table"></a>Concurrent Hash Table</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> BUCKETS (101)</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> __<span class="title">hash_t</span> &#123;</span><span class="type">list_t</span> lists[BUCKETS];&#125; <span class="type">hash_t</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">Hash_Init</span><span class="params">(<span class="type">hash_t</span> *H)</span> &#123;</span><br><span class="line">    <span class="type">int</span> i;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; BUCKETS; i++)</span><br><span class="line">    	List_Init(&amp;H-&gt;lists[i]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">Hash_Insert</span><span class="params">(<span class="type">hash_t</span> *H, <span class="type">int</span> key)</span> &#123;</span><br><span class="line">	<span class="keyword">return</span> List_Insert(&amp;H-&gt;lists[key % BUCKETS], key);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">Hash_Lookup</span><span class="params">(<span class="type">hash_t</span> *H, <span class="type">int</span> key)</span> &#123;</span><br><span class="line">	<span class="keyword">return</span> List_Lookup(&amp;H-&gt;lists[key % BUCKETS], key);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241224205440775.png" alt="image-20241224205440775"></p>
<p>如图所示，哈希表中，每个桶都是一个单独的链表，因此，比单独的大锁并发链表性能好很多。</p>
<h1 id="Condition-Variables"><a href="#Condition-Variables" class="headerlink" title="Condition Variables"></a>Condition Variables</h1><p>任何线程库的另一个主要组件是条件变量，主要用于线程间交互。</p>
<p>概念上，一个条件变量就是一个线程队列(thread queue)， 其中的线程正等待某个条件变为真，比如 <code>ready == 0</code>，每个条件变量$c$关联着一个<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%96%B7%E8%A8%80_(%E7%A8%8B%E5%BC%8F)">断言</a>，当一个线程等待时，该线程不算作占用了该管程，因而其它线程可以进入该管程执行，改变管程的状态，通知条件变量$c$其关联的断言$P_c$在当前状态下为真。</p>
<p>条件变量同锁一起使用使得线程可以以一种**<u>无竞争</u>**的方式等待任意条件的发生。所谓无竞争就是，条件改变之后这个信号会发送到所有等待这个信号的线程。而不是说一个线程接受到这个消息而其它线程就接收不到了。</p>
<h2 id="Precautions"><a href="#Precautions" class="headerlink" title="Precautions"></a>Precautions</h2><h3 id="“Wakeup”"><a href="#“Wakeup”" class="headerlink" title="“Wakeup”"></a>“Wakeup”</h3><p>线程状态:Ready, Run, Sleep</p>
<p><code>wait</code>: Run-&gt;Sleep</p>
<p><code>signal</code>: Sleep-&gt;Ready </p>
<h3 id="Specific-Condition"><a href="#Specific-Condition" class="headerlink" title="Specific Condition"></a>Specific Condition</h3><p>条件变量必须跟布尔条件挂钩，如果只是单纯地地像下面这样使用条件变量：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">thr_exit()&#123;</span><br><span class="line">	<span class="comment">// done = 1;</span></span><br><span class="line">	mutex_lock(&amp;m);</span><br><span class="line">	cond_signal(&amp;c);</span><br><span class="line">	mutex_unlock(&amp;m);</span><br><span class="line">&#125;</span><br><span class="line">thr_join()&#123;</span><br><span class="line">	mutex_lock(&amp;m);</span><br><span class="line">	<span class="comment">//while(done == 0)</span></span><br><span class="line">	cond_wait(&amp;c);</span><br><span class="line">	mutex_unlock(&amp;m);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在父线程调用join之前，子线程创建并运行了exit，就会导致空唤醒，父线程将持续睡下去。</p>
<h3 id="Recheck-While-Loop"><a href="#Recheck-While-Loop" class="headerlink" title="Recheck: While Loop"></a>Recheck: <strong>While</strong> Loop</h3><h4 id="Mesa-Semantic"><a href="#Mesa-Semantic" class="headerlink" title="Mesa Semantic"></a>Mesa Semantic</h4><p>发信号只是一个状态改变的暗示，并不能保证他运行之前的状态一直是期望的情况，线程的 Ready 和 Run 之间的状态转换是由调度程序决定的，<code>signal</code> 以后，Run 之前可能状态会发生变化。</p>
<p>另一个是Hoare Semantic 能直接唤醒线程立即执行，几乎所有系统都采用了前者的语义。</p>
<h4 id="Lost-Wakeup"><a href="#Lost-Wakeup" class="headerlink" title="Lost Wakeup"></a>Lost Wakeup</h4><p>条件变量代表的是一种条件，需要将 <code>pthread_cond_wait</code> 放在一个 while 循环，而不是 if 语句中，因为很可能会出现在wait之前正好切换走了，这时候signal信号就会丢失。所以线程被唤醒后必须重新检查当时的条件是否仍然满足，如若仍然满足 while 循环的条件，就不能继续执行。</p>
<p>假设线程 A 和线程 B 都在等待同一个条件变量，并且导致线程休眠的条件布尔值最初为 <code>false</code>：</p>
<ol>
<li>线程 A 进入等待状态：<ul>
<li><code>pthread_cond_wait(&amp;cond, &amp;mutex)</code> </li>
</ul>
</li>
<li>线程 B 也进入等待状态；</li>
<li>某个线程 C 修改了条件布尔值为 <code>true</code>，并通过条件变量发送信号唤醒线程：<ul>
<li><code>pthread_cond_signal(&amp;cond)</code>。</li>
</ul>
</li>
<li>线程 A 被唤醒，并退出等待。此时它执行任务后将条件变量重新置为 <code>false</code>。</li>
<li><strong>问题：</strong> 线程 B 也被唤醒，但条件变量已被线程 A 改回 <code>false</code>。<ul>
<li>如果使用 <code>if</code> 检查条件，线程 B 会直接跳过检查并继续执行任务，从而导致程序逻辑错误。</li>
</ul>
</li>
</ol>
<p><strong>解决方案：用 <code>while</code> 再次检查条件</strong>：</p>
<ul>
<li>当线程 B 被唤醒时，<code>while</code> 循环会再次检查条件变量，发现条件未满足，然后重新进入等待状态，确保安全。</li>
</ul>
<h4 id="Spurious-Wakeup"><a href="#Spurious-Wakeup" class="headerlink" title="Spurious Wakeup"></a>Spurious Wakeup</h4><p>有一些 pthread 实现可能会<strong>虚假地唤醒</strong>多个正在等待的线程；在这种情况下，在不重新检查的情况下，等待线程将继续认为条件已更改，即使它没有更改。因此，应该树立起一个恒等式:</p>
<p>被唤醒⇔条件确实已经改变</p>
<h3 id="Hold-the-Lock-When-signal-or-wait"><a href="#Hold-the-Lock-When-signal-or-wait" class="headerlink" title="Hold the Lock When signal() or wait()"></a>Hold the Lock When <code>signal()</code> or <code>wait()</code></h3><p> ==使用条件变量的前提是必须要持有这把锁== </p>
<p><strong>想象一下</strong>：一个线程是某个队列的消费者，它必须要等到队列中有数据时才能执行，如果队列为空，则会一直等待挂起，直到另外一个线程在队列中存入数据，并<strong>通知</strong>先前挂起的线程，该线程才会唤醒重新开始执行。在这个例子中，队列是否 空/满 是线程执行所依赖的状态，而这个状态是多个线程都可以访问的，所以需要加锁互斥访问，这种加锁模式与其他同步加锁略有不同：</p>
<p>锁在 <code>wait</code> 调用中，休眠前需要释放锁，唤醒之后，返回之前需要重新获取锁</p>
<h3 id="Covering-Conditions-broadcast"><a href="#Covering-Conditions-broadcast" class="headerlink" title="Covering Conditions: broadcast()"></a>Covering Conditions: <code>broadcast()</code></h3><p>考虑分配内存的场景：</p>
<ol>
<li>有多个想要申请不同空间的线程，但是此时没有足够空间，因此他们陷入了睡眠；</li>
<li>此时第三个线程释放了一定的空间，想要唤醒，但唤醒哪一个是不确定的，可能释放的空间不足以支持被唤醒者申请的空间；</li>
<li>因此需要唤醒所有在此CV上等待的线程：<code>broadcast()</code></li>
</ol>
<h2 id="Producer-Consumer-Problem"><a href="#Producer-Consumer-Problem" class="headerlink" title="Producer/Consumer Problem"></a>Producer/Consumer Problem</h2><p>生产者/消费者问题 或 有界缓冲区问题：</p>
<ul>
<li>生产者：从缓冲区中拿东西，如果没东西可拿就应该阻塞</li>
<li>消费者：向缓冲区中放东西，如果缓冲区满了就应当阻塞</li>
</ul>
<p>因此要注意如下事项：</p>
<ol>
<li>不能唤醒同类：生产者和消费者应该使用两个不同的条件变量</li>
<li>while 循环：重新检查条件，以防在 Run 之前，条件发生改变</li>
</ol>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> MAXSIZE 8</span></span><br><span class="line"><span class="type">int</span> buffer[MAXSIZE];</span><br><span class="line"><span class="type">int</span> fill_ptr = <span class="number">0</span>;</span><br><span class="line"><span class="type">int</span> use_ptr = <span class="number">0</span>;</span><br><span class="line"><span class="type">int</span> count = <span class="number">0</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">put</span><span class="params">(<span class="type">int</span> value)</span>&#123;</span><br><span class="line">    buffer[fill_ptr] = value;</span><br><span class="line">	fill_ptr = (fill_ptr + <span class="number">1</span>) % MAXSIZE;</span><br><span class="line">    count++;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">get</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> tmp = buffer[use_ptr];</span><br><span class="line">    fill_ptr = (fill_ptr + <span class="number">1</span>) % MAXSIZE;</span><br><span class="line">    count--;</span><br><span class="line">    <span class="keyword">return</span> tmp;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">cond_t</span> isEmpty,isFull;</span><br><span class="line"><span class="type">mutex_t</span> mutex;</span><br><span class="line"><span class="type">void</span> <span class="title function_">producer</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>;i &lt; loops;i++)&#123;</span><br><span class="line">        mutex_lock(&amp;mutex);</span><br><span class="line">        <span class="keyword">while</span>(count == MAXSIZE)</span><br><span class="line">            cond_wait(&amp;isFull, &amp;mutex);</span><br><span class="line">    	put(i);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;producer:%d puts value:%d&quot;</span>, gettid(), i);</span><br><span class="line">        cond_signal((&amp;isEmpty);</span><br><span class="line">    	mutex_unlock(&amp;mutex);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> consumer()&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>;i &lt; loops;i++)&#123;</span><br><span class="line">        mutex_lock(&amp;mutex);</span><br><span class="line">        <span class="keyword">while</span>(count == <span class="number">0</span>)</span><br><span class="line">            cond_wait(&amp;isEmpty, &amp;mutex);</span><br><span class="line">        <span class="type">int</span> value = get();</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;pid:%d gets value:%d&quot;</span>, gettid(), value);</span><br><span class="line">        cond_signal(&amp;isFull);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="Semaphores"><a href="#Semaphores" class="headerlink" title="Semaphores"></a>Semaphores</h1><p><strong>互斥</strong>：是指某一资源同时只允许一个访问者对其进行访问，具有唯一性和排它性。但互斥无法限制访问者对资源的访问顺序，即访问是无序的。 </p>
<p><strong>同步</strong>：指在互斥的基础上（大多数情况），通过其它机制实现访问者对资源的有序访问。在大多数情况下，同步已经实现了互斥，特别是所有写入资源的情况必定是互斥的。少数情况是指可以允许多个访问者同时访问资源</p>
<p>Semaphore <strong>支持跨进程的同步</strong>，是线程同步所有工作的单一原语，能够将其作为锁或条件变量</p>
<p>Condition Variable 只支持同一进程内部线程的同步</p>
<table>
<thead>
<tr>
<th>特性</th>
<th>信号量（Semaphore）</th>
<th>锁（Mutex）</th>
<th>条件变量（Condition Variable）</th>
</tr>
</thead>
<tbody><tr>
<td><strong>功能</strong></td>
<td>控制资源数量（同步和互斥）</td>
<td>提供互斥访问</td>
<td>等待特定条件满足后继续执行</td>
</tr>
<tr>
<td><strong>适用场景</strong></td>
<td>资源控制、多线程队列</td>
<td>保护临界区，单资源互斥</td>
<td>条件等待（生产者/消费者问题）</td>
</tr>
<tr>
<td><strong>能否跨进程</strong></td>
<td><strong>支持跨进程</strong></td>
<td>仅限线程同步（同一进程内）</td>
<td>仅限线程同步（同一进程内）</td>
</tr>
<tr>
<td><strong>是否需要互斥锁</strong></td>
<td><strong>不需要互斥锁</strong></td>
<td>自带互斥功能，不需要额外锁</td>
<td>必须依赖互斥锁来保护共享变量</td>
</tr>
<tr>
<td><strong>复杂条件判断</strong></td>
<td><strong>支持简单条件</strong>（通过计数控制）</td>
<td><strong>不支持条件判断</strong></td>
<td><strong>支持复杂条件</strong>判断和线程等待唤醒机制</td>
</tr>
</tbody></table>
<h2 id="POSIX-API"><a href="#POSIX-API" class="headerlink" title="POSIX API"></a>POSIX API</h2><p>POSIX API 给信号量添加了两个调用，这两个调用都是原子操作：</p>
<h3 id="sem-wait-sem-t-s-P"><a href="#sem-wait-sem-t-s-P" class="headerlink" title="sem_wait(sem_t *s)(P())"></a><code>sem_wait(sem_t *s)</code>(<code>P()</code>)</h3><p>信号量值减1，若变为负数，则阻塞在信号量上（信号量负数绝对值为阻塞的线程数量）</p>
<h3 id="sem-post-sem-t-s-V"><a href="#sem-post-sem-t-s-V" class="headerlink" title="sem_post(sem_t *s)(V())"></a><code>sem_post(sem_t *s)</code>(<code>V()</code>)</h3><p>将信号量的值加1，如果信号量值为负数，则肯定有线程正在此信号量上等待，唤醒其中一个线程</p>
<h2 id="Binary-Semaphores-Locks"><a href="#Binary-Semaphores-Locks" class="headerlink" title="Binary Semaphores: Locks"></a>Binary Semaphores: Locks</h2><p><strong>Workflow</strong>:</p>
<ol>
<li>信号量的初始值为 1，线程 A 调用 <code>sem_wait(*s)</code> 此时信号量为 0，直接返回，进入临界区</li>
<li>此时另一个线程 B 过来调用 <code>sem_wait(*s)</code> 此时信号量为 -1，休眠……</li>
<li>线程 A 完成临界区操作，调用 <code>sem_post(*s)</code> 此时信号量变成 0，唤醒线程 B </li>
<li>线程 B 从 <code>wait()</code> 返回，进入临界区</li>
</ol>
<p>因此二值信号量能够实现锁的功能。</p>
<h2 id="Semaphores-Condition-Variables"><a href="#Semaphores-Condition-Variables" class="headerlink" title="Semaphores: Condition Variables"></a>Semaphores: Condition Variables</h2><blockquote>
<p>给信号量设置初始值：在初始化之后愿意立即放弃的资源数量有多少？</p>
<ul>
<li><p>如果是锁，只有 1 把锁，那么就必须初始化为 1；</p>
</li>
<li><p>如果是用作任务排序，父进程等待子进程，没有能给出去的东西，那就只能初始化为 0</p>
</li>
<li><p>如果是消费者，一开始没有可以消费的东西，那就初始化为0；</p>
</li>
<li><p>如果是生产者，一开始可供生产的空间有MAXSIZE个，那就初始化为MAXSIZE。</p>
</li>
</ul>
</blockquote>
<h3 id="Mutex-Needed"><a href="#Mutex-Needed" class="headerlink" title="Mutex Needed"></a>Mutex Needed</h3><p>相当于将之前的 <code>count</code> 整合进条件变量中：</p>
<ul>
<li><code>sem_init(&amp;empty,0,MAXSIZE)</code> 空闲区域的大小为 MAXSIZE</li>
<li><code>sem_init(&amp;full,0,0)</code> 可消费区域大小为 0</li>
</ul>
<p><strong>Usage</strong>: </p>
<ul>
<li>生产者调用 <code>sem_wait(&amp;empty)</code> empty 自减，若为负数则生产者只能阻塞等待</li>
</ul>
<ul>
<li>消费者调用 <code>sem_wait(&amp;full)</code> full 自减，为负数则消费者需要阻塞等待</li>
</ul>
<ul>
<li><p>生产者操作完临界区， <code>sem_post(&amp;full)</code> 使 full 自增，某个消费者被唤醒并进入临界区</p>
</li>
<li><p>消费者操作完临界区， <code>sem_post(&amp;empty)</code> 使 empty 自增，某个生产者被唤醒并进入临界区</p>
</li>
</ul>
<p>这里没有锁，因此会出现并发问题：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> *<span class="title function_">producer</span><span class="params">(<span class="type">void</span> *arg)</span> &#123;</span><br><span class="line">    <span class="type">int</span> i;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; loops; i++) &#123;</span><br><span class="line">        sem_wait(&amp;mutex); <span class="comment">// Line P0 (NEW LINE) 加锁</span></span><br><span class="line">        sem_wait(&amp;empty); <span class="comment">// Line P1</span></span><br><span class="line">        put(i); <span class="comment">// Line P2</span></span><br><span class="line">        sem_post(&amp;full); <span class="comment">// Line P3</span></span><br><span class="line">        sem_post(&amp;mutex); <span class="comment">// Line P4 (NEW LINE) 解锁</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> *<span class="title function_">consumer</span><span class="params">(<span class="type">void</span> *arg)</span> &#123;</span><br><span class="line">	<span class="type">int</span> i;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; loops; i++) &#123;</span><br><span class="line">        sem_wait(&amp;mutex); <span class="comment">// Line C0 (NEW LINE) 加锁 </span></span><br><span class="line">        sem_wait(&amp;full); <span class="comment">// Line C1</span></span><br><span class="line">        <span class="type">int</span> tmp = get(); <span class="comment">// Line C2</span></span><br><span class="line">        sem_post(&amp;empty); <span class="comment">// Line C3</span></span><br><span class="line">        sem_post(&amp;mutex); <span class="comment">// Line C4 (NEW LINE) 解锁</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, tmp);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Deadlock"><a href="#Deadlock" class="headerlink" title="Deadlock"></a>Deadlock</h3><p>生产者加锁，进入临界区之前，调用empty发现缓冲区已满，遂休眠，此时生产者依然持有锁</p>
<p>切换到就绪的消费者，因为获取不到锁，只能休眠，这样就导致了死锁，因此需要缩小锁的范围:</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> *<span class="title function_">consumer</span><span class="params">(<span class="type">void</span> *arg)</span> &#123;</span><br><span class="line">	<span class="type">int</span> i;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; loops; i++) &#123;</span><br><span class="line">        sem_wait(&amp;full); <span class="comment">// Line C1</span></span><br><span class="line">        sem_wait(&amp;mutex); <span class="comment">// Line C1.5 (NEW LINE) 加锁 </span></span><br><span class="line">        <span class="type">int</span> tmp = get(); <span class="comment">// Line C2</span></span><br><span class="line">        sem_post(&amp;mutex); <span class="comment">// Line C2.5 (NEW LINE) 解锁</span></span><br><span class="line">        sem_post(&amp;empty); <span class="comment">// Line C3</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, tmp);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>最根本的区别在于，睡眠的线程不会释放锁，因此条件变量应该加到锁的外面</p>
<h2 id="Mutex-CV-amp-Semaphore"><a href="#Mutex-CV-amp-Semaphore" class="headerlink" title="Mutex + CV &amp; Semaphore"></a><code>Mutex + CV</code> &amp; <code>Semaphore</code></h2><table>
<thead>
<tr>
<th>特性</th>
<th>Mutex + Condition Variable</th>
<th>Semaphore</th>
</tr>
</thead>
<tbody><tr>
<td><strong>设计理念</strong></td>
<td>提供更高层次的<strong>条件等待机制</strong>，依赖互斥锁管理共享数据状态。</td>
<td>基于简单的<strong>计数器模型</strong>，直接控制资源可用数量。</td>
</tr>
<tr>
<td><strong>同步功能</strong></td>
<td>适合复杂条件等待或<strong>事件驱动</strong>的同步场景（例如生产者-消费者模型）。</td>
<td>控制固定数量的资源访问或线程数量（例如资源池管理）。</td>
</tr>
<tr>
<td><strong>互斥功能</strong></td>
<td>需要显式的 <code>Mutex</code> 实现互斥保护。</td>
<td>内部实现互斥，无需额外的互斥锁。</td>
</tr>
<tr>
<td><strong>跨进程支持</strong></td>
<td>仅支持线程级同步（同一进程内线程同步）。</td>
<td>支持跨进程和线程同步（POSIX 信号量支持跨进程）。</td>
</tr>
<tr>
<td><strong>复杂性</strong></td>
<td>支持复杂条件判断，但需要手动管理条件和唤醒逻辑。</td>
<td>简单直观，直接基于计数器操作，不需要条件管理。</td>
</tr>
<tr>
<td><strong>效率</strong></td>
<td>条件变量需要多步操作（加锁、解锁、条件检查、等待），效率略低。</td>
<td>基于计数器原子操作，性能较高，适合高并发场景。</td>
</tr>
<tr>
<td><strong>复杂条件处理</strong></td>
<td>支持复杂条件和多条件组合判断，适合生产者-消费者问题。</td>
<td>只能处理简单的资源计数条件，不适合复杂条件判断。</td>
</tr>
</tbody></table>
<h3 id="Mutex-Condition-Variable"><a href="#Mutex-Condition-Variable" class="headerlink" title="Mutex + Condition Variable"></a>Mutex + Condition Variable</h3><ol>
<li><strong>互斥锁（Mutex）：</strong><ul>
<li>提供临界区保护，确保线程在访问共享资源时互斥执行。</li>
<li>底层依赖于操作系统内核的<strong>互斥量数据结构</strong>（如 Linux 的 Futex 或信号量实现）。</li>
</ul>
</li>
<li><strong>条件变量（Condition Variable）：</strong><ul>
<li>条件变量不会保存条件状态，而是通过线程阻塞和唤醒机制等待条件变化。</li>
<li>必须与互斥锁配合使用，防止条件检查过程中出现竞争条件。</li>
</ul>
</li>
</ol>
<ul>
<li>条件变量使用<strong>等待队列（Wait Queue）</strong>机制管理线程。</li>
<li>当线程调用<code>pthread_cond_wait</code>，它会：<ol>
<li>释放锁（解锁 mutex）。</li>
<li>将线程放入条件变量的等待队列中，并进入<strong>阻塞状态</strong>（睡眠）。</li>
<li>等待其他线程通过 <code>pthread_cond_signal</code> 或 <code>pthread_cond_broadcast</code> 唤醒它。</li>
<li>被唤醒后，重新尝试获取互斥锁并继续执行。</li>
</ol>
</li>
</ul>
<figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">Thread</span> <span class="number">1</span><span class="operator">:</span>              <span class="built_in">Condition</span> <span class="variable">Variable</span><span class="operator">:</span></span><br><span class="line">  <span class="operator">-</span> <span class="variable">Acquire</span> <span class="variable">Lock</span>         <span class="punctuation">[</span> <span class="variable">Wait</span> <span class="variable">Queue</span> <span class="punctuation">]</span></span><br><span class="line">  <span class="operator">-</span> <span class="built_in">Check</span> <span class="built_in">Condition</span> <span class="operator">----&gt;</span> <span class="variable">Add</span> <span class="variable">to</span> <span class="variable">Queue</span></span><br><span class="line">  <span class="operator">-</span> <span class="variable">Wait</span> <span class="punctuation">(</span><span class="variable">Unlock</span><span class="punctuation">)</span>        <span class="punctuation">[</span> <span class="variable">Blocked</span> <span class="punctuation">]</span></span><br><span class="line">                         <span class="operator">&lt;-----</span> <span class="variable">Signal</span><span class="punctuation">(</span><span class="punctuation">)</span></span><br><span class="line"><span class="built_in">Thread</span> <span class="number">2</span><span class="operator">:</span>               <span class="variable">Wake</span> <span class="built_in">Up</span> <span class="built_in">Thread</span> <span class="number">1</span></span><br><span class="line">  <span class="operator">-</span> <span class="variable">Modify</span> <span class="built_in">Condition</span></span><br><span class="line">  <span class="operator">-</span> <span class="variable">Signal</span></span><br><span class="line">  <span class="operator">-</span> <span class="built_in">Release</span> <span class="variable">Lock</span></span><br></pre></td></tr></table></figure>

<ul>
<li><strong>条件变量没有条件状态：</strong> 共享条件需要程序员手动管理（例如标志位）。</li>
<li><strong>支持复杂条件判断：</strong> 等待某些条件的组合，例如缓冲区为空或满。</li>
<li><strong>虚假唤醒机制：</strong> 被唤醒后必须重新检查条件，避免不满足条件的线程继续执行。</li>
</ul>
<hr>
<h3 id="Semaphore"><a href="#Semaphore" class="headerlink" title="Semaphore"></a>Semaphore</h3><ul>
<li>信号量直接依赖<strong>原子操作</strong>（如 CPU 指令 <code>Test-And-Set</code> 或 <code>Compare-And-Swap</code>）更新计数器，确保多线程安全。</li>
<li>阻塞线程会进入<strong>等待队列</strong>，操作系统负责调度。</li>
</ul>
<ol>
<li>信号量内部维护一个<strong>计数器变量（Counter）</strong>，表示可用资源的数量。</li>
<li>当调用 <code>sem_wait</code> 时：<ul>
<li>如果计数器 &gt; 0，直接减 1，线程继续执行。</li>
<li>如果计数器 == 0，线程阻塞，进入等待队列。</li>
</ul>
</li>
<li>当调用 <code>sem_post</code> 时：<ul>
<li>增加计数器值。</li>
<li>如果等待队列中有线程，则唤醒其中一个线程。</li>
</ul>
</li>
</ol>
<figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">Semaphore</span> <span class="variable">Counter</span> <span class="operator">=</span> <span class="number">2</span></span><br><span class="line"><span class="built_in">Thread</span> <span class="number">1</span><span class="operator">:</span> <span class="variable">P</span><span class="punctuation">(</span><span class="punctuation">)</span> <span class="operator">----&gt;</span> <span class="variable">Counter</span><span class="operator">--</span> <span class="punctuation">(</span><span class="number">1</span><span class="punctuation">)</span></span><br><span class="line"><span class="built_in">Thread</span> <span class="number">2</span><span class="operator">:</span> <span class="variable">P</span><span class="punctuation">(</span><span class="punctuation">)</span> <span class="operator">----&gt;</span> <span class="variable">Counter</span><span class="operator">--</span> <span class="punctuation">(</span><span class="number">0</span><span class="punctuation">)</span></span><br><span class="line"><span class="built_in">Thread</span> <span class="number">3</span><span class="operator">:</span> <span class="variable">P</span><span class="punctuation">(</span><span class="punctuation">)</span> <span class="operator">----&gt;</span> <span class="variable">Blocked</span> <span class="punctuation">(</span><span class="variable">Counter</span> <span class="operator">==</span> <span class="number">0</span><span class="punctuation">)</span></span><br><span class="line"><span class="built_in">Thread</span> <span class="number">1</span><span class="operator">:</span> <span class="variable">V</span><span class="punctuation">(</span><span class="punctuation">)</span> <span class="operator">----&gt;</span> <span class="variable">Counter</span><span class="operator">++</span> <span class="punctuation">(</span><span class="number">1</span><span class="punctuation">)</span> <span class="operator">-&gt;</span> <span class="variable">Wake</span> <span class="built_in">Up</span> <span class="built_in">Thread</span> <span class="number">3</span></span><br></pre></td></tr></table></figure>

<ul>
<li>信号量管理的是资源数量，而不是条件状态。</li>
<li>自带互斥特性，适合多个线程访问有限资源。</li>
<li><strong>适合计数型条件：</strong> 一次允许多个线程执行，而不是简单的互斥。</li>
</ul>
<h3 id="Summary-1"><a href="#Summary-1" class="headerlink" title="Summary"></a>Summary</h3><ol>
<li><strong>Semaphore 更像一个通用工具：</strong><ul>
<li>适合管理固定资源数量，如线程池、连接池、令牌桶等。</li>
<li>更简单、更高效，适合需要资源计数的场景。</li>
<li>支持跨进程同步需求。</li>
</ul>
</li>
<li><strong>Mutex + Condition Variable 提供更高级的同步机制：</strong><ul>
<li>适合复杂条件判断或事件驱动模型，如生产者/消费者问题，依赖互斥锁保证数据一致性。</li>
<li>支持灵活的条件管理，适合多条件组合。</li>
<li>更适合线程间等待和唤醒机制，不适合跨进程同步。</li>
</ul>
</li>
</ol>
<ul>
<li>在实际开发中，如果场景简单且需求是资源访问控制，选择<strong>信号量</strong>；</li>
<li>如果需要更复杂的条件管理和线程间事件通知，则选择<strong>条件变量 + 锁</strong>。</li>
</ul>
<h2 id="Applications"><a href="#Applications" class="headerlink" title="Applications"></a>Applications</h2><h3 id="Reader-Writer-Lock"><a href="#Reader-Writer-Lock" class="headerlink" title="Reader/Writer Lock"></a>Reader/Writer Lock</h3><p>读者只读不写，写者才需要修改。类似 Shared/eXclusion 共享锁和独占锁</p>
<p>RW 锁支持一个写者或者多个读者：</p>
<ul>
<li>第一个读者首先获取lock（保护reader）增加reader，获取writelock，释放lock进入临界区</li>
<li>之后其他的读者只要获取lock后增加reader个数，直接访问临界区即可</li>
<li>写者需要等待最后一个读者释放writelock</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> _<span class="title">rwlock_t</span>&#123;</span></span><br><span class="line">    <span class="type">sem_t</span> lock; <span class="comment">// basic lock  INIT: 1</span></span><br><span class="line">    <span class="type">sem_t</span> writelock;<span class="comment">//allow 1 writer / many readers INIT: 1</span></span><br><span class="line">    <span class="type">int</span> readers;<span class="comment">//number of readers  INIT:0</span></span><br><span class="line">&#125;<span class="type">rwlock_t</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">rwlock_acquire_readlock</span><span class="params">(<span class="type">rwlock_t</span> *rw)</span>&#123;</span><br><span class="line">    sem_wait(rw-&gt;lock);</span><br><span class="line">    rw-&gt;readers++;</span><br><span class="line">    <span class="keyword">if</span>(readers == <span class="number">1</span>)</span><br><span class="line">        sem_wait(rw-&gt;writelock); <span class="comment">//第一个读者获取写锁</span></span><br><span class="line">    sem_post(rw-&gt;lock);</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">rwlock_release_readlock</span><span class="params">(<span class="type">rwlock_t</span> *rw)</span>&#123;</span><br><span class="line">    sem_wait(rw-&gt;lock);</span><br><span class="line">    rw-&gt;readers;</span><br><span class="line">    <span class="keyword">if</span>(readers == <span class="number">0</span>)</span><br><span class="line">        sem_post(rw-&gt;writelock);<span class="comment">//最后一个读者释放写锁</span></span><br><span class="line">    sem_post(rw-&gt;lock);</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">rwlock_acquire_readlock</span><span class="params">(<span class="type">rwlock_t</span> *rw)</span>&#123;</span><br><span class="line">    sem_wait(rw-&gt;lock);</span><br><span class="line">    rw-&gt;readers;</span><br><span class="line">    <span class="keyword">if</span>(readers == <span class="number">0</span>)</span><br><span class="line">        sem_post(rw-&gt;writelock);<span class="comment">//最后一个读者释放写锁</span></span><br><span class="line">    sem_post(rw-&gt;lock);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这种读写锁并不一定比自旋锁更快，并且公平性无法保证，过多读者通常会饿死写者，需要进一步进行优化。</p>
<h3 id="Dining-Philosopher’s-Problem"><a href="#Dining-Philosopher’s-Problem" class="headerlink" title="Dining Philosopher’s Problem"></a>Dining Philosopher’s Problem</h3><p><strong>问题描述</strong></p>
<ul>
<li>有 5 位哲学家围坐在一张圆桌旁，他们的生活方式是 <strong>思考</strong> 和 <strong>进餐</strong>。</li>
<li>桌子上摆放着 5 根筷子，每位哲学家左右各放一根。</li>
<li>哲学家要进餐时，需要同时拿起左右两根筷子。</li>
<li>哲学家只能在拿到两根筷子后才能吃饭，否则必须等待。</li>
</ul>
<p><strong>主要难题</strong>：</p>
<ul>
<li>**死锁 (Deadlock)**：所有哲学家都同时拿起左边的筷子，导致没有哲学家能拿到第二根筷子，进入无限等待状态。</li>
<li>**饥饿 (Starvation)**：某位哲学家可能永远无法获得两根筷子，从而无法进餐。</li>
<li><strong>并发控制</strong>：需要保证哲学家拿筷子和放筷子的动作是线程安全的。</li>
</ul>
<ul>
<li><strong>方案 1：引入顺序编号</strong><br>将哲学家编号为 0 到 4，规定编号为偶数的哲学家先拿左筷子，再拿右筷子；编号为奇数的哲学家先拿右筷子，再拿左筷子。或者，最后一个哲学家先拿右筷子，再拿左筷子。这样就不会互相卡住，打破了等待的循环。</li>
<li><strong>方案 2：限制最多 4 个哲学家进入用餐状态</strong><br>使用一个计数器，确保最多 4 位哲学家能尝试拿筷子，这样至少会有一根筷子空闲，避免死锁。</li>
</ul>
<h3 id="Thread-Throttling"><a href="#Thread-Throttling" class="headerlink" title="Thread Throttling"></a>Thread Throttling</h3><p>信号量比较适合<strong>资源数量有限制</strong>的情况：比如有一群线程，每个线程都需要申请一块很大的内存空间用于计算，用于计算的这片区域就是 <strong>内存密集型</strong> 区域，如果所有线程同时申请，就会造成内存抖动（不停地换出又换入页面导致程序以极慢的速度执行）。</p>
<p>一个简单的信号量就可以解决这个问题：通过将信号量的值初始化为您希望一次进入内存密集区域的最大线程数，然后在该区域周围放置 sem_wait() 和 sem_post()，信号量自然地限制那些并发地处于危险区域的线程数量。</p>
<h2 id="Implement-sem-using-mutex-amp-cond"><a href="#Implement-sem-using-mutex-amp-cond" class="headerlink" title="Implement sem using mutex &amp; cond"></a>Implement <code>sem</code> using <code>mutex</code> &amp; <code>cond</code></h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> _<span class="title">Zem_t</span>&#123;</span></span><br><span class="line">	<span class="type">int</span> value;</span><br><span class="line">	<span class="type">pthread_mutex_t</span> lock;</span><br><span class="line">	<span class="type">pthread_cond_t</span> cond;</span><br><span class="line">&#125; Zem_t;</span><br><span class="line"><span class="type">void</span> <span class="title function_">Zem_init</span><span class="params">(Zem_t *s, <span class="type">int</span> value)</span>&#123;</span><br><span class="line">	s-&gt;value = value;</span><br><span class="line">	Cond_init(s-&gt;cond);</span><br><span class="line">	Mutex_init(s-&gt;lock);</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">Zem_wait</span><span class="params">(Zem_t *s)</span>&#123;</span><br><span class="line">	Mutex_lock(&amp;s-&gt;lock);</span><br><span class="line">	<span class="keyword">while</span>(s-&gt;value &lt;= <span class="number">0</span>)</span><br><span class="line">		Cond_wait(&amp;s-&gt;cond, &amp;s-&gt;lock);</span><br><span class="line">	s-&gt;value--;</span><br><span class="line">	Mutex_unlock(&amp;s-&gt;lock);</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">Zem_post</span><span class="params">(Zem_t *s)</span>&#123;</span><br><span class="line">	Mutex_lock(&amp;s-&gt;lock);</span><br><span class="line">	s-&gt;value++;</span><br><span class="line">	Cond_signal(&amp;s-&gt;cond);</span><br><span class="line">	Mutex_unlock(&amp;s-&gt;lock);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="Common-Concurrency-Bugs"><a href="#Common-Concurrency-Bugs" class="headerlink" title="Common Concurrency Bugs"></a>Common Concurrency Bugs</h1><p>总的来说可以分为死锁(Deadlock)和非死锁(Non-deadlock)两种，其中后者占绝大多数</p>
<h2 id="Non-deadlock-Bugs"><a href="#Non-deadlock-Bugs" class="headerlink" title="Non-deadlock Bugs"></a>Non-deadlock Bugs</h2><h3 id="Atomicity-Violation-Lock"><a href="#Atomicity-Violation-Lock" class="headerlink" title="Atomicity-Violation(Lock)"></a>Atomicity-Violation(Lock)</h3><p>这种错误违反了<strong>原子性</strong>，下图的 <code>proc_info</code> 在刚进入 if 循环的时候被取消调度，线程2将其置为NULL，切换回去的时候导致空指针异常</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241225194108926.png" alt="image-20241225194108926"></p>
<p>解决方案：在访问共享资源的时候加锁</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241225194511624.png" alt="image-20241225194511624"></p>
<h3 id="Order-Violation-CV"><a href="#Order-Violation-CV" class="headerlink" title="Order-Violation(CV)"></a>Order-Violation(CV)</h3><p>模块化：不同线程承担不同职责，线程1负责初始化 <code>mThread</code> ，线程2访问 <code>mThread</code></p>
<p>如果<strong>乱序执行</strong>，就会出现线程2访问到空指针导致程序崩溃：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241225194032626-1735126873754-1.png" alt="image-20241225194032626"></p>
<p>因此，用一个状态变量或者<code>mThread</code>本身来代表初始化是否成功，然后用条件变量解决问题：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241225194350912.png" alt="image-20241225194350912"></p>
<h2 id="Deadlock-Bugs"><a href="#Deadlock-Bugs" class="headerlink" title="Deadlock Bugs"></a>Deadlock Bugs</h2><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241225195039934.png" alt="image-20241225195039934"></p>
<p>死锁原因：获取锁的顺序相反</p>
<ol>
<li>在大型代码库中组件依赖复杂 循环依赖就会导致死锁的发生</li>
<li>模块化封装会隐藏底层的细节 <code>v1.addAll(v2)</code> <code>v2.addAll(v1)</code> 同时调用可能会发生死锁</li>
</ol>
<p>产生死锁的四个条件：</p>
<ol>
<li><strong>互斥</strong>：线程对资源进行互斥的访问</li>
<li><strong>持有并等待</strong>：线程在持有资源的同时也在等待其他资源</li>
<li><strong>非抢占</strong>：线程获得的资源（如锁）不能被抢占</li>
<li><strong>循环等待</strong>：线程之间存在环路，上面的每个线程都会额外持有下个线程想要申请的资源</li>
</ol>
<h3 id="Prevention"><a href="#Prevention" class="headerlink" title="Prevention"></a>Prevention</h3><h4 id="Circular-Wait-Forced-Order"><a href="#Circular-Wait-Forced-Order" class="headerlink" title="Circular Wait: Forced Order"></a>Circular Wait: Forced Order</h4><p>强制规定获取锁的顺序</p>
<p><strong>偏序锁：</strong>如果资源之间的依赖关系较少或依赖是局部的，偏序锁，提供更好的性能和灵活性。</p>
<p><strong>全序锁：</strong>如果资源之间的依赖关系复杂且必须确保一致性（如事务或分布式系统），全序锁更可靠</p>
<p>如果一个函数要抢多个锁，可以根据<strong>锁的地址</strong>作为锁的顺序：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">do_something(mutex *m1,mutex *m2)&#123;</span><br><span class="line">	<span class="keyword">if</span>(m1 &lt; m2)&#123;</span><br><span class="line">		pthread_mutex_lock(*m1);</span><br><span class="line">		pthread_mutex_lock(*m2);</span><br><span class="line">	</span><br><span class="line">	&#125; <span class="keyword">else</span>&#123;</span><br><span class="line">		pthread_mutex_lock(*m2);</span><br><span class="line">		pthread_mutex_lock(*m1);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这样可以保证 <code>do_something(&amp;m1,&amp;m2)</code> 和 <code>do_something(&amp;m2,&amp;m1)</code> 是同样的抢锁顺序</p>
<h4 id="Hold-and-wait-Atomic-Acquiring"><a href="#Hold-and-wait-Atomic-Acquiring" class="headerlink" title="Hold-and-wait: Atomic Acquiring"></a>Hold-and-wait: Atomic Acquiring</h4><p>在抢锁的最外层加一道锁（原子性抢锁）防止抢锁过程中突然被取消调度，切换到其他线程：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241225203212407.png" alt="image-20241225203212407"></p>
<p>缺点：不适合封装，因为需要准确知道要抢哪些锁并提前全部抢到（即使当前并不需要）</p>
<h4 id="No-Preemption-trylock"><a href="#No-Preemption-trylock" class="headerlink" title="No Preemption:trylock"></a>No Preemption:<code>trylock</code></h4><p>可以通过<code>trylock</code>这种非阻塞式抢锁来避免死锁，但是这种方法会导致活锁，对封装的支持也不好，代码抢完锁中途获取的资源（比如申请的内存空间），如果抢锁失败，还应该释放</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241225204421920.png" alt="image-20241225204421920"></p>
<h5 id="Livelock"><a href="#Livelock" class="headerlink" title="Livelock"></a>Livelock</h5><p><strong>死锁：</strong> 所有线程都进入等待状态，完全停止运行。</p>
<p><strong>活锁：</strong> 所有线程仍然在运行，但因为不断调整状态，始终无法完成任务。</p>
<p>解决方案：</p>
<ol>
<li>退避算法（Backoff）:在循环结束的时候，先随机等待一段时间再重复</li>
<li>引入有限重试机制: 因为线程一直在运行，因此可以限制最大重试次数</li>
<li>使用更高层次的同步机制,结合条件变量或阻塞队列</li>
</ol>
<h4 id="Mutual-Exclusion-Lock-free-CAS"><a href="#Mutual-Exclusion-Lock-free-CAS" class="headerlink" title="Mutual Exclusion: Lock-free(CAS)"></a>Mutual Exclusion: Lock-free(CAS)</h4><p>利用硬件指令的原子性，完全避免互斥区的存在：CAS 失败就不断重试，直到成功为止（乐观锁）</p>
<p>COMPARE AND SWAP 加之前看看是不是对应的正确的值，是的话再赋值。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//自增:</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">CAS</span><span class="params">(<span class="type">int</span> *address, <span class="type">int</span> expected, <span class="type">int</span> new)</span>&#123;</span><br><span class="line">	<span class="keyword">if</span>(*address == expected)&#123;</span><br><span class="line">        *address = new;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">increment</span><span class="params">(<span class="type">int</span> *value, <span class="type">int</span> amount)</span>&#123;</span><br><span class="line">    <span class="type">int</span> old;</span><br><span class="line">    <span class="keyword">do</span>&#123;</span><br><span class="line">		old = *value;</span><br><span class="line">    &#125; <span class="keyword">while</span>(CAS(value, old, old + amount) == <span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//链表插入</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">CAS</span><span class="params">(<span class="type">node_t</span> **address, <span class="type">node_t</span> *expected, <span class="type">node_t</span> *new)</span>&#123;</span><br><span class="line">	<span class="keyword">if</span>(*address == expected)&#123;</span><br><span class="line">        *address = new;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">insert</span><span class="params">(<span class="type">int</span> value)</span> &#123;</span><br><span class="line">    <span class="type">node_t</span> *n = <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="type">node_t</span>));</span><br><span class="line">    assert(n != <span class="literal">NULL</span>);</span><br><span class="line">    n-&gt;value = value;</span><br><span class="line">    pthread_mutex_lock(listlock); <span class="comment">// begin critical section</span></span><br><span class="line">    n-&gt;next = head;</span><br><span class="line">    head = n;</span><br><span class="line">    pthread_mutex_unlock(listlock); <span class="comment">// end critical section</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">insert</span><span class="params">(<span class="type">int</span> value)</span>&#123;</span><br><span class="line">    <span class="type">node_t</span> *n = <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="type">node_t</span>));</span><br><span class="line">    assert(n!=<span class="literal">NULL</span>);</span><br><span class="line">    n-&gt;value = value;</span><br><span class="line">    <span class="keyword">do</span>&#123;</span><br><span class="line">        n-&gt;next = head;<span class="comment">//新节点的下一个应该是现在的头</span></span><br><span class="line">    &#125; <span class="keyword">while</span>(CAS(&amp;head, n-&gt;next, n) == <span class="number">0</span>);<span class="comment">//现在的头应该等于新节点的下一个,不等于</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Avoid-via-Scheduling"><a href="#Avoid-via-Scheduling" class="headerlink" title="Avoid via Scheduling"></a>Avoid via Scheduling</h3><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241225213119760.png" alt="image-20241225213119760"></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241225213105676.png" alt="image-20241225213105676"></p>
<p>不要同时并行执行需要获取完全相同锁的线程</p>
<h3 id="Detect-and-Recover"><a href="#Detect-and-Recover" class="headerlink" title="Detect and Recover"></a>Detect and Recover</h3><p>如果根除死锁实在很困难，可以定期检查死锁，并运行专门的程序来恢复</p>
<h1 id="Event-based-Concurrency"><a href="#Event-based-Concurrency" class="headerlink" title="Event-based Concurrency"></a>Event-based Concurrency</h1><p><strong>Event</strong> Loop: 等待事件-&gt;处理事件-&gt;等待事件，重点是如何获取事件？</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span>(<span class="number">1</span>)&#123;</span><br><span class="line">	events = getEvents();</span><br><span class="line">    <span class="keyword">for</span> (e in events)</span><br><span class="line">    	processEvent(e);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="select"><a href="#select" class="headerlink" title="select()"></a><code>select()</code></h2><h3 id="API-Usage"><a href="#API-Usage" class="headerlink" title="API Usage"></a>API Usage</h3><ul>
<li><strong>Purpose</strong>: 监视 FD 是否准备好接受 I/O 操作</li>
<li><strong>Function Signature</strong>: <code>int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *errorfds, struct timeval *timeout)</code></li>
<li><strong>Parameters</strong>:<ul>
<li><code>nfds</code>: 检查集合中 [0,nfds-1] 的 FD</li>
<li><code>readfds</code>: 监控 readfds 中的可读事件(新的数据包到达，准备处理)</li>
<li><code>writefds</code>: 监控 writefds 中的可写事件(服务器回复需要写入队列有空)</li>
<li><code>errorfds</code>: 监控 errorfds 中的错误事件</li>
<li><code>timeout</code>: 最大等待时间</li>
</ul>
</li>
<li><strong>Return Value</strong>: 返回准备好 I/O 的 FDs</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241225225619265.png" alt="image-20241225225619265"></p>
<h3 id="Lock-free"><a href="#Lock-free" class="headerlink" title="Lock-free"></a>Lock-free</h3><p>有了单CPU和基于事件的应用程序，并发程序中的问题就不再存在。具体来说，因为一次只处理一个事件，所以不需要获取或释放锁；基于事件的服务器不能被另一个线程中断，因为它绝对是单线程的。因此，线程程序中常见的并发错误不会在基于事件的基本方法中体现出来。</p>
<h3 id="Problem-Blocking-Syscalls"><a href="#Problem-Blocking-Syscalls" class="headerlink" title="Problem: Blocking Syscalls"></a>Problem: Blocking Syscalls</h3><p>如果某个事件要求发出可能会阻塞的系统调用怎么办？ 例如，假设一个请求从客户端发送到服务器，以从磁盘读取文件并将其内容返回到请求客户端（非常类似于简单的 HTTP 请求）。为了服务这样的请求，某些事件处理程序最终必须发出 <code>open()</code> 系统调用来打开文件，然后执行一系列 <code>read()</code> 调用来读取文件。当文件被读入内存时，服务器可能会开始将结果发送到客户端。 <code>open()</code> 和 <code>read()</code> 调用都可能向存储系统发出 I/O 请求（当所需的元数据或数据尚未在内存中时），因此可能需要很长时间才能提供服务。对于基于线程的服务器，这不是问题：当发出 I/O 请求的线程挂起（等待 I/O 完成）时，其他线程可以运行，从而使服务器能够取得进展。事实上，I/O 和其他计算的这种自然重叠使得基于线程的编程变得非常自然和直接。</p>
<p>然而，使用基于事件的方法，没有其他线程可以运行：只有主事件循环。这意味着，如果事件处理程序发出阻塞调用，则整个服务器将执行此操作：阻塞直到调用完成。当事件循环阻塞时，系统处于空闲状态，因此潜在地浪费了巨大的资源。因此，我们在基于事件的系统中必须遵守一条规则：不允许阻塞调用。</p>
<h2 id="Asynchoronous-I-O"><a href="#Asynchoronous-I-O" class="headerlink" title="Asynchoronous I/O"></a>Asynchoronous I/O</h2><h3 id="API-Usage-1"><a href="#API-Usage-1" class="headerlink" title="API Usage"></a>API Usage</h3><p>要对文件发出异步读取，应用程序应首先使用相关信息填充此 AIO 控制块（aiocb）：</p>
<ul>
<li>要读取的文件的文件描述符 (aio fildes)</li>
<li>文件内的偏移量 (aio offset) </li>
<li>长度请求的长度 (aio nbytes)</li>
<li>读取结果应复制到的内存位置 (aio buf)</li>
</ul>
<p>填充该结构后，应用程序必须发出 AIO 来读取文件；在 Mac 上，此 API 是一个异步读取的 API： <code>int aio_read(struct aiocb *aiocbp</code>);  该调用尝试发出 I/O；如果成功，它会立即返回，并且应用程序（即基于事件的服务器）可以继续其工作。 </p>
<p>然而，我们必须解决最后一块难题。我们如何判断 I/O 何时完成，从而确定缓冲区（由 aiobuf 指向）现在已在其中包含所请求的数据？  还需要最后一个 API。在 Mac 上，它被称为 <code>aio_error()</code> API 如下所示： <code>int aio_error(const struct aiocb *aiocbp)</code>;  该系统调用检查 aiocbp 引用的请求是否已完成。如果是，则返回成功（用 0 表示）；  如果不是，则返回 <code>EINPROGRESS</code>。</p>
<h3 id="Poll-or-Interrupt"><a href="#Poll-or-Interrupt" class="headerlink" title="Poll or Interrupt"></a>Poll or Interrupt</h3><p>对于每个未完成的异步 I/O，应用程序可以通过调用 <code>aio_error()</code> 定期<strong>轮询</strong>系统，以确定所述 I/O 是否尚未完成。但是轮询很浪费CPU。为了解决这个问题，一些系统提供了基于中断的方法。此方法使用 UNIX Signals 来通知应用程序异步 I/O 何时完成，从而无需重复询问系统。</p>
<p>在没有异步I/O的系统中，无法实现纯粹的基于事件的方法。然而，出现了一些相当有效的混合方法。其中事件用于处理网络数据包，线程池用于管理未完成的 I/O。<strong>I/O 多路复用</strong></p>
<h4 id="UNIX-Signals"><a href="#UNIX-Signals" class="headerlink" title="UNIX Signals"></a>UNIX Signals</h4><p>所有现代 UNIX 变体中都存在一个巨大且令人着迷的基础设施，称为信号。最简单的是，信号提供了一种与进程通信的方式。具体来说，可以将信号传递给应用程序；这样做会阻止应用程序运行信号处理程序（即应用程序中处理该信号的某些代码）正在执行的任何操作。 完成后，该进程将恢复其之前的行为。 每个信号都有一个名称，如HUP（挂起）、INT（中断）、SEGV（分段违规）等</p>
<p>有趣的是，有时是内核本身发出信号。例如，当程序遇到 Segmentation Violation 时，操作系统会向其发送 <code>SIGSEGV</code>；如果程序调用了<code>signal(SIGSEV, handler)</code> 就可以运行一些代码（signal handler）来响应。当发送到没有配置响应信号的进程时，将执行默认行为；对于SEGV，该进程被终止。 </p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">handle</span><span class="params">(<span class="type">int</span> arg)</span> &#123;<span class="comment">//handler</span></span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">&quot;stop wakin’ me up...\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *argv[])</span> &#123;</span><br><span class="line">    signal(SIGHUP, handle);</span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>)</span><br><span class="line">        ; <span class="comment">// doin’ nothin’ except catchin’ some sigs</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> <code>./main &amp;</code> 后台运行进程，随后返回pid；</p>
<p><code>kill -HUP [pid]</code> 给进程发送 SIGHUP 信号：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">prompt&gt; ./main &amp;</span><br><span class="line">[<span class="number">3</span>] <span class="number">36705</span></span><br><span class="line">prompt&gt; <span class="built_in">kill</span> <span class="literal">-HUP</span> <span class="number">36705</span></span><br><span class="line">stop wakin’ me up...</span><br><span class="line">prompt&gt; <span class="built_in">kill</span> <span class="literal">-HUP</span> <span class="number">36705</span></span><br><span class="line">stop wakin’ me up...</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="Problem-State-Management"><a href="#Problem-State-Management" class="headerlink" title="Problem: State Management"></a>Problem: State Management</h3><p>在 Thread-based 服务器中，从<code>read</code>调用返回，程序可以直接从栈上知道 sd 是多少</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> rc = read(fd, buffer, size);</span><br><span class="line">rc = write(sd, buffer, size);</span><br></pre></td></tr></table></figure>

<p>而在 Event-based 服务器中，从 <code>aio_read</code> 返回后，应当记录下在处理<code>read</code>事件时必要的信息(continuation)，比如将套接字描述符（sd）记录在某种数据结构（例如哈希表）中，并由文件描述符（fd）索引。</p>
<p>当<code>aio_error</code>显示成功读取后，事件处理器将使用 FD 来查找 continuation，这会将 sd 的值返回给调用者。最终，服务器可以完成最后一点工作，将数据写入套接字。</p>
<h2 id="Other-Problems-with-Events"><a href="#Other-Problems-with-Events" class="headerlink" title="Other Problems with Events"></a>Other Problems with Events</h2><ol>
<li><p>单核到多核将会有多个事件处理器同步运行的情况，会产生同步问题。不再可能进行无锁的简单事件处理。</p>
</li>
<li><p>不能与某些类型的系统活动（例如分页）很好地集成。例如，如果事件处理器发生Page Fault，这就会导致阻塞，因此服务器在Page Fault完成处理之前会一直阻塞。</p>
</li>
<li><p>随着各种程序的确切语义发生变化，基于事件的代码可能很难管理超时。例如，如果例程从非阻塞更改为阻塞，则调用该例程的事件处理程序也必须通过将自身分成两部分来进行更改以适应其新性质。由于阻塞对基于事件的服务器来说是灾难性的，因此程序员必须始终留意每个事件使用的 API 语义中的此类变化。 </p>
</li>
<li><p>异步磁盘 I/O 并未实现与异步网络 I/O 完全集成。例如，虽然人们只想使用 select() 接口来管理所有未完成的 I/O，但通常需要用于网络的 select() 和用于磁盘 I/O 的 AIO 调用的某种组合。</p>
</li>
</ol>
<h1 id="Monitor"><a href="#Monitor" class="headerlink" title="Monitor"></a>Monitor</h1><h2 id="Semaphore-amp-Monitor"><a href="#Semaphore-amp-Monitor" class="headerlink" title="Semaphore &amp; Monitor"></a>Semaphore &amp; Monitor</h2><ul>
<li>**信号量(Semaphere)**：操作系统提供的一种协调共享资源访问的方法。和用软件实现的同步比较，软件同步是平等线程间的的一种同步协商机制，不能保证原子性。而信号量则由操作系统进行管理，地位高于进程，操作系统保证信号量的原子性。</li>
<li>**管程(Monitor)**：解决信号量在临界区的 PV 操作上的配对的麻烦，把配对的 PV 操作集中在一起，生成的一种并发编程方法。其中使用了条件变量这种同步机制。</li>
</ul>
<p><strong>所谓管程，指的是管理共享变量以及对共享变量的操作过程，让他们支持并发。</strong>翻译为 Java 领域的语言，就是管理类的成员变量和成员方法，让这个类是线程安全的。一般采用 Mesa Semantic</p>
<p><strong>说明：</strong> 信号量将共享变量 S 封装起来，对共享变量 S 的所有操作都只能通过 PV 操作进行，这是不是和面向对象的思想是不是很像呢？事实上，封装共享变量是并发编程的常用手段。</p>
<p>在信号量中，当 P 操作无法获取到锁时，将当前线程添加到**同步队列(syncQueue)<strong>中。当其余线程 V 释放锁时，从同步队列中唤醒等待线程。但当有多个条件通过信号量 PV 配对时会异常复杂，所以管程中引入了</strong>等待队列(waitQueue)**的概念，进一步封装这些复杂的操作。</p>
<p>在用信号量实现的阻塞队列中，为了实现阻塞队列的功能，即等待-通知(wait-notify)，除了使用互斥锁 mutex 外，还需要两个判断队满和队空的资源信号量 full 和 empty，使用起来不仅复杂，还容易出错。管程在信号量的基础上，更进一步，增加了条件同步，对多个条件变量使用多个等待队列，将上述复杂的操作封装起来: <code>wait()</code> <code>notifyAll()</code> <code>notify()</code></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/1322310-20200320081430470-1065805408.png" alt=" "></p>
<h3 id="API-Usage-2"><a href="#API-Usage-2" class="headerlink" title="API Usage"></a>API Usage</h3><h4 id="While-Loop-wait"><a href="#While-Loop-wait" class="headerlink" title="While Loop wait()"></a>While Loop <code>wait()</code></h4><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/250px-Monitor_(synchronization)-Mesa.png" alt="img"></p>
<p>MESA 管程里面，T2 通知完 T1 后，T2 还是会接着执行，T1 并不立即执行，仅仅是从条件变量的等待队列进到入口等待队列里面。这样做的好处是 notify() 不用放到代码的最后，T2 也没有多余的阻塞唤醒操作。但是也有个副作用，就是<strong>当 T1 再次执行的时候，可能曾经满足的条件现在已经不满足了</strong>，所以需要以while循环方式检验条件变量。</p>
<p><code>notify()</code> or <code>notifyAll()</code> ？什么时候可以使用 <code>notify()</code> 呢？需要满足以下三个条件：</p>
<ol>
<li>所有等待线程拥有相同的等待条件；</li>
<li>所有等待线程被唤醒后，执行相同的操作；</li>
<li>只需要唤醒一个线程。</li>
</ol>
<p><code>notify()</code> 一般只适用于只有一个条件变量的情况，生产者和消费者等待在同一个条件上会导致错误唤醒同类，造成死锁。<code>notifyAll()</code> 类似于 <code>pthread_cond_broadcast()</code> 都可以用于唤醒多个等待在同一个条件变量上的线程。重点是 <strong>while 里面的等待条件是完全相同的。</strong></p>
<h2 id="BlockingQueue-Producer-Consumer"><a href="#BlockingQueue-Producer-Consumer" class="headerlink" title="BlockingQueue: Producer/Consumer"></a>BlockingQueue: Producer/Consumer</h2><p>Condition 能够更细粒度地进行编程</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BlockedQueue</span>&lt;T&gt; &#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="type">Lock</span> <span class="variable">lock</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ReentrantLock</span>();</span><br><span class="line">    <span class="comment">// 条件变量：队列不满</span></span><br><span class="line">    <span class="keyword">final</span> <span class="type">Condition</span> <span class="variable">notFull</span> <span class="operator">=</span> lock.newCondition();</span><br><span class="line">    <span class="comment">// 条件变量：队列不空</span></span><br><span class="line">    <span class="keyword">final</span> <span class="type">Condition</span> <span class="variable">notEmpty</span> <span class="operator">=</span> lock.newCondition();</span><br><span class="line">    <span class="comment">// 入队</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">enq</span><span class="params">(T x)</span> &#123;</span><br><span class="line">        lock.lock();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">while</span> (队列已满) &#123;</span><br><span class="line">                <span class="comment">// 等待队列不满</span></span><br><span class="line">                notFull.await();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// add x to queue</span></span><br><span class="line">            <span class="comment">// 入队后,通知可出队</span></span><br><span class="line">            notEmpty.signal();</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            lock.unlock();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 出队</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">deq</span><span class="params">()</span> &#123;</span><br><span class="line">        lock.lock();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">while</span> (队列已空) &#123;</span><br><span class="line">                <span class="comment">// 等待队列不空</span></span><br><span class="line">                notEmpty.await();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// remove the first element from queue</span></span><br><span class="line">            <span class="comment">// 出队后，通知可入队</span></span><br><span class="line">            notFull.signal();</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            lock.unlock();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="AQS-amp-synchronized"><a href="#AQS-amp-synchronized" class="headerlink" title="AQS &amp; synchronized"></a>AQS &amp; synchronized</h2><p>JUC AQS 就是基于管程实现的，内部包含两个队列，一个是同步队列，一个是等待队列：</p>
<ol>
<li>同步队列：锁被占用时，会将该线程添加到同步队列中。当锁释放后，会从队列中唤醒一个线程，又分为公平和非公平两种。</li>
<li>等待队列：当调用 await 时，会将该线程添加到等待队列中。当其它线程调用 notify 时，会将该线程从等待队列移动到同步队列中，重新竞争锁。</li>
</ol>
<p>synchronized 也是基于管程实现的，核心的数据结构见 ObjectMonitor。AQS 和 synchronized 都是管程 MESA 模型在 Java 中的应用。一切都套路，有章可循。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://scatteredream.github.io/2025/01/20/408-OS-%E8%99%9A%E6%8B%9F%E6%9C%BA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars.githubusercontent.com/u/62317679?s=400&v=4">
      <meta itemprop="name" content="碎梦">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="scatteredream's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | scatteredream's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/01/20/408-OS-%E8%99%9A%E6%8B%9F%E6%9C%BA/" class="post-title-link" itemprop="url">虚拟机</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-01-20 00:00:00" itemprop="dateCreated datePublished" datetime="2025-01-20T00:00:00+08:00">2025-01-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-05-05 11:51:29" itemprop="dateModified" datetime="2025-05-05T11:51:29+08:00">2025-05-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/OS/" itemprop="url" rel="index"><span itemprop="name">OS</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Hypervisor-VMM"><a href="#Hypervisor-VMM" class="headerlink" title="Hypervisor (VMM)"></a>Hypervisor (VMM)</h1><p>Hypervisor 是一种运行在基础硬件和操作系统之间的中间软件层，可允许多个操作系统和应用共享硬件。也可叫做虚拟机监视器，即 VMM（ virtual machine monitor ）。（操作系统的操作系统）</p>
<p>动机：</p>
<ol>
<li>提高硬件的利用率，一套硬件跑多个操作系统</li>
<li>方便多平台软件的开发与调试</li>
</ol>
<ul>
<li>当服务器启动并执行 Hypervisor 时，它会加载所有虚拟机客户端的操作系统同时会分配给每一台虚拟机适量的内存，CPU，网络和磁盘。它允许多个操作系统（称为<strong>Guest OS</strong>）在同一台物理机器（称为<strong>Host</strong>）上同时运行，每个操作系统被隔离在独立的虚拟机中。</li>
<li>Hypervisor 负责资源分配，如 CPU、内存和存储，协调着这些硬件资源的访问，而且在各个虚拟机之间施加防护，处理虚拟机之间的通信和安全隔离。</li>
</ul>
<h2 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h2><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/VMwarevsKVM1.png" alt="KVM vs VMware – Uma comparação de Hypervisors - Wintech"></p>
<ul>
<li><p><strong>Type 1 (裸机型):</strong> 直接运行在物理硬件上，例如 VMware ESXi、Microsoft Hyper-V、KVM。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/virtual-machine-diagram.svg" alt="体系结构图，显示 VM 如何运行完整的操作系统（独立于主机操作系统）"></p>
<p>KVM (Kernel-Based Virtual Machine) 是 x86 硬件上 Linux 的完整虚拟化解决方案。它由提供核心虚拟化基础设施的可加载内核模块 kvm.ko 和处理器特定模块 kvm-intel.ko 或 kvm-amd.ko 组成。采用硬件辅助虚拟化技术 Intel-VT、AMD-V，内存的相关如 Intel 的 EPT 和 AMD 的 RVI 技术</p>
</li>
<li><p><strong>Type 2 (托管型):</strong> 运行在操作系统之上，例如 VMware Workstation、Oracle VirtualBox。</p>
</li>
<li><p><strong>QEMU</strong>: </p>
<ul>
<li><p>最初 <strong>QEMU</strong>(Quick Emulator)是一个系统模拟器，它可以在一种体系结构的系统上模拟另一种体系结构的系统。不但模拟 CPU，还模拟各种外设。其中 CPU 的模拟主要是通过指令翻译的方式，所以速度比较慢：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/e45iakbuhu.jpeg" alt="img"></p>
</li>
<li><p>KVM 只靠上面的两个内核模块不能创建完整的虚拟机，KVM 是一种中间件，属于 Linux 的内核模块，将 Linux 变成一个 Hypervisor，可以虚拟化 CPU 和内存，在系统需要虚拟化功能的时候，内核把 KVM 模块调入内存中运行。但用户无法直接控制内核，所以需要一个处于内核和用户之间的一个桥梁 QEMU。KVM 团队 fork 了 QEMU 作为用户态的部分，一起实现了虚拟机(QEMU 模拟系统的其他组件如磁盘等；KVM 模拟 CPU 和内存)。</p>
</li>
<li><p>从 KVM 的角度看，它的用户态部分在 QEMU 里，一起虚拟出完整 Guest OS；</p>
</li>
<li><p>从 QEMU 的角度看，它有一个 Virtualization 模式，就是使用 KVM 来模拟 CPU 内存网络，实现加速。QEMU 通过 KVM 的用户态部分访问 KVM 的内核态部分。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/kvm-qemu-1735307591402-91.png" alt="figure1"></p>
</li>
</ul>
</li>
</ul>
<p>某些文献中，VMM 特指 Type 2 Hypervisor 中用于模拟 CPU 指令集和设备驱动的核心软件组件，特别是在微内核环境中，对 Hypervisor 和 VMM 进行了区分。在那里，两个组件形成了某个系统的整体虚拟化堆栈。 Hypervisor 指的是内核空间功能，VMM 指的是用户空间功能。具体来说，在这些上下文中，Hypervisor 是实现虚拟化基础设施的微内核，由于技术原因必须在内核空间中运行，例如 Intel VMX。实现虚拟化机制的微内核也称为微管理程序。将此术语应用到 Linux 中，KVM 是一个 Hypervisor，而 QEMU 是利用 KVM 作为 Hypervisor 的 VMM。</p>
<h2 id="CPU-Virtualization"><a href="#CPU-Virtualization" class="headerlink" title="CPU Virtualization"></a>CPU Virtualization</h2><h2 id="Memory-Virtualization"><a href="#Memory-Virtualization" class="headerlink" title="Memory Virtualization"></a>Memory Virtualization</h2>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://scatteredream.github.io/2025/01/18/408-OS-%E8%99%9A%E6%8B%9F%E5%8C%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars.githubusercontent.com/u/62317679?s=400&v=4">
      <meta itemprop="name" content="碎梦">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="scatteredream's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | scatteredream's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/01/18/408-OS-%E8%99%9A%E6%8B%9F%E5%8C%96/" class="post-title-link" itemprop="url">虚拟化</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-01-18 00:00:00" itemprop="dateCreated datePublished" datetime="2025-01-18T00:00:00+08:00">2025-01-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-05-05 11:42:43" itemprop="dateModified" datetime="2025-05-05T11:42:43+08:00">2025-05-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/OS/" itemprop="url" rel="index"><span itemprop="name">OS</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="CPU-Virtualization"><a href="#CPU-Virtualization" class="headerlink" title="CPU Virtualization"></a>CPU Virtualization</h1><h2 id="进程（process）"><a href="#进程（process）" class="headerlink" title="进程（process）"></a>进程（process）</h2><p><strong>操作系统</strong>：早期是一些函数库，然后发展出了保护的作用（内核态与用户态），之后是多道程序（多进程、多线程）</p>
<p><strong>软件设计思维</strong>：分离机制与策略</p>
<ul>
<li>机制：如何进行上下文切换？</li>
<li>策略：什么情况下，应该切换到谁？</li>
</ul>
<p><strong>进程</strong>：程序没有运行的时候，就是硬盘中静态的代码，程序开始运行了，就在内存中开辟属于自己的空间，进程可以看作是操作系统对程序运行的一种抽象。</p>
<h3 id="进程创建"><a href="#进程创建" class="headerlink" title="进程创建"></a>进程创建</h3><ul>
<li>内存地址空间，特定CPU寄存器的值</li>
<li><strong>内存分配</strong>：程序代码、静态数据、运行时数据（包括堆栈和IO设置）</li>
<li><strong>栈空间</strong>（Stack）：可以由<code>main</code>传参进行初始化，主要存放局部变量、函数参数和返回地址</li>
<li><strong>用于IO的文件描述符</strong>（Descriptor）：默认开启<code>stdin</code> <code>stdout</code> <code>stderr</code>三个文件</li>
<li><strong>堆空间</strong>（Heap）：用于在程序运行时动态地向OS申请一片内存(<code>malloc</code>)</li>
<li>在进程创建之后，OS将CPU控制权给到程序，开始执行<code>main</code></li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241207204834626.png" alt="image-20241207204834626"></p>
<h3 id="进程状态"><a href="#进程状态" class="headerlink" title="进程状态"></a>进程状态</h3><p>加载到内存的进程基本状态如下三种</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241207204852570.png" alt="image-20241207204852570"></p>
<ul>
<li><strong>运行中</strong>：运行中的进程，也可以被反向调度</li>
<li><strong>待运行</strong>（就绪）：就绪的程序随时可以运行，等待调度</li>
<li><strong>阻塞</strong>：程序运行到不需要CPU的部分（比如IO）就会到阻塞状态，等IO任务完成会变成就绪</li>
<li>OS选择在进程发起IO时切换到别的进程，这样可以保持CPU繁忙，<strong>在IO结束时没有选择切换回去，这就是策略</strong></li>
</ul>
<h3 id="进程的数据结构"><a href="#进程的数据结构" class="headerlink" title="进程的数据结构"></a>进程的数据结构</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// the registers xv6 will save and restore</span></span><br><span class="line"><span class="comment">// to stop and subsequently restart a process</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">context</span> &#123;</span></span><br><span class="line">    <span class="type">int</span> eip;<span class="comment">//instruction ptr </span></span><br><span class="line">    <span class="type">int</span> esp;<span class="comment">//stack ptr</span></span><br><span class="line">    <span class="type">int</span> ebx;</span><br><span class="line">    <span class="type">int</span> ecx;</span><br><span class="line">    <span class="type">int</span> edx;</span><br><span class="line">    <span class="type">int</span> esi;</span><br><span class="line">    <span class="type">int</span> edi;</span><br><span class="line">    <span class="type">int</span> ebp;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// the different states a process can be in</span></span><br><span class="line"><span class="class"><span class="keyword">enum</span> <span class="title">proc_state</span> &#123;</span> UNUSED, EMBRYO, SLEEPING,</span><br><span class="line">RUNNABLE, RUNNING, ZOMBIE &#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// the information xv6 tracks about each process</span></span><br><span class="line"><span class="comment">// including its register context and state</span></span><br><span class="line"><span class="comment">// PCB</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">proc</span> &#123;</span></span><br><span class="line">    <span class="type">char</span> *mem; <span class="comment">// Start of process memory</span></span><br><span class="line">    uint sz; <span class="comment">// Size of process memory</span></span><br><span class="line">    <span class="type">char</span> *kstack; <span class="comment">// Bottom of kernel stack for this process</span></span><br><span class="line">    <span class="class"><span class="keyword">enum</span> <span class="title">proc_state</span> <span class="title">state</span>;</span> <span class="comment">// Process state</span></span><br><span class="line">    <span class="type">int</span> pid; <span class="comment">// Process ID</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">proc</span> *<span class="title">parent</span>;</span> <span class="comment">// Parent process</span></span><br><span class="line">    <span class="type">void</span> *chan; <span class="comment">// If !zero, sleeping on chan</span></span><br><span class="line">    <span class="type">int</span> killed; <span class="comment">// If !zero, has been killed</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">file</span> *<span class="title">ofile</span>[<span class="title">NOFILE</span>];</span> <span class="comment">// Open files</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">inode</span> *<span class="title">cwd</span>;</span> <span class="comment">// Current directory</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">context</span> <span class="title">context</span>;</span> <span class="comment">// Switch here to run process</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">trapframe</span> *<span class="title">tf</span>;</span> <span class="comment">// Trap frame for the current interrupt</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<blockquote>
<p> A process list contains information about all processes in the system. Each entry is found in what is sometimes called a process control block (<strong>PCB</strong>), which is really just a structure that contains information about a specific process. </p>
</blockquote>
<ul>
<li><strong>上下文</strong>：指令指针、栈指针等都是CPU物理寄存器的内容，指令得以继续执行的关键，在恢复进程时很重要。</li>
<li><strong>进程状态</strong></li>
<li><strong>其他的静态信息</strong>：进程地址空间，父进程、中断信息、打开的文件等。</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/202209241609976.png" alt="vfs"></p>
<h3 id="进程API"><a href="#进程API" class="headerlink" title="进程API"></a>进程API</h3><h4 id="fork-wait-exec"><a href="#fork-wait-exec" class="headerlink" title="fork wait exec"></a>fork wait exec</h4><ul>
<li><strong>fork</strong>：复制一个和父进程一样的子进程（子进程直接从fork返回然后继续执行）子进程的内存空间和父进程是独立的，并且变量的值大部分一样，</li>
<li><strong>wait</strong>：子进程创建后，根据OS调度（schedule）决定先后顺序，wait可以使父进程等子进程执行完再开始运行</li>
<li><strong>exec</strong>：当前进程不想运行和之前一样的代码，可以调用exec加参数运行其他代码，新的程序会替代原来进程的所有信息，因此exec后边的代码是不会被执行的。</li>
</ul>
<h4 id="shell"><a href="#shell" class="headerlink" title="shell"></a>shell</h4><ul>
<li>shell的基本原理就是主进程fork wait 子进程这边exec 运行其他程序，运行完成主进程wait结束，继续进行其他操作</li>
<li><strong>输出重定向</strong>（redirecting）：默认输出就是标准输出流，如果你想重定向到一个文件，应当关闭stdout然后重新打开一个你想要的文件描述符。</li>
<li><strong>管道</strong>（pipe）：也类似与输出重定向，上一个的输出无缝作为下一个的输入</li>
<li><strong>有用的cli工具</strong>：top(table of processes), ps(process status), man(manual)…</li>
</ul>
<h4 id="signals-and-users"><a href="#signals-and-users" class="headerlink" title="signals and users"></a>signals and users</h4><blockquote>
<p>For example, control-c sends a SIGINT (interrupt) to the process (normally terminating it) and control-z sends a SIGTSTP (stop) signal thus pausing the process in mid-execution (you can resume it later with a command, e.g., the fg built-in command found in many shells).</p>
<p>receive and process those signals within individual processes, and  send signals to individual processes as well as entire process groups.</p>
</blockquote>
<p><code>signal()</code>可以使进程能够监听到上述这些信号，暂停现有程序执行，然后对信号做出一定的响应</p>
<blockquote>
<p>Users generally can only control their own processes; it is the job of the operating system to parcel out resources (such as CPU, memory, and disk) to each user (and their processes) to meet overall system goals.</p>
</blockquote>
<p>用户等级决定他们是否有权利发出某些特定的信号</p>
<hr>
<h2 id="机制：受限-直接执行"><a href="#机制：受限-直接执行" class="headerlink" title="机制：受限 直接执行"></a>机制：受限 直接执行</h2><h3 id="Limited-Direct-Execution"><a href="#Limited-Direct-Execution" class="headerlink" title="Limited Direct Execution"></a>Limited Direct Execution</h3><p><strong>直接执行</strong>：直接在CPU上运行程序。</p>
<p><strong>受限</strong>：一个进程要调用I/O，但是还不能让进程完全控制系统。</p>
<p><strong>用户模式</strong>（user mode）：应用程序不能完全控制硬件资源，如果硬要发起IO请求，CPU会出现异常，OS将终止进程</p>
<p><strong>内核模式</strong>（kernel mode）：操作系统可以完全掌控硬件。</p>
<blockquote>
<p>When changing protection levels from user to kernel mode, the kernel shouldn’t use the stack of the user process, because it may not be valid. The user process may be <strong>malicious</strong> or <strong>contain an error that causes the user %esp to contain an address that is not part of the process’s user memory</strong>.</p>
</blockquote>
<h4 id="syscall-amp-trap"><a href="#syscall-amp-trap" class="headerlink" title="syscall &amp; trap"></a>syscall &amp; trap</h4><p><strong>系统调用</strong>（system call）：允许内核小心地向用户暴露某些关键功能。执行<strong>trap</strong>指令，进入操作系统内核，将特权级别提升至内核模式，完成之后return from trap，返回值并将特权级别降低至用户模式。</p>
<blockquote>
<p>Typical user applications run in user mode, and use a system call to trap into the kernel to request operating system services.</p>
</blockquote>
<p>系统调用的参数放到一个指定的寄存器处，系统调用号也放到指定寄存器，需要仔细遵循约定来正确处理参数与返回值，高级语言通常屏蔽了底层硬件细节，因此需要使用汇编语言：</p>
<ul>
<li><strong>系统调用</strong>：用户程序通过陷阱指令请求内核服务（如文件操作、进程管理）。例如，在x86中：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mov eax, 1   ; 系统调用号 (exit)</span><br><span class="line">mov ebx, 0   ; 参数 (退出码)</span><br><span class="line">int 0x80     ; 触发陷阱</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>中断处理</strong>：硬件设备通过中断向量触发陷阱，操作系统用汇编语言编写中断向量表。</li>
<li><strong>异常处理</strong>：陷阱用于处理非法操作（如除零或非法内存访问）。</li>
</ul>
<p><strong>陷阱表</strong>（trap table）：用户态不能执行io等直接操控底层硬件，否则就是非法的。进入内核态以后也不能随便寻址执行程序，必须跳到指定地址去执行对应的程序，这个指定的程序地址是<strong>内核</strong>（kernel）在启动时通过<strong>陷阱表</strong>告诉硬件的。用户程序也不能够识别陷阱表的内容。</p>
<blockquote>
<p>The trap instruction saves register state carefully, changes the hardware status to kernel mode, and jumps into the OS to a pre-specified destination: the trap table.</p>
<p>When the OS finishes servicing a system call, it returns to the user program via another special return-from-trap instruction, which reduces privilege and returns control to the instruction after the trap that jumped into the OS</p>
</blockquote>
<p>Limited Direct Execution Timeline：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241207194358704.png" alt="image-20241207194358704"></p>
<ul>
<li><p>要么是内核态要么是用户态，在用户进程开始执行之前（main）的准备工作肯定是由内核态完成，因此就要return from trap，切换到用户态。跳转到main函数</p>
</li>
<li><p>执行系统调用或者响应中断时，通过trap指令，cpu控制权腾给os，陷入内核态，执行的是与之前不同的程序，就需要保存执行的现场以便之后继续执行，将cpu寄存器上的内容先保存到<strong>内核栈（kernel stack）</strong>。</p>
</li>
<li><p>在系统调用结束之后把内核栈的内容弹出恢复到CPU寄存器上，切换回用户模式，继续执行之前的内容，最后main函数返回，同时通过exit()进行trap，进入内核态，做清理工作。</p>
</li>
</ul>
<h3 id="Limited-Direct-Execution-Timer-Interrupt"><a href="#Limited-Direct-Execution-Timer-Interrupt" class="headerlink" title="Limited Direct Execution(Timer Interrupt)"></a>Limited Direct Execution(Timer Interrupt)</h3><p><strong>直接执行（Direct Execution）</strong>：用户进程占用CPU，OS作为一个程序并没有在运行。问题在于OS如何重新获得CPU的控制权，以便在操控程序运行取得主动权。</p>
<p><strong>协作</strong>：OS只能等待被动的系统调用或者触发异常才会重新获得CPU控制权。</p>
<p><strong>非协作</strong>：时钟硬件设备可以编程为若干毫秒产生一次中断信号，CPU 检测到时钟中断信号后，暂停当前正在运行的任务，跳转到内核中预定义的<strong>中断服务例程（ISR, Interrupt Service Routine）</strong>处理</p>
<p>CPU必须在硬件层面实现能够保存用户程序运行的现场（trap的精髓）</p>
<ul>
<li><p><strong>操作系统处理时钟中断</strong>操作系统在时钟中断处理程序中执行以下任务：</p>
<ul>
<li><p>更新系统时间。</p>
</li>
<li><p>检查是否需要切换任务（触发<strong>任务调度</strong>）。</p>
</li>
<li><p>处理延迟或周期性任务（如超时处理、定时器事件等）。</p>
</li>
</ul>
</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241207200809875.png" alt="image-20241207200809875"></p>
<p>如图 hardware部分 需要在响应时钟中断时，把进程A的运行现场（寄存器）保存到内核栈中，然后跳转到trap处理程序。</p>
<h4 id="上下文切换（context-switch）"><a href="#上下文切换（context-switch）" class="headerlink" title="上下文切换（context switch）"></a>上下文切换（context switch）</h4><p>然后操作系统调用switch进行进程的切换A到B，因为一段时间内A都不会再运行，这时候就需要把A的寄存器内容保存到其进程空间（内存空间）</p>
<h5 id="kernel-stack-vs-Process-Control-Block"><a href="#kernel-stack-vs-Process-Control-Block" class="headerlink" title="kernel stack  vs Process Control Block"></a><code>kernel stack</code>  vs <code>Process Control Block</code></h5><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/likui360/p/6224624.html">Linux 系统中堆栈的使用方法 - 扫地猿 - 博客园</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/188577062">浅谈Linux 中的进程栈、线程栈、内核栈、中断栈 - 知乎</a></p>
<p>当进程在用户态运行时，使用的是用户栈，当进程陷入到内核态时，这些内核代码所使用的栈并不是原先进程用户空间中的栈，而是一个单独内核空间的栈，这个称作进程内核栈，内核栈保存进程在内核态运行的相关信息，一旦进程返回到用户态后，内核栈中保存的信息无效，会全部恢复，因此每次进程从用户态陷入内核的时候得到的内核栈都是空的。所以在进程陷入内核的时候，直接把内核栈的栈顶地址给堆栈指针寄存器就可以了。</p>
<p>当位于用户空间的进程进行系统调用时，进程用户栈的地址会被存进内核栈中，CPU堆栈指针寄存器中的内容也会变为内核栈的地址。当系统调用执行完毕，进程从内核栈找到用户栈的地址，继续在用户空间中执行，此时CPU堆栈指针寄存器就变为了用户栈的地址。各进程独立的。进程运行时分用户态跟内核态，所以需要有内核栈和常说的堆栈段，寻址方式是相同的，都是查LDT和页表进行地址映射，但二者段描述符里的特权级不同，为了区分用户态和内核态。</p>
<p>为什么每个进程都有一个内核栈，而不是所有进程共用一个。老的UNIX和Linux当时就是每个CPU只有一个内核栈，那个时候不会出现“执行到一半的时候上下文切换”，因为不允许用户态程序抢占正在执行系统调用的另一个用户态程序。后来每个进程一个内核栈了，就可以发生“执行到一半的时候上下文切换”了</p>
<p>语言书里面讲的堆、栈大部分都是用户态的概念，用户态的堆、栈对应用户进程虚拟地址空间里的一个区域，栈向下增长，堆用malloc分配，向上增长。</p>
<ul>
<li>中断发生时，寄存器先保存到内核栈；如果需要切换进程，内核会将内核栈中的寄存器内容转存到进程结构中。</li>
<li><strong>内核栈</strong>主要用于快速保存和恢复寄存器内容，适用于临时的上下文切换或中断处理。</li>
<li><strong>进程结构</strong>适用于更复杂的进程调度和长时间的上下文切换，提供长期的状态保存。proc结构体中的context字段就是用来保存寄存器信息的（xv6）</li>
</ul>
<table>
<thead>
<tr>
<th><strong>方面</strong></th>
<th><strong>内核栈</strong></th>
<th><strong>进程结构（PCB）</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>保存时机</strong></td>
<td>短暂事件（如中断、系统调用）</td>
<td>进程调度时</td>
</tr>
<tr>
<td><strong>存储位置</strong></td>
<td>当前进程的内核栈</td>
<td>PCB 或其他持久性数据结构</td>
</tr>
<tr>
<td><strong>存储时间</strong></td>
<td><strong>临时保存</strong>，内核处理结束后直接恢复</td>
<td><strong>长期保存</strong>，直至进程切换回来</td>
</tr>
<tr>
<td><strong>访问开销</strong></td>
<td>较低，直接访问内核栈</td>
<td>较高，涉及更多内存操作</td>
</tr>
<tr>
<td><strong>适用场景</strong></td>
<td>快速上下文切换、临时中断处理</td>
<td>进程调度或长时间上下文切换</td>
</tr>
<tr>
<td><strong>局限性</strong></td>
<td>不能长期存储</td>
<td>开销大，需要额外的数据结构</td>
</tr>
<tr>
<td>优点</td>
<td>连续内存块，访问效率较高，内核处理完直接恢复</td>
<td>寄存器信息可以跨多个调度周期存储</td>
</tr>
</tbody></table>
<p>进程调度，需要把B的现场信息从进程空间中恢复到寄存器里，然后恢复到用户态，跳转到B的PC，执行B的内容。</p>
<p><strong>并发</strong>：系统调用时触发中断。</p>
<hr>
<h2 id="策略：CPU-调度"><a href="#策略：CPU-调度" class="headerlink" title="策略：CPU 调度"></a>策略：CPU 调度</h2><h3 id="基本策略"><a href="#基本策略" class="headerlink" title="基本策略"></a>基本策略</h3><h4 id="批处理"><a href="#批处理" class="headerlink" title="批处理"></a>批处理</h4><p><strong>FIFO</strong>：先到先得，计算密集型会阻塞io密集型，降低效率</p>
<p><strong>SJF</strong>：Shortest Job First 最短工作优先，<u>同时到达</u>，先进行最短的工作</p>
<p><strong>STCF</strong>：Shortest Time-to-Complete First 最短完成时间优先，针对<u>随时到达</u>的情况，到达时比较里完成还有多少时间，首次出现了任务切换的概念。</p>
<h4 id="交互式"><a href="#交互式" class="headerlink" title="交互式"></a>交互式</h4><p>以上能够逐步优化 T<del>周转</del> = T<del>完成</del> - T<del>到达</del>，但是对于T<del>响应</del> = T<del>首次运行</del> - T<del>到达</del> 不友好，因为完成时间最长的必须等其他任务完成，自己才能继续。</p>
<p>交互式的任务对于响应时间很敏感。因此需要另外一种调度策略</p>
<p><strong>RR</strong>：Round-Robin 轮转，运行一个任务到时间片就切换到下一个任务（context switch）</p>
<ul>
<li>上下文的切换需要时间，因此时间片的大小也应该选择恰当</li>
</ul>
<p><strong>Overlap</strong>：重叠，如果A任务有IO，当A因为IO而空出CPU时，CPU就应该去服务B</p>
<p><strong>不可预知性</strong>：调度程序不知道到来的任务持续多长时间。</p>
<h4 id="实时系统"><a href="#实时系统" class="headerlink" title="实时系统"></a>实时系统</h4><p>准时比准确更加重要</p>
<h3 id="基于优先级且无需先验知识的调度：多级反馈队列-MLFQ"><a href="#基于优先级且无需先验知识的调度：多级反馈队列-MLFQ" class="headerlink" title="基于优先级且无需先验知识的调度：多级反馈队列 MLFQ"></a>基于优先级且无需先验知识的调度：多级反馈队列 MLFQ</h3><p>MLFQ：Multi-Level Feedback Queue，多级反馈队列</p>
<ul>
<li>设置不同的优先级，每个任务刚到达都是最高级</li>
<li>级别低的任务必须先让级别高的执行完</li>
<li>相同级别的任务轮转执行</li>
<li>在同一个优先级执行时间达到阈值就降低优先级：防止高优先级一直占据CPU，如果采用每次执行的计时方法可能会有恶意占据CPU的情况发生</li>
<li>每隔一段时间就重置所有任务的优先级为最高：防止低优先级变成饥饿状态</li>
</ul>
<h1 id="Memory-Virtualization"><a href="#Memory-Virtualization" class="headerlink" title="Memory Virtualization"></a>Memory Virtualization</h1><h2 id="每个程序员都应该知道的时延"><a href="#每个程序员都应该知道的时延" class="headerlink" title="每个程序员都应该知道的时延"></a>每个程序员都应该知道的时延</h2><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/687474703a2f2f692e696d6775722e636f6d2f6b307431652e706e67" alt="img"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">L1 cache reference ......................... 0.5 ns</span><br><span class="line">Branch mispredict ............................ 5 ns</span><br><span class="line">L2 cache reference ........................... 7 ns</span><br><span class="line">Mutex lock/unlock ........................... 25 ns</span><br><span class="line">Main memory reference ...................... 100 ns             </span><br><span class="line">Compress 1 KB with Zippy ................. 3,000 ns  =       3 µs</span><br><span class="line">Send 2 KB over 1 Gbps network ........... 20,000 ns  =      20 µs</span><br><span class="line">SSD random read ........................ 150,000 ns  =     150 µs</span><br><span class="line">Read 1 MB sequentially from memory ..... 250,000 ns  =     250 µs</span><br><span class="line">Round trip within same datacenter ...... 500,000 ns  =     500 µs  =  0.5 ms</span><br><span class="line">Read 1 MB sequentially from SSD ...... 1,000,000 ns  =   1,000 µs  =    1 ms</span><br><span class="line">Disk seek ........................... 10,000,000 ns  =  10,000 µs  =   10 ms</span><br><span class="line">Read 1 MB sequentially from disk .... 20,000,000 ns  =  20,000 µs  =   20 ms</span><br><span class="line">Send packet CA-&gt;Netherlands-&gt;CA .... 150,000,000 ns  = 150,000 µs  =  150 ms</span><br></pre></td></tr></table></figure>

<h2 id="地址空间、分段（segmentation）"><a href="#地址空间、分段（segmentation）" class="headerlink" title="地址空间、分段（segmentation）"></a>地址空间、分段（segmentation）</h2><p><img src="https://upload.wikimedia.org/wikipedia/commons/7/70/VirtualMem01.png" alt="img"></p>
<p><strong>地址空间</strong>：程序认为自己独占了这片内存空间，以为自己是连续的内存空间。低位是代码，堆往上递增，栈往下反向增长。</p>
<p>实际上是在物理内存中申请了一片连续的内存空间分配给进程，进程根据指令寻址的时候，操作系统将虚拟地址 <strong>重定位</strong> 到真正的物理地址。虚拟地址从0开始，因此虚拟地址实际上就是物理地址的偏移量。直接打印指针变量的值是虚拟地址而不是物理地址。</p>
<h3 id="虚拟内存的作用"><a href="#虚拟内存的作用" class="headerlink" title="虚拟内存的作用"></a>虚拟内存的作用</h3><p><strong>隔离进程</strong>：物理内存通过虚拟地址空间访问，虚拟地址空间与进程一一对应。每个进程都认为自己拥有了整个物理内存，进程之间彼此隔离，一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。</p>
<p><strong>提升物理内存利用率</strong>：有了虚拟地址空间后，操作系统只需要将进程当前正在使用的部分数据或指令加载入物理内存。</p>
<p><strong>简化内存管理</strong>：进程都有一个一致且私有的虚拟地址空间，程序员不用和真正的物理内存打交道，而是借助虚拟地址空间访问物理内存，从而简化了内存管理。</p>
<p><strong>多个进程共享物理内存</strong>：进程在运行过程中，会加载许多操作系统的动态库。这些库对于每个进程而言都是公用的，它们在内存中实际只会加载一份，这部分称为共享内存。</p>
<p><strong>提高内存使用安全性</strong>：控制进程对物理内存的访问，隔离不同进程的访问权限，提高系统的安全性。</p>
<p><strong>提供更大的可使用内存空间</strong>：可以让程序拥有超过系统物理内存大小的可用内存空间。这是因为当物理内存不够用时，可以利用磁盘充当，将物理内存页（通常大小为 4 KB）保存到磁盘文件（会影响读写速度），数据或代码页会根据需要在物理内存与磁盘之间移动。</p>
<hr>
<p>著作权归JavaGuide(javaguide.cn)所有 基于MIT协议 原文链接：<a target="_blank" rel="noopener" href="https://javaguide.cn/cs-basics/operating-system/operating-system-basic-questions-02.html">https://javaguide.cn/cs-basics/operating-system/operating-system-basic-questions-02.html</a></p>
<h3 id="重定位（relocation）"><a href="#重定位（relocation）" class="headerlink" title="重定位（relocation）"></a>重定位（relocation）</h3><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241210205158811.png" alt="image-20241210205158811"></p>
<p><code>Virtual Address + Base = Physical Address</code> </p>
<p><strong>静态重定位</strong>：用软件实现，直接将指令中的虚拟地址用计算的真实物理地址覆盖。</p>
<ul>
<li>缺点：不安全，不方便更改。</li>
</ul>
<p><strong>动态重定位</strong>：用硬件实现，也就是CPU中的==MMU==，里面两个最基本的寄存器：<strong>基址寄存器</strong>、<strong>界限寄存器</strong>。将指令中的虚拟地址和基址相加得出真实物理地址，然后取得从硬件层面取得对应地址的值。这一切都是用硬件进行的。</p>
<ul>
<li>安全性：用界限（bound）和虚拟地址比较，如果超过了界限，说明虚拟地址访问越界，抛出异常</li>
<li>便于更改：改变寄存器的值即可实现基址的改变</li>
<li>性能高：硬件实现性能好</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241210205227715.png" alt="image-20241210205227715"></p>
<h3 id="实现虚拟内存"><a href="#实现虚拟内存" class="headerlink" title="实现虚拟内存"></a>实现虚拟内存</h3><p><strong>实现虚拟内存机制的硬件支持：MMU</strong></p>
<ul>
<li><p>划分用户空间和内核空间</p>
</li>
<li><p>一对基址寄存器和界限寄存器，专门用来进行地址转换的电路</p>
</li>
<li><p>专门用来判断是否越界的电路，判断越界之后应当向CPU抛出异常</p>
</li>
<li><p>特权指令：操作系统应当能够设置上述寄存器的值</p>
</li>
<li><p>特权指令：操作系统应当告诉硬件发现异常应该执行哪些代码（Exception Handler）</p>
</li>
</ul>
<p><strong>实现虚拟内存机制的软件支持：OS</strong></p>
<ul>
<li>内存管理：分配机制、释放机制、空闲空间的管理——free list</li>
<li>切换上下文时正确设置对应的寄存器</li>
<li>抛出异常（内存访问越界、非法指令）时执行特定的处理代码</li>
</ul>
<p><strong>地址空间的不足</strong>：内部碎片（inner fragment）栈和堆之间未使用的空间也分配给整个地址空间，浪费较大</p>
<h3 id="分段"><a href="#分段" class="headerlink" title="分段"></a>分段</h3><h4 id="segmentation"><a href="#segmentation" class="headerlink" title="segmentation"></a>segmentation</h4><p><strong>段式管理</strong>：以段(—段连续的物理内存)的形式管理/分配物理内存。应用程序的虚拟地址空间被分为大小不等的段，段是有实际意义的，每个段定义了一组逻辑信息，例如有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。然后给每个段都配一对基址寄存器和界限寄存器。</p>
<p>例：0-16KB的虚拟地址空间，虚拟地址14位，高2位为段号，低12位为最大4KB的段空间。虚拟地址 = 段号 + 偏移 </p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// get top 2 bits of 14-bit VA</span></span><br><span class="line">Segment = (VirtualAddress &amp; SEG_MASK) &gt;&gt; SEG_SHIFT</span><br><span class="line"><span class="comment">// now get offset</span></span><br><span class="line">Offset = VirtualAddress &amp; OFFSET_MASK</span><br><span class="line"><span class="keyword">if</span> (Offset &gt;= Bounds[Segment])</span><br><span class="line">	RaiseException(PROTECTION_FAULT)<span class="comment">//抛出异常</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">	PhysAddr = Base[Segment] + Offset<span class="comment">//基址+偏移</span></span><br><span class="line">	Register = AccessMemory(PhysAddr)<span class="comment">//访存</span></span><br></pre></td></tr></table></figure>

<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241210205528802.png" alt="image-20241210205528802"></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241210205438635.png" alt="image-20241210205438635"></p>
<table>
<thead>
<tr>
<th>段名称</th>
<th>段号</th>
<th>基址寄存器</th>
<th>界限寄存器</th>
<th>是否正向增长</th>
</tr>
</thead>
<tbody><tr>
<td>代码</td>
<td>00</td>
<td>26 KB</td>
<td>2 KB</td>
<td>1</td>
</tr>
<tr>
<td>堆</td>
<td>01</td>
<td>28 KB</td>
<td>2 KB</td>
<td>1</td>
</tr>
<tr>
<td>栈</td>
<td>11</td>
<td>18 KB</td>
<td>2 KB</td>
<td>0</td>
</tr>
</tbody></table>
<p>现在要判断虚拟地址15KB的真实地址：<code>11 11 00000 00000</code> 可见段号为 11，偏移 3 KB，栈空间反向增长，最大段空间为 4 KB，实际上就是计算15KB离全1有多远：3KB - 4KB = -1 KB,因此在基址寄存器减1KB即为实际物理地址。</p>
<h5 id="用于保护的额外状态字"><a href="#用于保护的额外状态字" class="headerlink" title="用于保护的额外状态字"></a>用于保护的额外状态字</h5><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241211001125226.png" alt="image-20241211001125226"></p>
<h5 id="分段的问题"><a href="#分段的问题" class="headerlink" title="分段的问题"></a>分段的问题</h5><ul>
<li><strong>外部碎片</strong>：每个分段的大小不一致，因此产生了大小不一致的碎片，无法使空间得到有效利用。</li>
<li><strong>不支持稀疏的大堆</strong>：Another problem is that some segments could have a larger size and since this segment can’t be “broken” into smaller pieces, it must be fully allocated in memory. 分段大小是固定的，并不能将其拆成小段，申请了一段物理内存，寄存器的基址和界限已经确定好，这部分物理空间就不能再由其他的进程使用了，因此不支持按需分配。</li>
<li>Segments of unequal size not suited as well for swapping.</li>
</ul>
<h5 id="段表：更细粒度的分段"><a href="#段表：更细粒度的分段" class="headerlink" title="段表：更细粒度的分段"></a>段表：更细粒度的分段</h5><p>细粒度分段需要进一步硬件支持，并且在内存中存储 段表 （segment table）</p>
<p>分段机制下的虚拟地址由两部分组成：</p>
<ul>
<li><strong>段号</strong>：标识着该虚拟地址属于整个虚拟地址空间中的哪一个段。</li>
<li><strong>段内偏移量</strong>：相对于该段起始地址的偏移量。</li>
</ul>
<p>具体的地址翻译过程如下：</p>
<ol>
<li>MMU 首先解析得到虚拟地址中的段号；</li>
<li>通过段号去该应用程序的段表中取出对应的段信息（找到对应的段表项）；</li>
<li>从段信息中取出该段的起始地址（物理地址）加上虚拟地址中的段内偏移量得到最终的物理地址。</li>
</ol>
<p><img src="https://miro.medium.com/v2/resize:fit:1313/1*82aSNHRAkNNinGuPpsl6TQ.png" alt="img">分段机制下的地址翻译过程</p>
<p>段表中还存有诸如段长(可用于检查虚拟地址是否超出合法范围)、段类型（该段的类型，例如代码段、数据段等）等信息。</p>
<p><strong>通过段号一定要找到对应的段表项吗？得到最终的物理地址后对应的物理内存一定存在吗？</strong></p>
<p>不一定。段表项可能并不存在：</p>
<ul>
<li><strong>段表项被删除</strong>：软件错误、软件恶意行为等情况可能会导致段表项被删除。</li>
<li><strong>段表项还未创建</strong>：如果系统内存不足或者无法分配到连续的物理内存块就会导致段表项无法被创建。</li>
</ul>
<h4 id="减少碎片"><a href="#减少碎片" class="headerlink" title="减少碎片"></a>减少碎片</h4><ul>
<li><p><strong>内存紧缩</strong>（compact）：内存存储不下程序，会把暂时休息的第一个进程方法放入磁盘，过段时间移除进程b放入进程a，这样会让内存中出现空洞，所以要将进程整体往下移动。必须将运行中的进程中断，将所有分散的内存碎片压到连续的部分中，然后再将新的基址和界限移动到寄存器中，进程按照新的上下文继续执行。缺点是代价太高，性能不好</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20240922142056246.png" alt="image-20240922142056246"></p>
</li>
<li><p><strong>改善空闲列表</strong>（free list）：分配内存的时候采取一定的策略，尽量减轻内存碎片的现象，但也无法根除碎片的出现</p>
</li>
</ul>
<h2 id="空闲空间的管理"><a href="#空闲空间的管理" class="headerlink" title="空闲空间的管理"></a>空闲空间的管理</h2><p>维护一个空闲空间的列表（freelist）</p>
<h3 id="机制：分割与合并"><a href="#机制：分割与合并" class="headerlink" title="机制：分割与合并"></a>机制：分割与合并</h3><p>splitting</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241210222509968.png" alt="image-20241210222509968"></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241210222527700.png" alt="image-20241210222527700"></p>
<p>coalescing</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241210222438918.png" alt="image-20241210222438918"></p>
<h3 id="内存-API"><a href="#内存-API" class="headerlink" title="内存 API"></a>内存 API</h3><h4 id="malloc"><a href="#malloc" class="headerlink" title="malloc"></a>malloc</h4><p><code>void* malloc(int size)</code> 申请大小为size的连续字节空间（虚拟意义上的连续），返回一个指向这个空间首部的指针</p>
<p>除了用户申请的空间之外，在malloc时还会申请一个头部Header，size用来表示申请空间的大小，magic魔数用来验证完整性<a target="_blank" rel="noopener" href="https://www.cnblogs.com/whiteBear/p/16729327.html">延迟分配：提供内存利用率的三种机制 - 牛犁heart - 博客园</a></p>
<ul>
<li>malloc只是分配了虚拟内存，程序真正访问才会触发页错误给这些虚拟页分配物理页框（demand paging）</li>
<li>在标准 C 库中，提供了 malloc / free 函数分配释放内存，这两个函数底层是由 brk，mmap，munmap 这些系统调用实现的。 (<em>详见Linux虚拟内存系统</em>) 不过跟直接调用还是有区别的。</li>
</ul>
<h4 id="free"><a href="#free" class="headerlink" title="free"></a>free</h4><p><code>void free(void* ptr)</code> 将指针ptr所指向的已分配空间释放掉，依据的信息是<strong>分配内存的Header部分</strong> ，因此malloc的size并不是真正的大小，还要分配头部<img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241210221647796.png" alt="image-20241210221647796"></p>
<h3 id="嵌入-free-list-到内存中"><a href="#嵌入-free-list-到内存中" class="headerlink" title="嵌入 free list 到内存中"></a>嵌入 free list 到内存中</h3><p>free list 本身也需要存储在内存中，这里我们知道：空闲的块作为空闲节点有额外的简单数据结构（int size, node* next），已分配的块同样也有简单的数据结构（int size, int magic），因此堆实际上是一个空闲内存和已分配的内存的混合。</p>
<ul>
<li>未分配空间</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241210222820688.png" alt="image-20241210222820688"></p>
<ul>
<li>连续分配了3个100字节的空间</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241210223130088.png" alt="image-20241210223130088"></p>
<ul>
<li>中间出现了空隙，可以看到空闲列表的头节点（head）发生了变化，两个空闲的块通过链表连接起来</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241210223253160.png" alt="image-20241210223253160"></p>
<ul>
<li>全部释放之后，出现了4个空闲的块，但是还没有合并（merge）</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241210223340586.png" alt="image-20241210223340586"></p>
<h3 id="策略：连续内存分配"><a href="#策略：连续内存分配" class="headerlink" title="策略：连续内存分配"></a>策略：连续内存分配</h3><h4 id="基本策略：空闲链表"><a href="#基本策略：空闲链表" class="headerlink" title="基本策略：空闲链表"></a>基本策略：空闲链表</h4><ul>
<li><strong>Best Fit</strong>：遍历整个列表，找到跟分配块大小最接近的空闲块，尽量减少碎片大小。细小碎片多，开销大。</li>
<li><strong>Worst Fit</strong>：遍历整个列表，找到跟分配块大小差距最大的，分割之后将剩余块加入空闲列表。碎片过量，开销大。</li>
<li><strong>First Fit</strong>：第一次找到足够大的块就直接分配。会让开头部分有许多小的碎片，可以通过按地址排序，便于合并操作。</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20240922142709440.png" alt="image-20240922142709440"></p>
<ul>
<li><strong>Next Fit</strong>：每次查找都从上次结束的地方开始，剩下逻辑依然是首次匹配，可以减少开头部分过多的小碎片，将其分散到其他地方。</li>
</ul>
<p><strong>位图</strong>：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/v2-ccf3e0ea94a135e7f8548f3e9ef42813_1440w.jpg" alt="img"></p>
<h4 id="内存池（memory-pool）"><a href="#内存池（memory-pool）" class="headerlink" title="内存池（memory pool）"></a>内存池（memory pool）</h4><p>如果能将一大块内存分成多个小内存（称为内存池），不同的内存池又按照不同的「尺寸」分成大小相同的内存块（比如分别按照32, 64, 128……字节），同一内存池中的空闲内存块按照free list的方式连接。每次分配的时候，选择和申请的的内存在「尺寸」上最接近的内存池，比如申请60字节的内存，就直接从单个内存块大小为64字节的内存池的free list上分配。</p>
<img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/v2-12148c36cd07924a26e0ce35b67f29eb_1440w.jpg" alt="img" style="zoom:150%;" />

<p>需要结合系统实际的内存分配需求，对内存池的大小进行合理的划分。比如一个系统常用的是256字节以下的内存申请，那设置过多的256字节以上的内存池，就会造成内存资源的闲置和浪费。</p>
<h4 id="其他策略"><a href="#其他策略" class="headerlink" title="其他策略"></a>其他策略</h4><p>Linux 发展出两种基于内存池的分配策略，<em>详见 Linux 实现</em></p>
<ul>
<li><strong>Buddy system</strong>: 将内存池划分为以2^n^为大小的类型，同一内存池中的空闲块大小相同，如果空闲块是相邻的则合并，将合并后的块加入更大的内存池中</li>
<li><strong>SLAB</strong>: 伙伴系统是按页分配的，但内核经常会申请一些特定大小的内存，往往不到一页，如果仍然使用伙伴系统将造成很多内部碎片，SLAB为它们分配了内核对象缓存，专门的连续内存区，依然使用内存池的思路，但是池子变得比以前更小。</li>
</ul>
<h2 id="分页（paging）"><a href="#分页（paging）" class="headerlink" title="分页（paging）"></a>分页（paging）</h2><h3 id="虚拟——物理页号转换"><a href="#虚拟——物理页号转换" class="headerlink" title="虚拟——物理页号转换"></a>虚拟——物理页号转换</h3><h4 id="页帧、页帧号、虚拟页号"><a href="#页帧、页帧号、虚拟页号" class="headerlink" title="页帧、页帧号、虚拟页号"></a>页帧、页帧号、虚拟页号</h4><p><strong>分页机制</strong>：将虚拟的地址替换成物理地址，用大小相等的页代替大小不等的段。原来一个进程是代码段和数据段不等，分配的内存空间也不一样，现在将段继续拆分成大小相等的页表项，这样从根本上解决了外部碎片的问题。</p>
<p><strong>页帧（Page Frame）</strong>：物理内存中存放数据的最小单位。当一个虚拟页被映射到物理页时，数据会存放在对应的<strong>页帧</strong>中。假设一个进程的虚拟地址空间中有一个虚拟页，虚拟地址 <code>0x1000</code> 对应的虚拟页页号是 <code>0x1</code>，偏移量为0。此时，操作系统通过页表将虚拟页 <code>0x1</code> 映射到物理内存中的一个页帧 <code>0x3</code>，即物理地址为 <code>0x3000</code>。那么，当该进程访问虚拟地址 <code>0x1000</code> 时，CPU 会通过页表将其转换为物理地址 <code>0x3000</code>，并在页帧 <code>0x3</code> 中访问数据。页帧大小固定为PageSize</p>
<p><strong>虚拟地址（Virtual Address）= 虚拟页号（VPN, Virtual Page Number） + 偏移量（Offset）</strong></p>
<p><strong>页表项（Page Table Entry）= 物理页号（PFN, Page Frame Number）+ 保留的功能位</strong></p>
<p><strong>页表的物理地址</strong>：加载到<strong>页表基址寄存器（PTBR, Page Table Base Register）</strong>，一个<strong>页表项（PTE）</strong>分为<strong>物理页号（PFN）</strong>，有效位valid，读写权限位protection，内核模式位，脏位dirty，引用reference，存在位present等功能位。</p>
<h4 id="从虚拟地址访存基本步骤"><a href="#从虚拟地址访存基本步骤" class="headerlink" title="从虚拟地址访存基本步骤"></a>从虚拟地址访存基本步骤</h4><ul>
<li><p><code>VirtualAddress = VPN + Offset</code> </p>
</li>
<li><p><code>PTE Address(Physical) = VPN * PageSize + PTBR</code> PTE保存着PFN以及其他功能位</p>
</li>
<li><p><code>Physical Address = PFN * PageSize + Offset</code> </p>
</li>
<li><p>实际上VPN PFN Offset都是通过和MASK（作用和子网掩码相同）相与，然后PFN移位后和Offset相或。</p>
</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Extract the VPN from the virtual address</span></span><br><span class="line">VPN = (VirtualAddress &amp; VPN_MASK) &gt;&gt; SHIFT</span><br><span class="line"><span class="comment">// Form the address of the page-table entry (PTE)</span></span><br><span class="line">PTEAddr = PTBR + (VPN * <span class="keyword">sizeof</span>(PTE))</span><br><span class="line"><span class="comment">// Fetch the PTE</span></span><br><span class="line">PTE = AccessMemory(PTEAddr)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Check if process can access the page</span></span><br><span class="line"><span class="keyword">if</span> (PTE.Valid == False)<span class="comment">// Valid bit = 0</span></span><br><span class="line">	RaiseException(SEGMENTATION_FAULT) <span class="comment">//illegal memory access</span></span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (CanAccess(PTE.ProtectBits) == False)</span><br><span class="line">	RaiseException(PROTECTION_FAULT)</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="comment">// Access OK: form physical address and fetch it</span></span><br><span class="line">    offset = VirtualAddress &amp; OFFSET_MASK</span><br><span class="line">    PhysAddr = (PTE.PFN &lt;&lt; PFN_SHIFT) | offset</span><br><span class="line">    Register = AccessMemory(PhysAddr)</span><br></pre></td></tr></table></figure>

<p><strong>一些功能位</strong></p>
<ul>
<li>Protection bit：权限位，保护位 r w x，如果违反了越权访问，就要陷入OS</li>
<li>Valid bit：有效位，虚拟地址空间并不是全部都要分配，如果访问了还没有分配的（valid bit = 0）就是非法访问，将会抛出异常陷入OS</li>
<li>Dirty bit：脏位，页面带入内存之后是否被修改过</li>
<li>Present bit：存在位，表示内存页在内存中还是已经被换出</li>
<li>Reference bit：参考位，追踪页面是否被访问</li>
</ul>
<h4 id="页表开销"><a href="#页表开销" class="headerlink" title="页表开销"></a>页表开销</h4><ul>
<li><strong>内存开销</strong>：每个页表项需要4B，页大小（PageSize）是4KB，要虚拟出一个4GB的空间，就要有4GB/4KB * 4B =4MB 空间来存储。对每个进程操作系统都要有4MB的空间用于页表的储存，开销很大。页表是按照页号进行索引查找的，这就需要本身是一段连续的内存空间，页表就是一个大的数组，实际上页表在物理上也连续。</li>
<li><strong>性能开销</strong>：对于每个内存引用，都要额外引入一次内存引用，效率不高,每一次访存都多了一步访问页表，性能显著下降</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/1075436-20190809172852450-661010612.png" alt="img"></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241212120853391.png" alt="image-20241212120853391"></p>
<h4 id="页表总结"><a href="#页表总结" class="headerlink" title="页表总结"></a>页表总结</h4><p><strong>Pros</strong>:</p>
<ul>
<li>No external fragments</li>
<li>Flexible, good support for sparse address space</li>
</ul>
<p><strong>Cons</strong>:</p>
<ul>
<li>Physical Space costs (Page table)</li>
<li>Speed Costs (extra memory access)</li>
</ul>
<h3 id="快表-TLB"><a href="#快表-TLB" class="headerlink" title="快表 TLB"></a>快表 TLB</h3><p><strong>如果想要快速的缓存，他就必须小，因为光速和其他物理限制会起作用</strong></p>
<p><strong>TLB</strong>：因为有二八定律，所以MMU要记下经常使用的虚拟页号，将VPN与PFN的映射关系存在 <strong>TLB</strong> 快表中（<strong>Translation Lookaside Buffer</strong> aka. <strong>Address Translation Cache</strong>）</p>
<h4 id="硬件实现-TLB-控制流"><a href="#硬件实现-TLB-控制流" class="headerlink" title="硬件实现 TLB 控制流"></a>硬件实现 TLB 控制流</h4><p>CISC 将tlb miss逻辑全权交给硬件负责，拿着虚拟页号 VPN 去 TLB 中查询</p>
<ul>
<li>TLB hit：直接访存(<code>AccessMemory</code>)</li>
<li><strong>TLB miss：查页表，查到PFN后写入TLB（<code>TLB_Insert</code>），重新执行TLB查询操作（<code>RetryInstruction</code>）</strong>  </li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241212122549686.png" alt="image-20241212122549686"></p>
<p>硬件实现：需要PTBR（x86架构中为CR3寄存器），页表的确切格式是写死在硬件里的（x86中为多级页表）</p>
<h4 id="软件实现-TLB-控制流"><a href="#软件实现-TLB-控制流" class="headerlink" title="软件实现 TLB 控制流"></a>软件实现 TLB 控制流</h4><p>RISC 将tlb miss看作一个异常，陷入OS，执行对应的处理程序</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241212124132429.png" alt="image-20241212124132429"></p>
<p><strong>软件实现的好处</strong>：可以随时更改，可扩展性强，页表的数据结构由操作系统自行决定，</p>
<p><strong>注意的问题</strong>：</p>
<ul>
<li>TLBmissHandler和一般的trap不同，一般return from trap 会从陷入后的地方继续执行，而TLBmiss则会从<strong>重试</strong>陷入之前的程序，因此保存的上下文很重要，尤其是程序计数器</li>
<li>TLBmissHandler也是代码，要访存，须谨防无限递归tlb miss的问题，可以专门把一块TLB的空间划给TLBmiss处理程序使用；或者也可以不使用虚拟内存，直接把代码物理地址告诉硬件（unmapped，陷阱表）</li>
</ul>
<h4 id="TLB-内容"><a href="#TLB-内容" class="headerlink" title="TLB 内容"></a>TLB 内容</h4><h5 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h5><p><code>VPN | PFN | other bits</code></p>
<p>是一个全相联（fully-associative）的cache结构，硬件会并行地查找这些项，</p>
<p><strong>other bits</strong>：</p>
<ul>
<li><p>protection：访问权限</p>
</li>
<li><p>valid：表示TLB是否记录着一个有效的<code>VPN-&gt;PFN</code>映射，PTE的有效位为0表示这是一个并未被应用申请过的非法地址</p>
</li>
<li><p>dirty：脏位</p>
</li>
<li><p>asid：access space id，地址空间id，用来标识不同进程的TLB条目<a target="_blank" rel="noopener" href="https://blog.csdn.net/Rong_Toa/article/details/110758233">Linux进程管理+内存管理：进程切换的TLB处理（ASID-address space ID、PCID-process context ID）_进程的asid-CSDN博客</a> </p>
</li>
</ul>
<h5 id="上下文切换"><a href="#上下文切换" class="headerlink" title="上下文切换"></a>上下文切换</h5><p>TLB集成在CPU内部的MMU，因此一定会有上下文切换的问题，VPN一样的条目会导致数据错误</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241212131757567.png" alt="image-20241212131757567"></p>
<p><strong>解决方案</strong>：</p>
<ul>
<li>上下文切换的时候将所有 TLB 条目的<strong>有效位</strong>置0（flush），下一个进程可以随便覆盖</li>
<li>使用ASID（类似于pid）记录这个TLB条目属于哪个进程</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241212131846711.png" alt="image-20241212131846711"></p>
<p><strong>PFN一样的条目</strong>：可能是共享代码页，这样可以减少额外分配物理页</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241212131859962.png" alt="image-20241212131859962"></p>
<h5 id="例：MIPS-TLB-Entry"><a href="#例：MIPS-TLB-Entry" class="headerlink" title="例：MIPS TLB Entry"></a>例：MIPS TLB Entry</h5><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241212134843225.png" alt="image-20241212134843225"></p>
<p>0-18 VPN  19 Global 进程间共享  24-31 ASID 进程空间 </p>
<h4 id="刷新、替换"><a href="#刷新、替换" class="headerlink" title="刷新、替换"></a>刷新、替换</h4><h5 id="TLB-flush"><a href="#TLB-flush" class="headerlink" title="TLB flush"></a>TLB flush</h5><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/66971714">TLB之flush操作[一] - 知乎</a> <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/66994486">TLB之flush操作[二] - 知乎</a> <a target="_blank" rel="noopener" href="https://blog.csdn.net/Rong_Toa/article/details/110760995">Linux内存管理：TLB flush操作-CSDN博客</a> </p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/Rong_Toa/article/details/110758233">Linux进程管理+内存管理：进程切换的TLB处理（ASID-address space ID、PCID-process context ID）_进程的asid-CSDN博客</a> </p>
<p>在页表PTE的内容出现变化时，比如page fault时页面被换出，munmap()时映射被解除，就需要invalidate对应的TLB entry，有时这个操作也被称为flush（以下的讨论将统一称为flush）。</p>
<p>当系统中各个cpu的TLB中的asid合起来不大于256个的时候，系统正常运行，一旦超过256的上限后，我们将全部TLB flush掉，并重新分配ASID，每达到256上限，都需要flush tlb并重新分配HW ASID。</p>
<p>在多核系统中，虽然每个核心的MMU是独立的，但它们在访问<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=695131149&content_type=Answer&match_order=1&q=%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98&zhida_source=entity">共享内存</a>时需要进行协调。共享内存区域允许多个核心同时访问相同的物理内存，这对于核心间的通信或共享数据非常关键。MMU可以通过为不同的内存区域设置权限和属性，确保多个核心在访问这些共享区域时不会出现数据冲突或不一致的情况。这在多线程或多进程系统中，尤其在同步和内存一致性方面，显得尤为重要。</p>
<h5 id="缓存更新策略"><a href="#缓存更新策略" class="headerlink" title="缓存更新策略"></a><a href="#eviction">缓存更新策略</a></h5><h2 id="优化分页"><a href="#优化分页" class="headerlink" title="优化分页"></a>优化分页</h2><h3 id="扩大页面大小（Bigger-Pages）"><a href="#扩大页面大小（Bigger-Pages）" class="headerlink" title="扩大页面大小（Bigger Pages）"></a>扩大页面大小（Bigger Pages）</h3><p>Linux</p>
<ul>
<li><p>对TLB更加友好，考虑到空间局部性，同一页能够访问更多数据，也就不用频繁地查页表了</p>
</li>
<li><p>增大页面大小，VPN<del>max</del>变小，每个虚拟页占空间4B，页表占用总空间减小；</p>
</li>
<li><p>但应用程序申请的并不一定是会充满整个页，所以会出现内部碎片（internal fragment）</p>
</li>
</ul>
<h3 id="分段-分页（Hybrid-Approach）"><a href="#分段-分页（Hybrid-Approach）" class="headerlink" title="分段 + 分页（Hybrid Approach）"></a>分段 + 分页（Hybrid Approach）</h3><h4 id="线性页表的局限"><a href="#线性页表的局限" class="headerlink" title="线性页表的局限"></a>线性页表的局限</h4><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241212210406110.png" alt="image-20241212210406110"></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241212210703824.png" alt="image-20241212210703824"></p>
<p>如图，虚拟空间是16KB，页面大小为1KB，因此页表共有16 entries，除去代码段，堆栈之间的空间是严重浪费的，就像分段会导致内部碎片一样，连续的线性页表也会导致内部碎片。</p>
<h4 id="段页结合"><a href="#段页结合" class="headerlink" title="段页结合"></a>段页结合</h4><p>VAX/VMS</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241212213305035-1734010396522-12.png" alt="image-20241212213305035"></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/8904fb89ae0c49c4b0f2f7b5a0a7b099.png" alt="img"></p>
<p>可以根据代码、堆、栈对页表进行分类，然后使用三个base-bound寄存器对，上下文切换时保存、恢复寄存器内容。更细粒度的分段可以使用段表。base存储段在物理内存的位置，bound表示段大小。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SN  = (VirtualAddress &amp; SEG_MASK) &gt;&gt; SN_SHIFT</span><br><span class="line">VPN = (VirtualAddress &amp; VPN_MASK) &gt;&gt; VPN_SHIFT</span><br><span class="line">AddressOfPTE = Base[SN] + (VPN * <span class="keyword">sizeof</span>(PTE))</span><br></pre></td></tr></table></figure>

<h4 id="缺陷"><a href="#缺陷" class="headerlink" title="缺陷"></a>缺陷</h4><ul>
<li>与分段的缺陷一样，只不过是将真正的数据部分换成了页表</li>
<li>不灵活，假设地址空间有一定的使用模式，分段则需要为整个堆段预留连续空间，即使中间部分未使用也无法释放。<ul>
<li>a large but sparsely-used heap 仍然可能导致大量的页表浪费</li>
</ul>
</li>
<li>由于界限寄存器的存在，每个段有多少页是不确定的，因此每个段的页表大小也不确定，导致寻找足够的连续自由空间比较复杂。虽然节省内存但是有外部碎片问题</li>
</ul>
<h3 id="多级页表（Multi-level-Page-Tables）"><a href="#多级页表（Multi-level-Page-Tables）" class="headerlink" title="多级页表（Multi-level Page Tables）"></a>多级页表（Multi-level Page Tables）</h3><p>x86 ARM Linux Windows</p>
<p>减小页表占用的空间，分散成多个页表，<strong>每张页表大小==相同==<strong>，</strong>并且刚好能填满一整个内存页</strong>，消灭了外部碎片</p>
<p><strong>如果整页的PTE都是无效的（未分配），则完全不分配该页面的页表。</strong></p>
<ul>
<li>PDE的有效位：此条目指向的页是否有页表？PTE的有效位：此条目是否是一个有效的PFN映射？</li>
<li>树形结构，不用的可以不分配页表空间。支持稀疏空间：不用的就不分配物理内存页</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241212214704876.png" alt="image-20241212214704876"></p>
<h4 id="页表目录-页表-内存"><a href="#页表目录-页表-内存" class="headerlink" title="页表目录-页表-内存"></a>页表目录-页表-内存</h4><p>CR3存的是页表目录（Page Directory）的基址，假设虚拟地址前4位是页表目录的编号，中间4位是页表（Page Table）编号，后12位为偏移。CR3找到了页表目录，根据前4位索引到PTE的PFN，根据中间4位找到页表中的PTE，PTE中存储着物理页的PFN。</p>
<ul>
<li><p>基本思想：基址 + 偏移 </p>
</li>
<li><p><code>VPN = PD_index | PT_index</code> </p>
</li>
<li><p><strong>页目录项</strong>地址: <code>PD_Entry_Addr = Page_Dir_Base + PD_index * sizeof(PD_Entry_Addr)</code> </p>
</li>
<li><p><strong>页表项</strong>地址：  <code>PT_Entry_Addr = PD_Entry.PFN &lt;&lt; SHIFT + PT_index * sizeof(PT_Entry_Addr)</code> </p>
</li>
<li><p>页面地址 ：<code>Page_Entry_Addr = PT_Entry.PFN &lt;&lt; SHIFT + Offset</code> </p>
</li>
</ul>
<p>以16位虚拟地址为例：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20240924221042539.png" alt="image-20240924221042539"></p>
<ul>
<li><strong>虚拟内存的要求</strong>：每一层级内部必须是连续的，因为分配物理内存空间只能一次性分配连续的一段</li>
<li>单级页表要想实现页表只能一次性分配256个连续的entries。</li>
<li>多级页表如果<strong>真的只有</strong>这3个地址所在的physical page被用到，那么只需要48 个entries就可以了</li>
</ul>
<p>在32位系统中，进程的虚拟地址空间为4GB，但某个进程实际使用的页只占其中的一小部分，其分布是稀疏的，因此非常适合使用多级页表这种稀疏的级联数组(<a href="https://link.zhihu.com/?target=https://en.wikipedia.org/wiki/Radix_tree">radix tree</a>)来表示。</p>
<h4 id="fill-the-pages"><a href="#fill-the-pages" class="headerlink" title="fill the pages"></a>fill the pages</h4><h5 id="例：30位虚拟地址"><a href="#例：30位虚拟地址" class="headerlink" title="例：30位虚拟地址"></a>例：30位虚拟地址</h5><p>目标：每张表填满一整个内存页 Page Size = 2^7^ * 4 B = 512 B，二级页表不能刚好占满一页</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241213134804005.png" alt="image-20241213134804005"><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241213135215659.png" alt="image-20241213135215659"></p>
<h5 id="实际的32位和64位页表"><a href="#实际的32位和64位页表" class="headerlink" title="实际的32位和64位页表"></a>实际的32位和64位页表</h5><p>在32位处理器中，采用4KB的page大小，则虚拟地址中低12位为offest，剩下高20位给页表，<strong>分成两级</strong>，每个级别占10个bit（10+10）。为什么32位系统的页表每级占10位，每个页的大小被设定为<code>4KB</code>而不是2KB或者8KB？</p>
<p>如果index为10位，则其可索引的范围是1024个entris，32位系统中，每级页表的每个entry的大小为4个字节，则每个页表的大小刚好是4KB。页表首地址也是要按页对齐的，如果占不满一个页，页中剩下的空间也就浪费了。80386引入<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=102569108&content_type=Article&match_order=1&q=%E5%88%86%E9%A1%B5%E6%9C%BA%E5%88%B6&zhida_source=entity">分页机制</a>的时候应该就考虑过把页设置为多大是最合适的，显然4KB的页大小对内存的利用是最充分的。1024 * 4 = 4 K</p>
<p><img src="https://i.stack.imgur.com/R19zY.png" alt="memory management - Why 32-bit Windows can maximum have 16TB Page File ..."></p>
<p>为什么64位系统的页表<strong>每级占9位</strong>呢？为了和硬件配合，基于i386编写的linux也采用4KB的页大小作为<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=102569108&content_type=Article&match_order=1&q=%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86&zhida_source=entity">内存管理</a>的基本单位。处理器进入64位时代后，其实可以不再使用4KB作为一个页帧的大小，但可能为了提供硬件的向前兼容性以及和操作系统的兼容性吧，大部分64位处理器依然使用4KB作为默认的页大小（ARMv8-A还支持16KB和64KB的页大小）。因为64位系统中，每级页表的每个entry的大小为8个字节，如果index为9位，则每个页表的大小也刚好是4KB。</p>
<p>512 * 8 = 4K </p>
<p><img src="https://i.sstatic.net/Bswtz.png" alt="img"></p>
<h4 id="TLB-控制流"><a href="#TLB-控制流" class="headerlink" title="TLB 控制流"></a>TLB 控制流</h4><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241213141353216.png" alt="image-20241213141353216"></p>
<p>依然是先查TLB，TLB没有再查页表，先用PDBR加偏移 算出PDE的物理地址得到PTE所在的PFN，找到PTE之后根据PTE里面的PFN加偏移算出真实的物理地址。</p>
<h3 id="倒排页表（Inverted-Page-Table）"><a href="#倒排页表（Inverted-Page-Table）" class="headerlink" title="倒排页表（Inverted Page Table）"></a>倒排页表（Inverted Page Table）</h3><p>PowerPC</p>
<p>页表的映射反过来，PFN-&gt;VPN，除了VPN，还有使用此页的进程标识。通常使用Hash散列表来加快搜索。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/1006507-20161224105816979-1390337413.png" alt="img"></p>
<h3 id="交换到磁盘（Swap）"><a href="#交换到磁盘（Swap）" class="headerlink" title="交换到磁盘（Swap）"></a>交换到磁盘（Swap）</h3><p>之前的页表都需要直接访问物理内存，页表本身并没有在程序的地址空间中，因此页表必须时时刻刻在物理内存中</p>
<p>VAX/VMS 把页表纳入内核的虚拟内存，允许在内存压力较大时将页表的一部分交换到磁盘。</p>
<h2 id="超越物理内存"><a href="#超越物理内存" class="headerlink" title="超越物理内存"></a>超越物理内存</h2><p>虚拟内存本质是虚的，实际数据可以存储在任何地方：<strong>寄存器（TLB）</strong>、<strong>物理内存（DRAM）</strong>，甚至是<strong>磁盘（HDD SSD）</strong>，因此虚拟内存大小跟物理内存大小并没有直接的关系，编程人员只需提供<code>Virtual Address</code>，由硬件和OS负责剩下的步骤，这就提升了程序的易用性，也提升了处理程序的多样性，考虑页表的数据结构，页表存储的位置等问题。</p>
<h3 id="机制"><a href="#机制" class="headerlink" title="机制"></a>机制</h3><h4 id="交换空间"><a href="#交换空间" class="headerlink" title="交换空间"></a>交换空间</h4><p>硬盘需要腾出一片专门的空间用来存放物理内存的内容，因此也需要进行编址。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241213145818889.png" alt="image-20241213145818889"></p>
<blockquote>
<p>The code pages from this binary are initially found on disk, and when the program runs, they are loaded into memory (either all at once when the program starts execution, or, as in modern systems, one page at a time when needed). However, if the system needs to <strong>make room in physical memory for other needs</strong>, it can safely re-use the memory space for these code pages, knowing that it can later swap them in again from the on-disk binary in the file system.</p>
</blockquote>
<p><strong>虚拟内存提供了一种将磁盘和物理内存结合起来的方式</strong>：</p>
<ul>
<li>代码页从磁盘加载到内存，过一段时间被换出，随后在需要的时候又被换入。</li>
<li>操作系统将整个物理内存看作“缓存”。</li>
<li>当内存不足时，系统会将不常用的内存页换出到磁盘（称为交换或分页）。</li>
<li>反之，如果需要使用换出的页面，系统会从磁盘重新加载到内存。</li>
</ul>
<h4 id="页错误（page-fault）"><a href="#页错误（page-fault）" class="headerlink" title="页错误（page fault）"></a>页错误（page fault）</h4><p><strong>存在位（presentation bit）</strong>：用来标识一个页是否在物理内存中，如果不在，对此内存地址的访问就会触发page fault（实际上是page miss），陷入OS</p>
<p><strong>Why OS</strong> <strong>Handles This?：</strong>TLB miss可以由硬件实现，但是Page Fault并不需要，因为Page Fault的处理性能瓶颈在硬盘：硬盘的读写速度比内存慢很多，硬件处理性能提升并不明显，并且硬件必须添加其他复杂的机制（写死在硬件里）</p>
<p>硬盘IO完成，更新PTE的PFN和存在位（也可以同时写入TLB中）然后Retry Instruction，IO过程中进程处于<strong>阻塞状态（blocked state）</strong>，OS可以在这段时间内切换到其他进程以提高CPU利用率。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/121-1.png" alt="Lightbox"></p>
<p>上述是硬性的页错误（虚拟内存地址不在物理内存中），还有一种软性页错误（虚拟内存地址在物理内存中），<em>详见VAX/VMS</em></p>
<p><strong>控制流</strong>：</p>
<ul>
<li>错误的严重程度：<ol>
<li><code>segmentation fault</code>（<code>valid bit = 0</code>, 没有分配） </li>
<li><code>protection fault</code>（<code>protect bits</code>, 权限不够）</li>
<li><code>page fault</code>（<code>present bit = 0</code>, 不在内存里）</li>
</ol>
</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241213153405737.png" alt="image-20241213153405737"><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241213153341054.png" alt="image-20241213153341054"></p>
<p><strong>Page-Fault Handler by OS</strong>：</p>
<ul>
<li>找空闲的物理内存，记录其PFN<ul>
<li>找不到就使用<strong>淘汰策略</strong>，把现在的物理内存页换一部分到磁盘里，腾出空间</li>
<li>如果找到了就进行磁盘 I/O，系统调用会<strong>休眠</strong>，直到 I/O 完成。</li>
</ul>
</li>
<li>换入完成就更新页表的存在位和PFN</li>
</ul>
<h4 id="访存机制总结"><a href="#访存机制总结" class="headerlink" title="访存机制总结"></a>访存机制总结</h4><p>首先到 MMU 集成的 TLB 中查询，TLB 中存储的是虚拟地址页号（VPN）和物理地址页号（PFN）的映射关系，TLB 命中则直接访问物理页框；之后就是之前正常的 CPU 访存过程，与操作系统没有关系。TLB 未命中则去找 CPU 集成的 Table Walk Unit，TWU 中的 CR3 寄存器存储着当前页目录（Page Directory）的物理地址页号PFN，如果内存中的页表没有对应的内容，则触发页错误（Page Fault）去磁盘中寻找，页表命中则更新 TLB，重试指令。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/slide_1.jpg" alt="Virtual to Physical Address Translation Effective Address TLB Lookup Page  Table Walk Update TLBPage Fault OS Table Walk Protection Check Physical  Address. - ppt download"></p>
<h3 id="Swap-页面置换策略"><a href="#Swap-页面置换策略" class="headerlink" title="Swap 页面置换策略"></a><span id="eviction">Swap 页面置换策略</span></h3><p>$$<br>AMAT=(P_\text{Hit} \cdot T_\text{Mem})+(P_\text{Miss} \cdot T_\text{Disk})<br>$$</p>
<p>Tmem = 100ns(100个时钟周期) Tdisk = 10ms（10000个时钟周期） 对性能影响极大</p>
<h4 id="基本策略-1"><a href="#基本策略-1" class="headerlink" title="基本策略"></a>基本策略</h4><p>将物理内存看作虚拟内存的缓存，置换策略实际上就是缓存淘汰策略</p>
<p><strong>局部性原理</strong></p>
<p><a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000043722445">缓存算法：LRU、LFU、随机替换等常见算法简介 - 个人文章 - SegmentFault 思否</a> </p>
<p>我们能不能既享受 CPU Cache 的速度，又享受内存、硬盘巨大的容量和低廉的价格呢？前辈们已经探索出了答案，那就是，存储器中数据的局部性原理（Principle of Locality）</p>
<ul>
<li><p>**时间局部性(temporal locality)**：如果一个数据被访问了，那么它在短时间内还会被再次访问。如 LRU 缓存机制，将频繁访问的数据保存在内存中。</p>
</li>
<li><p>**空间局部性(spatial locality)**：如果一个数据被访问了，那么和它相邻的数据也很快会被访问。如果数组的 CPU 预读功能。</p>
</li>
<li><p><strong>OPT 最优</strong>：事先知道缓存的访问顺序（不可能）但是可以作为一个比较指标。</p>
</li>
<li><p><strong>无状态策略</strong>：</p>
<ul>
<li><p>FIFO：先进先出</p>
</li>
<li><p>Random：随机</p>
</li>
</ul>
</li>
<li><p><strong>LRU</strong>(Recently)基于上次被访问时间，<strong>LFU</strong>(Frequently)基于被访问的频率</p>
</li>
</ul>
<p>基本有LRU FIFO Random，时钟算法（近似LRU），SecondChance（完善的FIFO），2Q（LRU+FIFO）</p>
<p>LFU：当使用 mmap() 访问文件缓存页面时，无法计数，实现较为复杂，不适合操作系统对虚拟内存的管理</p>
<h4 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a>性能比较</h4><h5 id="完全随机访问"><a href="#完全随机访问" class="headerlink" title="完全随机访问"></a>完全随机访问</h5><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241213175231404.png" alt="image-20241213175231404"></p>
<h5 id="二八定律"><a href="#二八定律" class="headerlink" title="二八定律"></a>二八定律</h5><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241213175332544.png" alt="image-20241213175332544"></p>
<h5 id="循环顺序访问"><a href="#循环顺序访问" class="headerlink" title="循环顺序访问"></a>循环顺序访问</h5><p>依次引用第0到第49页，LRU和FIFO，缓存在50以内，命中率为0</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241213175411886.png" alt="image-20241213175411886"></p>
<ul>
<li><p>LRU，基于<strong>时间局部性</strong>的策略，<strong>预测性强</strong>：对于访问频繁的页表项保留效果好。</p>
<ul>
<li>循环访问 n+1 页，但TLB只有n页容量，第一次TLB空的，全部 miss，由于空间限制，最后第n+1页会覆盖第1页。下一个循环开始第1页又 miss，第1页覆盖第2页内容，连锁的 miss</li>
</ul>
</li>
<li><p>Random，实现简单，避免出现极端情况下LRU命中率极低的情况，<strong>不可预测</strong>：无法优化特定程序的访问模式。</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>策略</th>
<th>优点</th>
<th>缺点</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td><strong>LRU</strong></td>
<td>高命中率，适应访问局部性</td>
<td>实现复杂，硬件成本高</td>
<td>对性能敏感的高端系统</td>
</tr>
<tr>
<td><strong>随机</strong></td>
<td>实现简单，硬件成本低，性能稳定</td>
<td>命中率较低，忽略访问规律</td>
<td>简单的嵌入式系统或硬件资源有限的场景</td>
</tr>
</tbody></table>
<h4 id="LRU-实现"><a href="#LRU-实现" class="headerlink" title="LRU 实现"></a>LRU 实现</h4><ul>
<li>可以对每一页添加时间字段，可以在页表中也可以专门在物理内存中的一片区域（redis就是这么做的），但代价高。</li>
</ul>
<p>添加一个 <strong>reference bit</strong> 使用位（用页表或者bitmap存储）当页被访问（读或写）时，由硬件（MMU）将其置1，操作系统负责将其置0，1代表最近用过了，0代表最近没用过</p>
<h5 id="近似-LRU：时钟算法"><a href="#近似-LRU：时钟算法" class="headerlink" title="近似 LRU：时钟算法"></a>近似 LRU：时钟算法</h5><p>维护一个循环列表，里面放着所有页的使用情况，时钟指针指向其中的一页，当需要替换页，如果use bit=1，将其置0，然后移动到下一页，直到寻找到第一个use bit = 0的页，将其换出</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241213184105746.png" alt="image-20241213184105746"></p>
<h5 id="脏位"><a href="#脏位" class="headerlink" title="脏位"></a>脏位</h5><p>dirty bit的优先级大于use bit 也由MMU维护，硬件会在发生<strong>写操作</strong>时自动设置脏位，页面换出首先考虑的是未被访问过的干净页，然后是被访问过的干净页。</p>
<ol>
<li><strong>标记页面是否被修改过</strong><ul>
<li>当一个页面被写入（例如进程对该页面的内容进行了修改），操作系统会将该页面的脏位置为 <code>1</code>。</li>
<li>如果页面从加载到内存以来未被修改，脏位保持为 <code>0</code>。</li>
</ul>
</li>
<li><strong>决定页面是否需要写回磁盘</strong><ul>
<li>如果一个页面需要被换出（从内存移到磁盘），操作系统会检查其脏位：<ul>
<li><strong>脏位为 1</strong>：表示页面内容已被修改，需要将修改后的内容写回磁盘（例如文件或交换区）。</li>
<li><strong>脏位为 0</strong>：页面未被修改，可以直接丢弃内存中的内容，因为磁盘上已有最新副本。</li>
</ul>
</li>
</ul>
</li>
<li><strong>减少不必要的磁盘写入</strong><ul>
<li>通过脏位的判断，可以避免无意义的磁盘写入操作，提高性能。例如，如果页面内容没有修改，就无需将内存中的数据写回磁盘。</li>
</ul>
</li>
</ol>
<h5 id="LRU-K"><a href="#LRU-K" class="headerlink" title="LRU-K"></a>LRU-K</h5><p>LRU-K中的K代表最近使用的次数，因此LRU可以认为是LRU-1。LRU-K的主要目的是为了解决LRU算法“缓存污染”的问题，其核心思想是将“最近使用过1次”的判断标准扩展为“最近使用过K次”。相比LRU，LRU-K需要多维护一个队列，用于记录所有缓存数据被访问的历史。只有当数据的访问次数达到K次的时候，才将数据放入缓存。当需要淘汰数据时，LRU-K会淘汰第K次访问时间距当前时间最大的数据。</p>
<img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/41aee01a98aa03f4c3d75ef4c2c7749a.png" alt="img" style="zoom:200%;" /> 

<ol>
<li>数据第一次被访问，加入到访问历史列表；</li>
<li>如果数据在访问历史列表里后没有达到K次访问，则按照一定规则（FIFO，LRU）淘汰；</li>
<li>当访问历史队列中的数据访问次数达到K次后，将数据索引从历史队列删除，将数据移到缓存队列中，并缓存此数据，缓存队列重新按照时间排序；</li>
<li>缓存数据队列中被再次访问后，重新排序；</li>
<li>需要淘汰数据时，淘汰缓存队列中排在末尾的数据，即：淘汰“倒数第K次访问离现在最久”的数据。</li>
</ol>
<p>LRU-K具有LRU的优点，同时能够避免LRU的缺点，实际应用中LRU-2是综合各种因素后最优的选择，LRU-3或者更大的K值命中率会高，但适应性差，需要大量的数据访问才能将历史访问记录清除掉。</p>
<h3 id="其他-Swap-策略"><a href="#其他-Swap-策略" class="headerlink" title="其他 Swap 策略"></a>其他 Swap 策略</h3><p><strong>页面置换策略</strong>：<u>which</u> page to <u>swap out</u>?</p>
<p><strong>页面选择策略</strong>：when to <u>swap in</u> which page? </p>
<ul>
<li>OS决定何时将页面载入内存，大多数页面是按需载入(demand paging)</li>
<li>有时会提前载入(prefetching)马上可能要被访问的页面，比如连续的代码页</li>
</ul>
<p><strong>写入磁盘策略</strong>：when and how to <u>swap out</u>? or not?</p>
<ul>
<li>不一定是内存满了才会开始交换，OS预留部分空闲空间，设置HW和LW，当可用页少于LW，就swap out，直到可用页数达到HW，有一个守护进程 <code>swapd</code> 专门做这件事情。</li>
<li>交换本身是IO操作，可以通过聚集/分组的方式将多个等待写入写出的页合并操作，提高硬盘效率，执行单次大的写操作比许多小的写操作有效。</li>
<li>数据一致性：脏页需要被换出（刷盘, sync）</li>
</ul>
<p><strong>颠簸（thrashing）</strong>: 内存被超额请求，os需要不断进行页面的置换，此时可能会考虑终止一些进程(linux oom killer会杀死内存密集型，一般这些都是低优先级的，也有一定的风险)</p>
<h2 id="完整的虚拟内存系统"><a href="#完整的虚拟内存系统" class="headerlink" title="完整的虚拟内存系统"></a>完整的虚拟内存系统</h2><h3 id="VAX-VMS-虚拟内存系统"><a href="#VAX-VMS-虚拟内存系统" class="headerlink" title="VAX/VMS 虚拟内存系统"></a>VAX/VMS 虚拟内存系统</h3><h4 id="地址空间"><a href="#地址空间" class="headerlink" title="地址空间"></a>地址空间</h4><h5 id="应用进程共享内核空间"><a href="#应用进程共享内核空间" class="headerlink" title="应用进程共享内核空间"></a>应用进程共享内核空间</h5><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241213214150106.png" alt="image-20241213214150106" style="zoom:150%;" />

<ul>
<li>地址空间的下半部分称为进程空间，前半段是代码和向下增长的堆（P0），后半段是向上增长的堆（P1），<strong>各自拥有一个页表</strong>，减少了内部碎片。</li>
<li>地址空间的上半段称为系统空间S，只使用其中一半</li>
</ul>
<p>内核段包含在用户空间中，是所有的进程共享的，这样使得内核与用户程序之间数据交互更加方便，OS可以轻松地解析用户程序传入的指针。通过给系统空间设置保护位来确保内核的安全。</p>
<h5 id="优化页表"><a href="#优化页表" class="headerlink" title="优化页表"></a>优化页表</h5><ul>
<li>分出来的两个段，各自有一个页表[段页式管理]，减少了内部碎片 </li>
<li>进程的虚拟地址空间也包含了内核段，因此可以把用户<strong>页表纳入受保护的内核虚拟内存</strong>中，当存储压力巨大时可以将页表换出到磁盘，有一定的访问性能开销。</li>
</ul>
<h5 id="空指针"><a href="#空指针" class="headerlink" title="空指针"></a>空指针</h5><p>NULL是一个宏，实际上就是0，虚拟地址0有效位始终是0，因此试图访问这个有效位会出现段错误异常，陷入OS终止进程</p>
<h4 id="惰性优化（Lazy）"><a href="#惰性优化（Lazy）" class="headerlink" title="惰性优化（Lazy）"></a>惰性优化（Lazy）</h4><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/whiteBear/p/16729327.html">延迟分配：提供内存利用率的三种机制 - 牛犁heart - 博客园</a> </p>
<h5 id="写入时复制-copy-on-write"><a href="#写入时复制-copy-on-write" class="headerlink" title="写入时复制 copy-on-write"></a>写入时复制 copy-on-write</h5><p>如果要将一个页面从一个地址空间复制到另一个地址空间，会获取相同的指针，指向相同的资源。这个资源或许是内存中的数据，又或许是硬盘中的文件，直到某个应用真正需要<strong>修改某一页</strong>时，操作系统才会（惰性地）<strong>复制一份该页的专用副本</strong>给该应用，填充数据而其他所见的最初资源仍然保持不变。</p>
<p>COW的优点：<strong>如果应用没有修改该资源，就不会产生副本，因此多个应用只是在读取操作时可以共享同一份资源，从而节省内存空间。</strong> <strong>fork 会复制应用 A 的很多关键数据，但不会复制应用 A 对应的物理内存页面，而是要监测这些物理内存的读写，只有这样才能让应用 A 和应用 B 正常运行</strong></p>
<ul>
<li>fork但未写入</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/1059417-20220925215845353-1129676397.png" alt="image"></p>
<ul>
<li>fork后写入</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/1059417-20220925221038426-1637796167.png" alt="image"></p>
<p>fork()需要复制整个地址空间的内容，如果fork之后还调用了exec，这些地址空间内容又会被马上覆盖，做无用功，cow避免了大量不必要的复制操作，仍然保留正确的语义。</p>
<h5 id="按需调页-demand-paging"><a href="#按需调页-demand-paging" class="headerlink" title="按需调页 demand paging"></a>按需调页 demand paging</h5><ul>
<li><p><strong>按需调页</strong>是一种<strong>动态内存分配技术</strong>，更是一种优化技术，它把<strong>物理内存页面的分配推迟到不能再推迟为止</strong>。之所以能实现，是因为应用程序开始运行时，并不会访问虚拟内存空间中的全部内容。</p>
</li>
<li><p>由于<strong>程序的局部性原理</strong>，使得应用程序在执行的每个阶段，真正使用的内存页面只有一小部分，对于暂时不用的物理内存页，就可以分配由其他应用程序使用。因此，在不改变物理内存页面数量的情况下，请求调页能够提高系统的吞吐量。</p>
</li>
</ul>
<p>当页添加到地址空间时，会在页表做一个标记（保留的操作系统字段），当进程真正访问到这个虚拟页时，操作系统才会真正寻找物理页并将其置零，映射到地址空间，这样就避免了申请了但是从来不访问 导致浪费的情况。</p>
<h4 id="SWAP-策略"><a href="#SWAP-策略" class="headerlink" title="SWAP 策略"></a>SWAP 策略</h4><h5 id="替换策略：Second-Chance-FIFO"><a href="#替换策略：Second-Chance-FIFO" class="headerlink" title="替换策略：Second Chance FIFO"></a>替换策略：Second Chance FIFO</h5><p>利用的是软性的页错误</p>
<ul>
<li>用RSS(Resident Set Size)限制每个进程可以保存在内存中的最大页数，超过RSS就要“First out”，防止自私进程</li>
<li>引入两个全局的页面表，一个记录空闲干净页，另一个记录脏页</li>
<li>First Out 被换出的页面根据脏位添加到 干净页列表 或 脏页列表 的<strong>末尾</strong> </li>
<li>另一个进程需要空闲页，会先去干净页列表中取出<strong>第一个</strong>空闲页</li>
<li>如果换出页面的进程触发了page fault，则会从表中重新回收页，避免磁盘I/O </li>
</ul>
<h5 id="批量换出：page-clustering"><a href="#批量换出：page-clustering" class="headerlink" title="批量换出：page clustering"></a>批量换出：page clustering</h5><p>把大批量的页从上述的全局脏页列表中分组聚集到一起，一起写入到磁盘中，使IO次数减少，单次IO写入量更大，提高性能</p>
<h3 id="Linux-虚拟内存系统"><a href="#Linux-虚拟内存系统" class="headerlink" title="Linux 虚拟内存系统"></a>Linux 虚拟内存系统</h3><p><strong>Linux 系统主要采用了分页管理，但是由于 Intel 处理器的发展史，Linux 系统无法避免分段管理</strong>。于是 Linux 就把所有段的基地址设为 <code>0</code>，也就意味着所有程序的地址空间都是线性地址空间（虚拟地址），相当于屏蔽了 CPU 逻辑地址的概念，所以段只被用于访问控制和内存保护。虚拟空间分布可分为<strong>用户态</strong>和<strong>内核态</strong>两部分</p>
<h4 id="地址空间-1"><a href="#地址空间-1" class="headerlink" title="地址空间"></a>地址空间</h4><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/v2-50e72a482d4b10604708f5e6a6c76435_r.jpg" alt="img"></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241213232325106.png" alt="image-20241213232325106"></p>
<ul>
<li>0-3GB是用户空间，其中用户态的分布：代码段(.ELF)、全局变量（初始化的数据段）、BSS（未初始化的数据段）、堆内存（Heap）、映射区（mmap）、函数栈（Stack）、初始化参数（argument, environment）</li>
<li>最高1GB为内核空间，存放内核的代码以及其他受保护的数据；像VAX/VMS一样，每个用户的进程空间内有着相同的内核。</li>
<li>64位的地址空间：低128T为用户空间，高128T为内核空间，中间未定义</li>
</ul>
<h5 id="逻辑内核空间（kmalloc）"><a href="#逻辑内核空间（kmalloc）" class="headerlink" title="逻辑内核空间（kmalloc）"></a>逻辑内核空间（kmalloc）</h5><ul>
<li><p>内核代码需要调用<code>kmalloc</code>申请，内核栈、页表等数据结构存储在这里</p>
</li>
<li><p>只能在物理内存中，不能被换出到磁盘</p>
</li>
<li><p><strong>严格的一对一直接映射</strong>：<code>0xC0000000</code> to <code>0x00000000</code>, <code>0xC0000FFF</code> to <code>0x00000FFF</code></p>
<ul>
<li><p>不需要进行复杂地址转换，直接将其当成物理地址即可，因此也不需要页表结构</p>
</li>
<li><p>连续的虚拟地址在物理上也一定是连续的</p>
</li>
<li><p>适合DMA</p>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>This makes memory allocated in this part of the kernel’s address space suitable for operations which need contiguous physical memory to work correctly, such as I/O transfers to and from devices via <strong>direct memory access (DMA)</strong></p>
</blockquote>
<h5 id="虚拟内核空间（vmalloc）"><a href="#虚拟内核空间（vmalloc）" class="headerlink" title="虚拟内核空间（vmalloc）"></a>虚拟内核空间（vmalloc）</h5><ul>
<li>内核代码需要调用<code>vmalloc</code>申请，returns 指向连续虚拟内存区域的指针</li>
<li>不是直接映射，因此连续的虚拟地址在物理上并不一定连续</li>
<li>容易分配(easy to allocate), 因此适合大块缓冲区，因为连续的大块物理内存显然不容易找到</li>
</ul>
<p>在32位Linux中，虚拟内核空间可以让内核空间大于1GB</p>
<blockquote>
<p>Kernel virtual addresses, and their disconnection from <strong>a strict one-to-one mapping to physical memory</strong>, make this possible. However, with the move to 64-bit Linux, the need is less urgent, because the kernel is not confined to only the last 1 GB of the virtual address space. （64位就没那么重要了）</p>
</blockquote>
<h4 id="内存分配"><a href="#内存分配" class="headerlink" title="内存分配"></a>内存分配</h4><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/overview.png" style="zoom:150%;" />

<h5 id="虚拟内存管理"><a href="#虚拟内存管理" class="headerlink" title="虚拟内存管理"></a>虚拟内存管理</h5><h6 id="malloc-1"><a href="#malloc-1" class="headerlink" title="malloc"></a>malloc</h6><ul>
<li><p>在不同OS中，malloc的实现也不同，有 dlmalloc, jemalloc, tcmalloc等实现</p>
</li>
<li><p>Linux中，用户可以显式调用mmap或者malloc分配，malloc底层基于mmap（大于128K）或brk（小于128K）</p>
</li>
<li><p>这两种方式分配的都是虚拟内存，没有分配物理内存。在第一次访问已分配的虚拟地址空间的时候，发生缺页中断，操作系统负责分配物理内存，然后建立虚拟内存和物理内存之间的映射关系。</p>
</li>
<li><p>大部分不建议使用brk，brk和sbrk分配的堆空间类似于缓冲池，调用它相当于增大缓冲池。用malloc可以重用前面空闲的内存空间，每次malloc从缓冲池获得内存，如果缓冲池不够了，malloc才会调用brk或sbrk扩充缓冲池，直到达到缓冲池大小的上限，free则将应用程序使用的内存空间归还给缓冲池。而free mmap会直接释放，将空间给操作系统，无法复用，一定会触发缺页中断。</p>
</li>
</ul>
<h6 id="brk"><a href="#brk" class="headerlink" title="brk"></a>brk</h6><p>brk 的实现方式是移动Program break，将数据段的最高地址指针 _edata(end of data) 往高地址推（分配的内存小于 128KB），sbrk是通过增量来控制的，原理类似。</p>
<ul>
<li><p>同一个程序bss的结束地址是固定的，而heap的起始地址在每次运行的时候都会改变 <strong>ASLR</strong>。</p>
</li>
<li><p>当<a target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Address_space_layout_randomization">ASLR</a>（Address Space Layout Randomization）关闭时，<code>start_brk</code>和brk同时指向<code>data/bss</code>段的结束位置（<a target="_blank" rel="noopener" href="http://lxr.free-electrons.com/source/include/linux/mm_types.h?v=3.8#L364">end_data</a>）。</p>
</li>
<li><p>当ASLR打开时，<code>start_brk</code>和brk同时指向<code>data/bss</code>段的结束位置（<code>end_data</code>）再加上一个随机的brk偏移。</p>
</li>
</ul>
<img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/20032_0.png" alt="img" style="zoom:150%;" />

<p>brk的问题：</p>
<p>使用brk连续申请了10K, 20K, 30K内存，前两部分释放了，但是不会归还给操作系统，如果再次申请内存小于30K，就可以复用空闲区域，但是如果申请40K，就会出现内部碎片问题，只能继续新申请40K内存，导致大量内存碎片问题</p>
<h6 id="mmap"><a href="#mmap" class="headerlink" title="mmap"></a>mmap</h6><p>在用户进程空间内的内存映射段找一块空闲的虚拟内存（分配的内存大于 128k））—匿名空间，具体使用可见: <em>Memory-mapped I/O</em> </p>
<h5 id="物理内存管理"><a href="#物理内存管理" class="headerlink" title="物理内存管理"></a>物理内存管理</h5><h6 id="伙伴系统（Buddy-system）"><a href="#伙伴系统（Buddy-system）" class="headerlink" title="伙伴系统（Buddy system）"></a>伙伴系统（Buddy system）</h6><p>Buddy分配系统在普通内存池的基础上，允许两个<strong>大小相同且相邻</strong>的内存块合并，合并之后的内存块的「尺寸」增大，因而将被移动到另一个内存池的free list上。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241210230312259.png" alt="image-20241210230312259"></p>
<p>总空间为2^N^，按照递归二分法分配内存，直到块大小刚好满足要求（显然这会导致内部碎片）当一个块释放的时候，allocator会检验与他相同大小的相邻块（buddy）是否空闲，若是则将二者合并，直到合并全部空闲内存。</p>
<p>优点：buddy的地址很容易确认，既然是相邻，说明首部地址只差一位，这个位决定了他们在整个数中的层次</p>
<p>在 Linux 系统中，连续内存管理采用了 <strong>伙伴系统（Buddy System）算法</strong> 来实现，对于内部碎片的问题，采用了SLAB进行解决。</p>
<p>它把所有的空闲页放到11个链表中，每个链表分别管理大小为1，2，4，8，16，32，64，128，256，512，1024个页的内存块。当系统需要分配内存时，就可以从buddy系统中获取。当分配内存时，会优先从需要分配的内存块链表上查找空闲内存块，当发现对应大小的内存块都已经被使用后，那么会从更大一级的内存块上分配一块内存，并且分成一半给我们使用，剩余的一半释放到对应大小的内存块链表上。</p>
<p>想要分配一个8KB大小的内存，但是发现对应大小的内存已经没有了，那么伙伴系统会从16KB的链表中查找一个空闲内存块，分成两个8KB大小，把其中的一个8KB大小返回给申请者使用，剩下的8KB放到8KB对应的内存块链表中进行管理。更坏的一种情况是，系统发现16KB大小的连续内存页已经没有了，那么以此会向更高的32KB链表中查找，如果找到了空闲内存块，那么就把32KB分成一个16KB和两个8KB，16KB的内存块放到16KB的链表进行管理，两个8KB的内存块一个返回给申请者，另一个放到8KB大小的链表进行管理。</p>
<p>当释放内存时，会扫描对应大小的内存块链表，查看是否存在地址能够连续在一起的内存块，如果发现有，那么就合并两个内存块放置到更大一级的内存块链表上，以此类推。比如我们释放8KB大小的内存，那么会从对应的链表扫描是否有能够合并的内存块，如果有另一个8KB大小的内存和我们使用的内存地址连续，那么就合并它们组成一个16KB大小的内存块，然后接着扫描16KB大小的内存块链表，继续查找合并的可能，以此类推下去。</p>
<p>操作系统的内存管理通常是基于<strong>页（page）</strong>的概念，即操作系统将物理内存分为固定大小的页。页是内存管理的基本单位，这样可以统一管理和访问内存。页的大小通常是2的幂次方，例如4KB、8KB或16KB等。</p>
<ul>
<li><strong>操作系统需要高效地管理内存</strong>，而将内存管理的单位限定为页大小可以简化这一过程。每一页都有一个对应的页表项，操作系统只需要管理页而不是单个字节或更小的单位。这减少了管理开销。</li>
</ul>
<h6 id="分离空闲列表（SLAB-segregated-free-lists）"><a href="#分离空闲列表（SLAB-segregated-free-lists）" class="headerlink" title="分离空闲列表（SLAB, segregated free lists）"></a>分离空闲列表（SLAB, segregated free lists）</h6><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/slab-org.png" alt="slab org" style="zoom:150%;" />



<p>为了方便管理，Linux中的buddy allocator以物理页框为最小粒度，而现实的应用中，操作系统作为一个一直在运行的程序，多是以<strong>内核objects</strong>（比如描述文件的”struct inode”）的大小来申请和释放内存的，这些内核objects的大小通常从几十字节到几百字节不等，远远小于一个page的大小。如果程序固定分配一个或者几个大小的的内存，那就专门给他分配一块内存用于分配这些固定大小空间，减少了大小上的差异，碎片自然也就少了</p>
<p>在内核启动时，为诸如锁、文件inode之类频繁请求的内核object分配 <strong>Object cache</strong>，他们的对象缓存分离了特定大小的空闲列表，获得了性能上的提升，当cache将要耗尽时从通用的内存分配程序申请slab（总量是page size和object size的最小公倍数）例如，2.5KB objectsize, 4KB pagesize 就去申请5个页, 专门用来放这种object,一个页能放5个</p>
<p>当cache中内核object的引用计数变为0，通用的内存分配程序会从专用的分配器中回收这些资源。同时还使空闲对象保持在预初始化的状态，避免频繁销毁、初始化的开销。</p>
<p>Linux实现</p>
<img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/understand-html037.png" alt="img" style="zoom:150%;" />

<img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/v2-90fe0938cf0c8ab8836257ed587654d1_1440w.jpg" alt="img" style="zoom:150%;" />

<p>每个<code>kmem_cache</code>都是链接在一起形成一个全局的双向链表，系统可以从Cache_chain开始扫描每个<code>kmem_cache</code>（相当于上面说的内存池, fixed size）</p>
<p><code>slab</code>是内存池从系统申请内存的最小单位，在实现上一个<code>slab</code>有一个或多个连续的物理页组成（通常只有一页）单个<code>slab</code>可以在<code>slab</code>链表之间移动，例如如果一个<code>slabs_partial</code>中的slab被分配了对象后变满了，就要从<code>slabs_partial</code>中被删除，同时插入到<code>slabs_full</code>中去。</p>
<h4 id="页表结构"><a href="#页表结构" class="headerlink" title="页表结构"></a>页表结构</h4><p>虚拟地址：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241214003409861.png" alt="image-20241214003409861"></p>
<p>4KB的页大小对应12位offset，共四级页表，每级索引为9位，一个表条目占用4B空间，一张表正好占满一页</p>
<h4 id="更大的页大小（huge-pages）"><a href="#更大的页大小（huge-pages）" class="headerlink" title="更大的页大小（huge pages）"></a>更大的页大小（huge pages）</h4><blockquote>
<p>Specifically, recent designs support 2-MB and even 1-GB pages in hardware. Thus, over time, Linux has evolved to allow applications to utilize these <strong>huge pages</strong> (as they are called in the world of Linux).</p>
</blockquote>
<h5 id="提升-TLB-命中率"><a href="#提升-TLB-命中率" class="headerlink" title="提升 TLB 命中率"></a>提升 TLB 命中率</h5><p>一方面是减少了页表项数，更重要的是<strong>提升了TLB的命中率（hit rate）</strong>：</p>
<ul>
<li><strong>TLB的条目数(slots)是固定的，因为空间局部性，同一页放更多数据，将更多的物理内存空间纳入到TLB中</strong></li>
<li>换个角度，如果发生TLBmiss，因为页表项数的减少，遍历速度就会加快</li>
<li>与此同时，某些情况下也可以加快分配内存</li>
</ul>
<h5 id="如何申请"><a href="#如何申请" class="headerlink" title="如何申请"></a>如何申请</h5><p>一些对性能要求严格的应用如大型数据库应该使用更大的页大小，用来提高性能，必须通过<code>mmap</code>或者<code>shmget</code>进行显式申请，因此其他正常使用4KB页大小的程序不受影响。</p>
<p>**透明大页(transparent huge pages)**：不需要应用程序修改源代码，OS 会自动根据情况决定是否分配大页。</p>
<h5 id="缺陷-1"><a href="#缺陷-1" class="headerlink" title="缺陷"></a>缺陷</h5><blockquote>
<p>Huge pages are not without their costs. The biggest potential cost is <strong>internal fragmentation</strong>, i.e., a page that is large but sparsely used. This form of waste can fill memory with large but little used pages. <strong>Swapping</strong>, if enabled, also does not work well with huge pages, sometimes greatly amplifying the amount of I/O a system does.</p>
</blockquote>
<ol>
<li><strong>内部碎片</strong>：由于各种内存操作基本都要求按照page对齐，比如一个可执行文件映射到进程地址空间，根据文件大小的不同，平均算下来会浪费掉半个page size的物理内存，使用large page的话这个消耗就显得比较大了。</li>
<li><strong>需要连续大块的物理内存</strong>：系统运行一段时间后，会很难再也大块的连续物理内存，这时分配large page将会变的很困难，所以通常需要在系统初始化的时候就划分出一段物理内存给large page用（类似于DMA的内存分配），这样就减少了一些灵活性。</li>
<li><strong>swap开销大</strong>：动态large page（THP）在换出到外部的flash/disk和从flash/disk换入物理内存的过程会比normal size的page带来更大的开销（可参考<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/117239320">这篇文章</a>）。</li>
</ol>
<h4 id="Page-Cache-Disk-Cache"><a href="#Page-Cache-Disk-Cache" class="headerlink" title="Page Cache/Disk Cache"></a>Page Cache/Disk Cache</h4><p><a target="_blank" rel="noopener" href="https://www.mazhen.tech/p/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-page-cache/">深入理解 Page Cache</a></p>
<p><strong>Page Cache</strong> 是由内核管理的内存，位于 <a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/latest/filesystems/vfs.html">VFS(Virtual File System)</a> 层和具体文件系统层（例如ext4，ext3）之间。应用进程使用 <code>read</code>/<code>write</code> 等文件操作，通过系统调用进入到 <strong>VFS</strong> 层，根据 <strong>O_DIRECT</strong> 标志，可以使用 <strong>Page Cache</strong> 作为文件内容的缓存，也可以跳过 <strong>Page Cache</strong> 不使用内核提供的缓存功能</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/vzb3z8uo.png" alt="vzb3z8uo"></p>
<blockquote>
<p>aggressive caching subsystem to <strong>keep popular data items from persistent storage</strong> in memory</p>
</blockquote>
<ul>
<li><p><strong>Buffered I/O</strong>: IO缓存 (<code>read()</code>, <code>write()</code>) [<code>dentry, inode cache</code>]</p>
</li>
<li><p><strong>Memory-mapped I/O</strong>: 内存映射 mmap()</p>
<ul>
<li><strong>File-backed 文件映射</strong>: 其可以将文件内容映射到用户空间，虚拟内存和磁盘文件中间通过 Page Cache 进行数据中转，因此可以像普通虚拟内存一样访问文件，这些虚拟内存<strong>在磁盘中有对应的文件</strong>，读取这部分内容就像是文件I/O一样</li>
<li><strong>Anonymous Mapping 匿名映射</strong>: mmap以<code>MAP_ANONYMOUS</code>方式申请内存，这些虚拟内存在磁盘中<strong>没有确切的文件，持久化到swap space</strong>，全部初始化为0，</li>
</ul>
</li>
<li><p>通过<code>page_cache_hashtable</code>搜索，加快访问速度。</p>
</li>
</ul>
<h5 id="Memory-mapped-I-O"><a href="#Memory-mapped-I-O" class="headerlink" title="Memory-mapped I/O"></a>Memory-mapped I/O</h5><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/longerzone/article/details/12948925#">Linux 下的两个特殊的文件 – /dev/null 和 /dev/zero 简介及对比_linux空洞文件null-CSDN博客</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/yangle4695/article/details/52139585">Linux 内存映射函数 mmap（）函数详解_mmap fb-CSDN博客</a>  </p>
<ul>
<li><code>void* mmap(void* start, size_t length, int prot, int flags, int fd, off_t offset);</code> </li>
<li><code>int munmap(void* start, size_t length);</code> <ul>
<li><code>prot:</code> 保护位 <code>PROT_EXEC</code>, <code>PROT_READ</code> , <code>PROT_WRITE</code> , <code>PROT_NONE</code></li>
<li><code>flags:</code> <code>MAP_SHARED</code>共享模式 <code>MAP_PRIVATE</code>写时复制，不共享 <code>MAP_ANONYMOUS</code>匿名模式fd无效</li>
<li><code>fd:</code> 文件描述符，如果是匿名模式可以置为<code>-1</code>，或者打开<code>/dev/zero</code>获取其fd</li>
<li><code>offset:</code>文件映射的偏移量，通常设置为0，代表从文件最前方开始对应，offset必须是分页大小的整数倍。</li>
</ul>
</li>
</ul>
<ol>
<li><code>fopen()</code> 系统调用打开文件，并返回描述符 <code>fd</code>。</li>
<li><code>mmap(start,...)</code>建立内存映射并返回映射首地址指针 <code>start</code>参数start可以是空指针，系统自动分配地址</li>
<li>通过对<code>start</code> 对文件进行各种操作，首次访问start指向的内容会触发页错误(demand paging)</li>
<li><code>munmap (start,...)</code> 关闭内存映射</li>
<li><code>fclose(fd)</code> 系统调用关闭文件 <code>fd</code> </li>
</ol>
<img src="https://miro.medium.com/v2/resize:fit:1313/0*DgRx8tGpS1T0St_b.png" alt="img" style="zoom:150%;" />

<p>通过对一个打开的FD调用<code>mmap()</code>，进程能够获得一个指向内存映射区的指针，内存映射区是一个独立区域，因此可以独立释放。通过这个指针就能够对文件进行操作。这里采用了demand paging——<strong>懒加载</strong>的策略，直到第一次访问触发页错误，才会真正把文件内容分配到物理页中。</p>
<p>数据一致性：</p>
<ul>
<li><strong>files</strong>：程序通过 <code>mmap</code> 映射文件时，如果页面未修改（脏位为 <code>0</code>），无需将内存中的数据写回磁盘</li>
<li><strong>Swap space</strong>：当内存不足时，未被修改的页面无需写回磁盘的 Swap space，节省时间和空间</li>
</ul>
<p>即使不显式调用<code>mmap</code>也会使用这个共享的文件映射区域，比如从可执行文件中加载的代码、进程之间共享的库代码</p>
<p>使用<code>pmap</code>分析<code>tcsh</code>进程的虚拟内存映射情况如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Virtual Address  	Size  	Protection  Source</span><br><span class="line">0000000000400000 	372K  	r-x--       tcsh</span><br><span class="line">00000000019d5000 	1780K 	rw---       [anon ]</span><br><span class="line">00007f4e7cf06000 	1792K 	r-x--       libc-2.23.so</span><br><span class="line">00007f4e7d2d0000	36K   	r-x--       libcrypt-2.23.so</span><br><span class="line">00007f4e7d508000	148K  	r-x--       libtinfo.so.5.9</span><br><span class="line">00007f4e7d731000 	152K  	r-x--       ld-2.23.so</span><br><span class="line">00007f4e7d932000 	16K   	rw---       [stack ]</span><br></pre></td></tr></table></figure>

<p>除了<code>tcsh</code>自己的代码，<code>libc, libcrypt, libtinfo</code> 这些共享库代码也被加载到tcsh的虚拟地址空间中，连接器<code>ld</code>的可执行代码也在其中。[anon]表示自己的heap堆空间，[stack]表示自己的stack栈空间</p>
<p>和 <strong>shmem</strong> 的区别：</p>
<p>System V 共享内存是持久的：除非被进程显式删除，否则它会保留在内存中并保持可用，直到系统关闭。 mmap 内存在应用程序的执行之间不是持久的（除非它由文件支持，<code>MAP_SHARED</code>）</p>
<h5 id="Buffered-I-O"><a href="#Buffered-I-O" class="headerlink" title="Buffered I/O"></a>Buffered I/O</h5><p><strong>Buffered I/O</strong> 与 <strong>内存映射文件</strong> 的区别：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/202209241611674.png" alt="d"></p>
<h6 id="读取机制"><a href="#读取机制" class="headerlink" title="读取机制"></a>读取机制</h6><ol>
<li><p><code>int fd = open(file_path)</code></p>
<ul>
<li>fd是内核对打开的文件的编号，通过fd就可以操作文件</li>
</ul>
</li>
<li><p><code>int c = read(fd, buf, 512)</code>  </p>
<ul>
<li>由内核负责将 fd 翻译成 inode+offset</li>
<li>读取inode，如果page cache没有就从磁盘读，然后写入inode到Page cache中</li>
<li>读取对应偏移的block，如果page cache没有就从磁盘读，然后写入block到Page cache中</li>
<li>从内存中的 cached block 复制 512 B 到 buf 中</li>
</ul>
</li>
</ol>
<h6 id="写入机制"><a href="#写入机制" class="headerlink" title="写入机制"></a>写入机制</h6><p><strong>Write-back (default)</strong> </p>
<p>write back 写回 只对缓存进行操作 read-allocate 先把数据读取到Cache中，再从Cache中读数据</p>
<blockquote>
<p>By default, kernel marks written pages dirty and flushes after a delay:</p>
</blockquote>
<ol>
<li><p><code>int fd = open(&quot;myfile&quot;);</code> </p>
</li>
<li><p><code>write(fd, &quot;hello world&quot;, 11)</code></p>
<ul>
<li>内核将hello world字符串写入到 cached block 对应的 page cache 页中</li>
<li>内核将被修改的页加入脏页列表中</li>
<li>按照一定的策略进行刷盘</li>
</ul>
</li>
</ol>
<p>在系统发生宕机的情况下无法确保数据已经落盘，因此存在数据丢失的问题。不过，在程序挂了，例如被 kill -9，Page Cache 中的数据操作系统还是会确保落盘；</p>
<p><strong>Write-through</strong></p>
<p>直写，在更改page cache的<strong>同时</strong>刷盘(synchoronized)</p>
<blockquote>
<p><strong>O_SYNC</strong> flag converts file descriptor to write-through</p>
</blockquote>
<ul>
<li><code>int fd = open(&quot;myfile&quot;, O_SYNC |...); </code></li>
<li><code>write(fd, &quot;hello world&quot;, 11);</code> <ul>
<li>This affects all accesses to the same disk blocks</li>
</ul>
</li>
</ul>
<p>以牺牲系统 I/O 吞吐量作为代价，向上层应用确保一旦写入，数据就已经落盘，不会丢失</p>
<h5 id="脏页刷盘"><a href="#脏页刷盘" class="headerlink" title="脏页刷盘"></a>脏页刷盘</h5><p>Page cache 追踪脏页，保存一个脏文件inode链表，脏页需要写入到磁盘的文件或者swap space中，确保内存数据的持久化，可以由叫做<code>pdflush</code>的后台线程，唤醒方式有如下</p>
<ul>
<li><p><strong>定期</strong>唤起<code>pdflush</code>，确保不会有脏页驻留时间过长</p>
</li>
<li><p>在脏页比例达到<strong>阈值</strong>时，按照一定速率刷盘（1024）</p>
</li>
<li><p>内存可用空间低到一定<strong>阈值</strong>，刷脏页释放内存</p>
</li>
<li><p>响应特定的系统调用</p>
<ul>
<li><p><code>fsync(int fd)</code> 将fd的脏数据和所有脏元数据刷盘</p>
</li>
<li><p><code>fdatasync(int fd)</code> 将fd的脏数据和必要的脏元数据刷盘</p>
</li>
<li><p><code>sync()</code> 将全部脏页刷盘</p>
</li>
<li><p><code>O_SYNC</code> 文件打开方式要求同步写操作</p>
</li>
</ul>
</li>
</ul>
<p><strong>应用</strong></p>
<ul>
<li><strong>文件映射</strong>：程序通过 <code>mmap</code> 映射文件时，如果页面未修改（脏位为 <code>0</code>），无需将内存中的数据写回磁盘。</li>
<li><strong>交换区</strong>：当内存不足时，未被修改的页面无需写回交换区，节省时间和空间。</li>
</ul>
<h5 id="Direct-I-O"><a href="#Direct-I-O" class="headerlink" title="Direct I/O"></a>Direct I/O</h5><p>Buffered I/O要在磁盘和VFS之间加一层Page cache，对于写入操作，需要在cache中开辟新页，然后将其标记为脏。</p>
<p>OS cache提供的这些预读取、顺序读取等特性，这些特性并不适用于所有的场景，比如数据库，数据库通常都有自己的一套缓存机制，就像mysql的innodb存储引擎，它有自己的缓存页，有自己的落盘机制，如果不使用directIO，这明显就会存在双重的cache，一个是OS设计的，一个是DB设计的，而通常，DB需要更加符合自己使用的cache机制，而非OS提供的通用化的缓存机制。直接写入不会将要写入的数据先从磁盘读到cache，而是直接将要写的数据写入磁盘。</p>
<p>O_DIRECT 下的 I/O 操作是直达磁盘的，用户空间通过 DMA 的方式与磁盘以及网卡进行数据拷贝。</p>
<h4 id="页面置换：2Q"><a href="#页面置换：2Q" class="headerlink" title="页面置换：2Q"></a>页面置换：2Q</h4><p>关键词：<strong>预读失效 + 缓存污染</strong> </p>
<ul>
<li><strong>预读失效：提前加载到内存，但是并没有访问</strong></li>
<li><strong>缓存污染：加载到内存，但是只访问一次</strong></li>
</ul>
<p><strong>LRU</strong>：如果打开一个非常大的文件，LRU会把其他在内存中的文件都淘汰掉，但是写入这个文件到内存中并没有什么用，就和循环访问一样，文件之前的数据在被淘汰掉之前再也被访问。</p>
<p><strong>Linux的2Q(Two queue)策略</strong></p>
<p>该算法类似于LRU-2，不同点在于2Q将LRU-2算法中的访问历史队列（注意这不是缓存数据的）改为一个FIFO缓存队列，即：2Q算法有两个缓存队列，一个是FIFO队列，一个是LRU队列。</p>
<img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/73bc553b295b04f7a2bc634b6bd10ab9.png" alt="img" style="zoom:200%;" />

<p>Linux对于2Q的实现，只淘汰FIFO队列里面的数据：</p>
<p>Page cache（Buffered I/O或mmap）维护两个队列:</p>
<p><code>inactive list(FIFO), active list(LRU)</code> </p>
<ul>
<li>第一次被访问，将页面加入<code>inactive list</code></li>
<li>之后的访问，将页面升至<code>active list</code> </li>
<li>需要进行替换时，<code>inactive list</code>进行FIFO</li>
<li><code>active list</code>对定期 LRU 到<code>inactive list</code>，使<code>active list</code>占 Page cache 的2/3左右。</li>
<li>循环访问大文件时，大文件的页面不会跑到<code>active list</code>中，因此原来<code>active list</code>的页面就不会被迫换出</li>
</ul>
<h4 id="其他策略-1"><a href="#其他策略-1" class="headerlink" title="其他策略"></a>其他策略</h4><ul>
<li><code>fork()</code> 采用COW写时复制的策略，减少无效的复制</li>
<li><code>swapd</code> 可以监控内存状况，内存占用过高（watermark）换出页面，释放到安全水平（异步）</li>
<li><strong>swappiness</strong>：修改换出页面的积极性，0为不主动换出</li>
<li><strong>关闭swap</strong>：服务器内存本身足够大，不需要换出操作，因为会降低效率</li>
<li><strong>内存颠簸（thrashing）</strong> 虚拟内存申请，但是物理内存几乎占满，导致同时出现大量缺页错误，此时linux oom killer会杀死内存密集型，一般这些都是低优先级的，也有一定的风险)</li>
</ul>
<h3 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h3><p>现代操作系统最大的一个特点就是对安全的注重，仅仅使用内核</p>
<h4 id="针对用户程序：缓冲区溢出攻击"><a href="#针对用户程序：缓冲区溢出攻击" class="headerlink" title="针对用户程序：缓冲区溢出攻击"></a>针对用户程序：缓冲区溢出攻击</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">some_function</span><span class="params">(<span class="type">char</span> *input)</span> &#123;</span><br><span class="line">    <span class="type">char</span> dest_buffer[<span class="number">100</span>];</span><br><span class="line">    <span class="built_in">strcpy</span>(dest_buffer, input); <span class="comment">// oops, unbounded copy!</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果输入超过缓冲区，input就会开始覆盖其他数据，攻击者可以利用缓冲区溢出注入他们的恶意代码，在页表中引入<code>NX</code>bit能够在一定程度上解决问题，但是黑客可以更改函数的执行栈，将函数的返回值指向恶意代码的地址。</p>
<p>return-to-libc attack:==ROP==</p>
<blockquote>
<p>Thus, an attacker can overwrite the stack such that the <strong>return address in the currently executing function</strong> points to <strong>a desired malicious instruction (or series of instructions)</strong>, followed by a return instruction.</p>
<p>By stringing together a large number of gadgets (i.e., ensuring each return jumps to the next gadget), the attacker can execute arbitrary code. Amazing!</p>
</blockquote>
<p>address space layout randomization:==ASLR==</p>
<blockquote>
<p>Instead of placing code, stack, and the heap <strong>at fixed locations</strong> within the virtual address space, the OS <strong>randomizes their placement</strong>, thus making it quite challenging to craft the intricate code sequence required to implement this class of attacks.</p>
</blockquote>
<p>ASLR可以确保客户的程序只崩溃不执行恶意代码，ASLR将brk、mmap、stack的开始段加一些随机数，</p>
<p>由此衍生出了KASLR，内核的地址空间也可以随机生成</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//random.c</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *argv[])</span> &#123;</span><br><span class="line">    <span class="type">int</span> <span class="built_in">stack</span> = <span class="number">0</span>;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%p\n&quot;</span>, &amp;<span class="built_in">stack</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/* </span></span><br><span class="line"><span class="comment">    prompt&gt; ./random</span></span><br><span class="line"><span class="comment">    0x7ffd3e55d2b4</span></span><br><span class="line"><span class="comment">    prompt&gt; ./random</span></span><br><span class="line"><span class="comment">    0x7ffe1033b8f4</span></span><br><span class="line"><span class="comment">    prompt&gt; ./random</span></span><br><span class="line"><span class="comment">    0x7ffe45522e94</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<h4 id="针对内核程序：Meltdown-amp-Spectre"><a href="#针对内核程序：Meltdown-amp-Spectre" class="headerlink" title="针对内核程序：Meltdown &amp; Spectre"></a>针对内核程序：Meltdown &amp; Spectre</h4><p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/23973128">CPU 的分支預測器是怎樣工作的？ - 知乎</a> </p>
<p>利用了 CPU 预测执行的漏洞，分支预测将串行的程序变成了并行的，而前后数据依赖，不可避免地在硬件上留下了踪迹，造成了并发安全问题</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mov rax byte[x]  ; 非法操作 将x的数据拷贝到rax</span><br><span class="line">shl rax 0xC  ; rax * 4096, 页对齐</span><br><span class="line">mov rbx qword [rbx + rax]  ; [rbx] 为用户空间的一个array，合法操作</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/32757727">解读 Meltdown &amp; Spectre CPU 漏洞 - 知乎</a> </p>
<p>操作系统会事先标注好内核的内存地址范围，如果 x 在内核的这个地址范围内，并且 CPU 不是以内核模式运行的话，那么该指令会被 CPU 标注为非法，引起异常，异常处理程序会将 rax 清空为0，并且终结此程序，这样后续指令再来读 rax 的时候就只能读到0了。</p>
<p>理论上讲，在执行第二条指令之前，rax应该已经被清零了。然而在实际的 CPU 运行中，为了达到更好的性能，第二条和第三条指令在异常处理生效之前都会被<strong>部分执行</strong>，直到异常处理时 rax 和 rbx 被清零。</p>
<p>但问题的关键就在第三行指令：<strong>如果地址 rbx + rax 不在cache中的话，CPU 会自动将这一地址调入cache中，以便之后访问时获得更好的性能，然而异常处理并不会将这个cache flush掉。而这条 cache 的地址是和 rax 直接相关的，这样就相当于在 CPU 硬件中留下了和rax 相关的信息。</strong>  </p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241214175132236.png" alt="image-20241214175132236"></p>
<p>那么如何还原 rbx + rax 这个被cache的地址呢？这时候需要用到的原理就是利用cache的访问延时，即已经被cache的数据访问时间短，没有被cache的数据访问时间长。由于[rbx]这个array是在用户地址空间内的，可以自由操作，首先我们要确保整个 [rbx]这个array 都是没有被cache的，然后执行上述攻击代码，这时候 rbx + rax 这个地址就已经被cache了，接下来遍历整个[rbx] array，来测量访问时间，访问时间最短的那个 page 就可以确定为 rbx + rax。</p>
<p>对于个人终端用户，利用Meltdown与Spectre漏洞，低权限用户可以访问内核的内容，泄露本地操作系统底层的信息、秘钥信息等，通过获取泄露的信息，可以绕过内核的隔离防护;如果配合其它漏洞，可以利用该漏洞泄露内核模块地址绕过KASLR等防护机制实现其他类型的攻击进行提权。另外，利用浏览器JIT特性预测执行特殊的JIT代码，从而读取整个浏览器内存中的数据，泄露用户帐号，密码，邮箱, cookie等隐私信息。</p>
<p>因此，增强内核保护的一种途径是从每个用户进程中删除尽可能多的内核地址空间，并为大多数内核数据提供单独的内核页表（称为内核页表隔离，或 KPTI）[G+17]。因此，不是将内核的代码和数据结构映射到每个进程中，而是只保留最低限度的代码和数据结构；当切换到内核时，现在需要切换到内核页表。这样做可以提高安全性并避免一些攻击媒介，但代价是：性能。切换页表的成本很高。</p>
<h2 id="内存虚拟化总结"><a href="#内存虚拟化总结" class="headerlink" title="内存虚拟化总结"></a>内存虚拟化总结</h2><ul>
<li><p>虚拟地址的作用</p>
</li>
<li><p>虚拟地址的翻译（重定位）</p>
<ul>
<li>段式 base+bound, bound varies from each other</li>
<li>页式 fixed bound</li>
<li>段页式 </li>
<li>多级页表 fill one page with one table, hi-level table points to low-level table</li>
<li>TLB：翻译缓存</li>
</ul>
</li>
<li><p>Swap：将物理内存看作虚拟内存的缓存</p>
<ul>
<li>机制：Page Fault &amp; Disk I/O </li>
<li>策略：<ul>
<li>是否需要SWAP？物理内存充足就没必要开启</li>
<li>具体换<strong>出</strong>哪一页？LRU, FIFO, Random, Second Chance, LRU-K, 2Q, Clock</li>
<li>何时换<strong>出</strong>？(被动watermark、主动swappiness&gt;0)</li>
<li>一次 I/O 换<strong>出</strong>多少页？(clustering)</li>
<li>何时换<strong>入</strong>？(lazy aka. demand paging)</li>
<li>一次 I/O 只换<strong>入</strong>一页<strong>吗</strong>？(prefetching)</li>
</ul>
</li>
</ul>
</li>
<li><p>内存分配:</p>
<ul>
<li>机制：空闲空间链表节点的分割与合并</li>
<li>物理：Buddy, SLAB</li>
<li>虚拟：mmap malloc brk</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://scatteredream.github.io/2025/01/14/408-%E8%AE%A1%E7%BD%91-%E5%BA%94%E7%94%A8%E5%B1%82/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars.githubusercontent.com/u/62317679?s=400&v=4">
      <meta itemprop="name" content="碎梦">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="scatteredream's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | scatteredream's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/01/14/408-%E8%AE%A1%E7%BD%91-%E5%BA%94%E7%94%A8%E5%B1%82/" class="post-title-link" itemprop="url">应用层</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-01-14 00:00:00" itemprop="dateCreated datePublished" datetime="2025-01-14T00:00:00+08:00">2025-01-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-05-14 15:48:32" itemprop="dateModified" datetime="2025-05-14T15:48:32+08:00">2025-05-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%A1%E7%BD%91/" itemprop="url" rel="index"><span itemprop="name">计网</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="域名系统（DNS）"><a href="#域名系统（DNS）" class="headerlink" title="域名系统（DNS）"></a>域名系统（DNS）</h1><p>Domain Name System based on UDP port 53 </p>
<h2 id="域名-名字空间"><a href="#域名-名字空间" class="headerlink" title="域名 名字空间"></a>域名 名字空间</h2><p><strong>层次结构</strong>：………三级域名.二级域名.顶级域名</p>
<p><strong>根</strong>：无名字</p>
<p><strong>顶级域名</strong>：国家、组织</p>
<p><strong>二级域名</strong>（我国）：类别域名、行政区域名</p>
<p>属于不同父亲的孩子节点可以有相同的名称: <a target="_blank" rel="noopener" href="http://www.example.cn/">www.example.cn</a>  <a target="_blank" rel="noopener" href="http://www.example.com/">www.example.com</a> </p>
<h2 id="域名服务器"><a href="#域名服务器" class="headerlink" title="域名服务器"></a>域名服务器</h2><p>DNS服务器实际是一个分布式的数据库。主从复制，读写分离，增强可用性。服务器可以采用anycast任播技术，多台服务器使用同一IP地址，路由自动选择最近的服务器。</p>
<p>分类：</p>
<ul>
<li><strong>根域名服务器</strong>（Root）：所有的根域名服务器都知道所有顶级域名服务器的IP地址和域名<ul>
<li>根域名有13个，分布于全球的若干根域名服务器，使用IP anycast技术，每个域名有多个物理实例，但对外展示同一个 IP。</li>
</ul>
</li>
<li><strong>顶级域名服务器</strong>（Top Level Domain）：管辖属于自己的二级域名</li>
<li><strong>权限域名服务器</strong>（Authoriative Name Server）：管辖区内的域名，一个服务器管一个域名，效率比较低，所以采用 <strong>区</strong> 的概念，区是域的子集。</li>
<li><strong>本地域名服务器</strong>：不在上述层次中，但是离客户最近的DNS服务器。</li>
</ul>
<h2 id="DNS-查询顺序"><a href="#DNS-查询顺序" class="headerlink" title="DNS 查询顺序"></a>DNS 查询顺序</h2><h3 id="先查缓存的查询流程"><a href="#先查缓存的查询流程" class="headerlink" title="先查缓存的查询流程"></a>先查缓存的查询流程</h3><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241129143353140.png" alt="image-20241129143353140"></p>
<ol>
<li>浏览器 DNS 缓存：首先，浏览器会检查自己的缓存中是否已经有该域名的IP地址记录。如果有，则直接使用这个IP地址，而不会发起DNS查询</li>
<li>操作系统 DNS 缓存：如果浏览器缓存中没有找到，浏览器会请求操作系统进行DNS解析。操作系统会先检查自己的DNS缓存。大多数现代操作系统都会维护一个 DNS 缓存来存储最近解析过的域名和对应的IP地址</li>
<li>本地 hosts 文件：如果操作系统缓存中也没有找到对应的记录，并且您使用的是Unix-like系统（如Linux或macOS），操作系统会查询本地的/etc/hosts文件。这个文件通常包含静态的IP地址到域名的映射</li>
<li>路由器DNS缓存：我们常用的路由器也带有自动缓存功能，路由器DNS被篡改会造成<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=216036547&content_type=Article&match_order=1&q=%E5%9F%9F%E5%90%8D%E5%8A%AB%E6%8C%81&zhida_source=entity">域名劫持</a>，将访问网址定位到另外一个服务器；</li>
<li>本地DNS服务器（递归查询，本地DNS服务器替主机查询，主机作为DNS客户端向DNS服务器请求服务）：如果/etc/hosts文件中也没有找到，操作系统会向配置的本地DNS服务器发送查询请求。这个本地DNS服务器可能是您的网络服务提供商提供的，或者是您在公司或学校网络中配置的，也具有缓存功能。本地DNS将解析结果告知客户端的同时，将记录缓存下来，当下次请求同一个域名时，直接会将记录返回，而无需再进行全球查询。</li>
<li>根域名服务器（迭代查询，从此开始就是本地DNS服务器反复查询）：如果本地DNS服务器无法解析该域名，它会向根域名服务器发送查询请求。根域名服务器会返回负责顶级域名（如.com）的权威DNS服务器的地址</li>
<li>顶级域名服务器：本地DNS服务器然后会向顶级域名服务器发送查询请求，获取该域名的权威DNS服务器的地址</li>
<li>权威DNS服务器：最后，本地DNS服务器会向权威DNS服务器发送查询请求，获取该域名的IP地址</li>
<li>返回IP地址：一旦本地DNS服务器从权威DNS服务器那里获得了IP地址，它就会将这个IP地址返回给操作系统，操作系统再返回给浏览器。浏览器最后使用这个IP地址来建立与服务器的连接</li>
</ol>
<p>在查询的过程中，一旦在某一环节找到有效的IP地址记录，就会停止后续的查询。而且，为了提高效率，本地DNS服务器和操作系统通常会对查询结果进行缓存，以便在后续请求中直接使用，减少网络延迟</p>
<h3 id="DNS-缓存"><a href="#DNS-缓存" class="headerlink" title="DNS 缓存"></a>DNS 缓存</h3><p>所谓DNS缓存是指DNS返回正确的IP地址之后，系统会将这个结果临时储存起来，并为缓存设定一个失效时间（<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=216036547&content_type=Article&match_order=1&q=TTL%E5%80%BC&zhida_source=entity">TTL值</a>），在TTL失效前，当再次访问这个网站，系统就会直接从<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=216036547&content_type=Article&match_order=1&q=DNS+%E7%BC%93%E5%AD%98&zhida_source=entity">DNS 缓存</a>中将结果返回，而不必再次委托递归服务器进行全球解析查询，加快了<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=216036547&content_type=Article&match_order=4&q=DNS%E8%A7%A3%E6%9E%90&zhida_source=entity">DNS解析</a>的流程。</p>
<p>当然TTL值失效后，系统还会自动再次询问DNS服务器以获取最新的解析结果。</p>
<h4 id="DNS-污染"><a href="#DNS-污染" class="headerlink" title="DNS 污染"></a>DNS 污染</h4><p>在中国大陆，对所有经过<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%98%B2%E7%81%AB%E9%95%B7%E5%9F%8E">防火长城</a>（英语：Great Firewall，常用简称：GFW）的在<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%8D%8F%E8%AE%AE">UDP</a>的53<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%80%9A%E4%BF%A1%E7%AB%AF%E5%8F%A3">端口</a>上的域名查询进行IDS<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%85%A5%E4%BE%B5%E6%A3%80%E6%B5%8B">入侵检测</a>，一经发现与黑名单关键词相匹配的域名查询请求，会马上伪装成目标解析服务器注入伪造的查询结果。攻击仅出现在DNS查询之路由经过防火长城时。伪造的查询结果中的IP地址不是一成不变的，在一段时间后会更新。</p>
<p>对于TCP协议下的域名查询，防火长城可使用<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/TCP%E9%87%8D%E7%BD%AE%E6%94%BB%E5%87%BB">TCP重置攻击</a>的方法进行干扰。</p>
<blockquote>
<p>重置（reset）是<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE">传输控制协议</a>（TCP）的一种消息，例如服务器端在没有客户端请求的端口或者其它连接信息不符时，系统的TCP协议栈就会给客户端回复一个重置通知消息，该功能本来用于应对例如服务器意外重启等情况，而防火长城阻止TCP连接的技术实际上就是比连接双方更快地发送连接重置消息，使连接双方以为对方终止了连接[<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%98%B2%E7%81%AB%E9%95%BF%E5%9F%8E#cite_note-clayton2006-66">65]</a>。</p>
</blockquote>
<h1 id="动态主机配置协议（DHCP）"><a href="#动态主机配置协议（DHCP）" class="headerlink" title="动态主机配置协议（DHCP）"></a>动态主机配置协议（DHCP）</h1><p>Dynamic Host Configuration Protocol based on <code>UDP</code> port <code>68</code> for <code>client</code>, <code>67</code> for <code>server</code></p>
<p>采用C/S通信模式，由客户端（DHCP Client）向服务器（DHCP Server）提出配置申请</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241129172615802.png" alt="image-20241129172615802"></p>
<h2 id="报文格式"><a href="#报文格式" class="headerlink" title="报文格式"></a><a target="_blank" rel="noopener" href="https://blog.csdn.net/scanf_linux/article/details/89415965#t2">报文格式</a></h2><p><strong>dhcp offer</strong>:</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241129175130504.png" alt="image-20241129175130504"></p>
<ul>
<li>Relay Agent 中继</li>
<li>Next Server 其他DHCP服务器</li>
<li>Client MAC Address 之前 Discover含有 客户端的MAC地址</li>
<li>bootp flags unicast 单播</li>
</ul>
<p><strong>dhcp offer:</strong></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241129175445723.png" alt="image-20241129175445723"></p>
<h2 id="分配IP"><a href="#分配IP" class="headerlink" title="分配IP"></a>分配IP</h2><p>  <strong>内网 使用DHCP协议</strong></p>
<ul>
<li><p>首次接入网络的DHCP客户端不知道DHCP服务器的<a target="_blank" rel="noopener" href="https://info.support.huawei.com/info-finder/encyclopedia/zh/IPv4.html">IP地址</a>，为了学习到DHCP服务器的IP地址，DHCP客户端以广播方式发送<code>DHCP DISCOVER</code>报文（目的IP地址为255.255.255.255）给同一网段内的所有设备（包括DHCP服务器或中继）。<code>DHCP DISCOVER</code>报文中携带了客户端的MAC地址（<a target="_blank" rel="noopener" href="https://support.huawei.com/hedex/pages/EDOC1100087046AZJ0324D/10/EDOC1100087046AZJ0324D/10/resources/dc/dc_cfg_dhcp_6005.html#ZH-CN_CONCEPT_0176371535__c1">chaddr字段</a>）、需要请求的参数列表选项（<a target="_blank" rel="noopener" href="https://support.huawei.com/hedex/pages/EDOC1100087046AZJ0324D/10/EDOC1100087046AZJ0324D/10/resources/dc/dc_cfg_dhcp_6005.html#ZH-CN_CONCEPT_0176371535__op55">Option55</a>）、广播标志位（<a target="_blank" rel="noopener" href="https://support.huawei.com/hedex/pages/EDOC1100087046AZJ0324D/10/EDOC1100087046AZJ0324D/10/resources/dc/dc_cfg_dhcp_6005.html#ZH-CN_CONCEPT_0176371535__f1">flags字段</a>）等信息。源IP 地址0.0.0.0   目的IP:255.255.255.255</p>
</li>
<li><p>某个（可能有多个服务器）DHCP服务器A监听到了DHCP请求，能够<strong>动态</strong>管理自己的IP池，通过<code>DHCP Offer</code>给计算机分配IP地址和默认网关（用于访问外部地址）以及子网掩码和<strong>DNS</strong>、租约信息，注意并不一定要全部提供。源IP为DHCP服务器的IP  目的IP:分配给客户端的IP，里面也有客户端的MAC地址。</p>
</li>
<li><p>设备收到以后会正式提出租用请求，<code>DHCP Request</code>，源IP为0.0.0.0  目的IP:255.255.255.255，==广播==形式可以告诉其他可能存在的DHCP服务器已经向DHCP服务器A提出租用请求，。</p>
</li>
<li><p>路由器收到以后发送<code>DHCP ACK</code>，确认分配并连接成功。源IP为DHCP服务器的IP  目的IP:分配给</p>
</li>
<li><p>客户端收到<code>DHCP ACK</code>报文，会广播发送<a target="_blank" rel="noopener" href="https://info.support.huawei.com/info-finder/encyclopedia/zh/ARP.html">免费ARP</a>报文，探测本网段是否有其他终端使用服务器分配的IP地址，如果在指定时间内没有收到回应，表示客户端可以使用此地址。如果收到了回应，说明有其他终端使用了此地址，客户端会向服务器发送<code>DHCP DECLINE</code>报文，并重新向服务器请求IP地址，同时，服务器会将此地址列为冲突地址。当服务器没有空闲地址可分配时，再选择冲突地址进行分配，尽量减少分配出去的地址冲突。</p>
</li>
<li><p>设备使用某个IP地址的时间有限，==单播==发送<code>DHCP Request</code>报文进行续约，如果收到<code>DHCP NAK</code>报文说明续租失败；如果到时间如果设备不再续用发送<code>DHCP Release</code>报文进行释放，DHCP服务器会回收，设备收到<code>DHCP</code>。某些设备可能需要为静态的IP，这个可以通过MAC绑定也可以手动配置。</p>
</li>
</ul>
<p><strong>宽带</strong>：</p>
<ul>
<li><p><strong>静态IP</strong>：根据运营商提供的静态IP，子网掩码，网关，DNS手动配置，是固定的IP。</p>
</li>
<li><p><strong>动态DHCP</strong> ：自动从ISP获取IP地址等网络配置信息。</p>
</li>
<li><p><strong>ADSL虚拟拨号</strong> ：使用PPPoE协议向运营商动态租用（PPPoE提供了身份验证功能，也就是宽带账号)。</p>
</li>
</ul>
<h2 id="典型场景"><a href="#典型场景" class="headerlink" title="典型场景"></a>典型场景</h2><ol>
<li><p>路由器从运营商的网络获取一个公网IP地址（通过运营商的DHCP服务器分配）。</p>
</li>
<li><p>路由器在局域网内充当DHCP服务器，为局域网设备分配私有IP地址（如192.168.0.x）。</p>
</li>
</ol>
<h2 id="RARP-协议"><a href="#RARP-协议" class="headerlink" title="RARP 协议"></a>RARP 协议</h2><p>RARP（反向地址转换协议，Reverse Address Resolution Protocol）是局域网的物理机器从网关服务器的ARP表或者缓存上根据MAC地址请求IP地址的协议。它的功能与ARP协议相反。</p>
<ol>
<li><strong>请求IP地址</strong>：当局域网中的某个物理机器只知道自己的MAC地址而不知道IP地址时，它可以通过RARP协议向RARP服务器发送一个请求，请求分配一个IP地址。</li>
<li><strong>服务器响应</strong>：RARP服务器在收到请求后，会查找其RARP列表或ARP表，查找该MAC地址对应的IP地址。如果找到匹配的MAC地址，RARP服务器就会将对应的IP地址发送给请求者。</li>
<li><strong>获取IP地址并通信</strong>：请求者在收到RARP服务器的响应后，就可以利用得到的IP地址进行网络通信。</li>
</ol>
<p><strong>RARP</strong>（Reverse Address Resolution Protocol）和<strong>DHCP</strong>（Dynamic Host Configuration Protocol）是两种网络协议，它们都可以为某个刚接入网络的设备提供IP地址以实现互联通信。区别主要有以下几点：</p>
<ol>
<li>RARP是数据链路层的协议，无法跨路由器和网段工作，每个本地网络都必须配置一台RARP服务器；而DHCP属于应用层协议，可以跨路由器和网段工作，因此多个网段可以共享同一个DHCP服务器。</li>
<li>RARP协议中，必须提前在RAPR服务器中手工配置好MAC地址和IP地址之间的映射；而DHCP允许动态的分配IP，更适应当前网络的需求。</li>
<li>RARP协议仅仅是分配IP地址，而DHCP协议不仅提供IP地址，还提供其他网络配置信息，如子网掩码、网关、DNS服务器</li>
</ol>
<h1 id="万维网（WWW）"><a href="#万维网（WWW）" class="headerlink" title="万维网（WWW）"></a>万维网（WWW）</h1><h2 id="超文本传输协议（HTTP）"><a href="#超文本传输协议（HTTP）" class="headerlink" title="超文本传输协议（HTTP）"></a><a href="https://scatteredream.github.io/2025/05/14/408-%E8%AE%A1%E7%BD%91-HTTP/">超文本传输协议（HTTP）</a></h2><h2 id="WebSocket"><a href="#WebSocket" class="headerlink" title="WebSocket"></a><a target="_blank" rel="noopener" href="https://xiaolincoding.com/network/2_http/http_websocket.html">WebSocket</a></h2><h2 id="内容分发网络（CDN）"><a href="#内容分发网络（CDN）" class="headerlink" title="内容分发网络（CDN）"></a>内容分发网络（CDN）</h2><p><strong>Content Distribution Network</strong></p>
<p><strong>push</strong>： 源服务器将内容推送给CDN</p>
<p><strong>pull</strong>：CDN遇到自己没有的资源就从源服务器pull过来</p>
<p><strong>anycast</strong>: 任播，与DNS服务器类似，很多CDN具有相同的IP地址，可以负载均衡。</p>
<p>CDN所需要的节点数量随着需求而不同，依照所需要服务的对象大小，有可能有数万台服务器。</p>
<p>服务器的运作方式一般是基于<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/Nginx">nginx</a>的模式，通过HTTP头的Host字段等方式区分服务域名来提供HTTP服务。不过，随着2017年世界各地CDN服务商纷纷推出<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/HTTPS">HTTPS</a>加速功能，运作方式也变得略有不同，变成了nginx+<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%90%8D%E7%A7%B0%E6%8C%87%E7%A4%BA">SNI</a>模式，同一个CDN节点上可以借此机制绑定多个域名而为不同域名提供HTTPS服务。同时，<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/BGP">BGP</a>的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/Anycast">anycast</a>技术也逐渐引入了CDN领域中。</p>
<p>P2P CDN(PCDN)：用户自愿以PC或专用设备利用闲置上行带宽充当CDN缓存节点</p>
<h1 id="进程间通信（IPC）"><a href="#进程间通信（IPC）" class="headerlink" title="进程间通信（IPC）"></a>进程间通信（IPC）</h1><p><a target="_blank" rel="noopener" href="https://xiaolincoding.com/network/2_http/http_rpc.html">既然有 HTTP 协议，为什么还要有 RPC？</a> </p>
<h1 id="P2P"><a href="#P2P" class="headerlink" title="P2P"></a>P2P</h1><h1 id="文件传送协议（FTP）"><a href="#文件传送协议（FTP）" class="headerlink" title="文件传送协议（FTP）"></a><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE">文件传送协议（FTP）</a></h1><p><strong>FTP 协议</strong> 基于 TCP 协议，是一种用于在计算机之间传输文件的协议，可以屏蔽操作系统和文件存储方式。</p>
<p>FTP 是基于客户—服务器（C/S）模型而设计的，在客户端与 FTP 服务器之间建立两个连接。如果我们要基于 FTP 协议开发一个文件传输的软件的话，首先需要搞清楚 FTP 的原理。关于 FTP 的原理，很多书籍上已经描述的非常详细了：</p>
<blockquote>
<p>FTP 的独特的优势同时也是与其它客户服务器程序最大的不同点就在于它在两台通信的主机之间使用了两条 TCP 连接（其它客户服务器应用程序一般只有一条 TCP 连接）：</p>
<ol>
<li>控制连接：用于传送控制信息（命令和响应）</li>
<li>数据连接：用于数据传送；</li>
</ol>
<p>这种将命令和数据分开传送的思想大大提高了 FTP 的效率。</p>
</blockquote>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/ftp.png" alt="FTP工作过程">FTP工作过程</p>
<p>注意 ：FTP 是一种不安全的协议，因为它在传输过程中不会对数据进行加密。因此，FTP 传输的文件可能会被窃听或篡改。建议在传输敏感数据时使用更安全的协议，如 SFTP（SSH File Transfer Protocol，一种基于 SSH 协议的安全文件传输协议，用于在网络上安全地传输文件）。</p>
<h1 id="电子邮件"><a href="#电子邮件" class="headerlink" title="电子邮件"></a>电子邮件</h1><h2 id="SMTP"><a href="#SMTP" class="headerlink" title="SMTP"></a><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%AE%80%E5%8D%95%E9%82%AE%E4%BB%B6%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE#%E7%9B%B8%E5%85%B3_RFC">SMTP</a></h2><p><strong>简单邮件传输(发送)协议（SMTP，Simple Mail Transfer Protocol）</strong> 基于 TCP 协议，是一种用于发送电子邮件的协议</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/what-is-smtp.png" alt="SMTP 协议">SMTP 协议</p>
<p>注意 ⚠️：<strong>接受邮件的协议不是 SMTP 而是 POP3 协议。</strong></p>
<p>SMTP 协议这块涉及的内容比较多，下面这两个问题比较重要：</p>
<ol>
<li>电子邮件的发送过程</li>
<li>如何判断邮箱是真正存在的？</li>
</ol>
<p><strong>电子邮件的发送过程？</strong></p>
<p>比如我的邮箱是“<a href="mailto:dabai@cszhinan.com">dabai@cszhinan.com</a>”，我要向“<a href="mailto:xiaoma@qq.com">xiaoma@qq.com</a>”发送邮件，整个过程可以简单分为下面几步：</p>
<ol>
<li>通过 <strong>SMTP</strong> 协议，我将我写好的邮件交给 163 邮箱服务器（邮局）。</li>
<li>163 邮箱服务器发现我发送的邮箱是 qq 邮箱，然后它使用 SMTP 协议将我的邮件转发到 qq 邮箱服务器。</li>
<li>qq 邮箱服务器接收邮件之后就通知邮箱为“<a href="mailto:xiaoma@qq.com">xiaoma@qq.com</a>”的用户来收邮件，然后用户就通过 <strong>POP3/IMAP</strong> 协议将邮件取出。</li>
</ol>
<p><strong>如何判断邮箱是真正存在的？</strong></p>
<p>很多场景(比如邮件营销)下面我们需要判断我们要发送的邮箱地址是否真的存在，这个时候我们可以利用 SMTP 协议来检测：</p>
<ol>
<li>查找邮箱域名对应的 SMTP 服务器地址</li>
<li>尝试与服务器建立连接</li>
<li>连接成功后尝试向需要验证的邮箱发送邮件</li>
<li>根据返回结果判定邮箱地址的真实性</li>
</ol>
<p>推荐几个在线邮箱是否有效检测工具：</p>
<ol>
<li><a target="_blank" rel="noopener" href="https://verify-email.org/">https://verify-email.org/</a></li>
<li><a target="_blank" rel="noopener" href="http://tool.chacuo.net/mailverify">http://tool.chacuo.net/mailverify</a></li>
<li><a target="_blank" rel="noopener" href="https://www.emailcamel.com/">https://www.emailcamel.com/</a></li>
</ol>
<h2 id="IMAP-POP3"><a href="#IMAP-POP3" class="headerlink" title="IMAP/POP3"></a><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%9B%A0%E7%89%B9%E7%BD%91%E4%BF%A1%E6%81%AF%E8%AE%BF%E9%97%AE%E5%8D%8F%E8%AE%AE">IMAP</a>/<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%83%B5%E5%B1%80%E5%8D%94%E5%AE%9A">POP3</a></h2><p>这两个协议没必要多做阐述，只需要了解 <strong>POP3 和 IMAP 两者都是负责邮件接收的协议</strong> 即可（二者也是基于 TCP 协议）。另外，需要注意不要将这两者和 SMTP 协议搞混淆了。<strong>SMTP 协议只负责邮件的发送，真正负责接收的协议是 POP3/IMAP。</strong></p>
<p>IMAP 协议是比 POP3 更新的协议，它在功能和性能上都更加强大。IMAP 支持邮件搜索、标记、分类、归档等高级功能，而且可以在多个设备之间同步邮件状态。几乎所有现代电子邮件客户端和服务器都支持 IMAP。</p>
<h2 id="E-mail-on-WWW"><a href="#E-mail-on-WWW" class="headerlink" title="E-mail on WWW"></a>E-mail on WWW</h2><h2 id="MIME"><a href="#MIME" class="headerlink" title="MIME"></a>MIME</h2><p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%BA%92%E8%81%94%E7%BD%91%E5%AA%92%E4%BD%93%E7%B1%BB%E5%9E%8B">MIME</a>改善了由 <a target="_blank" rel="noopener" href="https://tools.ietf.org/html/rfc822">RFC 822</a> 转变而来的 <a target="_blank" rel="noopener" href="https://tools.ietf.org/html/rfc2822">RFC 2822</a> ，这些旧标准规定<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%9B%BB%E5%AD%90%E9%83%B5%E4%BB%B6">电子邮件</a>标准并不允许在邮件消息中使用7位ASCII字符集以外的字符。正因如此，一些非英语字符消息和二进制文件，图像，声音等非文字消息原本都不能在电子邮件中传输（MIME可以）。MIME规定了用于表示各种各样的数据类型的符号化方法。此外，在<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%B8%87%E7%BB%B4%E7%BD%91">万维网</a>中使用的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/HTTP">HTTP协议</a>中也使用了MIME的框架，标准被扩展为<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%BA%92%E8%81%94%E7%BD%91%E5%AA%92%E4%BD%93%E7%B1%BB%E5%9E%8B">互联网媒体形式</a>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Content-Type: [type]/[subtype]; parameter</span><br></pre></td></tr></table></figure>

<h1 id="Telnet-amp-SSH"><a href="#Telnet-amp-SSH" class="headerlink" title="Telnet &amp; SSH"></a>Telnet &amp; SSH</h1><p><strong><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/Telnet">Telnet</a> 协议</strong> 基于 TCP 协议，用于通过一个终端登陆到其他服务器。Telnet 协议的最大缺点之一是所有数据（包括用户名和密码）均以明文形式发送，这有潜在的安全风险。这就是为什么如今很少使用 Telnet，而是使用一种称为 SSH 的非常安全的网络传输协议的主要原因。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/Telnet_is_vulnerable_to_eavesdropping-2.png" alt="Telnet:远程登陆协议"></p>
<p><strong><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/Secure_Shell">SSH</a> （Secure Shell）</strong> 基于 TCP 协议，通过加密和认证机制实现安全的访问和文件传输等业务。</p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV13P4y1o76u">SSH 握手详解 - bilibili 技术蛋老师</a> </p>
<p>SSH 的经典用途是登录到远程电脑中执行命令。除此之外，SSH 也支持隧道协议、端口映射和 X11 连接（允许用户在本地运行远程服务器上的图形应用程序）。借助 SFTP（SSH File Transfer Protocol） 或 SCP（Secure Copy Protocol） 协议，SSH 还可以安全传输文件。</p>
<p>SSH 使用客户端-服务器模型，默认端口是 22。SSH 是一个守护进程，负责实时监听客户端请求，并进行处理。大多数现代操作系统都提供了 SSH。</p>
<p>如下图所示，SSH Client（SSH 客户端）和 SSH Server（SSH 服务器）通过公钥交换生成共享的对称加密密钥，用于后续的加密通信。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/ssh-client-server.png" alt="SSH:安全的网络传输协议"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://scatteredream.github.io/2025/01/13/iot/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars.githubusercontent.com/u/62317679?s=400&v=4">
      <meta itemprop="name" content="碎梦">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="scatteredream's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | scatteredream's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/01/13/iot/" class="post-title-link" itemprop="url">物联网就业</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-01-13 00:00:00" itemprop="dateCreated datePublished" datetime="2025-01-13T00:00:00+08:00">2025-01-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-05-03 22:46:01" itemprop="dateModified" datetime="2025-05-03T22:46:01+08:00">2025-05-03</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="物联网"><a href="#物联网" class="headerlink" title="物联网"></a>物联网</h1><ul>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/331782286">物联网专业好就业吗？ - 知乎 (zhihu.com)</a></li>
</ul>
<p>物联网行业很有前景，但不代表<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E7%89%A9%E8%81%94%E7%BD%91%E4%B8%93%E4%B8%9A&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2767766898%7D">物联网专业</a>好，两者不是一码事。</p>
<p>从实际情况看，物联网不应该也没办法成为一个具体的专业。</p>
<p>物联网涵盖的内容太多，许多大学在本科开设物联网专业确实有点坑。</p>
<p>物联网和人工智能和金融很像，没有具体的、统一的概念，没有具体的指向。就像一个金融业人士自我介绍，如果是对非业内人士一般就说我是做金融的，对业内人士一般会说我是做量化的、做风头的、做<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E7%A7%81%E5%8B%9F&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:%223041148568%22%7D">私募</a>的、做基金的、做行研的、做柜员的、做大堂经理、做理财的、做风控的……</p>
<p>人工智能也是这样，对非业内人士一般就说我是做人工智能的的，对业内人士一般会说做<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E7%AE%97%E6%B3%95%E4%BC%98%E5%8C%96&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2767766898%7D">算法优化</a>、做<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E8%BF%90%E7%AD%B9%E6%8E%A7%E5%88%B6&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2632452604%7D">运筹控制</a>、做计算机<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2915052959%7D">神经网络</a>、做<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2632452604%7D">自然语言处理</a>（比如语言识别、自动翻译）、做机器学习（深度学习）、做<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%BD%B1%E5%83%8F%E5%AD%A6&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2632452604%7D">计算机影像学</a>（比如人脸、虹膜和指纹识别）……</p>
<p>物联网也是如此，对非业内人士一般就说我是做物联网的，对业内人士一般会说做<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%BC%80%E5%8F%91&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2767766898%7D">嵌入式开发</a>、做信号处理、做传感技术、做<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2767766898%7D">网络技术</a>、做RFID技术……</p>
<p>所以物联网能包含的范围太大，而且作为一项新兴科技是不断变化和延伸的，根本不是固有的、静态的。以上任何一个方向、岗位都是博大精深探索无止境的，跟很多岗位都是有密切关系的，很多专业都可以从事的。</p>
<p>所以这些工作根本不是你学了物联网就可以做的，学物联网和做物联网是两码事，学很多专业都可以做物联网，学物联网的反而因为学的多而杂不知道怎么定位自己了。比如你学<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E7%94%B5%E5%AD%90%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2632452604%7D">电子科学与技术</a>、<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E7%94%B5%E5%AD%90%E4%BF%A1%E6%81%AF%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2632452604%7D">电子信息科学与技术</a>、<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E7%BD%91%E7%BB%9C%E5%B7%A5%E7%A8%8B&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2632452604%7D">网络工程</a>、嵌入式开发、<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2915052959%7D">信息工程</a>（信息技术）、<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E7%94%B5%E5%AD%90%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2915052959%7D">电子信息工程</a>、电波传导和天线、<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E7%94%B5%E7%A3%81%E5%9C%BA%E4%B8%8E%E6%97%A0%E7%BA%BF%E6%8A%80%E6%9C%AF&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2632452604%7D">电磁场与无线技术</a>、自动化都可以从事物联网相关工作，毕竟物联网的范围太大了，涉及的专业、行业、岗位、工种太多了。</p>
<p>一些儿可行性建议：</p>
<p><strong>1.明确正确的技术观</strong>，物联网是一个行业，而不是一个专业。学好物联网里任何一项技术，都可以独当一面，迅速实现个人<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E4%BB%B7%E5%80%BC%E7%A7%AF%E7%B4%AF&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:3024228794%7D">价值积累</a>。如果贪多贪快，除了给自己带来无尽的失望和打击，没什么好处。</p>
<p><strong>2.明确正确的发展方向</strong>，物联网涉及软硬件、互联网、App等多个领域，作为个人而言，只可能精其一样。如果是做硬件，那就好好学数电模电、<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E5%BA%94%E7%94%A8%E7%94%B5%E8%B7%AF&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:3024228794%7D">应用电路</a>、布线画板、传感器特性等等。如果是做软件，明确方向，一般建议本科阶段学好<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E5%8D%95%E7%89%87%E6%9C%BA&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2915052959%7D">单片机</a>编程、熟悉一两种传感器或应用，做一两款小产品即可。毕业后，可逐步过渡，学会和其他工程师配合，学会<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E7%BB%84%E7%BD%91&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:3024228794%7D">组网</a>应用，多出作品练手。</p>
<p><strong>3.实践大于理论</strong>，学物联网或者嵌入式一定要勤上手，多出作品。多出作品，不仅可以增长技术能力、了解物联网构架，最重要的是可以提高自信心。人与人的区别，大部分都在教育，而教育成功与否，自信是非常重要的评估法则。当然，由于物联网一般都是系统产品，建议学习者可以基于成熟的构架去做产品，这样容易成功做出完整产品。</p>
<p><strong>4.毕业后，尽量不要去初创公司</strong>，一定要去中型企业或大企业的核心团队，哪怕打杂都行。无论未来是打算做市场还是做技术，一定要记得毕业招工作的时候，要想办法进企业的核心研发团队，大公司进不了，就进小一点的，再进不了，就再小一点。可能有人会问，人家不一定要我啊。对，人家不一定要你，你本科期间作出的物联网作品，就是敲门砖。</p>
<p><strong>5. 就业后，不要急于成功，闷下心思，跟着团队技术带头人做技术</strong>。有什么做什么，尽多培养不同领域的应用，多结实靠谱的技术朋友。三五年后，某一天，你会发现你自己有技术、有团队，可以做任何产品的时候，你的路也会宽阔起来。</p>
<p>人才有两种，一种是<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E5%BA%94%E7%94%A8%E5%9E%8B%E4%BA%BA%E6%89%8D&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2767766898%7D">应用型人才</a>，把各种技术结合起来，组装成一样东西解决某个问题：例如硬件方面，第一境界是使用各种模块接线；第二境界是使用万用板自己焊接；第三境界是自己画电路图和PCB图打板；软件方面，第一境界，抄别人的代码；第二境界，移植别人的代码然后修改；第三境界，调用库的代码，如果没有就抄；第四境界，熟知各种库的API，自己写代码；应用型人才找工作是最方便的，大公司小公司都会要，只要老板请你做并你愿意做，就会给你开工资。</p>
<p>第二种是是理论型人才，理论知识非常强，数学非常棒，使用<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E4%BB%BF%E7%9C%9F%E8%BD%AF%E4%BB%B6&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2767766898%7D">仿真软件</a>验证了一遍，还会拿纸和笔自己再算一遍。一般这样人才不是考研就是去国企等大型企业或<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E7%A0%94%E7%A9%B6%E6%89%80&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2915052959%7D">研究所</a>从事理论性非常强的工作，比如算法、 <a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E9%AB%98%E9%A2%91%E7%94%B5%E8%B7%AF&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:3019505700%7D">高频电路</a>、芯片研发、<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2632452604%7D">信号处理</a>等。</p>
<p>物联网的真正技术，大学是学不完的，它是一个庞大的体系，研究生的话会细分方向，让你更加清晰自己在做什么。大学学习的大多数理论知识，一定要私下多多学点儿东西，没有坏处。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/551003511">物联网工程以后就业前景怎么样? - 知乎 (zhihu.com)</a></li>
</ul>
<p>就业前景很好，跟计算机专业的就业前景差不多。</p>
<p>可以从事纯硬件工作，比如画PCB电路板，画<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E5%8E%9F%E7%90%86%E5%9B%BE&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:%222654139657%22%7D">原理图</a>等。可以从事纯软件工作，比如做网页，做APP等。还可以从事嵌入式行业，嵌入式行业分类很多，我所熟悉的是<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E5%B5%8C%E5%85%A5%E5%BC%8F%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%B8%88&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:%222654139657%22%7D">嵌入式软件工程师</a>，该类工程师不仅需要懂硬件原理图，还需要会编程，编写程序来操作硬件。</p>
<p>总之，选<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E7%89%A9%E8%81%94%E7%BD%91%E5%B7%A5%E7%A8%8B&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:%222654139657%22%7D">物联网工程</a>专业，可以从事的行业很多，并不用害怕找不到工作。希望对题主有所帮助。</p>
<p>其实一个行业的前景不代表个人的前景，一个人在这个行业里面发展的怎么样，能走多远看的是个人能力和付出了多少努力。</p>
<p>但是物联网这个领域本身还是可以的，现在万物互联，发展肯定是可以的。</p>
<p>唯一的问题是大学里面学的知识比较乱，也比较基础，加上物联网的市场需求还没有那么高，所以在找工作的时候机会少一些。</p>
<p>物联网也算是计算机的相关专业，你可以选择一门编程语言深入学习之后就业的。</p>
<p>这么跟你说吧，物联网是一个行业不是一个专业，是行业就有很多岗位，所以物联网找工作不上不下的，软件有软工，硬件有电气，学的东西太杂乱，好像什么都会一点，但多数企业要的是一个方面专精的，如果真想读物联网一定要大一就确定一门语言去学精他，真不好找工作</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/64290050">各位前辈，请问一下为什么有的人说物联网工程是个坑，学的杂而不精，然而它的就业平均薪酬还那么高呢？ - 知乎 (zhihu.com)</a></li>
</ul>
<p>简答：物联网工程是坑，行业平均薪资也确实有竞争力</p>
<p>原因：物联网工程其实也属于工程技术，只是它属于近代技术广泛应用，你去学这个。</p>
<p>打个比方你要搞特斯拉，其实这玩意并没有啥高精尖的技术，大部分还是原来传统车积累下来的。真正变更的是类似特斯拉自动驾驶以及电池管理技术：对比物联网中云技术以及射频技术。</p>
<p>如果你在物联网行业，并没有负责核心技术抑或不能有独特竞争力，那么与其他行业没有太多变化。只是公司如果发展好，你的待遇可能会跟上。</p>
<p>现在物联网行业比传统企业待遇个人觉得是会好一点，因为缺口稍微大一点。毕竟搞智能硬件的需要一批新人才，也比传统硬件复杂一点。</p>
<p>而且物联网技术人员是跟互联网大厂抢人，能搞云架构，云安全，语音，嵌入式，前后端这些哪些不是本来就高待遇。</p>
<p>认清物联网本质，这个问题就好理解了。</p>
<p>谢邀，15年某211物联网毕业生，女生，同班同学，包括上一届学长学姐，没有说哪个毕业后是以物联网相关岗位进去工作的，要么硬件工程师要么软件，只要有一项精通的，进去做技术之后再慢慢转，而且国内大部分都是打着物联网的旗号该干嘛还是干嘛，真正做的好的就是小米智能家居，据我所知，没有应届生能进得去，都是个行业的大牛，加油吧</p>
<p>大四二本物联网工程在读，这就是个通信软硬件杂交专业，还是不建议你选择这个专业，目前我们班44人就业选择：Java、C++、前端、测试、运维、嵌入式、大数据、Android，射频工程师，你可以看出就业方向五花八门，但都是互联网计算机岗位，所以薪资还是不错的。这个专业怎么说呢。你只要不是太划水。懂点物联网知识，对于你找你自己选择的方向很有帮助。因为物联网工程归根究底还是属于工科计算机学科，算科班。我自己是选择了Java，拿了3，4个工业软件和物联网方向公司的Java offer</p>
<p>16年电子信息工程专业学生，19年开始北漂，目前在做数字智能化的相关业务。</p>
<p>当时我们的系叫做计算机科学与技术专业，然后分三个通信工程，物联网，和电信。然后上了半学期大家觉得都挺坑的，课程很难且不专一，一开始我认为我是一个很喜欢创造的人，我想借此学习很多知识然后去做一个什么事情，但是我被这一堆课程以及每周日一整天的实验课给干趴下了，到大三还有实验课。然后成绩一般，也少了跟老师做项目的机会，我记得当时系里面有一个电脑鼠竞速比赛的项目，就是一个电子老鼠跑迷宫。算是国际上相对知名的智能电子开发的比赛了。然后很多同学都参与了一开始学校的内选，但是物联的队伍就很突出。</p>
<p>他们的队伍有几个特点，你问的所谓杂而不精，其实在大多数时候，杂与精的距离没那么远，而且一个团队大家可以相互配合，你清楚所有的链路之后就可以衔接各位在各方面有突出的队员去实现一个目标。</p>
<p>而且真正在毕业之后还在做这一行的同学，他们的薪酬影响因素根本就不是专业什么的，就他们的技术能力，对于技术开发的热情，学校时期就一屁股的参赛奖项，他的工资就低不了，老板太清楚什么事人才了。</p>
<p>这些长期坚持的兄弟要么之后自己创业搞个小队伍自己创造去了，要么一早靠着奖项进大厂深造去了，去其他厂的时候面试的时候知识面也足够应对大多数问题了，凭啥薪资不高。</p>
<p>我一开始去干市场，干媒体，最后回到这个行业做解决方案的时候，才后悔，当初要是认真学点技术，现在焊面包板一定比写PPT有趣多了。</p>
<p>选专业什么的不用想那么多，如果奔着薪资去的，那努力就好。</p>
<p>各位学弟，看看up“01星球”的吧，没必要焦虑具体的专业是什么，尽管学习内容有偏差，说实话，计算机类包括计科和互联网在内的许多细分专业，但大学的课都比较水（名校除外），其核心是围绕计算机4大件展开的，只不过有些具体的专业内容更深入（比如计科要学硬件，软件工程主要是软件，很少设计到硬件，除非以后你去人家公司做别的复杂点的项目)，其实本科选什么专业差别对你以后所想去的具体岗位影响不大，关键是看你们在学校有没有好好“自学”（尽早出去实习给自己接触社会的机会）.好好学习热爱技术，把技术学精湛，管你什么专业，只要你给企业带来价值，走什么技术岗位人家都要你的</p>
<p>后端springboot springcloud netty，数据库Redis MySQL influxdb，运维docker Jenkins，嵌入式 rtthread stm32， 4g模组 蓝牙WiFi模组，电源设计，还能画下原理图和pcb，阁下又如何应对呢？</p>
<p>真正在班上拔尖的同学，参加比赛，研究代码年年拿奖学金。软硬件虽说不特别牛逼，但是做项目刚刚好，学完Linux环境编译，<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E5%A4%9A%E7%BA%BF%E7%A8%8B&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2630753191%7D">多线程</a>。真的，每次做成功一个属于自己的项目真的特别开心。特别是在硬件和软件结合起来用。</p>
<p>真正看的还是自学能力，难道到了计科就完美了吗，不计科还要拉跨，我有接触过计科的教学大纲和她们也有朋友，毕竟之前还是一个宿舍，换校区就不是了。计科也要学硬件和软件。我们的大纲还重合了很多，只是在某些硬件上更加仔细。<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E7%89%A9%E7%90%86%E7%BD%91&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2630753191%7D">物理网</a>工程的话，因为要上云服务，所以还要学习Java，Javaweb，Python。不做网页，所以这些不用特别专业。更加注重是<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E5%BC%80%E5%8F%91%E7%89%88&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2630753191%7D">开发版</a>驱动和传感器方面，是我们核心专业课。还有物联网控制技术，各种组网ZIgbee，wife，蓝牙，也是重点。</p>
<p>往下阅读之前，先问问自己，BATD四大厂，工农建交四大行，快手华为爱奇艺，京东网易拼夕夕，还有哔哩哔哩和滴滴……这些大厂都投完简历了么？</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://scatteredream.github.io/2025/01/06/408-OS-Boot/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars.githubusercontent.com/u/62317679?s=400&v=4">
      <meta itemprop="name" content="碎梦">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="scatteredream's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | scatteredream's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/01/06/408-OS-Boot/" class="post-title-link" itemprop="url">操作系统启动 CPU模式</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-01-06 00:00:00" itemprop="dateCreated datePublished" datetime="2025-01-06T00:00:00+08:00">2025-01-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-05-05 11:44:39" itemprop="dateModified" datetime="2025-05-05T11:44:39+08:00">2025-05-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/OS/" itemprop="url" rel="index"><span itemprop="name">OS</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Operating-Modes"><a href="#Operating-Modes" class="headerlink" title="Operating Modes"></a>Operating Modes</h1><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241219213730449.png" alt="image-20241219213730449"></p>
<ul>
<li>x86-64 架构的处理器正常工作在 <u>Long Mode</u>，支持 64 位 OS/UEFI，有两个子模式<ul>
<li><u>64-bit Mode</u>: 只能运行 64 位软件，32 位软件需要重新编译</li>
<li><u>Compatibility Mode</u>: 兼容 32 位和 16 位保护模式软件，不支持实模式/虚拟86</li>
</ul>
</li>
<li>IA-32 或 x86 架构的处理器(i286后)正常工作在 <u>Protected Mode</u>，支持 32 位 OS/UEFI<ul>
<li><u>Protected Mode</u>: 支持运行 32 位 和 16 位保护模式的软件</li>
<li><u>Virtual 8086 Mode</u>: 类似 Compatibility Mode，可直接向下兼容运行 real mode 软件</li>
</ul>
</li>
<li>8086 处理器的 <u>Real Mode</u>，最高支持 16 位的操作系统，只能运行实模式软件</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220141424897.png" alt="image-20241220141424897"></p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/80186">80186</a> 和早期的 CPU 仅仅只有一种操作模式，也就是相当于后来芯片的这种 Real Mode；</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/80286">80286</a> 和之后的 x86 CPU 都是以 Real Mode 开机，然后经过 BIOS/UEFI, Bootloader 等引导程序切换到 Protected Mode 或 Long Mode，以便运行 32 或 64 位的操作系统。</p>
</li>
<li><p>启动操作系统之后，通常是在对应模式下运行，如果要运行向前兼容的程序只能使用子模式，切换模式需要重新初始化 CPU 代价太大</p>
</li>
</ul>
<h2 id="Real-Mode"><a href="#Real-Mode" class="headerlink" title="Real Mode"></a>Real Mode</h2><p>80286 以前：</p>
<p><strong>Intel 80186</strong>是<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/Intel">Intel</a>针对<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%B7%A5%E4%B8%9A%E6%8E%A7%E5%88%B6">工业控制</a>／<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%80%9A%E4%BF%A1">通信</a>等嵌入式市场，于1982年推出的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/8086">8086</a>处理器的扩展产品，除8086内核，另外包括了中断控制器、定时器、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%9B%B4%E6%8E%A5%E8%A8%98%E6%86%B6%E9%AB%94%E5%AD%98%E5%8F%96">DMA</a>、I/O、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/UART">UART</a>、片选电路等外设。</p>
<p><strong>实模式</strong>，Real mode[Real-Address Mode]，是Intel <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/80286">80286</a>和之后的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/X86">x86</a>兼容<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/CPU">CPU</a>的操作模式。实模式的特性是20位寻址空间，最大寻址空间1MB，最大分段64KB，可以直接软件访问<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/BIOS">BIOS</a>以及周边硬件，没有任何硬件等级的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%A8%98%E6%86%B6%E9%AB%94%E4%BF%9D%E8%AD%B7">保护</a>观念或<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%A4%9A%E5%B7%A5">多任务</a>支持。所有的80286系列和之后的x86 CPU都是以实模式下开机；<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/80186">80186</a>和早期的CPU仅仅只有一种操作模式，也就是相当于后来芯片的这种实模式。CPU <a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E5%A4%8D%E4%BD%8D/6156307?fromModule=lemma_inlink">复位</a>（reset）或加电（power on）的时候以实模式启动。</p>
<p>实模式出现于早期 8088 CPU 时期。当时由于 CPU 的性能有限，一共有 20 位<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=8464187&content_type=Article&match_order=1&q=%E5%9C%B0%E5%9D%80%E7%BA%BF&zhida_source=entity">地址线</a>（所以地址空间只有1MB），以及 8 个 16 位的通用寄存器，以及 4 个 16 位的段寄存器。16 位寄存器只能支持64KB的线性地址空间，需要使用另外一个寄存器配合才能利用所有的地址线，因此这种管理内存的方式称为<strong>段式管理</strong>（segmentation）由于 80286 以前只有实模式一种，当时并不叫实模式，286 以后出现保护模式才给以前这个模式取名叫实模式，而硬件上有一定改进，因此 8086 和 80286 的实模式还有有一些细微区别的。详见A20 Gate</p>
<h3 id="x86-Registers"><a href="#x86-Registers" class="headerlink" title="x86 Registers"></a>x86 Registers</h3><p>图中绿色标记为 8086 的 4 个段寄存器，还有剩下的 16 位寄存器</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241221225031752.png" alt="image-20241221225031752"></p>
<ul>
<li>4 个段寄存器 <strong>CS</strong>、<strong>SS</strong>、<strong>DS</strong> 和 <strong>ES</strong>，用来描述特定段的基址，不能混用，都是 16 位；</li>
<li>1 个指令指针寄存器 <strong>IP</strong> ， 用于和 CS 组成 <strong>CS:IP</strong> 逻辑地址，指向下一条要执行的指令，16 位；</li>
<li>8 个通用寄存器，其中 <strong>SP</strong> 一般固定用于保存堆栈指针，其他可以任意混用，16 位；</li>
<li>1 个程序状态字 <strong>FLAGS</strong>(<strong>PSW</strong>, Program Status Word) 16 位，保存当前程序执行的一些状态和结果的某些信息</li>
</ul>
<h3 id="Segmentation-before-80286"><a href="#Segmentation-before-80286" class="headerlink" title="Segmentation before 80286"></a>Segmentation before 80286</h3><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/20131020015240765.jpeg" alt="img"></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220001927471.png" alt="image-20241220001927471"></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220141646817.png" alt="image-20241220141646817"></p>
<p>当某个指令想要访问某个内存地址时，它通常需要用下面的这种格式来表示：(段基址：段偏移量) </p>
<ul>
<li><p>段基址：它的值是由<strong>段寄存器</strong>提供的(一般来说，段寄存器有6种，分别为cs，ds，ss，es，fs，gs，这几种段寄存器都有自己的特殊意义，这里不做介绍)</p>
<ul>
<li>段寄存器除了有 16 位的可见部分，还有不可见的隐藏部分：描述符缓存“descriptor cache”或隐藏寄存器“shadow register” 当一个段选择子装入段寄存器的可见部分，处理器同时也把它指向的段表内容缓存cache中，避免在翻译逻辑地址时花费额外的开销去访问段表。处理器指令中可以明示使用哪些段寄存器，这将替换掉默认使用的段寄存器。</li>
</ul>
</li>
<li><p>段内偏移量：代表你要访问的这个内存地址距离这个段基址的偏移。它的值由<strong>通用数据寄存器</strong>来提供的，所以也是 16 位。那么两个 16 位的值如何组合成一个20位的地址呢？CPU采用的方式是把段寄存器所提供的段基址先向左移4位。这样就变成了一个20位的值，然后再与段偏移量相加。段偏移量16位，因此最大分段为 64 KB</p>
</li>
<li><p><code>物理地址 = 段基址 &lt;&lt; 4 位 + 段内偏移</code> </p>
<ul>
<li>段寄存器是0xff00，段偏移量为0x0110，物理地址 0xff00&lt;&lt;4 + 0x0110 = 0xff110</li>
</ul>
</li>
</ul>
<p>实模式的”实”更多地体现在其地址是<strong>真实的物理地址</strong>(Real-Address Mode)</p>
<p>段基址 + 偏移，Segmentation 分段的雏形，逻辑地址</p>
<h3 id="Limitations"><a href="#Limitations" class="headerlink" title="Limitations"></a>Limitations</h3><p>由于程序可以任意修改当前的 CS/DS 值，所有程序可以使用全部  1 MB 的内存，所以这个CPU几乎没有办法有效地支持多任务，因为两个程序一起运行的话很容易互相踩到内存。所以当时的使用的方式系统中同时运行的只有一个应用程序和一个DOS操作系统。操作系统和应用规定了各自能使用的内存地址范围，比如说DOS只使用高 64KB 的内存，其它的内存给应用程序使用。这样就可以互不影响。要想运行另一个应用程序必须先退出当前运行的应用程序。</p>
<h3 id="A20-Gate"><a href="#A20-Gate" class="headerlink" title="A20 Gate"></a>A20 Gate</h3><p>在 8086 时代使用CS&lt;&lt; 4 + IP计算物理地址， 从理论上讲，最大可以表示的数值是 0xFFFF0 + 0xFFFF = 0x10FFEF，即大约1M+64KB-16B,然而由于当时的地址线只有 20 根（A0~A19)，这个地址最前面的1无法被表示，当CS=0xFFFF时，实际访问的地址0x10FFEF就变成了0xFFEF，这也导致当时程序编写者为了适应这个问题使用了特殊的技巧。到了80286，地址线变成24位，此时0x10FFEF可以访问到了。为了兼容性考虑，由A20 Gate来控制第21根地址总线的开关。能够在实模式下增加了对额外 65,520 字节（64 KB - 16 字节）内存的访问，而无需进行重大软件更改。</p>
<ul>
<li>开关打开：实模式能访问10000-10FFEF的高地址</li>
<li>开关关闭：实模式无法访问10000-10FFEF，保护模式只能访问 0到1M，2M到3M，寻址空间减少一半。</li>
</ul>
<p>另外实模式和8086还有中断向量的区别，详见虚拟 86 模式</p>
<h2 id="Protected-Mode"><a href="#Protected-Mode" class="headerlink" title="Protected Mode"></a>Protected Mode</h2><p>80286 到 80386 开始：<br><strong>保护模式</strong>，Protected Mode，内存保护模式，寻址采用32位段和偏移量，最大寻址空间为4GB，最大分段4GB 。保护模式拥有内存保护，分页系统，以及硬件支持的虚拟内存等功能，支持抢占式多任务调度，CPU 特权模式。在保护模式下，进行寻址时，段寄存器值不再被简单的解析为段基址，而是全局/局部描述符表（GDT/LDT）的索引，也即是所谓的段选择子。</p>
<p>80286 开始支持保护模式，但是寄存器仍然是 16 位，属于 16 位的保护模式。</p>
<p>80386 以后，CPU 寄存器变成 32 位，IA-32 的保护模式寻址发生了一定变化: 地址线的个数从原来的20根变为现在的32根，所以可以访问的内存空间也从 1 MB 变为 4 GB。实模式下的内存地址计算方式就已经不再适合了。</p>
<h3 id="80286-Protected-Mode-16-bit"><a href="#80286-Protected-Mode-16-bit" class="headerlink" title="80286 Protected Mode(16-bit)"></a>80286 Protected Mode(16-bit)</h3><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/080810-protected-286-segments.png" alt="undefined"></p>
<h4 id="New-Features-of-80286"><a href="#New-Features-of-80286" class="headerlink" title="New Features of 80286"></a>New Features of 80286</h4><ul>
<li><p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/80286">Intel 80286</a> 的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%9C%B0%E5%9D%80%E7%B8%BD%E7%B7%9A">地址总线</a>增加到 24 位，物理最大可寻址空间为 2^24^（即16 MB）</p>
</li>
<li><p>寄存器：</p>
<ul>
<li><p>通用寄存器的位数仍为 16 位，只能使用段式管理，增加了保护模式通过段表间接访存</p>
</li>
<li><p>引入了 机器状态字 <strong>MSW</strong>(Machine Status Word)寄存器用来控制处理器整体的状态，比如保护模式与实模式的切换</p>
</li>
<li><p>引入 <strong>GDTR</strong> <strong>LDTR</strong> <strong>IDTR</strong> <strong>TR</strong>，工作在保护模式，为分段服务，是多任务实现的基础</p>
</li>
</ul>
</li>
<li><p>80286 保护模式下的应用程序能访问的内存<strong>线性地址空间仅为 64 KB</strong>，非常有限。所以程序员编写使用大内存的应用程序时还必须使用远指针、近指针，相当繁琐。这影响了 80286 保护模式的推广使用。</p>
</li>
</ul>
<h4 id="x86-Segmentation"><a href="#x86-Segmentation" class="headerlink" title="x86 Segmentation"></a>x86 Segmentation</h4><h5 id="Descriptor-Table"><a href="#Descriptor-Table" class="headerlink" title="Descriptor Table"></a>Descriptor Table</h5><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220142126857-1734679595859-13-1734679601817-15.png" alt="image-20241220142126857"></p>
<p>在80286中，CS/DS/ES/FS寄存器存储的内容变成了选择子。使用段表管理之后，CPU 使用的就是逻辑地址（段选择子+偏移量），经过段表翻译才能有实际物理地址，而段描述符表只有系统内核才能修改。这就保证了一个进程只能访问内核分配给他的段上的物理内存。寻址时，依然是 base and bound 的思想，只不过要先去段表中查找段表项，里面有对应段的物理地址以及界限以及权限位，这里就体现出了虚拟内存的保护作用，之前偏移量受位数限制，现在偏移量不能超过界限，并且必须通过权限鉴别。</p>
<p>下图为段表（描述符表）的基本情况：共 3 个，可直接访问的有 GDT 与 LDT 两个，IDT 是中断表，里面的描述符指向的都是特定的段，也叫 Gate</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220152155629.png" alt="image-20241220152155629"></p>
<p>选择子一共有 16 位：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220175738856.png" alt="image-20241220175738856"></p>
<ul>
<li><p>高 13 位是段表的 index；</p>
</li>
<li><p>TI(Table Index)为第 2 位，表示选择 GDT 还是 LDT，有专门的 GDTR、LDTR 寄存器保存段表基址 STBaseAddress。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220142058130-1734679404141-3.png" alt="image-20241220142058130"></p>
<ul>
<li><p>LDT 存放在 GPT 的 LDT 类型描述符中，LDT 本身是一个段，而 GDT 不是一个段</p>
</li>
<li><p>访问 LDT 需要使用段选择子，为了减少访问 LDT 时段转换的次数，LDT 的段选择符，段基址，界限都要放在 LDTR 寄存器之中。</p>
</li>
<li><p>GDT 本身不是一个段，而是线性地址空间的一个数据结构；GDT 的线性基地址和长度必须加载进 GDTR 之中。因为每个描述符长度是8，所以 GDT 的基地址最好进行8字节对齐。</p>
</li>
<li><p>段寄存器仍然有之前类似 TLB 的 <strong>缓存</strong> 机制，有可见和不可见两个部分：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220180035716.png" alt="image-20241220180035716"></p>
</li>
</ul>
</li>
<li><p>0 - 1 为权限位(RPL) RPL 称为<strong>请求</strong>权限级别。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241221224507677.png" alt="image-20241221224507677"></p>
<ul>
<li><strong>CPL</strong> 是当前<strong>正在执行的代码段</strong>的特权级（CS 寄存器的低 2 位）<ul>
<li>0 和 3 分别表示用户态和内核态.中间是驱动程序的优先界别</li>
<li>CPL只在代码段改变时改变，即跳转指令 JMP CALL</li>
</ul>
</li>
<li>RPL 是对于一个段的请求特权级别</li>
<li><code>max&#123;RPL,CPL&#125; &lt; DPL</code> 方可访问此段</li>
</ul>
</li>
</ul>
<h4 id="Address-Translation"><a href="#Address-Translation" class="headerlink" title="Address Translation"></a>Address Translation</h4><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220180347195.png" alt="image-20241220180347195"></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220141603315.png" alt="image-20241220141603315"></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/929457-20161229210613367-1902103210-1734526656105-28.png" alt="img"></p>
<p><code>STEntry Address = STBaseAddress + 8 * index</code>  DTEntry 的大小 = 每条目 8 字节</p>
<p>Descriptor(DTEntry) 中含有段基址 界限 DPL 等       物理地址 = 段基址 + 偏移 </p>
<p>CS:IP 组合称为逻辑地址，CS 唯一对应到段表的一个条目，应用程序内存不够用时，需要调用一些系统调用，让 DOS 分配一段内存，把这段内存的 base, limit 做成一个条目（Descriptor）加入到GDT或LDT中， 只有OS能更改CS，如果用户擅自更改CS，段表中找不到对应条目，会发生segmentation fault。逻辑地址一共有13+1=14位有效，偏移16位，因此虚拟内存 1 GB。但是地址线数量限制了物理内存大小最大 16 MB。</p>
<p>基于这种内存管理方式，用户应用程序可以实现动态链接。比如说一个程序分为代码段、数据段、零初始化段等，它依赖的库也是分段的，系统在加载程序时，只需为每个段分配一段内存，并为每个段设置一个描述符即可。 每个段的起始地址可以在加载时根据实际情况修改。</p>
<p>为了区分不同段的功能，可以在TYPE字段设置，比如代码段可读可执行，数据段可读可写等。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220180319764.png" alt="image-20241220180319764"></p>
<h4 id="Workflow-Example"><a href="#Workflow-Example" class="headerlink" title="Workflow Example"></a>Workflow Example</h4><p>为了加深理解，用一个简单的指令执行流程来说明：</p>
<ol>
<li>取指：CPU 从 CS:IP 逻辑地址 获取指令的物理地址，取指令(16bit)，CS不变，IP+2；<ul>
<li>CS 此时就是一个选择子，只要代码段无变化，当前指令的执行权限就不变</li>
</ul>
</li>
<li>译码：翻译指令，指令被解析为 <code>MOV AX, [BX]</code> 操作数的逻辑地址 DS:BX 算出物理地址</li>
<li>执行：从物理地址取数，将 取来的数存到 AX 通用寄存器</li>
</ol>
<h3 id="IA-32-Protected-Mode-32-bit"><a href="#IA-32-Protected-Mode-32-bit" class="headerlink" title="IA-32 Protected Mode(32-bit)"></a>IA-32 Protected Mode(32-bit)</h3><h4 id="New-Features-of-80386"><a href="#New-Features-of-80386" class="headerlink" title="New Features of 80386"></a>New Features of <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/80386">80386</a></h4><ol>
<li><p>首次在 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/X86">x86</a> 处理器中实现了 32 位系统（<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/IA-32">IA-32</a>）；</p>
</li>
<li><p>可配合使用 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/w/index.php?title=80387&action=edit&redlink=1">80387</a> 数字<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%BC%94%E5%8A%A9%E8%99%95%E7%90%86%E5%99%A8">辅助处理器</a>增强<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%B5%AE%E7%82%B9">浮点</a>运算能力；</p>
</li>
<li><p>首次采用 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98">高速缓存</a>（外置）解决内存速度瓶颈问题；</p>
</li>
<li><p>在 IA-32 保护模式下，CPU 的 32 条地址线全部有效，可寻址高达 4 GB 的物理地址空间；</p>
<p>Descriptor 的变化，可以看到变成 32位 基地址：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/929457-20161230154447711-2105143159-1734688534787-30.png" alt="img"></p>
</li>
<li><p>寄存器变化：</p>
<ol>
<li><p>在原来的四个段寄存器的基础上引入两个通用数据段寄存器 FS 和 GS；</p>
</li>
<li><p>除了段寄存器，其他寄存器全部升级到 32 位，名称加前缀 E，代表扩展；</p>
</li>
<li><p>将 80286 引入的 16 位 <strong>MSW</strong> 扩展为几个 32 位控制寄存器 <strong>CRx</strong> 用于控制机器特性。比如实模式、保护模式的切换以及分页机制的开启(CR0)页表的物理地址(CR3)，相对静态，初始化或特性切换时才改动，因此只有内核态可访问，以及还有用于调试的DRx寄存器；</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220175501376.png" alt="image-20241220175501376"></p>
</li>
<li><p>保护模式下的分段机制使用的寄存器 GDTR IDTR LDTR TR 有一些变化</p>
</li>
</ol>
</li>
</ol>
<h4 id="Flat-Memory-Model"><a href="#Flat-Memory-Model" class="headerlink" title="Flat Memory Model"></a>Flat Memory Model</h4><p><strong>最初的 Flat Model</strong>: </p>
<p>8086 以前，地址总线和数据寄存器只有 16 位，线性地址<strong>等于</strong>物理地址，最多支持64 KB的内存</p>
<p><strong>Real-Address Mode model</strong>: 实模式分段</p>
<p>1978 年的 8086 开始引入了内存<strong>分段</strong>，这使得 16 位 CPU 可以访问超过 64 KB (65,536字节)的内存，实际上 8086 CPU到内存的地址总线是 20 位，即可访问2^20^=1MB内存。</p>
<p>在 16 位模式，要让应用程序使用多个存储器分段（能够访问大于64K的内存）相当复杂。根源在于：数据总线位数少于地址总线，并且没有适当的地址算术指令适合做整个存储器范围的平面寻址，平面寻址方式也可以用像实模式那样的两个寄存器配合的乘法操作完成，但这会导致较慢的程序执行速度。并且 8086 只支持固定大小的段，这就引出了真正的分段机制</p>
<p><strong>Segmented Model</strong>: 保护模式分段</p>
<p>1982 年面世的 80286 不再将段寄存器左移 4 位作为段基址，而是索引到段表中获取段基址，这就是虚拟地址。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220002439505-1734680053190-17.png" alt="image-20241220002439505"></p>
<p>分段机制有固有的问题：处理器的实模式与保护模式，以及 80386 推出的虚拟 86 模式，分段最大 64 KiB（使用 16 位索引寄存器）。在实模式下的分段架构的内存空间会有所重叠，这是一种不好的设计。</p>
<p><strong>32-bit Flat Memory Model</strong>: 32 位分页</p>
<p>1985 年面世的 80386 及其后续处理器的 32 位保护模式下，一个分段长度上限是2^20^个粒度单位，粒度可以是 1 字节或 4K 字节（一页），因此分段长度上限可以是 4 GB，与 32 位数据寄存器匹配。随着 32 位操作系统的推出，以及更舒适的 32-bit Flat Memory Model，到 1990 年末期几乎淘汰了使用分段寻址，转而使用分页寻址。</p>
<p>然而使用 32-bit Flat Memory Model 最多只能访问 4 GB 的线性地址空间，这种限制并没有远离日常。此时，分段机制可以支持更多根地址线，比如奔腾Pro, 2, 3在 IA-32 的架构下拥有 36 条地址线，最大64 GB的内存，就靠分段的支持，但这种最终回归到分段的尴尬，经常被引述为朝着 64 位处理器发展的动机。</p>
<p><strong>真正的 Flat Memory Model</strong>: 64 位分页</p>
<p>2003 年问世的 x86-64 架构下，强制实现了 Flat Memory Model 这种最简明有效的寻址模型，但保留了使用段寄存器 FS 或 GS 的 64 位下的分段寻址。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220153250680.png" alt="image-20241220153250680"></p>
<h4 id="Paging"><a href="#Paging" class="headerlink" title="Paging"></a>Paging</h4><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/2560px-080810-protected-386-paging.svg.png" alt="undefined"></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241219214149653.png" alt="image-20241219214149653"></p>
<p><strong>页表</strong>：采用二级页表，10+10+12 划分</p>
<p><strong>多进程</strong>：每个进程有一个页表，页表的物理地址存储在 CR3 寄存器</p>
<p>在Intel 80386及以后的版本中，保护模式保留了 80286 保护模式的分段机制，但增加了分页单元作为分段单元和物理总线之间的第二层地址转换。</p>
<ol>
<li>逻辑地址是 48 位，16 位属于段号，32 位偏移量，段表项中的段基址也是 32 位</li>
<li>应用程序寻址首先根据段号和段表基址定位到段表项，段的基地址加上偏移量算出线性地址</li>
<li>若关闭分页单元，段基址就是物理地址，直接送到地址总线上进行访存。</li>
<li>若启用分页单元，段表项存储的段基址是线性地址，而不是 80286 那样的物理地址。分页单元负责最终查询页表将这些线性地址转换为物理地址。</li>
</ol>
<p>80386 分页内存管理，比 80286 保护模式寻址具有更多的优点：</p>
<ul>
<li>操作系统可以控制与限制进程对页面的访问权限</li>
<li>为应用程序创造一个连续的、独立的、线性的虚拟内存空间</li>
<li>页面可以移出<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%B8%BB%E5%AD%98">主存</a>，存入更慢速的次级<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%A4%96%E5%AD%98%E5%82%A8%E5%99%A8">外存</a>如<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%A1%AC%E7%9B%98">硬盘</a>。这使得操作系统可以使用比物理内存更大的存储空间。</li>
</ul>
<h4 id="CR0-Enabling-Features"><a href="#CR0-Enabling-Features" class="headerlink" title="CR0: Enabling Features"></a>CR0: Enabling Features</h4><ol>
<li>通过清除 CR0 控制寄存器中的最低位，可以返回实模式，但这是一项特权操作，以增强安全性和鲁棒性。相比之下，80286 只能通过强制处理器重置来返回实模式，例如由三重故障或使用外部硬件。</li>
<li>控制寄存器 CR0 中的位 0 用 PE 标记，控制分段管理机制的操作，所以把它们称为保护控制位。 PE 控制分段管理机制。 PE=0，处理器运行于实模式； PE=1，处理器运行于保护方式。</li>
<li>是否启用分页由 CR0 的位 31 标记</li>
</ol>
<h4 id="Enabling-Protected-Mode"><a href="#Enabling-Protected-Mode" class="headerlink" title="Enabling Protected Mode"></a>Enabling Protected Mode</h4><p>进入保护模式前，必须初始化 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%85%A8%E5%B1%80%E6%8F%8F%E8%BF%B0%E7%AC%A6%E8%A1%A8">GDT</a>，并最少包含三个描述符：空描述符、CS 描述符以及 DS 描述符。并把（全局描述符表的所占用的字节数-1）和 GDT 的物理地址保存到 GDTR 寄存器中。如果是IBM兼容的机器，则还需要打开 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/A20%E6%80%BB%E7%BA%BF">A20总线</a> </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">; 设置CR0寄存器的PE位</span><br><span class="line">mov eax, cr0       ; 必须通过其他寄存器来修改CR0寄存器</span><br><span class="line">or eax, 1</span><br><span class="line">mov cr0, eax</span><br><span class="line"></span><br><span class="line">; 远转移 (cs = 代码段描述符)</span><br><span class="line">jmp cs:@pmode</span><br><span class="line"></span><br><span class="line">[bits 32]</span><br><span class="line">@pmode:</span><br><span class="line">; 现在已经进入了保护模式</span><br></pre></td></tr></table></figure>

<h3 id="Virtual-8086-Mode"><a href="#Virtual-8086-Mode" class="headerlink" title="Virtual 8086 Mode"></a>Virtual 8086 Mode</h3><p>80286 开始的保护模式支持<strong>更大的寻址空间</strong>和<strong>一定程度的保护措施</strong>，但是为了<strong>向下兼容</strong>运行在实模式下的软件，仍然保留了实模式（BIOS 工作在实模式，因此在正式启动操作系统之前必须运行在实模式，开始启动的<strong>第一步就是将实模式转换为保护模式</strong>）启动系统之后，80286 的 16 位保护模式，受硬件的限制，不支持分页，多任务支持也有限，因此不能向下兼容实模式的软件，<strong>必须遵循一定的标准将实模式代码重新编译、汇编才能在 16 位的保护模式运行</strong>，这就造成了诸多不便。</p>
<p>80386 开始的 IA-32 架构中，寄存器扩展至 32 位，随之而来的 32 位保护模式较完整，因此可以<strong>在 32 位保护模式直接运行 16 位实模式程序</strong>，也就是虚拟 8086 模式。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241219214209871.png" alt="image-20241219214209871"></p>
<ul>
<li>利用健全的多任务机制，多个虚拟 86 程序可以和 32 位程序并发执行，提升效率</li>
<li>利用分页机制，模拟出和 8086 一样的寻址方式，段基址 &lt;&lt; 4 + 段内的偏移地址，寻址空间为1 MB，将不同虚拟 86 程序的地址空间映射到不同的物理地址上，这样每个虚拟86任务看起来都认为自己在 0 ~ 1 MB 的地址空间。</li>
</ul>
<h4 id="Real-mode-Virtual-8086-8086"><a href="#Real-mode-Virtual-8086-8086" class="headerlink" title="Real mode/Virtual 8086/8086"></a>Real mode/Virtual 8086/8086</h4><p>下表可以看出 实模式、8086、虚拟 86 的中断向量表是不完全一致的</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220173857308.png" alt="image-20241220173857308"></p>
<ul>
<li>和实模式、8086相比：</li>
</ul>
<ol>
<li>段描述符加载之后会缓存，加快之后的访存速度</li>
<li>虚拟 8086 模式并不是完美兼容的，因为在 16 位架构里没有保护概念，CPU 也没有特权指令这一说，所以改变段寄存器、直接访问硬件等操作会陷入 OS 或者抛出异常，这就导致这些指令无法正常运行，但也没有办法，为了适应现代操作系统，只能放弃对这些应用的支持。</li>
</ol>
<h3 id="IA-32-Address-Translation"><a href="#IA-32-Address-Translation" class="headerlink" title="IA-32 Address Translation"></a>IA-32 Address Translation</h3><p>在 x86-64 架构下，长模式以外的三种模式也叫做 Legacy Mode </p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241219214044009-1734615684145-17.png" alt="image-20241219214044009"></p>
<h2 id="Long-Mode-IA-32e-Mode"><a href="#Long-Mode-IA-32e-Mode" class="headerlink" title="Long Mode(IA-32e Mode)"></a>Long Mode(IA-32e Mode)</h2><p>在x86-64 等现代新架构中，长模式是64位操作系统可以访问64位指令和寄存器的模式，有两个子模式。 </p>
<p>64位程序在称为 64-bit Mode 的子模式下运行，32 位和 16 位保护模式程序在称为 Compatibility Mode 的子模式下执行，其允许 64 位操作系统运行现有的 16 位和 32 位 x86 应用程序。 在兼容模式下运行的应用程序使用 32 位或 16 位寻址，并且可以访问前 4 GB 虚拟地址空间。传统 x86 指令前缀在 16 位和 32 位地址和操作数大小之间切换。 与 64 位模式一样，兼容性模式由操作系统在单个代码段的基础上启用。</p>
<p>然而，与 64-bit Mode 不同的是，x86 分段功能与传统 x86 架构中相同，使用 16 位或 32 位保护模式语义。从应用程序的角度来看，兼容模式看起来就像传统的 x86 保护模式环境。然而，从操作系统的角度来看，地址转换、中断和异常处理以及系统数据结构都使用 64 位长模式机制。</p>
<p>删除了 HW Task Switch, TSS 变成一个堆栈表, 不再存储段相关的信息</p>
<h3 id="x86-64-Registers"><a href="#x86-64-Registers" class="headerlink" title="x86-64 Registers"></a>x86-64 Registers</h3><p>x86-64 架构在长模式（64 位模式）下，大部分寄存器位数增加为 64 位，前缀位为 R</p>
<ul>
<li>分段的概念被无限弱化：其中四个段寄存器 CS、SS、DS 和 ES 被强制设置为基地址 0，并且限制为 2^64^ ，形式上还有内存分段，但实际上所有内存都在唯一的一个分段中。</li>
<li>段寄存器 FS 和 GS 仍然可以具有非零基地址，这允许操作系统将这些段用于特殊目的。与传统模式使用的 GDT 机制不同，这些段的基地址存储在特定于模型的寄存器中。 x86-64架构还提供了特殊的 SWAPGS 指令，该指令允许交换内核模式和用户模式基地址。例如，x86-64 上的 Microsoft Windows 使用 FS 段指向线程环境块(TEB)，这是每个线程的一个小型数据结构，其中包含有关异常处理、线程局部变量和其他每线程状态的信息。同样，Linux 内核使用 GS 段来进行类似的线程本地存储(TLS)</li>
</ul>
<p><strong>应用程序编程</strong>使用如下寄存器：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220183652263.png" alt="image-20241220183652263"></p>
<p>系统编程使用如下寄存器：    </p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220183817147.png" alt="image-20241220183817147"></p>
<h3 id="Address-Translation-1"><a href="#Address-Translation-1" class="headerlink" title="Address Translation"></a>Address Translation</h3><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241219213948185.png" alt="image-20241219213948185"></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220183850040.png" alt="image-20241220183850040"></p>
<h3 id="Legacy-Mode"><a href="#Legacy-Mode" class="headerlink" title="Legacy Mode"></a>Legacy Mode</h3><p>以前的模式统称 Legacy Mode</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220184344031.png" alt="image-20241220184344031"></p>
<h1 id="Interrupt-and-Exception-Handling"><a href="#Interrupt-and-Exception-Handling" class="headerlink" title="Interrupt and Exception Handling"></a>Interrupt and Exception Handling</h1><h2 id="Concepts"><a href="#Concepts" class="headerlink" title="Concepts"></a>Concepts</h2><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/computer-interrupt1-l.jpg" alt="PPT - BIOS and DOS Interrupts PowerPoint Presentation, free download ..."></p>
<h3 id="Interrupt"><a href="#Interrupt" class="headerlink" title="Interrupt"></a>Interrupt</h3><p>中断可以分为硬件和软件引起的中断</p>
<ul>
<li><p>硬件中断(Hardware) 通常是 CPU 执行指令过程中收到外部硬件的中断信号，属于外部中断</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/273421-20210821212504824-517540124.png" alt="img"></p>
<ul>
<li>可屏蔽中断：<strong>INTR</strong> 引脚传入，可以通过 <code>IF</code> 标志位屏蔽</li>
<li>不可屏蔽中断：<strong>NMI</strong> 引脚传入(Non-maskable Interrupt)，电源掉电、内存读写错误、总线奇偶校验错误等灾难性的错误，不可屏蔽，CPU 必须立刻处理。有一个专用的中断向量号，一般是不可屏蔽的，这样可以防止嵌套执行，直到 <code>IRET</code> 从中断返回</li>
<li>通过中断控制器从总线读取中断向量，高级可编程中断控制器 <strong>APIC</strong> 可以通过 LINT 引脚接收中断，可以处理 INTR 和 NMI，如果 APIC 禁用则会使用 INTR 和 NMI</li>
<li>CPU 收到硬中断以后需要保存执行现场，转去执行中断服务程序（ISR, Interrupt Service Routine）硬中断是异步、随机、无法预知的。</li>
</ul>
</li>
<li><p>软件中断(Software) 通常显式调用中断指令触发的中断，属于内部中断</p>
<ul>
<li>基础的汇编指令，由指令提供中断向量号 <code>INT n</code> </li>
</ul>
</li>
<li><p>中断服务程序的最后一条一定是 <code>IRET</code> 指令，恢复原先程序的执行</p>
</li>
</ul>
<h3 id="Exception-Processor"><a href="#Exception-Processor" class="headerlink" title="Exception(Processor)"></a>Exception(Processor)</h3><p>异常主要是 CPU 执行指令过程中发现的，属于内部中断,从源头来看，大体分为三类：</p>
<ol>
<li>处理器在执行指令的过程中检测到的程序错误(program error)，比如 <code>zero division</code> </li>
<li>软件生成的异常：<code>INTO, INT1, INT2, INT3, BOUND</code> 指令。有一些异常提供错误码，发生异常需要将错误码压栈，以便正确处理。如果使用 <code>INT n</code> 模拟异常，不会提供错误码，会将 EIP 指令指针错误提供，可能会出现错误。<ul>
<li><code>INTO</code>: Overflow</li>
<li><code>INT3</code>: Breakpoint, debugging</li>
<li><code>BOUND</code>: Bound Range Exceeded</li>
<li><code>UD</code>: Invalid Opcode</li>
</ul>
</li>
<li>还有一些异常源是机器检查（Machine-check）提供的</li>
</ol>
<h2 id="Restart"><a href="#Restart" class="headerlink" title="Restart"></a>Restart</h2><p>下文的 中断/异常处理程序 泛指 处理中断或异常的程序</p>
<ol>
<li><code>Fault</code>: (<strong>RETRY</strong>) 异常处理程序 返回指向 <strong>异常源指令</strong> 的指针，因此将会<strong>重新执行</strong>这条指令。一般是在无法正常通过地址访问到操作数就会触发这种异常，最典型的比如 Page Fault，为了能正确恢复需要 CPU 保存必要的寄存器（上下文）。</li>
<li><code>Trap</code>: (<strong>CONTINUE</strong>) 异常处理程序 返回指向 <strong>异常源的后一条指令</strong> 的指针，因此将会从下一条指令开始，最大特点就是不会影响程序执行的连贯性。比如 INTO 溢出异常，不过这里的下一条指的是逻辑上的下一条，他不一定和异常源相邻。比如执行 JMP 指令，返回的是指向 JMP 目的地的指针。</li>
<li><code>Abort</code>: (<strong>EXIT</strong>) 会影响程序的执行的连贯性，具体来说就是 异常处理程序 不能保证可靠的返回，旨在发生abort异常时收集有关处理器状态的诊断信息，然后尽可能优雅地关闭应用程序和系统。</li>
<li><code>Interrupt</code>: 中断严格支持程序的正确返回，不会影响可靠性与程序执行的连贯性，除非是掉电或者是硬件错误。中断虽然不可预知，但是 CPU 有完善的应对策略：首先，CPU 在每个指令周期都会检查是否有中断，一般是在最后阶段。第二，在开始执行 中断处理程序 之前，一定会保存当时指令执行的现场以便恢复执行，比如 I/O 操作，恢复时执行的指令就是中断前执行的最后一条指令的下一条</li>
</ol>
<h2 id="IDT"><a href="#IDT" class="headerlink" title="IDT"></a>IDT</h2><h3 id="Interrupt-Descriptor-Table"><a href="#Interrupt-Descriptor-Table" class="headerlink" title="Interrupt Descriptor Table"></a>Interrupt Descriptor Table</h3><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241219181455217.png" alt="image-20241219181455217"></p>
<p>中断描述符表是一张用于存储<strong>中断处理程序入口</strong>的表格，每个表项（Entry）是一个中断描述符（Gate Descriptor），用于指明当某个中断或异常发生时，中断/异常处理程序 的入口地址、权限等信息。为了帮助处理异常和中断，需要处理器进行特殊处理的每个体系结构定义的异常和每个中断条件都被分配了一个唯一的标识号，称为中断向量号。处理器使用分配给异常或中断的向量号作为中断描述符表 (IDT) 的索引。该表提供了异常或中断 中断/异常处理程序 的入口点。中断表的索引范围是 0 到 255。</p>
<ul>
<li><p><code>0</code> 到 <code>31</code> 范围内的向量编号由 Intel 64 和 IA-32 体系结构保留，用于体系结构定义的异常和中断。并非所有中断都有相应的处理函数。该范围内未分配的向量编号被保留，不能使用。 </p>
</li>
<li><p><code>32</code> 到 <code>255</code> 范围内的向量编号被指定为用户定义的中断，并且不被 Intel 64 和 IA-32 体系结构保留，这些中断通常分配给外部 I/O 设备，以使这些设备能够通过外部硬件中断机制之一向处理器发送中断。</p>
</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th><strong>Trap Table</strong></th>
<th><strong>IDT</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>适用范围</strong></td>
<td>较简单的操作系统或教学架构中使用</td>
<td>主要用于 x86 架构的保护模式</td>
</tr>
<tr>
<td><strong>数据结构</strong></td>
<td>简单的映射表</td>
<td>复杂的描述符表，包含地址和其他元信息</td>
</tr>
<tr>
<td><strong>功能</strong></td>
<td>仅存储中断处理程序地址</td>
<td>支持权限管理、段选择、复杂异常和硬件中断处理</td>
</tr>
<tr>
<td><strong>实现机制</strong></td>
<td>直接使用固定大小的数组存储入口地址</td>
<td>通过描述符表实现，包含段选择子和偏移地址的组合</td>
</tr>
</tbody></table>
<p><strong>CPU 上电后（Real Mode阶段）：</strong> </p>
<ul>
<li>在实模式下，CPU 使用一个简单的中断向量表（Interrupt Vector Table, IVT），这是一个固定位置的内存表，系统刚引导时，内存0x00000到0x0003FF共1KB的空间用于存放中断向量表。每个中断向量占用4个字节，共可存储 256 个中断向量，中断向量表中存储的是异常处理程序的起始地址。</li>
<li>这个 IVT 是 16 位架构的中断处理机制，和 IDT 不同。</li>
</ul>
<p><strong>进入保护模式（Protected Mode）时：</strong> </p>
<ul>
<li>当系统进入保护模式后，操作系统需要配置自己的 IDT，因为保护模式支持更复杂的中断和异常处理。</li>
<li>操作系统初始化过程中会：<ol>
<li>分配一块内存用于存储 IDT。</li>
<li>填充 IDT 条目（包括中断号、处理程序地址、权限等）。</li>
<li>使用 <code>lidt</code> 指令加载 IDT 的基址和限制到 CPU 的 IDTR 寄存器。</li>
</ol>
</li>
</ul>
<p><strong>进入长模式（Long Mode）时：</strong></p>
<ul>
<li>在 64 位模式（长模式）下，IDT 同样需要重新设置，因为长模式支持更复杂的地址模式和更大的描述符。</li>
<li>通常操作系统会重新配置或直接复用保护模式下的 IDT。</li>
</ul>
<p>不过，本质都是中断向量表，本质存储的都是Handler入口</p>
<h3 id="Workflow"><a href="#Workflow" class="headerlink" title="Workflow"></a>Workflow</h3><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241219204336594.png" alt="image-20241219204336594"></p>
<ol>
<li><p><strong>中断或异常发生</strong>：</p>
<ul>
<li>CPU 收到一个中断或异常信号。</li>
<li>信号对应一个中断号（Interrupt Vector），范围是 <code>0-255</code>。</li>
</ul>
</li>
<li><p><strong>查找 IDT</strong>（interrupt Descriptor Table）</p>
<ul>
<li>CPU 从 <strong>IDTR 寄存器</strong> 中读取 IDT 的基地址（起始地址）。</li>
</ul>
</li>
</ol>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220095504456.png" alt="image-20241220095504456"></p>
<ol start="3">
<li><p><strong>跳转到处理程序</strong>：</p>
<ul>
<li><p>根据中断向量在 IDT 中找到对应的 Descriptor (比如中断门和陷阱门)</p>
</li>
<li><p>Descriptor 中存储了 段选择器（Selector）和偏移量用来定位 中断/异常处理程序 的位置、特权级、类型（中断门、陷阱门、任务门等）</p>
</li>
<li><p>CPU 跳转到 中断/异常处理程序 并开始执行中断或异常的处理。</p>
</li>
</ul>
</li>
</ol>
<h3 id="Gate-Descriptors"><a href="#Gate-Descriptors" class="headerlink" title="Gate Descriptors"></a>Gate Descriptors</h3><h4 id="Interrupt-Trap-Gate"><a href="#Interrupt-Trap-Gate" class="headerlink" title="Interrupt/Trap Gate"></a>Interrupt/Trap Gate</h4><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241219204408842.png" alt="image-20241219204408842"></p>
<table>
<thead>
<tr>
<th>特性</th>
<th>中断门(Interrupt Gate)</th>
<th>陷阱门(Trap Gate)</th>
<th align="left">任务门(Task Gate)</th>
</tr>
</thead>
<tbody><tr>
<td>触发来源</td>
<td>硬件中断/软件中断</td>
<td>异常/软件触发</td>
<td align="left">任务切换</td>
</tr>
<tr>
<td>IF 标志位</td>
<td><code>IF</code> 自动清零（关中断）</td>
<td><code>IF</code> 不变（不屏蔽中断）</td>
<td align="left">与任务无关</td>
</tr>
<tr>
<td>跳转目标</td>
<td>中断服务例程</td>
<td>异常或调试服务例程</td>
<td align="left">任务状态段（TSS）</td>
</tr>
<tr>
<td>返回方式</td>
<td><code>IRET</code> 指令</td>
<td><code>IRET</code> 指令</td>
<td align="left">任务切换完成后返回</td>
</tr>
<tr>
<td>典型用途</td>
<td>硬件中断处理</td>
<td>调试、异常处理</td>
<td align="left">多任务</td>
</tr>
</tbody></table>
<h4 id="Call-Gate"><a href="#Call-Gate" class="headerlink" title="Call Gate"></a>Call Gate</h4><p><strong>调用门</strong>(Call Gate)：调用门可以通过 <code>CALL</code> <code>JMP</code> 调用，从一个低特权级代码段跳转到另外一个高特权级的代码段，存在 GDT 和 LDT 中，但从未被实际使用过。对于系统调用的实现来说，这是不方便的并且不是最佳实现。大多数操作系统使用<strong>陷阱门</strong>（Linux 中的 <code>INT 0x80</code> 和 Windows 中的 <code>INT 0x2E</code>）或更强大的 <code>SYSENTER/SYSEXIT</code> 指令来代替调用门</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">; CALL 指令与 JMP 指令示例</span><br><span class="line">section .text</span><br><span class="line">global _start</span><br><span class="line"></span><br><span class="line">_start:</span><br><span class="line">    call 0x10:0x0000      ; 调用子程序 需要返回(my_function)</span><br><span class="line">    jmp  0x18:0x0000      ; 无条件跳转 不需要返回(end_program)</span><br><span class="line"></span><br><span class="line">0x10:0x0000:</span><br><span class="line">    ; 子程序代码</span><br><span class="line">    ret                   ; 返回主程序</span><br><span class="line"></span><br><span class="line">0x18:0x0000:</span><br><span class="line">    ; 程序结束</span><br><span class="line">    mov eax, 1            ; 系统调用号（exit）</span><br><span class="line">    xor ebx, ebx          ; 返回值（0）</span><br><span class="line">    int 0x80              ; TRAP into kernel</span><br></pre></td></tr></table></figure>

<h4 id="Task-Gate"><a href="#Task-Gate" class="headerlink" title="Task Gate"></a>Task Gate</h4><p>详见下文的硬件任务切换</p>
<h2 id="HW-Task-Switch"><a href="#HW-Task-Switch" class="headerlink" title="HW Task Switch"></a>HW Task Switch</h2><h3 id="Task-Gate-1"><a href="#Task-Gate-1" class="headerlink" title="Task Gate"></a>Task Gate</h3><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220170638814-1734685697132-27.png" alt="image-20241220170638814"></p>
<p>在中断处理过程(IDT)或者在GDT LDT里索引到任务门，会开启硬件任务切换，影响着。</p>
<p><strong>任务门</strong>(Task Gate)：为多任务处理提供<strong>硬件</strong>支持，跳转到 TSS，目前不被使用。</p>
<p><strong>任务状态段</strong>(TSS, Task Status Segment): 保存了任务的执行上下文环境</p>
<h3 id="Task-Status-Segment"><a href="#Task-Status-Segment" class="headerlink" title="Task Status Segment"></a>Task Status Segment</h3><p><strong>TSS Descriptor 的结构，位于 GDT 中：</strong></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220094926788-1734660034533-1.png" alt="image-20241220094926788"></p>
<p>一般 TSS 的 DPL 是小于3的，因为只有操作系统内核才有权调度任务</p>
<hr>
<p><strong>IA-32 TSS 内部的结构</strong>：</p>
<ul>
<li><p>I/O map的基地址， bitmap 本体通常映射到 TSS，通过 bitmap 限制进程对 IO 端口的访问</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220180936358.png" alt="image-20241220180936358"></p>
</li>
<li><p>本进程对应的 LDT Selector</p>
</li>
<li><p>所有的x86普通寄存器：6 个段，8个通用，1 个指令指针，1 个程序状态字</p>
</li>
<li><p>CR3 页表地址</p>
</li>
<li><p>其他特权级别的栈段和栈指针 SS2<del>0 ESP2</del>0 (内核栈)</p>
</li>
<li><p>用于嵌套任务的 link，也就是上一个 父任务的 TSS Selector</p>
</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220001641685.png" alt="image-20241220001641685"></p>
<p><strong>TSS 寻址：</strong></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220001517922-1734684881103-23.png" alt="image-20241220001517922"></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220094649039.png" alt="image-20241220094649039"></p>
<hr>
<h3 id="Workflow-1"><a href="#Workflow-1" class="headerlink" title="Workflow"></a>Workflow</h3><p>处理器能够<strong>自动</strong>保存执行上下文，响应来自硬件或软件的请求，恢复另一任务的上下文：</p>
<ol>
<li>显式切换：<code>CALL/JMP tss_selector</code> <code>CALL/JMP task_gate_selector</code></li>
<li>隐式切换：中断/错误处理程序触发</li>
<li>可以通过控制特定的中断向量陷入 IDT 中的特定 Task Gate 来完成跳转，比如<code>INT n</code></li>
<li>嵌套任务的 <code>IRET</code>，EFLAGS 的 <code>NT</code> 标志位(Nested Tasks) 置位用于嵌套任务的跳转。</li>
</ol>
<p>下面为通过 IDT 的 Task Gate 进行任务切换的例子：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220100119251.png" alt="image-20241220100119251"></p>
<ul>
<li><p>TR 寄存器结构如下：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220001552753-1734684981103-25.png" alt="image-20241220001552753"></p>
</li>
<li><p>当 依赖 TSS 进行任务切换的时候，CPU 做了以下几件事情：</p>
</li>
</ul>
<ol>
<li><strong>保存现场</strong>：当前 TSS 中所有寄存器值填写到当前的 <strong>TR</strong> 寄存器（task register）指向的 TSS 中</li>
<li><strong>加载新现场</strong>：把新 TSS Selector 载入 <strong>TR</strong> ，<strong>按照一定的检验流程</strong>把新的 TSS 覆盖到寄存器。</li>
<li><strong>开始执行新代码</strong>：新设置的 EIP 指向将要执行的新代码</li>
</ol>
<ul>
<li><strong>缺点</strong>： 受硬件限制较大，且流程繁杂，不灵活也不便于调试</li>
</ul>
<ol>
<li>TSS 只能存在 GDT （最大长度只有 8,192）(TSS+LDT)*2+12=8192,最多 4090 个进程    </li>
<li>算上检验流程要消耗 200 多个时钟周期，全部串行，中间出现一个差错就无法切换成功。</li>
<li>硬件的切换过于重量级，保存完整的上下文，实际上任务切换不一定需要那么多寄存器</li>
</ol>
<p>ex. <strong>嵌套任务切换</strong></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220172753514.png" alt="image-20241220172753514"></p>
<h3 id="SW-Task-Switch"><a href="#SW-Task-Switch" class="headerlink" title="SW Task Switch"></a>SW Task Switch</h3><p><strong>操作系统</strong> 将关键的上下文内容存到类似 PCB 等自由可控的轻量环境中，可以完全控制任务切换逻辑，能够支持指令流水的并行优化技术，更加适合复杂的多任务调度算法，提升性能。</p>
<p>Linux 2.4之前的内核有进程最大数的限制，受限制的原因是，每一个进程都有自已的 TSS 和 LDT。Linux 2.4以后，在同一个CPU上的进程使用同一个 TSS，有效内容只剩下 <code>ESP0</code> 和<code>IO MAP Address</code> </p>
<ul>
<li><code>ESP0</code>: 内核堆栈指针，因为linux完全使用分页，所以SS段没有用处</li>
<li><code>IO bitmap</code>: 控制进程的 I/O 许可</li>
</ul>
<h2 id="Stack-Usage-by-Handler"><a href="#Stack-Usage-by-Handler" class="headerlink" title="Stack Usage by Handler"></a>Stack Usage by Handler</h2><p><strong>有特权级别的转换</strong>（为防止恶意程序,一般会切换，比如系统调用、异常 陷入 OS 的内核模式）:</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220162644295.png" alt="image-20241220162644295"></p>
<p>因为有特权级别切换，因此要根据 TSS 里的内核栈段 SS0 和 ESP0 切换到处理程序自己的栈上，保存好被中断程序原先的 SS 和 ESP，将他的 CS, EIP, EFLAGS 也搬过去，最后将错误码压栈。</p>
<hr>
<p>如果没有特权级别转换，就不会切换执行堆栈，内核中发生了中断或者异常：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220165159628.png" alt="image-20241220165159628"></p>
<h2 id="Concurrency"><a href="#Concurrency" class="headerlink" title="Concurrency"></a>Concurrency</h2><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241219194949413.png" alt="image-20241219194949413"><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241219204058993.png" alt="image-20241219204058993"></p>
<h3 id="INTR"><a href="#INTR" class="headerlink" title="INTR"></a>INTR</h3><p>从 0 到 32 的任何向量的中断都可以通过 INTR 引脚传递到处理器，并且从 16 到 32 的任何向量都可以通过本地 APIC 传递。当通过 INTR 引脚模拟异常向量中断(比如 Page Fault)，处理器不会将错误码压栈，因此异常处理程序可能无法正确运行。（和 <code>INT n</code> 的问题一样） </p>
<h4 id="EFLAGS-PSW"><a href="#EFLAGS-PSW" class="headerlink" title="EFLAGS(PSW)"></a>EFLAGS(PSW)</h4><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220002704824.png" alt="image-20241220002704824"></p>
<h4 id="Masking-maskable-interrupts"><a href="#Masking-maskable-interrupts" class="headerlink" title="Masking maskable interrupts"></a>Masking maskable interrupts</h4><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/2f761a5d7cb13f08919db2447c92f0aa.png" alt="在这里插入图片描述"></p>
<ol>
<li><code>STI</code><del>SET</del>, <code>CLI</code><del>CLEAR</del>这两个特权指令可以改变 <code>IF</code> 标志位（位于程序状态字 PSW, aka EFLAGS）控制 CPU 是否能够响应外部中断请求，是多重中断的基本条件，<code>IRET</code>也可以改变</li>
<li><strong>关中断</strong>：将 <code>IF</code> 中断标志位置零，用于保护现场、恢复现场和跳转到 ISR。</li>
<li>在执行 ISR 之前可以<strong>开中断</strong>，执行 ISR 的过程可以被其他中断打断，如果使用中断屏蔽技术(MASK)，就可以实现多重中断，高优先级有权打断低优先级，反之则不行。</li>
<li><strong>中断屏蔽技术</strong>：每个中断可以设置其他中断源的 <code>mask</code> ，被设置为0则被停止执行</li>
</ol>
<h1 id="OS-Booting"><a href="#OS-Booting" class="headerlink" title="OS Booting"></a>OS Booting</h1><p>一些早期的计算机系统，在接收到来自操作人员或外围设备的启动信号后，可以将极少量的固定指令加载到存储器的特定位置，初始化至少一个CPU，然后将CPU指向这些指令并执行指令这些指令通常从一些外围设备（可以由操作员通过开关选择）启动输入操作。其他系统可能会直接向外围设备或 I/O 控制器发送硬件命令，从而执行极其简单的输入操作（例如“将系统设备的扇区 0 读取到从位置 1000 开始的内存中”），从而有效地加载一个小文件。然后开始==链式引导系统启动==。</p>
<p>对于现代操作系统，当计算机关闭时，其软件（包括操作系统、应用程序代码和数据）仍存储在非易失性存储器中。当计算机开机时，它的 RAM 中通常没有操作系统或其加载程序。计算机首先执行存储在 ROM（后来的EEPROM，NOR Flash）中的相对较小的程序（也就是 ==BIOS== 与 ==UEFI==）。该程序支持就地执行，初始化 CPU 和主板，初始化 DRAM（特别是在x86系统上），访问非易失性存储器设备（通常是块寻址设备，例如 NAND Flash、SSD、HDD）或其他可以将操作系统程序和数据加载到 RAM 中的设备（U盘、CD-ROM、甚至是网络设备）此外，该程序还可以初始化显示设备（例如GPU）、文本输入设备（例如键盘）和指针输入设备（例如鼠标）加载到 RAM 中的第一个程序可能不足以加载操作系统，而必须加载另一个更大的程序，它加载的程序称为第二阶段引导加载程序（狭义上的 ==Bootloader==）</p>
<h2 id="BIOS"><a href="#BIOS" class="headerlink" title="BIOS"></a>BIOS</h2><p><strong>B</strong>asic <strong>I</strong>nput/<strong>O</strong>utput <strong>S</strong>ystem，基本输入输出系统，主要负责硬件层面的初始化和基本 I/O 管理，目标是找到设备上的 Bootloader，从Bootloader启动操作系统。</p>
<p>早年，BIOS 存储于<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/ROM">ROM</a>芯片上；现在的 BIOS 多存储于<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%BF%AB%E9%96%83%E8%A8%98%E6%86%B6%E9%AB%94">闪存</a>芯片上，这方便了 BIOS 的更新。BIOS 也可从<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%B6%B2%E5%8D%A1">网卡</a>等设备启动。</p>
<p>当电脑通电，BIOS 就会从存储器上加载，执行<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%8A%A0%E9%9B%BB%E8%87%AA%E6%AA%A2">加电自检</a>（POST），测试和初始化 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/CPU">CPU</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%9A%8F%E6%9C%BA%E5%AD%98%E5%8F%96%E5%AD%98%E5%82%A8%E5%99%A8">RAM</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%9B%B4%E6%8E%A5%E8%A8%98%E6%86%B6%E9%AB%94%E5%AD%98%E5%8F%96">DMA</a>控制器、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%99%B6%E7%89%87%E7%B5%84">芯片组</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%8D%B5%E7%9B%A4">键盘</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%BB%9F%E7%A2%9F">软盘</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%A1%AC%E7%A2%9F">硬盘</a>等设备。</p>
<p>所有的 Option ROM（扩展 BIOS 程序）被加载后，BIOS 就试图从启动设备（如<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%A1%AC%E7%A2%9F">硬盘</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%BB%9F%E7%A2%9F">软盘</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%85%89%E7%A2%9F">光盘</a>）加载 Bootloader，由 Bootloader 加载<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%BD%9C%E6%A5%AD%E7%B3%BB%E7%B5%B1">操作系统</a>。BIOS 以 16 位<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%9C%9F%E5%AF%A6%E6%A8%A1%E5%BC%8F">实模式</a>执行。现代操作系统以<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%BF%9D%E8%AD%B7%E6%A8%A1%E5%BC%8F">保护模式</a>或<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%95%BF%E6%A8%A1%E5%BC%8F">长模式</a>执行。</p>
<h3 id="BIOS-Filmware"><a href="#BIOS-Filmware" class="headerlink" title="BIOS Filmware"></a>BIOS Filmware</h3><p>BIOS 本身是汇编语言代码，是在 16 位实模式下执行的，由于 x86-64 是一个高度兼容的<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=100152930&content_type=Article&match_order=1&q=%E6%8C%87%E4%BB%A4%E9%9B%86&zhida_source=entity">指令集</a>，也为了迁就 BIOS 的 16 位实模式的运行环境，所以即使现在的 CPU 都已是 64 位，如果还是在 BIOS 启动（基本见于 09 年以前的主板），在开机时仍然都是在 16 位实模式下执行的。16 位实模式直接能访问的内存只有 1 MB，就算你安了 4G、8G 或者 16 G 还是 32 G 内存，到了 BIOS 上一律只先认前 1 MB。在这 1 M内存中，前 640 K 称为基本内存，后面 384 K 内存留给开机必要硬件和各类 BIOS 本身使用。</p>
<h3 id="BIOS-Setup"><a href="#BIOS-Setup" class="headerlink" title="BIOS Setup"></a>BIOS Setup</h3><p>大约从<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/80386">80386</a> PC开始，个人电脑的 BIOS ROM 集成了设置程序（Setup）。主板的 CMOS 芯片用于存储 BIOS 设置值及硬件侦测值。</p>
<p>现代的 BIOS 可以让用户选择由哪个启动设备启动电脑，如<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%85%89%E7%A2%9F%E6%A9%9F">光盘驱动器</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%A1%AC%E7%A2%9F">硬盘</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%BB%9F%E7%A2%9F">软盘</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%9A%A8%E8%BA%AB%E7%A2%9F">U盘</a>等等。现代大多数 BIOS 支持图形化交互界面，有一些是厂商制作的，用户可以用鼠标键盘完成操作。</p>
<h4 id="CMOS"><a href="#CMOS" class="headerlink" title="CMOS"></a>CMOS</h4><p>CMOS 是计算机上另一个重要的存储器。之所以提到它，是因为 BIOS 程序的设置值、硬件参数侦测值就保存在 CMOS 中。而且，在 BIOS 程序启动计算机时，需要加载 CMOS 中的设置值。CMOS 通常被集成在南桥芯片组中。UEFI 系统则多用 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/NVRAM">NVRAM</a> 存储设置。</p>
<ul>
<li>BIOS 芯片属于 ROM ，不需要供电保存信息，其中存储的是固件（filmware，程序代码）</li>
<li>CMOS 芯片属于 RAM，内容在断电会消失，存储的是普通信息。主板上的钮扣电池用于让 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/CMOS">CMOS </a>存储 BIOS 设置值，以及电脑在断电时依然可以让系统时钟运作。把<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%B8%BB%E6%A9%9F%E6%9D%BF">主板</a>的电池拆出，便可重置其内容，拆出电池也会重置系统时钟。</li>
</ul>
<h3 id="Pre-booting"><a href="#Pre-booting" class="headerlink" title="Pre-booting"></a>Pre-booting</h3><h4 id="POST"><a href="#POST" class="headerlink" title="POST"></a>POST</h4><p>先进行 CPU 初始化：当按下电源开关时，电源就开始向主板和其他设备供电，这时电压还不稳定，在早期的南北桥主板上，由主板北桥向CPU发复位信号，对CPU初始化；稳定电压后复位信号便撤掉。而对于现在的单南桥主板，则由CPU自身调整稳定电压达到初始化的目的，当电压稳定后，CPU 便在系统BIOS保留的内存地址处执行跳转 BIOS 起始处指令，开始执行 POST 自检。</p>
<p><strong>加电自检</strong>(POST, Power-On Self Test)是计算机 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/BIOS">BIOS</a> 的一个重要功能，主要用于在 BIOS 加载操作系统之前检查计算机设备硬件是否存在问题，进而保证计算机的正常运行。在设备启动的过程中，自检程序主要检查<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/CPU">CPU</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%9A%8F%E6%9C%BA%E5%AD%98%E5%82%A8%E5%99%A8">内存</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/I/O">I/O设备</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%B8%BB%E6%9D%BF">主板</a>等对计算机正常运行会产生影响的设备硬件。</p>
<p>在POST自检中，BIOS 只检查系统的必要核心硬件是否有问题，主要是 CPU、640K基本内存、显卡是否正常，PS/2 键盘控制器、系统时钟是否有错误等等。由于 POST 检查在显卡初始化以前，因此在这个阶段如发生错误，是无法在屏幕上显示的，不过主板上还有个报警扬声器，而且如果主板的 8255 外围可编程接口芯片没有损坏的话，POST报警声音一定是会出来的。可以根据报警声的不同大致判断错误所在，一般情况下，一声短“嘀”声基本代表正常启动，不同的错误则是不同的短“嘀”声和长“嘀”声组合。POST 自检结束后，BIOS 开始调用中断完成各种硬件初始化工作。</p>
<h4 id="BIOS-Interrupt-Call"><a href="#BIOS-Interrupt-Call" class="headerlink" title="BIOS Interrupt Call"></a>BIOS Interrupt Call</h4><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241220173802326.png" alt="image-20241220173802326"></p>
<p>与中断相对的是轮询（polling）<a target="_blank" rel="noopener" href="https://www.cnblogs.com/jadeshu/p/10663505.html">中断向量表 - jadeshu - 博客园</a> </p>
<p><strong>CPU 上电后（实模式阶段）：</strong> </p>
<ul>
<li>在实模式下，CPU 使用一个简单的中断向量表（Interrupt Vector Table, IVT），这是一个固定位置的内存表，系统刚引导时，内存0x00000到0x0003FF共1KB的空间用于存放中断向量表。每个中断向量占用4个字节，共可存储256个中断向量，中断向量表中存储的是异常处理程序的起始地址。这个 IVT 是 16 位架构的中断处理机制，和 IDT 不同。</li>
</ul>
<p><strong>进入保护模式（Protected Mode）或长模式（Long Mode）时：</strong> </p>
<ul>
<li>当系统进入保护模式后，操作系统需要配置自己的 IDT，因为保护模式支持更复杂的中断和异常处理。</li>
<li>操作系统初始化过程中会：<ol>
<li>分配一块内存用于存储 IDT。</li>
<li>填充 IDT 条目（包括中断号、处理程序地址、权限等）。</li>
<li>使用 <code>lidt</code> 指令加载 IDT 的基址和限制到 CPU。</li>
</ol>
</li>
</ul>
<p>BIOS 可通过 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/BIOS%E4%B8%AD%E6%96%B7%E5%91%BC%E5%8F%AB">BIOS 中断调用</a>为 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/MS-DOS">MS-DOS</a> 操作系统及 MS-DOS 程序提供磁盘、键盘、显示等标准服务。通过 BIOS 中断调用访问视频硬件非常缓慢。许多现代操作系统（如<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/Windows">Windows</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/Linux">Linux</a>）的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%95%9F%E5%8B%95%E7%A8%8B%E5%BC%8F">启动程序</a>(Bootloader)会使用 BIOS 中断调用加载内核，然后由<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%86%85%E6%A0%B8">内核</a>将处理器从16位<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%9C%9F%E5%AF%A6%E6%A8%A1%E5%BC%8F">实模式</a>转换到32位<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%BF%9D%E8%AD%B7%E6%A8%A1%E5%BC%8F">保护模式</a>（或64位<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%95%BF%E6%A8%A1%E5%BC%8F">长模式</a>）</p>
<p>在INTEL后续的32位CPU中，使用中断描述符表 IDT 来代替中断向量表 IVT。中断描述符表的起始地址由中断描述符表寄存器（IDTR）来定位，因此不再限于底部1K位置。另一方面，中断描述符表的每一个项目——称作门描述符——除了含有中断处理程序地址信息外，还包括许多属性／类型位。门描述符分为三类：任务门、中断门和自陷门。CPU对不同的门有不同的调用（处理）方式。</p>
<h4 id="HW-Initialization"><a href="#HW-Initialization" class="headerlink" title="HW Initialization"></a>HW Initialization</h4><p>硬件初始化工作是通过 BIOS 中断调用实现的，经过POST检测后，电脑终于出现了开机启动画面，这就是已经检测到了显卡并完成了初始化。但是请注意，由于BIOS是在16位实模式运行，因此该画面是以VGA分辨率（640*480，纵横比 4:3）显示的，因为实模式最高支持的就是 VGA。以前的小 14-17 寸CRT显示器由于都是 4:3 比例，最高分辨率也比较低，因此这个开机启动画面没有什么违和感，但现在的液晶显示器基本上都是宽屏 16:9 的，分辨率也较高，因此在这样的显示屏下，启动画面上的一切东西显示都可以说“惨不忍睹”——图形被拉长，字体很大很模糊，可以很明显看到显示字体的锯齿。</p>
<h3 id="Bootloader-Location"><a href="#Bootloader-Location" class="headerlink" title="Bootloader Location"></a>Bootloader Location</h3><p>引导启动的过程也是使用 BIOS 中断调用，因为 BIOS 处在实模式，Bootloader 才能切换模式</p>
<p>BIOS 根据 Setup 中用户指定的硬件启动顺序，如果将启动顺序设为“第一：DVD 驱动器；第二：硬盘驱动器”，固件会先尝试从 DVD 驱动器启动，再尝试从本地的硬盘驱动器启动。BIOS 负责硬件和软件间的相互通信。如果发现所有硬件都没有能引导操作系统的记录，则会在屏幕上显示相应错误信息（NO ROM BASIC）将电脑维持在 16 位实模式。BIOS 只识别到由主引导记录（MBR）初始化的硬盘。</p>
<h4 id="MBR"><a href="#MBR" class="headerlink" title="MBR"></a>MBR</h4><p>主引导扇区，Master Boot Record，BIOS 检查时会把硬盘最初一个扇区(MBR)加载到内存中。</p>
<p>它在硬盘上的三维地址(CHS 地址)为（柱面，磁头，扇区）＝（0，0，1）</p>
<p>MBR 位于磁盘的第一个扇区（LBA 0），其大小为 <strong>512 字节</strong>，划分如下：</p>
<ul>
<li><strong>前 446 字节</strong>: 引导代码（Bootloader Code）</li>
<li><strong>接下来的 64 字节</strong>: 分区表（DPT, Disk Partition Table），记录最多 4 个主分区的信息</li>
<li><strong>最后的 2 字节</strong>: 魔数（Signature, 0x55AA），表示这是一个有效的 MBR。</li>
</ul>
<p>BIOS 硬件检查方式：这个存储设备的前 512 字节是不是以0x55 0xAA(10101010,01010101)结尾？如果不是就按照顺序检查下一个，如果是就加载这 512 字节内部的引导代码，然后执行它。</p>
<p>MBR 最开头是第一阶段引导代码。主要作用是在检查分区表是否正确和在系统硬件完成自检以后，在活跃分区的 PBR 找到并执行 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%BC%95%E5%AF%BC%E7%A8%8B%E5%BA%8F">Bootloader</a> 主程序（如 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/GNU_GRUB">GNU GRUB</a>），不依赖任何操作系统，而且启动代码也是可以改变的，从而能够实现<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/w/index.php?title=%E5%A4%9A%E7%B3%BB%E7%BB%9F%E5%BC%95%E5%AF%BC&action=edit&redlink=1">多系统引导</a>  </p>
<p>MBR 还记录着硬盘本身的相关信息以及硬盘各个分区的大小及位置信息（分区表），是数据信息的重要入口。如果它受到破坏，硬盘上的基本数据结构信息将会丢失，需要用繁琐的方式试探性的重建数据结构信息后才可能重新访问原先的数据。因为 512B 的限制，分区表也有限制，MBR 支持最大卷为2 TB（<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/Terabyte">Terabyte</a>s）并且每个磁盘最多有4个主分区（或3个主分区，1个扩展分区和无限制的逻辑驱动器）</p>
<h4 id="Sector-amp-LBA"><a href="#Sector-amp-LBA" class="headerlink" title="Sector &amp; LBA"></a>Sector &amp; LBA</h4><p>在 GPT 分区中，每一个数据读写单元成为 LBA（逻辑块地址），一个“逻辑块”相当于传统 MBR 分区中的一个“扇区”，之所以会有区别，是因为GPT除了要支持传统硬盘，还需要支持以 NAND FLASH 为材料的 SSD 硬盘。</p>
<p>不像磁盘那样有磁片，而磁片又划分磁道和扇区来保存数据，因此，闪存材料需要采用模拟扇区来保持统一性。这些硬盘的一个读写单元是 2KB 或 4KB，所以，GPT 分区中干脆用 LBA 来表示一个基础读写块，当 GPT 分区用在传统硬盘上时，通常，LBA 就等于扇区号，有些物理硬盘支持 2KB 或 4KB 对齐，此时，LBA 所表示的一个逻辑块就是 2KB的空间，为了方便，我们后面仍然将逻辑块称为扇区。</p>
<p>以 CHS 寻址的硬盘， 最高容量是 512×63×256×1024=8064 MiB，BIOS 使用的是 LBA 寻址</p>
<h2 id="UEFI"><a href="#UEFI" class="headerlink" title="UEFI"></a>UEFI</h2><p>作为 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/BIOS">BIOS </a>的替代方案，可扩展固件接口 UEFI 负责 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%8A%A0%E9%9B%BB%E8%87%AA%E6%AA%A2">加电自检</a>（POST）、联系操作系统以及提供连接操作系统与硬件的接口。前身是 EFI</p>
<h3 id="EFI"><a href="#EFI" class="headerlink" title="EFI"></a>EFI</h3><p>虽然 BIOS 作为电脑加电启动所必不可少的部分，但是从其于 1975 年诞生之日起近 30 余年，16 位汇编语言代码，1 M 内存寻址，调用中断一条条执行的理念和方式竟然一点都没有改变，虽然经各大主板商不懈努力，BIOS 也有了 ACPI、USB 设备支持，PnP 即插即用支持等新东西，但是这在根本上没有改变 BIOS 的本质，而英特尔为了迁就这些旧技术，不得不在一代又一代处理器中保留着 16 位实模式，否则根本无法开机。英特尔推出了可扩展固件接口(EFI, Extensible Filmware Interface) 和后继的 UEFI(Unified EFI) ，是现在电脑的主要预启动环境。</p>
<h4 id="Features"><a href="#Features" class="headerlink" title="Features"></a>Features</h4><ol>
<li>摒弃 16 位实模式，完全是 32 位或 64 位模式，在 EFI 中可以实现处理器的最大寻址，因此可以在任何内存地址存放任何信息</li>
<li>模块化，C 语言风格的参数堆栈传递方式，动态链接的形式构建的系统，通用性和兼容性较好，在 EFI 驱动环境(DXE)中解释执行 EFI 字节码（虚拟机器指令）写成的 EFI 驱动，识别系统硬件并完成硬件初始化。EFI 的驱动开发非常简单，基于 EFI 的驱动模型原则上可以使 EFI 接触到所有硬件功能</li>
<li>和 OS 相比，EFI 没有中断访问机制，只能轮询</li>
<li>只有简单的存储器管理机制，在段保护模式下只将存储器分段，所有程序都可以存取任何一段位置，不提供真实的保护服务。</li>
<li>支持 GPT 分区模式</li>
<li>区分不同的开机模式，向前兼容模式(Legacy) 可以启动 16 和 32 位的操作系统，采用64位UEFI固件的PC，在UEFI 开机模式下只能执行64位操作系统启动程序</li>
</ol>
<h4 id="GPT"><a href="#GPT" class="headerlink" title="GPT"></a>GPT</h4><p><strong>全局唯一标识分区表</strong> GUID Partition Table，使用通用唯一标识符(也称为全局唯一标识符(GUID))对物理计算机存储设备(例如硬盘驱动器或固态驱动器)的分区表进行布局</p>
<p>在MBR硬盘中，分区信息直接存储于主引导扇区中（其中还存储着引导 Bootloader 的引导代码）但在GPT硬盘中，分区表的位置信息储存在GPT头中。出于兼容性考虑，硬盘的第一个扇区仍然用作 MBR，之后才是 GPT 头。为了减少分区表损坏的风险，GPT在硬盘最后保存了一份分区表的副本。其中的 EFI 系统分区可以被 EFI 存取，用来存取部分驱动和应用程序。</p>
<img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/1024px-GUID_Partition_Table_Scheme.svg.png" alt="undefined" style="zoom: 33%;" />

<p>GPT分区表的结构。此例中，每个逻辑块（LBA）为512字节，每个分区的记录为128字节。负数的LBA地址表示从最后的块开始倒数，−1表示最后一个块。</p>
<p><strong>保护性 MBR（Protective MBR）</strong></p>
<ul>
<li><strong>位置</strong>: 分区表的第一个扇区（LBA 0）。</li>
<li><strong>作用</strong>: 这是兼容性区域，用于保护 GPT 磁盘免受旧式 MBR 工具的意外覆盖。保护性 MBR 声明整个磁盘为一个分区，以阻止不支持 GPT 的软件误将磁盘视为未分区。</li>
</ul>
<p><strong>GPT 标头（GPT Header）</strong> </p>
<ul>
<li><strong>位置</strong>: 磁盘的第一个逻辑块地址（LBA 1）。</li>
<li><strong>作用</strong>: 包含 GPT 的全局信息，包括分区表的起始位置、大小和校验和。</li>
</ul>
<p><strong>分区条目表（Partition Entries）</strong></p>
<ul>
<li><strong>位置</strong>: 通常从 LBA 2 开始，连续占用一定数量的扇区。</li>
<li><strong>作用</strong>: 存储每个分区的详细信息，包括分区类型、GUID、起始和结束地址。</li>
</ul>
<p><strong>引导分区（EFI System Partition, ESP）</strong></p>
<ul>
<li><strong>位置</strong>: 通常是 GPT 分区中专门指定的一部分（由 EFI 分区条目指定）</li>
<li><strong>作用</strong>: 用于存储 Bootloader EFI 文件、操作系统引导管理器，以及其他必要的启动文件。EFI 系统分区可以位于任何地方，只要分区条目中有正确的指向即可。实际上是一个FAT32文件系统</li>
<li><strong>固定 GUID</strong>: <code>C12A-7328-F81F-11D2-BA4B-00A0-C93E-C93B</code></li>
</ul>
<p><strong>备份 GPT 数据</strong></p>
<ul>
<li><strong>位置</strong>: 通常在磁盘的最后几个逻辑块地址（倒数第一个扇区存储备份 GPT Header，倒数第二个扇区起存储备份分区条目）。</li>
<li><strong>作用</strong>: 用于恢复主 GPT 数据结构。</li>
</ul>
<h4 id="UEFI-Optimization"><a href="#UEFI-Optimization" class="headerlink" title="UEFI Optimization"></a>UEFI Optimization</h4><ol>
<li>拥有完整的图形驱动。EFI多数还是一种类DOS界面（仍然是640*480VGA分辨率），只支持PS/2键盘操作（极少数支持鼠标操作）。无论是PS/2还是USB键盘和鼠标，UEFI一律是支持的，而且UEFI在显卡也支持GOP VBIOS的时候，显示的设置界面是显卡高分辨率按640*480或1024*768显示</li>
<li>安全启动。固件验证：根据硬件签名对各硬件判断，只有符合认证的硬件驱动才会被加载</li>
</ol>
<h3 id="Pre-booting-1"><a href="#Pre-booting-1" class="headerlink" title="Pre-booting"></a>Pre-booting</h3><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/Efi_flowchart_extended.jpg" alt="undefined" style="zoom: 67%;" />

<h4 id="POST-1"><a href="#POST-1" class="headerlink" title="POST"></a>POST</h4><p>当打开电源开关时，电脑的主要部件都开始有了供电，与 BIOS 不同的是，UEFI 预加载(Pre-EFI)环境首先开始执行，负责 CPU 和内存（是全部容量）的初始化工作，这里如出现重要问题，电脑即使有报警喇叭也不会响，因为 UEFI 没有去驱动 8255 发声，不过预加载环境只检查 CPU 和内存，如果这两个主要硬件出问题，屏幕没显示可以立即确定，另外一些主板会有提供LED提示，可根据CPU或内存亮灯大致判断故障。</p>
<h4 id="HW-Initialization-1"><a href="#HW-Initialization-1" class="headerlink" title="HW Initialization"></a>HW Initialization</h4><p>CPU 和内存初始化成功后，驱动执行环境（DXE）载入，当 DXE 载入后，UEFI 就具有了逐个加载UEFI 驱动的能力，在此阶段，UEFI 会迭代搜索各个硬件的 UEFI 驱动并相继加载，加载各种总线（包括PCI、SATA、USB、ISA）及硬件的 UEFI 驱动程序，完成硬件初始化工作，这相比 BIOS 的中断速度会快的多，同样如加载显卡的 UEFI 驱动成功，电脑也会出现启动画面，硬件驱动全部加载完毕后，最后同 BIOS 一样，去寻找硬盘上的操作系统的引导启动程序。</p>
<p>UEFI 应用程序（UEFI Application）和 UEFI 驱动程序（UEFI driver）是 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%8F%AF%E7%A7%BB%E6%A4%8D%E5%8F%AF%E6%89%A7%E8%A1%8C">PE格式</a> 的<code>.efi</code>文件，可用C语言编写。</p>
<h3 id="Bootloader-Location-1"><a href="#Bootloader-Location-1" class="headerlink" title="Bootloader Location"></a>Bootloader Location</h3><p>UEFI 引导管理程序可以直接从支持的文件系统（如FAT32）中读取启动文件，而不依赖硬件中断和传统的16位服务调用，UEFI 整体就处在保护模式或者长模式下。</p>
<p>在启动操作系统的阶段，同样是根据启动记录的启动顺序，转到相应设备（GPT）引导记录，引导操作系统并进入，在 UEFI 开机模式下，Bootloader 本身也是 UEFI 应用程序，其 EFI 文件存储在 EFI 系统分区（ESP）</p>
<p>这里需要注意的是，UEFI 在检测到无任何操作系统启动设备时，会直接进入 UEFI 设置页面，而不是像 BIOS 那样黑屏显示相关信息。</p>
<p>如果启动传统 MBR 设备，则需要打开 CSM 支持。</p>
<h2 id="Legacy-MBR"><a href="#Legacy-MBR" class="headerlink" title="Legacy + MBR"></a>Legacy + MBR</h2><p><strong>MBR+Legacy</strong> 是通过引导代码指向 <strong>Bootloader</strong> 文件.</p>
<ul>
<li><p><strong>Windows</strong>: </p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/1460000020850912-1734487610917-44.png" alt="image"></p>
<ul>
<li><p>Windows 中根据 MBR 分区表指向活跃分区记录 PBR，这里启动系统用的分区和真正装系统的分区不一定在一起，Windows 的 PBR 可以识别 FAT32 和 NTFS 两种分区，找到分区根目录的 bootmgr 文件，并加载、执行 bootmgr。</p>
</li>
<li><p>bootmgr 没有 MBR 和 PBR 的大小限制，可以做更多的事，它会加载并分析BCD启动项存储，而且 bootmgr 可以跨越磁盘读取文件。所以无论我们有几个磁盘，在多少块磁盘上装了 Windows，一个电脑只需要一个 bootmgr 就行了。bootmgr 会去加载某磁盘某 NTFS 分区的 <code>\Windows\System32\WinLoad.exe</code>，然后，由 <code>WinLoad.exe</code> 启动 Windows (<code>ntoskrnl.exe</code>) 系统分区和启动分区可能不是位于同一分区。</p>
</li>
</ul>
</li>
<li><p>Linux:</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/v2-709d9b2f76d718894bcc04c706986fcf_1440w-1734485433191-9-1734487325852-39-1734487632482-49.jpg" alt="img"></p>
<ul>
<li><p>写入 0 号扇区的 446 字节是第一阶段，其作用就是用来找到和加载真正的Grub bootloader主程序，也就是位于操作系统启动分区的Grub2第二阶段的程序。而且受限于446字节的大小，这个阶段的stage1 binary是不包含文件系统功能 对应 boot.img</p>
</li>
<li><p>被加载Stage1加载后，解析/boot/grub2/grub.cfg配置文件，跟据该配置文件的定义，显示多系统的启动选择界面，或者直接加载Linux kernel和文件系统，然后就由Kernel来启动后续的过程。Grub2 Stage2的镜像对应于core.img，位置为/boot/grub2/i386-pc目录下。</p>
</li>
</ul>
</li>
</ul>
<h2 id="UEFI-GPT"><a href="#UEFI-GPT" class="headerlink" title="UEFI + GPT"></a>UEFI + GPT</h2><p>**GPT+UEFI **没有明显的引导代码指向 Bootloader EFI 文件</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/1460000020850915.png" alt="image"></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/1460000020850916-1734486587950-27.png" alt="image"></p>
<p>GPT 直接把 Bootloader 存到 EFI 分区</p>
<table>
<thead>
<tr>
<th>特性</th>
<th>MBR + Legacy</th>
<th>GPT + UEFI</th>
</tr>
</thead>
<tbody><tr>
<td>代码位置</td>
<td>磁盘第一个扇区 (LBA 0)</td>
<td>EFI 分区</td>
</tr>
<tr>
<td>引导文件</td>
<td>BIOS 引导代码</td>
<td>支持 EFI 格式文件 (.efi)</td>
</tr>
<tr>
<td>机制</td>
<td>根据引导代码启动 Bootloader</td>
<td>UEFI 直接去读取并运行 Bootloader</td>
</tr>
<tr>
<td>代码大小</td>
<td>446 字节 非 Bootloader 本身</td>
<td>Bootloader，上限取决于 EFI 分区大小</td>
</tr>
<tr>
<td>Bootloader</td>
<td>MBR 同时存储分区表和引导代码，Bootloader 在其他位置</td>
<td>GPT 分区表 存储分区信息，ESP 分区直接存储 Bootloader</td>
</tr>
</tbody></table>
<p>Legacy 无法识别 GPT 分区表格式，所以也就没有 Legacy + GPT 组合方式。</p>
<p>UEFI 可同时识别 MBR 分区(开启 CSM 模式)和 GPT 分区，所以在 UEFI 下，MBR 和 GPT 磁盘都可用于启动操作系统。不过由于微软限制，UEFI 下使用 Windows 安装程序安装操作系统是只能将系统安装在 GPT 磁盘中。</p>
<h2 id="Bootloader"><a href="#Bootloader" class="headerlink" title="Bootloader"></a>Bootloader</h2><p>加载到 RAM 中的第一个程序可能不足以加载操作系统，而必须加载另一个更大的程序。第一个加载到 RAM 中的程序称为第一阶段引导加载程序（BIOS、UEFI），它加载的程序称为第二阶段引导加载程序（狭义上的 Bootloader）</p>
<p>Bootloader 有 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/GNU_GRUB">GNU GRUB</a>、<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/REFInd">rEFInd</a>、<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/SYSLINUX">Syslinux</a>、Windows 的 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/BOOTMGR">BOOTMGR</a>、 和 Windows NT/2000/XP 的 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/NTLDR">NTLDR</a> 等，它们本身不是操作系统，但能够正确加载操作系统并将 CPU 控制权转移到它;操作系统随后会自行初始化并可能加载额外的设备驱动程序。</p>
<p>Bootloader 不需要驱动程序来进行自身操作，可以使用系统固件（例如 BIOS、UEFI 或开放固件）提供的通用存储访问方法，但通常硬件功能有限且性能较低。</p>
<p>许多 Bootloader 可以配置为给用户提供多种引导选择。这些选择可以包括不同的操作系统（用于从不同分区或驱动器进行双重或多重引导）、同一操作系统的不同版本（以防新版本出现意外问题）、不同的操作系统加载选项（例如，引导至不同的操作系统）、安全模式），以及一些无需操作系统即可运行的独立程序，例如内存测试程序（例如 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Memtest86%2B">memtest86+</a>）、基本 shell（如 GNU GRUB 中），甚至游戏。</p>
<p>一些 Bootloader 可以加载其他 Bootloader，例如，GRUB 可以加载 BOOTMGR 而不是直接加载 Windows。通常，默认选择是预先选择的，并有一定的时间延迟，在此期间用户可以按某个键来更改选择；在此延迟之后，默认选择将自动运行，因此无需交互即可正常启动。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://scatteredream.github.io/2025/01/05/408-%E8%AE%A1%E7%BD%91-%E7%BD%91%E7%BB%9C%E5%B1%82/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars.githubusercontent.com/u/62317679?s=400&v=4">
      <meta itemprop="name" content="碎梦">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="scatteredream's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | scatteredream's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/01/05/408-%E8%AE%A1%E7%BD%91-%E7%BD%91%E7%BB%9C%E5%B1%82/" class="post-title-link" itemprop="url">网络层</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-01-05 00:00:00" itemprop="dateCreated datePublished" datetime="2025-01-05T00:00:00+08:00">2025-01-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-05-05 11:31:17" itemprop="dateModified" datetime="2025-05-05T11:31:17+08:00">2025-05-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%A1%E7%BD%91/" itemprop="url" rel="index"><span itemprop="name">计网</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="网络层概述"><a href="#网络层概述" class="headerlink" title="网络层概述"></a>网络层概述</h1><h2 id="家用无线路由器组网示意图"><a href="#家用无线路由器组网示意图" class="headerlink" title="家用无线路由器组网示意图"></a>家用无线路由器组网示意图</h2><p>通过ADSL或者FTTx与ISP相连</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241124141658211.png" alt="image-20241124141658211"></p>
<h2 id="网络层提供不可靠的传输服务"><a href="#网络层提供不可靠的传输服务" class="headerlink" title="网络层提供不可靠的传输服务"></a>网络层提供不可靠的传输服务</h2><h3 id="面向连接"><a href="#面向连接" class="headerlink" title="面向连接"></a>面向连接</h3><p>先建立起虚电路（Virtual Circuit）通过虚电路的存储转发搭配可靠的协议建立起可靠的服务。</p>
<h3 id="无连接的数据报服务"><a href="#无连接的数据报服务" class="headerlink" title="无连接的数据报服务"></a>无连接的数据报服务</h3><p>因为计算机本身有强大的计算功能，因此完全可以将可靠的传输交给终端主机本身去做，网络层设计得尽量简单，向上提供简单的，无连接的，尽最大努力交付的数据报服务(datagram/packet) 不保证分组一定到达，到达也不保证顺序就是发送的顺序。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/91fbdd548f6b4e86d639649f7aae4c30.jpg" alt="91fbdd548f6b4e86d639649f7aae4c30"></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/87d7a972d7095f0f2bcf894527d05dd1.jpg" alt="87d7a972d7095f0f2bcf894527d05dd1"></p>
<h2 id="网络层的两个层面"><a href="#网络层的两个层面" class="headerlink" title="网络层的两个层面"></a>网络层的两个层面</h2><ul>
<li><strong>控制层面</strong>：负责维护路由表，和其他路由节点进行路由数据交互。典型协议就是各种路由选择协议（OSPF、BGP）</li>
<li><strong>数据层面</strong>：负责根据路由表将 分组/数据报 转发到其他路由器。典型协议就是IP</li>
<li><strong>SDN</strong>：软件定义网络，将控制层面用一个远程控制器实现，路由器只需要做转发数据报的工作就可以了。</li>
</ul>
<h1 id="IP（Internet-Protocol）"><a href="#IP（Internet-Protocol）" class="headerlink" title="IP（Internet Protocol）"></a>IP（Internet Protocol）</h1><p>各个局域网通过路由器相互连接称为一个虚拟的互联网，internet</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/internet_protocol_ip_address_diagram.png" alt="IP 地址使数据包到达其目的地"></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/256851fcb6cde44eb5d73863a00da8b2-1732450187866-2.jpg" alt="256851fcb6cde44eb5d73863a00da8b2"></p>
<h2 id="IP-地址"><a href="#IP-地址" class="headerlink" title="IP 地址"></a>IP 地址</h2><p>IPv4 32位 有网络号和主机号两个部分，网络号唯一标识互联网中的一个网络，主机号表示网络中的一台设备（网络号+主机号才能唯一确定一台设备）</p>
<h3 id="ABC-分类地址"><a href="#ABC-分类地址" class="headerlink" title="ABC 分类地址"></a>ABC 分类地址</h3><p>网络号分别是前8位，前16位，前24位，随着互联网用户暴涨，固定的分类方法显然已经无法满足需求。</p>
<h3 id="无类别域间路由-Classless-Inter-Domain-Routing-CIDR"><a href="#无类别域间路由-Classless-Inter-Domain-Routing-CIDR" class="headerlink" title="无类别域间路由(Classless Inter-Domain Routing,==CIDR==)"></a>无类别域间路由(Classless Inter-Domain Routing,==<strong>CIDR</strong>==)</h3><ul>
<li>不采用固定分类的做法，把网络前缀的位数放到最后。</li>
<li>网络前缀完全相同的处于同一个CIDR地址块中。</li>
<li>128.14.35.7/20 表示网络号是前20位。</li>
<li>原先的分类地址法只能分出3级8/16/24，较为死板和浪费，B类地址也无法表示C类地址，导致路由表的膨胀。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">192.168.0.0/24</span><br><span class="line">192.168.1.0/24</span><br><span class="line">192.168.2.0/24</span><br></pre></td></tr></table></figure>

<ul>
<li>路由聚合：这3个地址块可以用192.168.0.0/22概括起来，多个子网的地址具有相同的前缀，便于聚合。</li>
</ul>
<h3 id="子网掩码（subnet-mask）"><a href="#子网掩码（subnet-mask）" class="headerlink" title="子网掩码（subnet mask）"></a>子网掩码（subnet mask）</h3><p>告诉计算机网络前缀的位数，128.14.35.7/20的子网掩码是255.255.240.0（二进制比点分十进制更加直观）子网掩码和主机的IP地址进行按位与运算结果即为网络地址。子网是在一个IP网络中划分子网使我们能将一个至少从逻辑上看上去单一的大型网络分成若干个较小的网络。而主机必须知道自己的IP地址，也要知道自己处于哪一个网段，因此mask就诞生了</p>
<h3 id="Facts-about-IP-address"><a href="#Facts-about-IP-address" class="headerlink" title="Facts about IP address"></a>Facts about IP address</h3><ul>
<li>IP地址实质上是对接口指派地址，路由器有多个接口，说明接入到多个网络中，准确转发到多个网络中需要根据IP。</li>
<li>同一局域网的主机IP网络前缀相同，网络地址的主机号必须全0。</li>
<li>路由器必须处在不同网络中，必须有大于等于2个IP地址，两台交换机互连仍在同一网络中。</li>
<li>交换机只有MAC地址，没有IP地址。</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241124133937330.png" alt="image-20241124133937330"></p>
<h3 id="匿名网络（Anoymous-Unnumbered-Network）"><a href="#匿名网络（Anoymous-Unnumbered-Network）" class="headerlink" title="匿名网络（Anoymous/Unnumbered Network）"></a>匿名网络（Anoymous/Unnumbered Network）</h3><ul>
<li><p>从网络层的严格定义来说，<strong>网络层主要负责不同网络之间的路由和转发</strong>。路由器用了几个接口就表示接到几个网络</p>
</li>
<li><p>即使路由器间直接相连，也需要抽象为一个点对点网络（匿名网络）不过通常为了节省资源，并不分配IP地址</p>
</li>
<li><p>A为公网<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E4%B8%BB%E6%9C%BA/0?fromModule=lemma_inlink">主机</a>，D为拥有公网IP的主机，通信过程为A－B－C－D，B和C用unnumbered，没有必要占用两个ip地址了，让B、C间的口借用另一边口的地址，这样B和C就只是<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E9%93%BE%E8%B7%AF%E5%B1%82/0?fromModule=lemma_inlink">链路层</a>连接[ip unnumber_百度百科](<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/ip">https://baike.baidu.com/item/ip</a> unnumber/4480818) 。如果两台路由器之间还有一个拥有主机的网络E，就必须给接口指派一个网络E的地址。</p>
</li>
</ul>
<h1 id="地址解析协议（Address-Resolution-Protocol-ARP）"><a href="#地址解析协议（Address-Resolution-Protocol-ARP）" class="headerlink" title="地址解析协议（Address Resolution Protocol, ARP）"></a>地址解析协议（Address Resolution Protocol, ARP）</h1><ul>
<li><p>网络层基于IP地址（虚拟地址），主机A有IP<del>1</del>= 192.168.38.10， 主机B有IP<del>2</del>=192.168.38.11 </p>
</li>
<li><p>下层为上层提供服务，所以上层可以不用管下层的实现细节，体现在：主机只需要一个包含源IP和目标IP的数据报即可交给网卡开始传输。实际上数据链路层的网卡要根据IP<del>2</del>解析出应该发给哪个MAC地址，以便构造以太网帧时填入目标MAC地址。<strong>ARP</strong>就提供了IP地址到MAC地址的映射。</p>
</li>
</ul>
<h2 id="ARP-高速缓存（ARP-Cache）"><a href="#ARP-高速缓存（ARP-Cache）" class="headerlink" title="ARP 高速缓存（ARP Cache）"></a>ARP 高速缓存（ARP Cache）</h2><p>这是主机中的一个映射表，缓存了IP-&gt;MAC的关系，经常动态变换，所以也叫 ARP 高速缓存</p>
<ul>
<li><p>刚刚上电，ARP Cache为空，此时就要发送一个<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%9C%B0%E5%9D%80%E8%A7%A3%E6%9E%90%E5%8D%8F%E8%AE%AE#ARP%E6%8A%A5%E6%96%87">ARP报文</a>（<strong>广播</strong>帧 ARP request），目标MAC地址是“FF.FF.FF.FF.FF.FF”，这表示向<strong>同一网段内</strong>的所有主机发出这样的询问：“192.168.38.11的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/MAC%E5%9C%B0%E5%9D%80">MAC地址</a>是什么？” </p>
</li>
<li><p>网络内其他主机并不响应ARP询问，只有<strong>同一网段内</strong>的主机B接收到这个帧时，才向主机A做出回应（ARP response）：“192.168.38.11的MAC地址是00-BB-00-62-C2-02”，此回应以<strong>单播</strong>方式进行。</p>
</li>
<li><p>这样，主机A就知道主机B的MAC地址，它就可以向主机B发送信息。同时它还更新自己的ARP cache，下次再向主机B发送信息时，直接从ARP缓存表里查找就可。实际上，ARP Request中包含源IP和源MAC，这样B收到帧的时候就能直接写入ARP缓存，不需要多余通信</p>
</li>
<li><p>ARP Cache 会设置<strong>生存时间</strong>（Time To Live, TTL）逾期会自动删除，给新的映射关系留下空间（因为可能有的网卡坏了MAC地址也换了，IP地址因为是软件地址，不会跟着硬件走）</p>
</li>
</ul>
<h2 id="ARP-代理（ARP-Proxy）"><a href="#ARP-代理（ARP-Proxy）" class="headerlink" title="ARP 代理（ARP Proxy）"></a>ARP 代理（ARP Proxy）</h2><p>ARP 只适用于<strong>同一局域网</strong>内部的IP到MAC的映射。<strong>不同局域网之间</strong>的通信依靠路由器，主机会把IP数据报发给自己的默认网关（也就是路由器）由于默认网关是IP地址形式，所以也要发一个ARP请求广播帧来获取<strong>路由器的MAC地址</strong>，随后将自己的IP数据报封装成以太网帧发给路由器R<del>1</del>。</p>
<p>路由器R<del>1</del>获取网帧之后经过剥离拿到IP数据报，如果目标IP恰好跟R<del>1</del>在同一个网络内，那么再次通过ARP找到目标IP的MAC地址即可。如果<strong>仍然不在同一个网络</strong>内，则需要查路由表来确定下一跳应该发到哪个网络。</p>
<p><strong>广播域隔离</strong>：路由器并不会在不同子网间转发<strong>基于MAC地址的广播帧</strong>，同样也不会转发<strong>IP广播数据报</strong>，因为这样可能会造成<strong>广播风暴</strong>，瘫痪网络。</p>
<p><strong>为什么不直接使用MAC地址通信</strong>：MAC地址相比于IP地址的劣势</p>
<ul>
<li>MAC帧格式并不统一（以太网帧、802.11帧<del>Wi-Fi</del>等）地址转换过程非常复杂，并且和硬件绑定缺乏灵活性</li>
<li>使用更高层次的抽象IP地址就可以屏蔽上述差异，灵活分配，具体由ARP协议负责找到IP对应的MAC。</li>
<li>MAC地址可轻易被伪造或篡改，而IP地址则可以结合其他协议（如防火墙和ACL）进行更复杂的安全策略。</li>
</ul>
<h1 id="IP-数据报首部（IP-Header）"><a href="#IP-数据报首部（IP-Header）" class="headerlink" title="IP 数据报首部（IP Header）"></a>IP 数据报首部（IP Header）</h1><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/d448bf2729381d8aa9f09d12f454726d.png" alt="d448bf2729381d8aa9f09d12f454726d"></p>
<table>
<thead>
<tr>
<th>字段名称</th>
<th>长度（bit）</th>
<th>功能</th>
</tr>
</thead>
<tbody><tr>
<td>版本</td>
<td>4</td>
<td>区分协议的版本 (IPv4, IPv6等)</td>
</tr>
<tr>
<td>首部长度</td>
<td>4</td>
<td>整个<strong>首部</strong>的长度，单位4字节（0101（20字节）~1111（60字节））</td>
</tr>
<tr>
<td>区分服务</td>
<td>8</td>
<td>用来获得更好的服务类型，区分服务类型才使用</td>
</tr>
<tr>
<td>总长度</td>
<td>16</td>
<td>单位字节，首部+数据的总长度，最大65536，实际上超过1500（MTU）必须分片，如果分片，则为这个数据报分片的总长度</td>
</tr>
<tr>
<td>标识</td>
<td>16</td>
<td>IP 软件给每个 IP 数据报分配的标识，属于<strong>同一个数据报的分片标识相同</strong></td>
</tr>
<tr>
<td>标志</td>
<td>3</td>
<td>0 | DF | MF (MF =  1表示还有分片，MF = 0表示最后一个分片，DF = 1不允许分片)</td>
</tr>
<tr>
<td>片偏移（Offset）</td>
<td>13</td>
<td>单位8字节，$2^{13}\times8 = 65536$，表示<strong>分片的数据</strong>在<strong>原数据</strong>中的偏移量</td>
</tr>
<tr>
<td>生存时间（TTL）</td>
<td>8</td>
<td><strong>数据报的寿命</strong>，以前单位为秒，后来变成了<strong>跳数</strong>，减少路由表配置错误导致的网络风暴</td>
</tr>
<tr>
<td>协议</td>
<td>8</td>
<td>用来标识数据部分使用的是什么协议（ICMP, UDP, TCP, OSPF 等）</td>
</tr>
<tr>
<td>首部校验和（Checksum）</td>
<td>16</td>
<td><strong>首部</strong>按照16位字划分成如上图的几行，将首部各行加和的反码填入，发送者会先置0，然后再运算，接收者会直接运算结果，如果不出错结果肯定是0</td>
</tr>
<tr>
<td>源地址</td>
<td>32</td>
<td>源 IPv4 地址</td>
</tr>
<tr>
<td>目的地址</td>
<td>32</td>
<td>目标 IPv4 地址</td>
</tr>
<tr>
<td>可变部分</td>
<td>1~40</td>
<td>用于排错、测量和安全功能，由于是可变 加重路由器的负担，可有可无，IPv6 变为定长</td>
</tr>
<tr>
<td>数据部分（Payload）</td>
<td>——</td>
<td>上层传下来的数据</td>
</tr>
</tbody></table>
<h2 id="从以太网帧中找出目的IP地址"><a href="#从以太网帧中找出目的IP地址" class="headerlink" title="从以太网帧中找出目的IP地址"></a>从以太网帧中找出目的IP地址</h2><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241124195904437.png" alt="image-20241124195904437"></p>
<p>以太网帧有14B的头，IP的目的地址之前有16B的头，因此目的地址从第31个字节开始</p>
<h1 id="IP-转发分组过程"><a href="#IP-转发分组过程" class="headerlink" title="IP 转发分组过程"></a>IP 转发分组过程</h1><h2 id="基于终点转发：前缀匹配"><a href="#基于终点转发：前缀匹配" class="headerlink" title="基于终点转发：前缀匹配"></a>基于终点转发：前缀匹配</h2><table>
<thead>
<tr>
<th>前缀匹配</th>
<th>下一跳</th>
</tr>
</thead>
<tbody><tr>
<td>128.1.2.192/26</td>
<td>直接，接口1</td>
</tr>
<tr>
<td>128.1.2.128/26</td>
<td>直接，接口2</td>
</tr>
<tr>
<td>128.1.3.64/26</td>
<td>R<del>2</del></td>
</tr>
</tbody></table>
<p>ARP代理机制中，我们接触到了逐跳转发的概念，如果转发到第一个路由器和目标IP仍然不在一个网络，就要转发到路由表的下一跳。</p>
<p><strong>路由表</strong>：分别是网络IP地址、子网掩码和下一跳，网络地址和子网掩码确定接口在哪个网络，下一跳同样是网络的地址而不是主机的IP地址，这主要是为了防止浪费，提高转发的效率。</p>
<p><strong>匹配前缀</strong>：将子网掩码和目的地址相与 得出的网络地址匹配，则进入下一跳，否则继续匹配下一个</p>
<p>R<del>1</del>查到下一跳之后，会将下一跳IP地址传给数据链路层，用ARP解析出路由器R<del>2</del>的MAC地址。</p>
<p>因此，查找路由表的过程就是寻找前缀匹配的过程。</p>
<h2 id="查询路由表"><a href="#查询路由表" class="headerlink" title="查询路由表"></a>查询路由表</h2><h3 id="最长前缀匹配"><a href="#最长前缀匹配" class="headerlink" title="最长前缀匹配"></a>最长前缀匹配</h3><p>CIDR路由聚合可以将网络前缀相同的地址块合并，初衷就是减少路由表项，但同时也减少了路由的具体性，举例：</p>
<p><code>128.1.24.0/22</code>与<code>128.1.24.0/24</code> 这两个CIDR地址块并不一致，尽管后者可以聚合到前者中，但是如果特意不聚合（比如公司B和公司A同时从ISP申请了同一网段的IP地址），放到路由表就表示不同的网段，</p>
<p><strong>128.1.24.0/24</strong>：</p>
<ul>
<li>掩码：<code>255.255.255.0</code></li>
<li>包含的地址范围：<code>128.1.24.0 ~ 128.1.24.255</code> （公司A）</li>
</ul>
<p><strong>128.1.24.0/22</strong>：</p>
<ul>
<li>掩码：<code>255.255.252.0</code></li>
<li>表面上可以包含的地址范围：<code>128.1.24.0 ~ 128.1.27.255</code> </li>
<li>实际上包含的地址范围： <code>128.1.25.0/24</code>, <code>128.1.26.0/24</code>, <code>128.1.27.0/24</code> (公司B)</li>
<li>为了节省空间，使用路由聚合将公司B的3个地址块聚合成1个大地址块</li>
</ul>
<p>多个前缀匹配成功（精确和模糊网段同时出现在路由表），模糊网段实际上并没有包括这个精确网段，路由器采取的原则是 <strong>最长前缀匹配</strong> ，如果不这样做，会被错误路由到模糊的网段，找不到目标。</p>
<p>为了方便这个实践这个原则，路由表会按照前缀长度进行排序，越长防越靠前，避免发生错误多余的查找。</p>
<p>路由表中还有两个特殊的可选路由项：</p>
<h3 id="主机路由（host-route）"><a href="#主机路由（host-route）" class="headerlink" title="主机路由（host route）"></a>主机路由（host route）</h3><p>前缀长度是32位，直接定位到一台主机，目标IP和主机路由相同，则直接认定匹配，网络测试比较方便，免去地址聚合带来的不确定性</p>
<h3 id="默认路由（default-route）"><a href="#默认路由（default-route）" class="headerlink" title="默认路由（default route）"></a>默认路由（default route）</h3><p><strong>网络前缀</strong>：</p>
<ul>
<li><code>0.0.0.0</code>：表示网络地址是 0。</li>
<li><code>/0</code>：表示前缀长度是 0 位，也就是说没有固定的前缀，所有 IP 地址的前缀都可以匹配它。</li>
</ul>
<p><strong>含义</strong>：</p>
<ul>
<li>默认路由是路由表中的一个“兜底规则”。</li>
<li>当某个目标地址不匹配任何其他路由条目时，数据包会被转发到默认路由指向的下一跳（指定的网关）。</li>
<li>适用于对外连接较少的路由器（比如这个路由器不直接跟外网连接，而是通过另一个网关）</li>
</ul>
<p>当路由表中存在更精确的匹配（如 <code>/24</code> 或 <code>/16</code>），则优先使用更精确的匹配；只有当没有其他匹配时，才使用默认路由。这个可以减少路由表的条数，提高单个路由表的查询性能。</p>
<h1 id="网际控制报文协议（ICMP）"><a href="#网际控制报文协议（ICMP）" class="headerlink" title="网际控制报文协议（ICMP）"></a>网际控制报文协议（ICMP）</h1><h2 id="ICMP报文种类"><a href="#ICMP报文种类" class="headerlink" title="ICMP报文种类"></a>ICMP报文种类</h2><h3 id="差错报告报文"><a href="#差错报告报文" class="headerlink" title="差错报告报文"></a>差错报告报文</h3><ul>
<li><p>终点不可达：路由器或主机无法交付数据报时向源点发送destination unreachable，比如UDP数据包目标是一个不存在的端口</p>
<ul>
<li><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241126195147654.png" alt="image-20241126195147654"></li>
</ul>
</li>
<li><p>时间超过：TTL归零，路由器要丢弃数据报，并向源点发送time exceeded</p>
</li>
<li><p>参数问题：IP首部出错，BAD IP HEADER</p>
</li>
<li><p>改变路由：路由器发现了更好的路由，遂向主机发送redirecting，改变默认路由</p>
</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241125220916277.png" alt="image-20241125220916277"></p>
<p>ICMP的数据部分包括IP数据报首部，和IP数据负载的前8字节（UDP，TCP的目标端口和源端口，TCP报文段的发送序列号）</p>
<h3 id="询问报文"><a href="#询问报文" class="headerlink" title="询问报文"></a>询问报文</h3><ul>
<li>回送请求、回送回答：向特定主机发送的询问，收到回答用来测试可达和主机状态</li>
<li>时间戳请求、时间戳回答：利用时间戳可以计算往返时间</li>
</ul>
<h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><h3 id="PING"><a href="#PING" class="headerlink" title="PING"></a>PING</h3><p>Packet InterNet Gopher ，应用层直接调用网络层的一个例子，向节点连续发送ICMP回送请求报文，可以计算出往返时间，统计出丢失的分组数（不知道原因）</p>
<p>ECHO REQUEST(8)    ECHO REPLY(0)</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241125221744772.png" alt="image-20241125221744772"></p>
<h4 id="socket编程实现"><a href="#socket编程实现" class="headerlink" title="socket编程实现"></a>socket编程实现</h4><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/eb0963a11439dff361dbe0e7a8876abd.png" alt="图片"></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241126203039467.png" alt="image-20241126203039467"></p>
<p>UNIX系统编程实现中，计算机传输层以下比较底层的部分通过socket接口封装起来，调用比较方便，socket编程接口就是应用程序访问网络，操作网卡的方式。</p>
<p>创建socket套接字时有不同的参数，可以选择基于字节流（TCP）/数据报（UDP），另外一个方面，还可以选择协议TCP UDP 或者ICMP，这样socket</p>
<p>在 TCP 传输中创建的方式是 <code>socket(AF_INET, SOCK_STREAM, 0)</code> 其中 <code>AF_INET</code> 表示将使用 IPV4 里 host:port 的方式去解析待会你输入的网络地址。<code>SOCK_STREAM</code> 是指使用面向字节流的 TCP 协议，工作在传输层。 创建好了 socket 之后，就可以愉快的把要传输的数据写到这个文件里。调用 socket 的<code>sendto</code>接口的过程中进程会从用户态进入到内核态，最后会调用到 <code>sock_sendmsg</code> 方法。 然后进入传输层，带上TCP头。网络层带上IP头，数据链路层带上 MAC头等一系列操作后。进入网卡的发送队列 ring buffer ，顺着网卡就发出去了。 回到 ping ， 整个过程也基本跟 TCP 发数据类似，差异的地方主要在于，创建 socket 的时候用的是 <code>socket(AF_INET,SOCK_RAW,IPPROTO_ICMP)</code>，<code>SOCK_RAW</code> 是原始套接字 ，工作在网络层， 所以构建ICMP（网络层协议）的数据，是再合适不过了。ping 在进入内核态后最后也是调用的 <code>sock_sendmsg</code> 方法，进入到网络层后加上ICMP和IP头后，数据链路层加上MAC头，也是顺着网卡发出。        </p>
<p>因此 本质上ping 跟 普通应用发消息 在程序流程上没太大差别。 这也解释了<strong>为什么当你发现怀疑网络有问题的时候，别人第一时间是问你能ping通吗？</strong>因为可以简单理解为ping就是自己组了个数据包，让系统按着其他软件发送数据的路径往外发一遍，能通的话说明其他软件发的数据也能通。</p>
<h4 id="PING-127-0-0-1"><a href="#PING-127-0-0-1" class="headerlink" title="PING 127.0.0.1"></a>PING 127.0.0.1</h4><p>PING localhost 127.0.0.1 本机IP都会走回环路径</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/c1019a8be584b27c4fc8b8abda9d3cf1.png" alt="图片"></p>
<p>The local network card is actually a “fake network network card”. It does not have a <strong>ring buffer</strong> like the “real network card”. The “fake network card” will push data into a linked list called <code>input_pkt_queue</code>. This linked list is actually shared by <strong>all</strong> network cards, and contains various messages sent to this machine. After the message is sent to this linked list, a soft interrupt will be triggered。</p>
<p>0.0.0.0 ping不通，不过服务器listen0.0.0.0表示监听所有目标地址</p>
<h3 id="traceroute"><a href="#traceroute" class="headerlink" title="traceroute"></a>traceroute</h3><ol>
<li>记录路由路径和路由时间</li>
<li>确定链路的MTU</li>
</ol>
<p>连续发送多个数据报(含有目标端口非法的UDP数据报)，TTL从1开始递增，路由器减TTL并准备转发，此时看到TTL归零就会向源点发送ICMP <strong>时间超过</strong> 差错报告报文，能够记录路由的路径，如果路由到目标主机，目标主机不会继续转发，也不会减TTL，看到UDP数据报不合法向源点发送ICMP <strong>终点不可达</strong> 差错报告报文。</p>
<p>每个TTL会发送3个相同数据报</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241125221948199.png" alt="image-20241125221948199"></p>
<p>第二个作用：<strong>故意设置不分片，从而确定路径的 MTU</strong>。</p>
<p>First, when the sending host sends an IP datagram, it sets the DF(Don’t Fragment) flag bit in the IP packet header to 1. According to this flag, routers on the way will not fragment large data packets, but will <strong>discard</strong> the packets.</p>
<p>Subsequently, the value of the <strong>MTU on the data link</strong> is sent to the sending host through an ICMP unreachable message. The type of the unreachable message is “Fragmentation is required but the DF-bit is set.”</p>
<p>Each time the sending host receives an ICMP error message, it reduces the packet size to locate an appropriate MTU value so that it can reach the target host.</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241126195846876.png" alt="image-20241126195846876"></p>
<h1 id="网际分组管理协议（IGMP）"><a href="#网际分组管理协议（IGMP）" class="headerlink" title="网际分组管理协议（IGMP）"></a>网际分组管理协议（IGMP）</h1><h2 id="一对多通信"><a href="#一对多通信" class="headerlink" title="一对多通信"></a>一对多通信</h2><h3 id="IP-单播（Unicast）"><a href="#IP-单播（Unicast）" class="headerlink" title="IP 单播（Unicast）"></a>IP 单播（Unicast）</h3><p>单播是点对点通信，一台设备直接与另一台设备通信。数据包通过网络传输到特定的目标地址。</p>
<p><strong>特点</strong></p>
<ul>
<li>每个数据包有唯一的目标 IP 地址。</li>
<li>用于一对一的通信场景。</li>
<li>网络负载低，目标明确。</li>
</ul>
<p><strong>应用场景</strong></p>
<ul>
<li>普通的网页浏览、邮件通信等。</li>
<li>服务器与客户端的直接通信。</li>
</ul>
<p><strong>示例</strong><br>一台电脑向服务器（如 192.168.1.1）请求网页内容。</p>
<h3 id="IP-广播（Broadcast）"><a href="#IP-广播（Broadcast）" class="headerlink" title="IP 广播（Broadcast）"></a>IP 广播（Broadcast）</h3><table>
<thead>
<tr>
<th>网络号</th>
<th>主机号</th>
<th>源地址使用</th>
<th>目的地址使用</th>
<th>用途</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0</td>
<td>OK</td>
<td>NO</td>
<td>本网络的本主机，用于 DHCP，此时本主机 IP 未知</td>
</tr>
<tr>
<td>0</td>
<td>X</td>
<td>OK</td>
<td>NO</td>
<td>本网络的 X 主机</td>
</tr>
<tr>
<td>127</td>
<td>除全0和全1</td>
<td>OK</td>
<td>OK</td>
<td>本地软件测试环回地址 (loopback)</td>
</tr>
<tr>
<td><strong>Y</strong></td>
<td><strong>全1</strong></td>
<td><strong>NO</strong></td>
<td><strong>OK</strong></td>
<td><strong>Y 网络的广播（路由器参与转发）</strong></td>
</tr>
<tr>
<td><strong>全1</strong></td>
<td><strong>全1</strong></td>
<td><strong>NO</strong></td>
<td><strong>OK</strong></td>
<td><strong>本网络的广播（路由器不参与转发）</strong></td>
</tr>
</tbody></table>
<p>由此可见，IP 广播主要是聚焦局域网（LAN）所有主机都会接收广播消息，无需特定的接收者。</p>
<p><strong>应用场景</strong>：</p>
<ul>
<li>地址解析协议（ARP）。</li>
<li>动态主机配置协议（DHCP）的请求。</li>
</ul>
<h3 id="IP-多播（Multicast）"><a href="#IP-多播（Multicast）" class="headerlink" title="IP 多播（Multicast）"></a>IP 多播（Multicast）</h3><ul>
<li><strong>定义</strong>：<br>多播是一种将数据包发送给特定一组接收者（多播组）的通信方式。这组接收者需要事先加入一个特定的多播组，只有组内的成员会接收到数据包。也叫组播</li>
<li><strong>特点</strong>：<ul>
<li>可以跨越多个网络。</li>
<li>使用 <strong>多播地址</strong>：IPv4中的多播地址范围是 <code>224.0.0.0</code> 到 <code>239.255.255.255</code>。（D类地址）</li>
<li>接收者需要加入一个多播组（通过 IGMP 协议进行管理）。</li>
<li>节省带宽，因为数据只发送给需要的设备。</li>
</ul>
</li>
<li><strong>优缺点</strong>：<ul>
<li><strong>优点</strong>：更高效，特别是在需要发送给大量接收者时。</li>
<li><strong>缺点</strong>：需要更多的配置和支持，例如多播路由器。</li>
</ul>
</li>
<li><strong>应用场景</strong>：<ul>
<li>视频会议。</li>
<li>实时股票行情分发。</li>
<li>流媒体广播。</li>
</ul>
</li>
</ul>
<h3 id="IP-任播（Anycast）"><a href="#IP-任播（Anycast）" class="headerlink" title="IP 任播（Anycast）"></a>IP 任播（Anycast）</h3><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241129180917624.png" alt="image-20241129180917624"></p>
<p><strong>定义</strong><br>任播是点对最近点通信，数据包发送给一个目标地址，但由多个具有相同地址的设备接收，最终到达距离最近的一个设备。</p>
<p><strong>特点</strong></p>
<ul>
<li>使用普通的单播地址，但配置在多个设备上。</li>
<li>路由选择最近的目标（通常基于最短路径）。</li>
<li>增强服务的可用性和效率。用于负载均衡和冗余。</li>
</ul>
<p><strong>应用场景</strong></p>
<ul>
<li>内容分发网络（CDN）。</li>
<li>公共 DNS 服务（如 Google 的 8.8.8.8）。</li>
</ul>
<p><strong>示例</strong><br>用户请求 DNS 服务，数据包被路由到最近的 DNS 服务器（多个 DNS 服务器配置了同样的地址 8.8.8.8）。</p>
<h3 id="对比总结"><a href="#对比总结" class="headerlink" title="对比总结"></a>对比总结</h3><table>
<thead>
<tr>
<th>类型</th>
<th>特点</th>
<th>应用场景</th>
</tr>
</thead>
<tbody><tr>
<td>单播</td>
<td>一对一通信，目标明确</td>
<td>普通网络通信（网页、邮件等）</td>
</tr>
<tr>
<td>组播</td>
<td>一对多通信，针对订阅组传输</td>
<td>视频直播、分布式同步等</td>
</tr>
<tr>
<td>广播</td>
<td>一对全通信，子网内所有设备接收</td>
<td>ARP、DHCP 发现等</td>
</tr>
<tr>
<td>任播</td>
<td>一对最近点通信，选择最近设备</td>
<td>CDN、全球 DNS 服务等</td>
</tr>
</tbody></table>
<h3 id="局域网上的硬件多播"><a href="#局域网上的硬件多播" class="headerlink" title="局域网上的硬件多播"></a>局域网上的硬件多播</h3><p>MAC地址 FF:FF:FF:FF:FF:FF为<strong>广播地址</strong></p>
<p>MAC地址 第一个字节末位为1 表示多播，前25位固定不变，后23位来自D类IP地址的后23位 为MAC多播地址</p>
<h2 id="协议"><a href="#协议" class="headerlink" title="协议"></a>协议</h2><h3 id="IGMP"><a href="#IGMP" class="headerlink" title="IGMP"></a>IGMP</h3><h3 id="多播路由协议"><a href="#多播路由协议" class="headerlink" title="多播路由协议"></a>多播路由协议</h3><p>本质区别：多播路由需要考虑源地址的组和网络，也要考虑目的地址的组和网络</p>
<h1 id="缓解IPv4地址短缺"><a href="#缓解IPv4地址短缺" class="headerlink" title="缓解IPv4地址短缺"></a>缓解IPv4地址短缺</h1><h2 id="CIDR"><a href="#CIDR" class="headerlink" title="CIDR"></a>CIDR</h2><h2 id="虚拟专用网络（Virtual-Private-Network-VPN）"><a href="#虚拟专用网络（Virtual-Private-Network-VPN）" class="headerlink" title="虚拟专用网络（Virtual Private Network, VPN）"></a>虚拟专用网络（Virtual Private Network, VPN）</h2><h3 id="专用IP地址与隧道技术（tunnel）"><a href="#专用IP地址与隧道技术（tunnel）" class="headerlink" title="专用IP地址与隧道技术（tunnel）"></a>专用IP地址与隧道技术（tunnel）</h3><p><code>10.0.0.0 ~ 10.255.255.255</code> 1个A类网络</p>
<p><code>172.16.0.0 ~ 172.31.255.255</code> 16个B类网络</p>
<p><code>192.168.0.0 ~ 192.168.255.255</code> 256个C类网络</p>
<p>IP地址短缺，机构内部的主机都会使用专用IP网段，如果机构内部的主机AB分隔两地需要进行通信，私密性和安全性是关键，要么向运营商租用昂贵的电信线路将他们直接连成局域网，</p>
<p>要么利用互联网，用两台路由器静态配置IP，将原本的IP数据报加密后封装到一个新的IP数据报中，这个新的IP数据报负责在公网进行路由传递，最终到达目标主机所在网络的路由器，由路由器将数据报交付给目标主机。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241125223910383.png" alt="image-20241125223910383"></p>
<table>
<thead>
<tr>
<th>步骤</th>
<th>目标IP</th>
<th>源IP</th>
<th>所属网络</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>10.2.0.3</td>
<td>10.1.0.1</td>
<td>10.1.0.0</td>
</tr>
<tr>
<td>2</td>
<td>194.4.5.6</td>
<td>125.1.2.3</td>
<td>公网IP</td>
</tr>
<tr>
<td>3</td>
<td>10.2.0.3</td>
<td>10.1.0.1</td>
<td>10.2.0.0</td>
</tr>
</tbody></table>
<p>步骤2是外层数据报，13都是内层的加密数据报内容。</p>
<h2 id="网络地址转换（Network-Address-Translation-NAT）"><a href="#网络地址转换（Network-Address-Translation-NAT）" class="headerlink" title="网络地址转换（Network Address Translation, NAT）"></a>网络地址转换（Network Address Translation, NAT）</h2><p>同样是IP地址短缺的背景，路由器给主机分配了专用IP网段，内网IP的数据包根本不可能在公网上传播，因为公网上的路由器都是屏蔽掉了这些私网IP，因此主机要通过路由器的公网IP向外发送消息，但是之后外部就无法联络内部，此时就出现了网络地址转换（NAT）NAT提供了主机的专用IP地址到路由器所持公网IP的映射关系，外部发送消息到路由器的特定公网IP，NAT路由器根据映射表将消息转发到对应的主机。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241125225315413.png" alt="image-20241125225315413"></p>
<h3 id="NAPT"><a href="#NAPT" class="headerlink" title="NAPT"></a>NAPT</h3><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241125225356469.png" alt="image-20241125225356469"></p>
<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>网络地址转换（Network Address Translation，NAT）机制的问题在于，NAT设备自动屏蔽了非内网主机主动发起的连接，也就是说，从外网发往内网的数据包将被NAT设备丢弃，这使得位于不同NAT设备之后的主机之间无法直接交换信息。这一方面保护了内网主机免于来自外部网络的攻击，另一方面也为P2P通信带来了一定困难。Internet上的NAT设备大多是地址限制圆锥形NAT或端口限制圆锥形 NAT，外部主机要与内网主机相互通信，必须由内网主机主动发起连接，使 NAT设备产生一个映射条目，这就有必要研究一下<strong>内网穿透</strong>技术。</p>
<h3 id="内网穿透（Intranet-penetration）"><a href="#内网穿透（Intranet-penetration）" class="headerlink" title="内网穿透（Intranet penetration）"></a>内网穿透（Intranet penetration）</h3><h4 id="UDP-打洞"><a href="#UDP-打洞" class="headerlink" title="UDP 打洞"></a>UDP 打洞</h4><h5 id="通信双方一台位于-NAT-之后"><a href="#通信双方一台位于-NAT-之后" class="headerlink" title="通信双方一台位于 NAT 之后"></a>通信双方一台位于 NAT 之后</h5><p>一台主机B有一个公网 IP，另一台主机A有一个内网 IP。如图2.4所示， A 位于 NAT 之后，并拥有[IP 地址：端口]对[10.0.0.1：1234]， B位于 NAT 之前，并拥有[IP 地址：端口]对[138.76.29.7：1234]，NAT 拥有公网 IP 155.99.25.11。由于  B 有一个公网 IP， A 可以直接通过 TCP 连接到[138.76.29.7：1234]，然而，如果  B 向  A 发起主动连接，则不会成功。此时，需要一个公有的服务器辅助进行内网穿透。 A 和  B 向服务器发起登陆请求，并保持一个 TCP 或 UDP 连接，服务器记录其 IP 地址和端口号，这里服务器对  A 是记录其经过 NAT 映射之后的 IP 和端口号。当  B 想连接  A 时，首先向服务器提出请求，服务器在收到请求后向  A 发出打洞命令，并将  B 的[IP 地址：端口]对发给  A， A 根据接收到的 IP地址和端口号向  B 发起 TCP 连接或发送 UDP 数据包。接下来  A 和 B 之间便可以建立数据传输通道。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241125230637435.png" alt="image-20241125230637435"></p>
<h5 id="通信双方主机均位于NAT设备之后"><a href="#通信双方主机均位于NAT设备之后" class="headerlink" title="通信双方主机均位于NAT设备之后"></a>通信双方主机均位于NAT设备之后</h5><p>两台主机都处于内网中，如图2.5所示。服务器记录的[IP 地址：端口]对是  A 和  B 经过 NAT 映射之后的IP 地址和端口号，此时， A 和  B 之间任意方向的连接请求都会被对方的 NAT 设备屏蔽。 A 首先向服务器提出连接请求，服务器将  A 的 IP地址和端口号对[155.99.25.11:51200]发给  B，并向  B 发出打洞命令； B 收到服务器的打洞命令后首先向[155.99.25.11:51200]发送一定数目的 UDP探测包或 TCP 连接请求，在 NAT B 上打一个方向为[155.99.25.11:51200]的洞， B 随后向服务器报告打洞完成；服务器在收到  B 的报告后将  B 的公网IP 地址和端口号对[110.10.33.10：5000]，此时由于 NAT B 上已经留下了对应于[155.99.25.11:51200]方向的洞， A 向[110.10.33.10：5000]发出的数据包或连接请求将不会被丢弃。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241125230725093.png" alt="image-20241125230725093"></p>
<p>这项技术需要使用<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2">圆锥型NAT</a>设备，对称型NAT不能使用这项技术。</p>
<h4 id="STUN（NAT会话穿越应用程序）"><a href="#STUN（NAT会话穿越应用程序）" class="headerlink" title="STUN（NAT会话穿越应用程序）"></a>STUN（NAT会话穿越应用程序）</h4><p>NAT 穿越技术拥有这样的功能，它能够让网络应用程序主动发现自己位于 NAT 设备之后，并且会主动获得 NAT 设备的公有 IP，并为自己建立端口映射条目，注意这些都是 NAT设备后的应用程序自动完成的。</p>
<p>也就是说，在 NAT 穿透技术中，NAT设备后的应用程序处于主动地位，它已经明确地知道 NAT 设备要修改它外发的数据包，于是它主动配合 NAT 设备的操作，主动地建立好映射，这样就不像以前由 NAT 设备来建立映射了。</p>
<p>说人话，就是客户端主动从 NAT 设备获取公有 IP 地址，然后自己建立端口映射条目，然后用这个条目对外通信，就不需要 NAT 设备来进行转换了。</p>
<h1 id="路由选择协议"><a href="#路由选择协议" class="headerlink" title="路由选择协议"></a>路由选择协议</h1><h2 id="静态配置路由导致的路由环路"><a href="#静态配置路由导致的路由环路" class="headerlink" title="静态配置路由导致的路由环路"></a>静态配置路由导致的路由环路</h2><p>聚合路由和精确路由同时出现在一张路由表中，应该按照精确地址进行匹配，（模糊地址中不包括精确地址）</p>
<p><strong>路由配置错误</strong>：路由表手动配置错误导致出现路由环路。</p>
<p><strong>聚合不存在的网络</strong>：路由表中只有模糊地址，但是模糊地址里面不存在某个精确地址，而目的地址是精确地址会导致数据包会被错误地路由到模糊的网络，因此路由器应当配置黑洞路由，将不存在的地址路由到黑洞中（丢弃）</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241127123732804.png" alt="image-20241127123732804"></p>
<p><strong>网络故障</strong>：路由器检测到与其直连的网络发生故障会把路由表中的条目删除，但下次来就不知道要转发到哪里，只能交给默认路由，此时可能会导致环路，正确的做法是故障时启用对应网络的黑洞路由，恢复时关闭黑洞路由，启用正常的接口路由    </p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241127124109191.png" alt="image-20241127124109191"></p>
<h2 id="路由协议概述"><a href="#路由协议概述" class="headerlink" title="路由协议概述"></a>路由协议概述</h2><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241127124155110.png" alt="image-20241127124155110"></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241127124212549.png" alt="image-20241127124212549"></p>
<p>路由表：对网络拓扑计算最优化</p>
<p>转发表：使得查找过程最优化，优化路由表的查找性能</p>
<h2 id="路由信息协议（Routing-Information-Protocol-RIP）"><a href="#路由信息协议（Routing-Information-Protocol-RIP）" class="headerlink" title="路由信息协议（Routing Information Protocol, RIP）"></a>路由信息协议（Routing Information Protocol, RIP）</h2><ul>
<li>属于内部网关协议（IGP），是一个自治系统内部的路由协议</li>
<li>最早出现的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%B7%9D%E9%9B%A2%E5%90%91%E9%87%8F%E8%B7%AF%E7%94%B1%E5%8D%94%E5%AE%9A">距离向量路由协议</a>，其主要应用于规模较小的、可靠性要求较低的网络。收敛速度较慢，支持的广播网络规模有限</li>
<li>路由<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%AE%97%E6%B3%95">算法</a>是<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/Bellman-Ford">Bellman-Ford</a>算法</li>
</ul>
<h3 id="原则"><a href="#原则" class="headerlink" title="原则"></a>原则</h3><ul>
<li><p>每隔30秒会与相邻的路由器交换子消息，以动态的建立<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%B7%AF%E7%94%B1%E8%A1%A8">路由表</a>。</p>
</li>
<li><p><strong>RIP规定度量值取0~15之间的整数，大于或等于16的跳数被定义为无穷大。</strong></p>
</li>
<li><p>对方的路由表复制过来，下一跳全部改成对方，距离全部加1；</p>
</li>
<li><p>不存在网络B的条目，直接添加；</p>
</li>
<li><p>存在网络A的条目，下一跳相同，直接更新；</p>
</li>
<li><p>存在网络A的条目，下一跳不同，距离更短才更新；距离相同则添加条目（等价负载均衡）；距离更长则不更新。</p>
</li>
</ul>
<h3 id="问题：坏消息传得慢"><a href="#问题：坏消息传得慢" class="headerlink" title="问题：坏消息传得慢"></a>问题：坏消息传得慢</h3><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241127124509184.png" alt="image-20241127124509184"></p>
<ul>
<li><strong>水平分割</strong>：水平分割指的是RIP从某个接口学到的路由，不会从该接口再发回给邻居设备。在帧中继和X.25等NBMA网络中，水平分割功能缺省为禁止状态。</li>
<li><strong>触发更新</strong>：触发更新是指路由信息发生变化时，立即向邻居设备发送触发更新报文，通知变化的路由信息。（触发更新不会触发接收路由器重置自己的更新定时器）</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241127125439393.png" alt="image-20241127125439393"></p>
<p>检测到不可达：说明之前距离是1（直连接口）</p>
<p>收敛：R3 到网络距离为1，R2和R1到网络的距离为2</p>
<p>不可达：R3 到网络距离为16，通告给R2，变更距离为16，随后R1没来得及更新，就将自己的路由表内容发给了</p>
<h2 id="开放式最短路径优先（Open-Shortest-Path-First-OSPF）"><a href="#开放式最短路径优先（Open-Shortest-Path-First-OSPF）" class="headerlink" title="开放式最短路径优先（Open Shortest Path First, OSPF）"></a>开放式最短路径优先（Open Shortest Path First, OSPF）</h2><ul>
<li><p>属于内部网关协议（IGP）</p>
</li>
<li><p>在链路状态路由协议中，每个节点都知晓整个网络的拓扑信息。各节点使用自己了解的网络拓扑情况来各自独立地对网络中每个可能的目的地址计算出其最佳的转发地址（下一跳）。所有最佳转发地址汇集到一起构成该节点的完整路由表。与距离-矢量路由协议使用的那种每个节点与其相邻节点分享自己的路由表的工作方式不同，链路状态路由协议的工作方式是节点间仅传播用于构造网络连通图所需的信息。最初创建这类协议就是为了解决距离-矢量路由协议收敛缓慢的缺点，然而，为此链路状态路由协议会消耗大量的内存与处理器能力。</p>
</li>
<li><p>大多数<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%BA%92%E8%81%94%E7%BD%91%E6%9C%8D%E5%8A%A1%E4%BE%9B%E5%BA%94%E5%95%86">ISP</a>必须使用BGP来与其他ISP建立路由连接（尤其是当它们采取多宿主连接时）</p>
</li>
<li><p>采用<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%88%B4%E5%85%8B%E6%96%AF%E7%89%B9%E6%8B%89%E7%AE%97%E6%B3%95">Dijkstra 算法</a>计算<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E6%A0%91">最短路径树</a>，使用“开销（Cost）”作为路由度量。</p>
</li>
<li><p>链路状态数据库（LSDB）用来保存当前<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%BD%91%E7%BB%9C%E6%8B%93%E6%89%91">网络拓扑</a>结构，<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%B7%AF%E7%94%B1%E5%99%A8">路由器</a>上属于同一区域的链路状态数据库是相同的（属于多个区域的路由器会为每个区域维护一份链路状态数据库）。</p>
</li>
<li><p>基于 IP 协议，路由信息直接封装在 IP 数据报中</p>
</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241127125916904.png" alt="image-20241127125916904"></p>
<h2 id="边界网关协议（Border-Gateway-Protocol-BGP）"><a href="#边界网关协议（Border-Gateway-Protocol-BGP）" class="headerlink" title="边界网关协议（Border Gateway Protocol, BGP）"></a>边界网关协议（Border Gateway Protocol, BGP）</h2><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241127125154032.png" alt="image-20241127125154032"></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241127125208832.png" alt="image-20241127125208832"></p>
<h2 id="向路由选择协议提供服务的实体"><a href="#向路由选择协议提供服务的实体" class="headerlink" title="向路由选择协议提供服务的实体"></a>向路由选择协议提供服务的实体</h2><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241127125231763.png" alt="image-20241127125231763"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/default/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/default/">1</a><span class="page-number current">2</span><a class="page-number" href="/default/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/default/page/8/">8</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/default/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2023 – 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">碎梦</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/scatteredream" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
