<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 5.4.2">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&family=Arvo:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&family=JetBrains+Mono:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"scatteredream.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":true,"version":"8.23.0","exturl":false,"sidebar":{"position":"right","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"flat"},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js" defer></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="scatteredream&#39;s blog">
<meta property="og:url" content="http://scatteredream.github.io/default/index.html">
<meta property="og:site_name" content="scatteredream&#39;s blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="碎梦">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://scatteredream.github.io/default/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"default/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>scatteredream's blog</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous" defer></script>
<script src="/js/third-party/search/local-search.js" defer></script>







  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">scatteredream's blog</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="碎梦"
      src="https://avatars.githubusercontent.com/u/62317679?s=400&v=4">
  <p class="site-author-name" itemprop="name">碎梦</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">60</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">170</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://scatteredream.github.io/2025/05/03/22408/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars.githubusercontent.com/u/62317679?s=400&v=4">
      <meta itemprop="name" content="碎梦">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="scatteredream's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | scatteredream's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/05/03/22408/" class="post-title-link" itemprop="url">22408</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2025-05-03 22:25:09 / 修改时间：22:25:45" itemprop="dateCreated datePublished" datetime="2025-05-03T22:25:09+08:00">2025-05-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%80%83%E7%A0%94/" itemprop="url" rel="index"><span itemprop="name">考研</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="22408"><a href="#22408" class="headerlink" title="22408"></a>22408</h1><p>转自：<a target="_blank" rel="noopener" href="https://blog.csdn.net/smilehappiness/article/details/109964058">考研公共部分科目分支分布以及计算机408分值分布-CSDN博客</a> </p>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>现在考研的竞争压力越来越大，这里，笔者也把考研中计算机的，408试卷分值分布做一个总结，方便以后考研的时候使用。</p>
<h2 id="计算机4科分值分配比"><a href="#计算机4科分值分配比" class="headerlink" title="计算机4科分值分配比"></a>计算机4科分值分配比</h2><table>
<thead>
<tr>
<th><strong>科目</strong></th>
<th><strong>大概分值</strong></th>
</tr>
</thead>
<tbody><tr>
<td>数据结构</td>
<td>45分</td>
</tr>
<tr>
<td>计算机组成原理</td>
<td>45分</td>
</tr>
<tr>
<td>操作系统</td>
<td>35分</td>
</tr>
<tr>
<td>计算机网络</td>
<td>25分</td>
</tr>
</tbody></table>
<h2 id="分值分析"><a href="#分值分析" class="headerlink" title="分值分析"></a>分值分析</h2><p><strong>408考试中，分值总分150分，大致题型以及分值如下（仅供参考）：</strong></p>
<h3 id="选择题-共80分"><a href="#选择题-共80分" class="headerlink" title="选择题 (共80分)"></a>选择题 (共80分)</h3><table>
<thead>
<tr>
<th>选择题</th>
<th>题目序号</th>
<th>分值</th>
</tr>
</thead>
<tbody><tr>
<td>数据结构</td>
<td>1~11</td>
<td>11X2=22分</td>
</tr>
<tr>
<td>计算机组成原理</td>
<td>12~22</td>
<td>11X2=22分</td>
</tr>
<tr>
<td>操作系统</td>
<td>23~32</td>
<td>10X2=20分</td>
</tr>
<tr>
<td>计算机网络</td>
<td>33~40</td>
<td>8X2=16分</td>
</tr>
</tbody></table>
<h3 id="综合应用题-共70分"><a href="#综合应用题-共70分" class="headerlink" title="综合应用题 (共70分)"></a>综合应用题 (共70分)</h3><p>一共有41、42、43、44 、45、46 、47，共七个大题，<code>总分值70分</code><br><strong>21年考研大题41~47分值分布依次为：</strong>15、8、15、8、7、8、9</p>
<p>正在备考的童鞋们，根据以上的分支分布，可以做一下复习侧重点呦</p>
<h2 id="其他公共科目"><a href="#其他公共科目" class="headerlink" title="其他公共科目"></a>其他公共科目</h2><h3 id="英语二分值分布"><a href="#英语二分值分布" class="headerlink" title="英语二分值分布"></a>英语二分值分布</h3><p>英语二试题分四部分，共48题，总计<code>100分</code>，包括<code>英语知识运用</code>、<code>阅读理解</code>、<code>英译汉</code>和<code>写作</code>。</p>
<p><strong>表格速览：</strong></p>
<table>
<thead>
<tr>
<th>题目类型</th>
<th>题目序号</th>
<th>分值</th>
</tr>
</thead>
<tbody><tr>
<td>英语知识运用</td>
<td>1~20</td>
<td>20X0.5=<code>10分</code></td>
</tr>
<tr>
<td>阅读理解</td>
<td>21~45</td>
<td>25X2=<code>50分</code></td>
</tr>
<tr>
<td>英译汉</td>
<td>第三部分</td>
<td><code>15分</code></td>
</tr>
<tr>
<td>作文</td>
<td>第四部分</td>
<td><code>25分</code></td>
</tr>
</tbody></table>
<h4 id="第一部分（英语知识运用）"><a href="#第一部分（英语知识运用）" class="headerlink" title="第一部分（英语知识运用）"></a>第一部分（英语知识运用）</h4><p>主要考查考生对英语知识的综合运用能力。共<code>20</code>小题，每小题<code>0.5</code>分，<code>共10分</code>。</p>
<p>在一篇约350词的文章中留出20个空白，要求考生从每题给出的4个选项中选出最佳答案，使补全后的文章意思通顺、前后连贯、结构完整。</p>
<h4 id="第二部分（阅读理解）"><a href="#第二部分（阅读理解）" class="headerlink" title="第二部分（阅读理解）"></a>第二部分（阅读理解）</h4><p>主要考查考生获取信息、理解文章、猜测重要生词词义并进行推断等方面的能力。该部分<code>由A、B两节组成</code>，共<code>25</code>小题，每小题<code>2</code>分，共<code>50</code>分。</p>
<ul>
<li><p><strong>A节(20小题)</strong><br>本部分为多项选择题。<code>共四篇文章</code>，总长度为1500词左右。<code>每篇文章设5题，共20题</code>。每小题2分，共40分。</p>
</li>
<li><p><strong>B节(5小题)</strong><br>本部分有两种备选题型。每次考试从这两种题型中选择其中的一种形式，或者两种形式的组合进行考查。本节文章设<code>5小题</code>，每小题2分，<code>共10分</code>。</p>
<p>备选题型包括：<br><strong>1)多项对应</strong><br>本部分为一篇长度为450~550词的文章，试题内容分为左右两栏，左侧一栏为5道题目，右侧一栏为7个选项。要求考生在阅读后根据文章内容和左侧一栏中提供的信息从右侧一栏中的7个选项中选出对应的5项相关信息。</p>
<p><strong>2)小标题对应</strong><br>在一篇长度为450~550词的文章前有7个概括句或小标题。这些文字或标题分别是对文章中某一部分的概括或阐述。要求考生根据文章内容和篇章结构从这7个选项中选出最恰当的5个概括句或小标题填入文章空白处。</p>
</li>
</ul>
<h4 id="第三部分（英译汉）"><a href="#第三部分（英译汉）" class="headerlink" title="第三部分（英译汉）"></a>第三部分（英译汉）</h4><p>要求考生阅读、理解长度为150词左右的一个或几个英语段落，并将其全部译成汉语，<code>共15分</code>。</p>
<h4 id="第四部分（写作）"><a href="#第四部分（写作）" class="headerlink" title="第四部分（写作）"></a>第四部分（写作）</h4><p>该部分由<code>A、B</code>两节组成，主要考查考生的书面表达能力。<code>共2题</code>，<code>25分</code>。</p>
<ul>
<li><strong>A节</strong><br>考生根据所给情景写出约100词(标点符号不计算在内)的应用性短文，包括私人和公务信函（常见的有：）、备忘录、报告等。共10分。</li>
</ul>
<p><strong>大致分类如下：</strong><br><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/8c5d133eb5d9b1deaa794f4441f60b77.png" alt="在这里插入图片描述"></p>
<ul>
<li><strong>B节</strong><br>要求考生根据所规定的情景或给出的提纲，写出一篇150词左右的英语说明文或议论文。提供情景的形式为图画、图表或文字。共15分。</li>
</ul>
<h3 id="政治分值分布"><a href="#政治分值分布" class="headerlink" title="政治分值分布"></a>政治分值分布</h3><p>政治部分分值，总共<code>100</code>分。</p>
<table>
<thead>
<tr>
<th>题目类型</th>
<th>题目序号</th>
<th>分值</th>
</tr>
</thead>
<tbody><tr>
<td>单项选择题</td>
<td>1~16</td>
<td>16X1=<code>16分</code></td>
</tr>
<tr>
<td>多项选择题</td>
<td>17~33</td>
<td>17X2=<code>34分</code></td>
</tr>
<tr>
<td>材料分析题</td>
<td>共5个大题</td>
<td>10X5=<code>50分</code></td>
</tr>
</tbody></table>
<h3 id="数学二分值分布"><a href="#数学二分值分布" class="headerlink" title="数学二分值分布"></a>数学二分值分布</h3><p>数学部分分值，总共<code>150</code>分。</p>
<table>
<thead>
<tr>
<th>题目类型</th>
<th>题目序号</th>
<th>分值</th>
</tr>
</thead>
<tbody><tr>
<td>单项选择题</td>
<td>1~10</td>
<td>10X5=<code>50分</code></td>
</tr>
<tr>
<td>填空题</td>
<td>11~16</td>
<td>16X5=<code>30分</code></td>
</tr>
<tr>
<td>大题</td>
<td>共6个大题</td>
<td>1X10 + 5X12=<code>70分</code></td>
</tr>
</tbody></table>
<p><strong>参考资料</strong>：<a target="_blank" rel="noopener" href="https://zhidao.baidu.com/question/12821750.html">https://zhidao.baidu.com/question/12821750.html</a></p>
<p><code>注意：</code> <strong>以上总结仅供参考，实际还是以实际的考卷分值分布为准</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">希望笔者总结的分值分布，对小伙伴有所帮助~</span><br></pre></td></tr></table></figure>

<blockquote>
<p>写博客是为了记住自己容易忘记的东西，另外也是对自己工作的总结，希望尽自己的努力，做到更好，大家一起努力进步！</p>
<p>如果有什么问题，欢迎大家评论，一起探讨</p>
<p>给自己的梦想添加一双翅膀，让它可以在天空中自由自在的飞翔！</p>
</blockquote>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://scatteredream.github.io/2025/05/01/%E5%8D%8E%E4%B8%BA%E4%B8%80%E9%9D%A2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars.githubusercontent.com/u/62317679?s=400&v=4">
      <meta itemprop="name" content="碎梦">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="scatteredream's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | scatteredream's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/05/01/%E5%8D%8E%E4%B8%BA%E4%B8%80%E9%9D%A2/" class="post-title-link" itemprop="url">4.30 华为一面+主管面</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-05-01 00:00:00" itemprop="dateCreated datePublished" datetime="2025-05-01T00:00:00+08:00">2025-05-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-05-03 23:32:20" itemprop="dateModified" datetime="2025-05-03T23:32:20+08:00">2025-05-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/review/" itemprop="url" rel="index"><span itemprop="name">review</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><strong>华为 半导体业务部 通用软件开发工程师 暑期实习</strong> </p>
<p>3.28投递 4.9笔试 4.30 一面 主管面</p>
<p>一面：</p>
<ul>
<li>自我介绍。</li>
<li>介绍一下项目中遇到的难点？答得不好。</li>
<li>数组和链表的区别？</li>
<li>队列和栈的区别？两个队列能否实现栈？</li>
<li>手撕（寻找缺失的第一个正整数）</li>
<li>复盘笔试</li>
<li>c语言宏定义的求两个数之间的大数怎么办？（c语言忘得差不多了）</li>
<li>反问：</li>
<li>实习生如何培养的？</li>
<li>部门主要用什么语言开发的？（c，不过都会有对应的培训）</li>
<li>您对我的面试有什么建议？（处女面，太紧张了脱口而出，不然没话聊了）</li>
</ul>
<p>主管面：</p>
<ul>
<li>你们专业主要学什么？</li>
<li>绩点排名怎样？保研还是考研？</li>
<li>英语水平怎么样？</li>
<li>现在数学是不是比以前难很多？</li>
<li>反问</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://scatteredream.github.io/2025/02/03/rpc-interpretation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars.githubusercontent.com/u/62317679?s=400&v=4">
      <meta itemprop="name" content="碎梦">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="scatteredream's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | scatteredream's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/02/03/rpc-interpretation/" class="post-title-link" itemprop="url">基于 Netty 的 RPC 框架</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-02-03 00:00:00" itemprop="dateCreated datePublished" datetime="2025-02-03T00:00:00+08:00">2025-02-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-05-02 00:57:46" itemprop="dateModified" datetime="2025-05-02T00:57:46+08:00">2025-05-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E9%A1%B9%E7%9B%AE/" itemprop="url" rel="index"><span itemprop="name">项目</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="基于-Netty-的-RPC-框架"><a href="#基于-Netty-的-RPC-框架" class="headerlink" title="基于 Netty 的 RPC 框架"></a>基于 Netty 的 RPC 框架</h1><p>实现要点： </p>
<ul>
<li>实现了 Netty <a href="#%E5%BF%83%E8%B7%B3%E6%9C%BA%E5%88%B6">心跳机制</a>，保持连接。客户端<a href="#%E6%8C%87%E6%95%B0%E9%80%80%E9%81%BF">指数退避</a>重试连接，服务端用线程池处理请求。可选 HTTP 和 Socket。</li>
<li>实现了自定义 RPC <a href="#protocol">通信协议</a>，<a href="#codec">自定义编解码器和拆包解码器</a>解决粘包和半包，实现了 Kryo 等5种<a href="#serialization">序列化方式</a>。</li>
<li><a href="#center">注册中心</a>支持 Nacos 与 Zookeeper，服务发现支持本地缓存、实时监听。除利用健康检查机制外，下线服务还会主动通知注册中心注销，实现优雅下线。支持一致性哈希等3种<a href="#loadbalance">负载均衡</a>算法。</li>
<li>集成 SpringBoot。通过<a href="#annotation">自定义注解</a>，提供者自动扫描并注册服务 Bean，消费者自动注入<a href="#proxy">代理对象</a>。自定义 starter 实现<a href="#autoconfig">自动装配</a>。</li>
<li>参考 Dubbo 实现 <a href="#spi">SPI</a>，支持<a href="#spi1">序列化</a>、<a href="#spi2">服务发现</a>等的动态扩展，实现与类型解耦的<a href="#cache">单例缓存</a>，减少大量冗余的对象创建。</li>
</ul>
<h2 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h2><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/项目架构图.png" alt="项目架构图" style="zoom:67%;" />

<p><code>consumer</code>模块：服务的消费者，依赖于 <code>rpc-client-spring-boot-starter</code> 模块；</p>
<p><code>provider-api</code>模块：服务提供者暴露的API；</p>
<p><code>provider</code>模块：服务的提供者，依赖于 <code>rpc-server-spring-boot-starter</code> 模块：</p>
<p><code>rpc-client-spring-boot</code>模块：rpc 客户端模块，封装客户端发起的请求过程，提供服务发现、动态代理，网络通信等功能；</p>
<p><code>rpc-client-spring-boot-stater</code>模块：是<code>rpc-client-spring-boot</code>的stater模块，负责引入相应依赖进行自动配置；</p>
<p><code>rpc-framework-core</code>模块：是rpc核心依赖，提供负载均衡、服务注册发现、消息协议、消息编码解码、序列化算法；</p>
<p><code>rpc-server-spring-boot</code>模块：rpc 服务端模块，负责启动服务，接受和处理RPC请求，提供服务发布、反射调用等功能；</p>
<p><code>rpc-server-spring-boot-stater</code>模块：是<code>rpc-server-spring-boot</code>的stater模块，负责引入相应依赖进行自动配置；</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/02/03/rpc-interpretation/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://scatteredream.github.io/2025/01/24/OSTEP%20Concurrency/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars.githubusercontent.com/u/62317679?s=400&v=4">
      <meta itemprop="name" content="碎梦">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="scatteredream's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | scatteredream's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/01/24/OSTEP%20Concurrency/" class="post-title-link" itemprop="url">并发</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-01-24 00:00:00" itemprop="dateCreated datePublished" datetime="2025-01-24T00:00:00+08:00">2025-01-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-05-03 21:08:55" itemprop="dateModified" datetime="2025-05-03T21:08:55+08:00">2025-05-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/OS/" itemprop="url" rel="index"><span itemprop="name">OS</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h1><h2 id="Thread-A-New-Executor"><a href="#Thread-A-New-Executor" class="headerlink" title="Thread: A New Executor"></a>Thread: A New Executor</h2><h3 id="Different-from-Process"><a href="#Different-from-Process" class="headerlink" title="Different from Process"></a>Different from Process</h3><p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Concurrency.assets/image-20241221230956042.png" alt="image-20241221230956042"></p>
<p>线程和进程最大的区别是，线程之间可以共享地址空间，因此线程的上下文切换不需要切换页表，但是每个线程都有独立的执行栈，它们分散在整个地址空间中，任何有关线程执行相关的信息都存在线程的执行栈——线程本地存储(TLS, Thread Local Storage)中。</p>
<ol>
<li><strong>进程是容器</strong>：一个进程可以包含<strong>一个或多个线程</strong>。线程依赖于进程，不能独立存在。</li>
<li><strong>线程属于进程</strong>：线程是进程的一部分，所有线程共享该进程的资源，如代码段、数据段和打开的文件等。</li>
<li><strong>进程管理资源，线程执行任务</strong>：进程管理资源和环境，而线程负责实际计算和操作。</li>
</ol>
<h3 id="Why-Threads"><a href="#Why-Threads" class="headerlink" title="Why Threads?"></a>Why Threads?</h3><p>事实证明，您应该使用线程至少有两个主要原因。</p>
<p>第一个很简单：==并行性==。想象一下，您正在编写一个对非常大的数组执行操作的程序，例如，将两个大数组相加，或者将数组中每个元素的值增加一定量。如果仅在单个处理器上运行，则任务很简单：只需执行每个操作即可完成。 如果在具有多个处理器的系统上执行程序，则可以通过使用每个处理器执行一部分工作来显著加快此过程。将标准单线程程序转换为在多个 CPU 上执行此类工作的程序的任务称为并行化，并且使用每个 CPU 的线程来执行此工作是使程序运行的自然而典型的方法在现代硬件上速度更快。</p>
<p>第二个原因有点微妙：避免由于 I/O 缓慢而**==阻塞程序进度==**。想象一下，您正在编写一个执行不同类型 I/O 的程序：等待发送或接收消息、等待显式磁盘 I/O 完成，甚至（隐式）等待页面错误完成。您的程序可能不想等待，而是希望做其他事情，包括利用 CPU 执行计算，甚至发出进一步的 I/O 请求。使用线程是避免阻塞的自然方法；当程序中的一个线程等待时（即被阻塞等待 I/O），CPU 调度程序可以切换到其他线程，这些线程已准备好运行并执行一些有用的操作。线程允许 I/O 与单个程序中的其他活动重叠，就像多道程序设计对跨程序的进程所做的那样；因此，许多现代基于服务器的应用程序（Web 服务器、数据库管理系统等）在其实现中都使用了线程。</p>
<p>当然，在上述任何一种情况下，您都可以使用多个进程而不是线程。然而，**==线程共享地址空间==<strong>，因此可以轻松共享数据，因此是构建这些类型的程序时的自然选择，</strong>==线程更加轻量==**，切换成本没有那么高。对于逻辑上独立的任务来说，进程是一个更合理的选择，因为这些任务几乎不需要共享内存中的数据结构。</p>
<h3 id="Problems"><a href="#Problems" class="headerlink" title="Problems"></a>Problems</h3><p>一、不可控调度引发的问题：</p>
<ol>
<li>临界区(critical section): 多个任务共享的一片区域</li>
<li>竞态条件(race condition): 多个任务几乎同时读取一片区域，并做了修改，结果不符合预期</li>
<li>不确定性(indeterminate)：多个竞态条件组成程序，导致结果不确定</li>
<li>解决方案：注重原子性<ul>
<li>线程使用互斥(mutex exclusion)原语，保证同时只有一个任务进入临界区修改，避免竞态</li>
<li>原语：若干条指令组成的程序段，用来实现某个特定功能，在执行过程中不可被中断</li>
<li>在<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/192?fromModule=lemma_inlink">操作系统</a>中，某些被进程调用的操作，如队列操作、对信号量的操作、检查启动外设操作等，一旦开始执行，就不能被中断，否则就会出现操作错误，造成系统混乱。</li>
</ul>
</li>
</ol>
<p>二、任务之间应该如何唤醒对方？</p>
<h2 id="POSIX-Thread-API"><a href="#POSIX-Thread-API" class="headerlink" title="POSIX Thread API"></a>POSIX Thread API</h2><h3 id="Structured-“fork-join”-Parallelism"><a href="#Structured-“fork-join”-Parallelism" class="headerlink" title="Structured (“fork-join”) Parallelism"></a>Structured (“fork-join”) Parallelism</h3><h4 id="Compile-and-Run-pthread"><a href="#Compile-and-Run-pthread" class="headerlink" title="Compile and Run: -pthread"></a>Compile and Run: <code>-pthread</code></h4><p>在链接行上，您还必须通过添加 <code>-pthread</code> 标志来显式动态链接 pthreads 库。</p>
<p><code>prompt&gt; gcc -o thread thread.c -Wall -pthread</code> </p>
<p><code>prompt&gt; gcc thread.c -o thread -lpthread</code> </p>
<p>并且要在源码中加入 <code>pthread.h</code></p>
<h4 id="Creation-pthread-create"><a href="#Creation-pthread-create" class="headerlink" title="Creation: pthread_create()"></a>Creation: <code>pthread_create()</code></h4><p><code>create</code>:</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">pthread_create</span><span class="params">(<span class="type">pthread_t</span> *thread,</span></span><br><span class="line"><span class="params">                   <span class="type">const</span> <span class="type">pthread_attr_t</span> *attr,</span></span><br><span class="line"><span class="params">                   <span class="type">void</span> *(*start_routine)(<span class="type">void</span>*),</span></span><br><span class="line"><span class="params">                   <span class="type">void</span> *arg)</span>;</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>参数说明</strong>：<ul>
<li><code>thread</code> 是一个 <code>pthread_t</code> 类型的指针，也就是待初始化的线程指针</li>
<li><code>attr</code> 用来配置这个线程的属性，比如栈大小，线程调度优先级，默认可以为 <code>NULL</code></li>
<li><code>start_routine</code> 是函数指针,,前面是返回值类型，后面是参数类型及个数</li>
<li><code>void *</code> 可以代表任何类型的参数/返回值， <code>arg</code> 和 <code>start_routine</code> 参数类型一致</li>
</ul>
</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    <span class="type">int</span> a;</span><br><span class="line">    <span class="type">int</span> b;</span><br><span class="line">&#125; <span class="type">myarg_t</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> *<span class="title function_">mythread</span><span class="params">(<span class="type">void</span> *arg)</span> &#123;</span><br><span class="line">    <span class="type">myarg_t</span> *args = (<span class="type">myarg_t</span> *) arg;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d %d\n&quot;</span>, args-&gt;a, args-&gt;b);</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *argv[])</span> &#123;</span><br><span class="line">    <span class="type">pthread_t</span> p;</span><br><span class="line">    <span class="type">myarg_t</span> args = &#123; <span class="number">10</span>, <span class="number">20</span> &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> rc = pthread_create(&amp;p, <span class="literal">NULL</span>, mythread, &amp;args);</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们只是创建一个传递两个参数的线程，并将其打包成我们自己定义的单个类型（<code>myarg t</code>）</p>
<p>线程一旦创建，就可以简单地将其参数转换为它期望的类型，从而根据需要解压参数。</p>
<p>创建线程后，您实际上拥有另一个实时的执行实体，具有自己的调用堆栈，与程序中所有当前现有线程在同一地址空间中运行。 </p>
<h4 id="Completion-pthread-join"><a href="#Completion-pthread-join" class="headerlink" title="Completion: pthread_join()"></a>Completion: <code>pthread_join()</code></h4><p><strong><code>join</code></strong>:</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">pthread_join</span><span class="params">(<span class="type">pthread_t</span> thread, <span class="type">void</span> **value_ptr)</span>;</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>参数说明</strong>：<ul>
<li> <code>thread</code> 用于指定要等待哪个线程。该变量由线程创建例程初始化（当您将指向它的指针作为参数传递给 <code>pthread_create()</code> 时）；如果保留，则可以使用它等待线程终止。</li>
<li><code>value_ptr</code> 是指向 指向期望返回值的指针 的二级指针，因为还没返回，只能传进去一个指针变量，<code>join</code>修改指针就需要传二级指针</li>
</ul>
</li>
</ul>
<p>Usage: </p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span> <span class="type">int</span> a; <span class="type">int</span> b; &#125; <span class="type">myarg_t</span>;</span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span> <span class="type">int</span> x; <span class="type">int</span> y; &#125; <span class="type">myret_t</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> *<span class="title function_">mythread</span><span class="params">(<span class="type">void</span> *arg)</span> &#123;</span><br><span class="line">    <span class="comment">// 这里用的是包装函数，首字母大写，用来应对可能发生的异常</span></span><br><span class="line">    <span class="type">myret_t</span> *rvals = Malloc(<span class="keyword">sizeof</span>(<span class="type">myret_t</span>));</span><br><span class="line">    rvals-&gt;x = <span class="number">1</span>;</span><br><span class="line">    rvals-&gt;y = <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">return</span> (<span class="type">void</span> *) rvals;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *argv[])</span> &#123;</span><br><span class="line">    <span class="type">pthread_t</span> p;</span><br><span class="line">    <span class="type">myret_t</span> *rvals;</span><br><span class="line">    <span class="type">myarg_t</span> args = &#123; <span class="number">10</span>, <span class="number">20</span> &#125;;</span><br><span class="line">    <span class="comment">// 这里用的是包装函数，首字母大写，用来应对可能发生的异常</span></span><br><span class="line">    Pthread_create(&amp;p, <span class="literal">NULL</span>, mythread, &amp;args);</span><br><span class="line">    Pthread_join(p, (<span class="type">void</span> **) &amp;rvals);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;returned %d %d\n&quot;</span>, rvals-&gt;x, rvals-&gt;y);</span><br><span class="line">    <span class="built_in">free</span>(rvals);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在代码中，再次创建单个线程，并通过 <code>myarg_t</code> 结构传递几个参数。要返回值，请使用 <code>myret_t</code> 类型。一旦线程完成运行，一直在 <code>pthread_join()</code> 例程1内等待的主线程就会返回，我们可以访问从线程返回的值，即 <code>myret_t</code> 中的任何内容。 </p>
<p>关于这个例子有几点需要注意：</p>
<ol>
<li><p>首先，很多时候我们不必进行所有这些痛苦的参数打包和拆包。例如，如果我们只是创建一个不带参数的线程，则可以在创建线程时将 <code>NULL</code> 作为参数传入。类似地，如果我们不关心返回值，我们可以将 <code>NULL</code> 传递给 <code>pthread_join()</code>。</p>
</li>
<li><p>```c<br>void *mythread(void *arg) {</p>
<pre><code>long long int value = (long long int) arg;
printf(&quot;%lld\n&quot;, value);
return (void *) (value + 1);
</code></pre>
<p>}<br>int main(int argc, char *argv[]) {</p>
<pre><code>pthread_t p;
long long int rvalue;
Pthread_create(&amp;p, NULL, mythread, (void *) 100);
Pthread_join(p, (void **) &amp;rvalue);
printf(&quot;returned %lld\n&quot;, rvalue);
return 0;
</code></pre>
<p>}</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">   如上图，如果我们只是传递单个值（例如，`long long int`），则不必将其打包为参数。在这种情况下，我们不必将参数和返回值打包在结构体内部。  </span><br><span class="line"></span><br><span class="line">3. ```c</span><br><span class="line">   void *mythread(void *arg) &#123;</span><br><span class="line">       myarg_t *args = (myarg_t *) arg;</span><br><span class="line">       printf(&quot;%d %d\n&quot;, args-&gt;a, args-&gt;b);</span><br><span class="line">       myret_t oops; // ALLOCATED ON STACK: BAD!</span><br><span class="line">       oops.x = 1;</span><br><span class="line">       oops.y = 2;</span><br><span class="line">       return (void *) &amp;oops;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<p>如上图，必须非常小心线程的返回值，永远不要**<u>返回指向线程栈上分配的内容的指针</u>**，因为栈随着函数返回，空间也会自动释放，<code>oops</code>返回的指针指向的是一片不确定区域。</p>
</li>
<li><p>这种 fork-join 式的多线程编程方式是较为普遍的结构化编程方法。但我们应该注意，并非所有多线程代码都使用 <code>join</code> 例程。例如，多线程 Web 服务器可能会创建多个工作线程，然后使用主线程无限期地接受请求并将它们传递给工作线程。因此，此类长期计划可能不需要加入。然而，创建线程来执行特定任务（并行）的并行程序可能会使用 <code>join</code> 来确保所有此类工作在退出或进入下一个计算阶段之前完成。</p>
</li>
</ol>
<h4 id="Mutex-lock-unlock"><a href="#Mutex-lock-unlock" class="headerlink" title="Mutex: lock() unlock()"></a>Mutex: <code>lock()</code> <code>unlock()</code></h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">pthread_mutex_t</span> lock;  <span class="comment">// lock is here</span></span><br><span class="line">pthread_mutex_lock(&amp;lock);  <span class="comment">// LOCK</span></span><br><span class="line">... <span class="comment">// critical section</span></span><br><span class="line">pthread_mutex_unlock(&amp;lock);<span class="comment">// UNLOCK</span></span><br></pre></td></tr></table></figure>

<p>整体结构如上，但是缺乏正确的初始化和各种细节：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">pthread_mutex_t</span> lock = PTHREAD_MUTEX_INITIALIZER;<span class="comment">// 宏，设置为默认的值</span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> rc = pthread_mutex_init(&amp;lock, <span class="literal">NULL</span>);</span><br><span class="line">assert(rc == <span class="number">0</span>); <span class="comment">// always check success!</span></span><br><span class="line">Pthread_mutex_lock(lock);</span><br><span class="line">...</span><br><span class="line">Pthread_mutex_unlock(lock);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Keeps code clean; only use if exit() OK upon failure 包装</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">Pthread_mutex_lock</span><span class="params">(<span class="type">pthread_mutex_t</span> *mutex)</span> &#123;</span><br><span class="line">    <span class="type">int</span> rc = pthread_mutex_lock(mutex);</span><br><span class="line">    assert(rc == <span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><code>int pthread_mutex_init(pthread_mutex_t *mutex, pthread_mutexattr_t)</code>: <ul>
<li><code>pthread_mutexattr_t</code>: 具体的参数设置，可以使用 <code>NULL</code> 作为缺省选项</li>
</ul>
</li>
<li><code>int pthread_mutex_destroy(pthread_mutex_t *mutex)</code>: <ul>
<li>销毁一个已经初始化但未上锁的互斥锁是安全的。</li>
<li>使用完锁资源需要释放 (RAII 的思想) ，只能是被释放，不再被争抢，不再被需要时才可以</li>
</ul>
</li>
</ul>
<p>改进：增加适当的检测错误机制，健壮的程序需要能够应对调用失败的情况（断言）</p>
<p><strong>还有其他与锁交互的例程</strong>：</p>
<ul>
<li><code>int pthread_mutex_trylock(pthread_mutex_t *mutex)</code> 只尝试一次，non-blocking</li>
<li><code>int pthread_mutex_timedlock(pthread_mutex_t *mutex, timespec *tsptr)</code> 尝试一段时间，如果等一段时间获取不到锁就直接返回 <code>ETIMEOUT</code> </li>
</ul>
<h4 id="Condition-Variables-wait-signal"><a href="#Condition-Variables-wait-signal" class="headerlink" title="Condition Variables: wait() signal()"></a>Condition Variables: <code>wait()</code> <code>signal()</code></h4><h5 id="Thread-Interaction"><a href="#Thread-Interaction" class="headerlink" title="Thread Interaction"></a>Thread Interaction</h5><p><code>int pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex)</code></p>
<ul>
<li>使调用的线程休眠，等待唤醒(通常是在程序中的某些内容发生更改，使某个条件发生了变化，而使得 wait 处于的 while 循环条件发生了变化)</li>
<li>您可能会注意到等待调用将 <code>mutex</code> 作为其第二个参数，而 <code>signal</code> 不需要。造成这种差异的原因是 wait 调用除了使调用线程进入睡眠状态之外，还使调用者进入睡眠状态时释放锁。<ul>
<li>进入 wait 状态就会自动 release mutex。当其他线程通过<code>pthread_cond_signal()</code>或<code>pthread_cond_broadcast</code>，把该线程唤醒，之后需要重新获取 mutex 来进行之后的操作</li>
<li>1.将线程加入等待队列 2.将线程持有的锁先释放 这两个步骤必须是原子的</li>
</ul>
</li>
<li>被唤醒之后，从<code>wait</code>返回之前，还应该重新获取锁，防止竞态条件的发生</li>
</ul>
<p><code>int pthread_cond_signal(pthread_cond_t *cond)</code> </p>
<ul>
<li>一旦条件满足，**<code>pthread_cond_signal</code>** 函数可以被用来唤醒至少一个等待该条件(ready ==0)的线程，如果有多个线程阻塞在条件变量上，它们被唤醒的顺序由调度策略决定。</li>
<li>如果没有线程在条件变量上阻塞，调用 <strong><code>pthread_cond_signal</code></strong> ==将不会有任何效果==。</li>
<li>在实际应用中，**<code>pthread_cond_signal</code>** 通常用于<strong>生产者-消费者</strong>问题，其中生产者在添加了新项目后会通知消费者线程。此外，它也用于实现读写锁，以及在两阶段提交算法中通知所有客户端即将提交事务。</li>
<li><code>pthread_cond_broadcast()</code> 用于唤醒当前全部等待的线程</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">pthread_mutex_t</span> mutex = PTHREAD_MUTEX_INITIALIZER;</span><br><span class="line"><span class="type">pthread_cond_t</span> cond = PTHREAD_COND_INITIALIZER;</span><br><span class="line"><span class="type">int</span> ready = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 符合特定条件，进入睡眠</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">thread_function</span><span class="params">(<span class="type">void</span> *arg)</span> &#123;</span><br><span class="line">    pthread_mutex_lock(&amp;mutex);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (!ready) &#123;<span class="comment">//循环检查条件	</span></span><br><span class="line">    	pthread_cond_wait(&amp;cond, &amp;mutex);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 执行当条件满足时的操作</span></span><br><span class="line">    execute_task();</span><br><span class="line">    pthread_mutex_unlock(&amp;mutex);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/***************************************************/</span></span><br><span class="line"><span class="comment">// 改变条件之后，唤起正在等待的线程</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">signal_condition</span><span class="params">()</span> &#123;</span><br><span class="line">    pthread_mutex_lock(&amp;mutex);</span><br><span class="line">    </span><br><span class="line">    ready = <span class="number">1</span>;</span><br><span class="line">    pthread_cond_signal(&amp;cond);</span><br><span class="line">    </span><br><span class="line">    pthread_mutex_unlock(&amp;mutex);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="Simple-Flags"><a href="#Simple-Flags" class="headerlink" title="Simple Flags"></a>Simple Flags</h5><p>请注意，有时很容易使用简单的标志在两个线程之间发出信号，而不是使用条件变量和关联的锁。 例如，我们可以重写上面的等待代码，使其在等待代码中看起来更像这样：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// wait code:</span></span><br><span class="line"><span class="keyword">while</span> (ready == <span class="number">0</span>)</span><br><span class="line">; <span class="comment">// spin</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// notify code:</span></span><br><span class="line">ready = <span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<p><strong>永远不要这样做，原因如下</strong>:</p>
<p>首先，它在很多情况下表现不佳（长时间自旋浪费 CPU 周期）。</p>
<p>其次，容易出错。正如最近的研究表明 ，使用 FLAG 在线程之间进行同步时非常容易出错；在那项研究中，这些临时同步的使用中大约有一半是有问题的！不要偷懒；即使您认为不这样做也可以逃脱，也要使用条件变量。</p>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li><p>Keep simple. 任何在线程之间锁定或发出信号的代码都应该尽可能简单，避免复杂的线程交互</p>
</li>
<li><p><strong>最大限度减少线程交互方式</strong>，尝试将线程交互方式的数量保持在最低限度</p>
</li>
<li><p><strong>初始化</strong>锁和条件变量 (mutex and condition variables) <code>INITIALIZER</code></p>
</li>
<li><p>始终<strong>使用条件变量</strong>在线程之间发出信号。虽然使用简单的 <strong>FLAG</strong> 通常很诱人，但不要这样做</p>
</li>
<li><p>检查函数的<strong>返回码</strong>，比如断言失败导致的返回码会异常</p>
</li>
<li><p>如何向线程传递参数以及线程的返回值。比如<strong>不要返回 指向栈上变量的指针</strong> </p>
</li>
<li><p>每个线程都有<strong>自己的栈</strong>。如果线程正在执行的某个函数内部有一个局部分配的变量，那么它本质上是该<strong>线程私有</strong>的(Thread-Local)；没有其他线程可以（轻松）访问它。要在线程之间共享数据，值必须位于<strong>堆</strong>中或其他可全局访问的区域设置中。  </p>
</li>
</ul>
<h1 id="Locks"><a href="#Locks" class="headerlink" title="Locks"></a>Locks</h1><p>锁——程序员在 OS 调度的基础上实现对调度的最小控制，使调度的混乱状态变得更加可控</p>
<h2 id="Efficient-Lock"><a href="#Efficient-Lock" class="headerlink" title="Efficient Lock"></a>Efficient Lock</h2><ol>
<li>最基本的互斥(<strong>mut</strong>ual <strong>ex</strong>clusion)：能否在 OS 调度下，阻止多个线程同时进入临界区？</li>
<li>公平性(fairness)：是否会有线程始终无法竞争到锁(starvation)?</li>
<li>性能(performance)：在有竞争与没有竞争的情况下，抢锁、释放锁的开支如何？</li>
</ol>
<h2 id="Implementations"><a href="#Implementations" class="headerlink" title="Implementations"></a>Implementations</h2><ul>
<li>完全由软件实现的锁（✕）</li>
<li>硬件支持有更强大的原子指令 + 操作系统调用支持（✓）</li>
</ul>
<h3 id="Control-Interrupts"><a href="#Control-Interrupts" class="headerlink" title="Control Interrupts"></a>Control Interrupts</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">lock</span><span class="params">()</span> &#123;</span><br><span class="line">	DisableInterrupts();</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">unlock</span><span class="params">()</span> &#123;</span><br><span class="line">	EnableInterrupts();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>加锁：关中断</p>
<p>释放锁：开中断</p>
<ul>
<li><p>优点：实现简单，操作系统本身可能会采用这种方式保证访问自己数据结构的原子性</p>
</li>
<li><p>缺点</p>
</li>
</ul>
<ol>
<li>性能开销大：开关中断的指令耗时较长</li>
<li>丢失中断：关中断导致一些中断没有及时被 CPU 接收</li>
<li>调度失效：恶意程序一直运行，而时钟中断被屏蔽，操作系统的抢占式调度失效</li>
</ol>
<h3 id="Spin-Locks"><a href="#Spin-Locks" class="headerlink" title="Spin Locks"></a>Spin Locks</h3><h4 id="Set-flag-after-check"><a href="#Set-flag-after-check" class="headerlink" title="Set flag after check"></a>Set flag <strong>after</strong> check</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> __<span class="title">lock_t</span> &#123;</span> <span class="type">int</span> flag; &#125; <span class="type">lock_t</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">init</span><span class="params">(<span class="type">lock_t</span> *mutex)</span> &#123;</span><br><span class="line">    <span class="comment">// 0 -&gt; lock is available, 1 -&gt; held</span></span><br><span class="line">    mutex-&gt;flag = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// LOCK GAIN</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">lock</span><span class="params">(<span class="type">lock_t</span> *mutex)</span> &#123;</span><br><span class="line">    <span class="keyword">while</span> (mutex-&gt;flag == <span class="number">1</span>) <span class="comment">// TEST the flag</span></span><br><span class="line">    	; <span class="comment">// spin-wait (do nothing)</span></span><br><span class="line">    mutex-&gt;flag = <span class="number">1</span>; <span class="comment">// now SET it!</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">unlock</span><span class="params">(<span class="type">lock_t</span> *mutex)</span> &#123;</span><br><span class="line">    mutex-&gt;flag = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面是简单的 flag 实现的，先检验 FLAG 是否为 1，如果不是就将其设置为 1，否则就自旋等待</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Concurrency.assets/image-20241222220609945.png" alt="image-20241222220609945"></p>
<p>线程1第一次检验到锁是空闲的，于是想将flag设为1，但与此同时也已耗尽时间片，切换到线程2以后线程2依然试图获取锁，结果获取成功，耗尽时间片回到线程1，线程1竟然也成功获取到了锁！</p>
<h4 id="Test-and-Set-TAS"><a href="#Test-and-Set-TAS" class="headerlink" title="Test-and-Set(TAS)"></a>Test-and-Set(<strong>TAS)</strong></h4><p>导致失败的主要原因是检验Test与赋值Set这两个操作并不是原子化的，会出现只执行一半的情况</p>
<p>因此应该改进锁的实现，使用一个硬件原语：TAS(Atomic Exchange)</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">TestAndSet</span><span class="params">(<span class="type">int</span> *old_ptr, <span class="type">int</span> new)</span> &#123;</span><br><span class="line">    <span class="type">int</span> old = *old_ptr; <span class="comment">// fetch old value at old_ptr</span></span><br><span class="line">    *old_ptr = new; <span class="comment">// store ’new’ into old_ptr</span></span><br><span class="line">    <span class="keyword">return</span> old; <span class="comment">// return the old value</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">lock</span><span class="params">(<span class="type">lock_t</span> *lock)</span> &#123;</span><br><span class="line">	<span class="keyword">while</span> (TestAndSet(&amp;lock-&gt;flag, <span class="number">1</span>) == <span class="number">1</span>)</span><br><span class="line">		; <span class="comment">// spin-wait (do nothing)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其中 <code>TestAndSet()</code> 是一个原子命令，功能是：获取旧值，将其设置为新值，然后返回旧值。这三个一定会在一次操作内完成。如果检测到锁被占用，就会<strong>自旋</strong>等待，一旦锁被释放，检测返回值为0的同时将其设置为1，成功获取锁，原子命令要么全部成功要么全部失败。自旋锁（spin lock）需要抢占式调度，通过时钟进行线程的中断。</p>
<h4 id="CAS-LL-SC-and-FAA"><a href="#CAS-LL-SC-and-FAA" class="headerlink" title="CAS, LL-SC and FAA"></a><strong>CAS</strong>, LL-SC and FAA</h4><p><strong>Compare-And-Swap(CAS)</strong></p>
<p>x86 中也叫 Compare-And-Exchange(cmpxchg)</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">CompareAndSwap</span><span class="params">(<span class="type">int</span> *ptr, <span class="type">int</span> expected, <span class="type">int</span> new)</span>&#123;</span><br><span class="line">	<span class="type">int</span> actual = *ptr;</span><br><span class="line">	<span class="keyword">if</span> (actual == expected)&#123;</span><br><span class="line">		*ptr = new;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> actual;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">lock</span><span class="params">(<span class="type">lock_t</span> *lock)</span>&#123;</span><br><span class="line">    <span class="keyword">while</span>(CompareAndSwap(&amp;lock-&gt;flag, <span class="number">0</span>, <span class="number">1</span>) == <span class="number">1</span>)</span><br><span class="line">        ; <span class="comment">// spin-wait (do nothing)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>Load-Linked, Store-Conditional(LL-SC)</strong></p>
<p>MIPS, PowerPC, Alpha, ARM 都有类似功能的指令</p>
<figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Load_Linked(address): <span class="comment">// 读取某地址的值并将该地址标记为“保留地址”</span></span><br><span class="line">    value ← *address          <span class="comment">// 从地址中加载值</span></span><br><span class="line">    LL_reserved ← address      <span class="comment">// 设置保留的地址</span></span><br><span class="line">    <span class="keyword">return</span> value               <span class="comment">// 返回加载的值</span></span><br><span class="line">    </span><br><span class="line">Store_Conditional(address, value): </span><br><span class="line"><span class="comment">// 尝试将值存入地址，但前提是自 LL 设置保留后，该地址未被其他线程修改。</span></span><br><span class="line">    <span class="keyword">if</span> (LL_reserved == address) then  <span class="comment">// 检查是否仍然保留该地址</span></span><br><span class="line">        *address ← value              <span class="comment">// 将值存储到地址中</span></span><br><span class="line">        LL_reserved ← NULL            <span class="comment">// 清除保留状态</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>                      <span class="comment">// 存储成功</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>                      <span class="comment">// 存储失败</span></span><br></pre></td></tr></table></figure>

<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">lock</span><span class="params">(<span class="type">lock_t</span> *lock)</span>&#123;</span><br><span class="line">	<span class="keyword">do</span> &#123;</span><br><span class="line">        <span class="keyword">while</span>(LL(&amp;lock-&gt;flag) == <span class="number">1</span>);  <span class="comment">// 首先加载当前值并标记保留</span></span><br><span class="line">                 ; <span class="comment">//spin-wait</span></span><br><span class="line">    &#125; <span class="keyword">while</span> (SC(&amp;lock-&gt;flag, <span class="number">1</span>) == <span class="number">0</span>);  <span class="comment">// 如果存储失败，则重试</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">lock_boolean_short_circuiting</span><span class="params">(<span class="type">lock_t</span> *lock)</span>&#123;</span><br><span class="line">    <span class="keyword">while</span>(LL(&amp;lock-&gt;flag) || !SC(&amp;lock-&gt;flag, <span class="number">1</span>))  </span><br><span class="line">                 ; <span class="comment">//spin-wait</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol>
<li>A 和 B 都执行 <strong>LL</strong>，地址相同，但状态保存在各自寄存器中。</li>
<li>假设 A 先执行 <strong>SC</strong> 并成功，硬件会==清除== B 的保留状态。</li>
<li>B 执行 <strong>SC</strong> 时发现状态无效，返回失败并进入重试。</li>
</ol>
<p><strong>Fetch-and-Add(FAA)</strong></p>
<figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">FAA(address):</span><br><span class="line">    old_value = *address             <span class="comment">// 读取当前值</span></span><br><span class="line">    *address = old_value + <span class="number">1</span>         <span class="comment">// 增加指定值</span></span><br><span class="line">    <span class="keyword">return</span> old_value                 <span class="comment">// 返回旧值</span></span><br></pre></td></tr></table></figure>

<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">lock_t</span>&#123;</span></span><br><span class="line">    <span class="type">int</span> ticket;<span class="comment">//初始化为0</span></span><br><span class="line">    <span class="type">int</span> turn;<span class="comment">//初始化为0</span></span><br><span class="line">&#125; <span class="type">lock_t</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">lock</span><span class="params">(<span class="type">lock_t</span> *lock)</span>&#123;</span><br><span class="line">    <span class="type">int</span> myturn = FAA(&amp;lock-&gt;ticket);</span><br><span class="line">	<span class="keyword">while</span>(lock-&gt;turn != myturn)</span><br><span class="line">		;   <span class="comment">// spin-wait	</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">unlock</span><span class="params">(<span class="type">lock_t</span> *lock)</span>&#123;</span><br><span class="line">    FAA(&amp;lock-&gt;turn);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol>
<li>每个线程通过 <strong>FAA</strong> 获取一个唯一的排队号 (<strong>myturn</strong>)。</li>
<li>当前服务号 (<strong>ticket</strong>)表示哪个线程正在被服务。</li>
<li>线程不断检查自己的排队号是否等于当前服务号，只有匹配时才能获得锁。</li>
<li>解锁时，将服务号递增，以便下一个线程继续执行。</li>
<li>特性：实现了<strong>公平性</strong>，每个线程最终都有机会被服务，类似排队机制，按照来的先后顺序排队</li>
</ol>
<h4 id="Evaluating-Spin-Locks"><a href="#Evaluating-Spin-Locks" class="headerlink" title="Evaluating Spin Locks"></a>Evaluating Spin Locks</h4><ol>
<li><strong>正确性</strong>: 能够实现最基本的互斥功能，不会被操作系统的调度影响</li>
<li><strong>公平性</strong>: 实际上并不能保证一个竞争的线程一定能够拿到锁，可能会有饥饿的现象发生</li>
<li><strong>性能</strong>: 单核性能差，只有一个执行的单位，如果一个获取锁的线程刚进入临界区就被抢占，那么直到此线程再次被调度之前，其他的等待者必须轮流自旋一整个时间片；而多核环境下，由于是各个线程物理上并行执行(parallel)，因此获取到锁的线程很快就会执行完并释放锁给别人。</li>
</ol>
<h5 id="Priority-Inversion"><a href="#Priority-Inversion" class="headerlink" title="Priority Inversion"></a>Priority Inversion</h5><p>自旋锁适合<strong>短时间的临界区操作</strong>，但不适合长时间持有锁的场景。在等待锁释放时，线程会<strong>忙等待（busy-waiting）</strong>，一直循环检查锁状态，而不会主动放弃 CPU。</p>
<p><strong>高优先级线程 A</strong>：需要自旋锁资源。</p>
<p><strong>低优先级线程 C</strong>：当前持有自旋锁资源。</p>
<p><strong>中优先级线程 B</strong>：占用 CPU 时间，导致 C 无法执行。</p>
<ol>
<li><strong>C 获得锁</strong>并进入临界区，但是此时被更高优先级的 A 抢占。</li>
<li><strong>A 尝试获取锁</strong>，但由于 C 持有锁，A 进入自旋状态忙等待。</li>
<li><strong>B 开始运行</strong>，其优先级高于 C，导致 C 仍然无法继续执行，因此也无法释放锁。</li>
<li><strong>A 等待 C 释放锁，但 C 被 B 抢占</strong> </li>
<li><strong>结果：高优先级的 A 无法执行，但是更低优先级的 B 反而能够顺利执行，优先级反转发生。</strong></li>
</ol>
<p><strong>解决方案：</strong></p>
<p><strong>(1) 优先级继承机制</strong>(Priority inheritance)</p>
<ul>
<li><strong>原理：</strong> 当低优先级线程持有锁，而高优先级线程请求锁时，系统会<strong>临时提高低优先级线程的优先级</strong>到高优先级线程的级别。</li>
<li><strong>效果：</strong> 确保低优先级线程尽快运行并释放锁，防止高优先级线程长期等待。</li>
<li><strong>应用：</strong> 常用于<strong>互斥锁 (mutex)</strong> 中，但自旋锁通常不支持该机制。</li>
</ul>
<p><strong>(2) 使用互斥锁替代自旋锁</strong></p>
<ul>
<li><strong>互斥锁会主动挂起等待线程</strong>，释放 CPU 给其他任务，提高资源调度效率。</li>
<li>适合可能存在较长等待时间的临界区操作，避免忙等待浪费资源。</li>
</ul>
<p><strong>(3) 控制自旋时间或自旋次数</strong></p>
<ul>
<li>设置自旋锁的最大等待时间或循环次数，超过后将线程挂起，而不是一直忙等待。</li>
<li>在 Linux 内核中，可通过**<code>spin_trylock()</code><strong>或</strong>自旋锁超时机制**控制。</li>
</ul>
<p><strong>(4) 避免中间优先级线程干扰，或取消优先级差异</strong></p>
<h3 id="Sleep"><a href="#Sleep" class="headerlink" title="Sleep"></a>Sleep</h3><h4 id="Yield"><a href="#Yield" class="headerlink" title="Yield"></a>Yield</h4><p>改进自旋锁：如果获取不到锁就立即让出 CPU (yield)</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">init</span><span class="params">()</span> &#123;</span><br><span class="line">	flag = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">lock</span><span class="params">()</span> &#123;</span><br><span class="line">	<span class="keyword">while</span> (TestAndSet(&amp;flag, <span class="number">1</span>) == <span class="number">1</span>)</span><br><span class="line">		yield(); <span class="comment">// give up the CPU</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">unlock</span><span class="params">()</span> &#123;</span><br><span class="line">	flag = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>缺点</strong>: <strong>容易受操作系统的调度影响</strong>，可能导致有线程被饿死，并且如果锁的拥有者在进入临界区之后被调度走，其他程序必须反复执行 运行-&gt;让出 的循环，上下文切换成本也不容忽视</p>
<h4 id="Queue-amp-Park-Solaris"><a href="#Queue-amp-Park-Solaris" class="headerlink" title="Queue &amp; Park(Solaris)"></a>Queue &amp; Park(Solaris)</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> __<span class="title">lock_t</span> &#123;</span></span><br><span class="line">    <span class="type">int</span> flag;</span><br><span class="line">    <span class="type">int</span> guard;</span><br><span class="line">    <span class="type">queue_t</span> *q;</span><br><span class="line">&#125; <span class="type">lock_t</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">lock_init</span><span class="params">(<span class="type">lock_t</span> *m)</span> &#123;</span><br><span class="line">    m-&gt;flag = <span class="number">0</span>;</span><br><span class="line">    m-&gt;guard = <span class="number">0</span>;</span><br><span class="line">    queue_init(m-&gt;q);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">lock</span><span class="params">(<span class="type">lock_t</span> *m)</span> &#123;</span><br><span class="line">    <span class="keyword">while</span> (TestAndSet(&amp;m-&gt;guard, <span class="number">1</span>) == <span class="number">1</span>)</span><br><span class="line">    		; <span class="comment">//acquire guard lock by spinning</span></span><br><span class="line">    <span class="keyword">if</span> (m-&gt;flag == <span class="number">0</span>) &#123;</span><br><span class="line">        m-&gt;flag = <span class="number">1</span>; <span class="comment">// lock is acquired</span></span><br><span class="line">        m-&gt;guard = <span class="number">0</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        queue_add(m-&gt;q, gettid());</span><br><span class="line">        m-&gt;guard = <span class="number">0</span>;</span><br><span class="line">        park(); <span class="comment">// sleep here!</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">unlock</span><span class="params">(<span class="type">lock_t</span> *m)</span> &#123;</span><br><span class="line">    <span class="keyword">while</span> (TestAndSet(&amp;m-&gt;guard, <span class="number">1</span>) == <span class="number">1</span>)</span><br><span class="line">    		; <span class="comment">//acquire guard lock by spinning</span></span><br><span class="line">    <span class="keyword">if</span> (queue_empty(m-&gt;q))</span><br><span class="line">        m-&gt;flag = <span class="number">0</span>; <span class="comment">// let go of lock; no one wants it</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        unpark(queue_remove(m-&gt;q)); <span class="comment">// hold lock</span></span><br><span class="line">    								<span class="comment">// (for next thread!)</span></span><br><span class="line">    m-&gt;guard = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>锁外面套了一层 guard 锁，基本思想是，既然不能直接休眠，那就尽量减小自旋等待的范围，原来需要反复自旋获取 flag 锁，并且临界区是整个lock到unlock的区域，现在只需要先自旋获取 guard，临界区只需要获取锁(flag 设置为 1)或者休眠等待锁的释放(唤醒后直接返回，意为锁被上一个线程让了出来)</p>
<p><strong>加锁逻辑</strong>：</p>
<ul>
<li>自旋等待获取 <code>guard</code> </li>
<li>获取 <code>guard</code> 之后，如果 <code>flag</code> 未被占用，则直接获取 lock；</li>
<li>如果 <code>flag</code> 被占用，此时不要直接放弃，而是将自己加入等待队列中，释放 <code>guard</code>，并将自己休眠。先休眠后释放一定会造成死锁</li>
</ul>
<p><strong>释放锁逻辑</strong>：（可控调度的关键）</p>
<ul>
<li><p>自旋等待获取 <code>guard</code> </p>
</li>
<li><p>获取 <code>guard</code> 之后，如果队列为空，直接将 lock 释放，因为没有人正在等待                                                                                               </p>
</li>
<li><p><strong>如果队列不为空，唤醒队头线程，不能将 lock 释放，因为要为下一个要执行的线程保管好锁</strong></p>
</li>
<li><p>被唤醒的线程之前一直阻塞在 <code>park()</code> ，被唤醒之后依然符合 <code>flag == 1</code> 的条件，直接返回，进入临界区。</p>
<ul>
<li><p><code>wakeup race</code>: 如果在 <code>park()</code> 之前切换到了另一个线程（例如，持有锁的线程）可能会导致麻烦，例如，如果该线程随后释放了锁，就会试图唤醒队头线程并FIFO，但是此时线程并没有处于休眠状态，因此唤醒信号丢失，这个线程将永远挂起</p>
</li>
<li><p><strong>解决方案</strong>：Solaris 通过添加第三个系统调用来解决此问题：<code>setpark()</code> 通过调用此例程，线程A可以指示它即将停止(about to park)。如果A随后恰好被中断，并且另一个线程B在A实际调用 park 之前调用了 unpark，则后续 park 会立即返回而不是 sleep</p>
</li>
<li><p>```c<br>void lock(lock_t *m) {</p>
<pre><code>while (TestAndSet(&amp;m-&gt;guard, 1) == 1)
        ; //acquire guard lock by spinning
if (m-&gt;flag == 0) &#123;
    m-&gt;flag = 1; // lock is acquired
    m-&gt;guard = 0;
&#125; else &#123;
    queue_add(m-&gt;q, gettid());
    setpark(); // be about to sleep, ready to receive SIGWAKEUP
    m-&gt;guard = 0; // release guard
    park(); // return immediately if received SIGWAKEUP
&#125;
</code></pre>
<p>}</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 最后返回之前将 `guard` 释放</span><br><span class="line"></span><br><span class="line">也可以将 guard 放入内核中，这样就能保持原子的释放</span><br><span class="line"></span><br><span class="line">#### **Futex**(Linux)</span><br><span class="line"></span><br><span class="line">Linux 提供了一个类似于 Solaris 接口的 futex(**F**ast **U**serspace mu**TEX**)，但提供更多 in-kernel 功能。具体来说，每个 futex 与特定的物理内存位置以及每个 futex 内核队列相关联（**SLAB Allocator**）</span><br><span class="line"></span><br><span class="line">```c</span><br><span class="line">void mutex_lock (int *mutex) &#123;</span><br><span class="line">    int v;</span><br><span class="line">    // Bit 31 was clear(0), we got the mutex (fastpath, no SYSCALL)</span><br><span class="line">    // Set bit 31 to 1, variable mutex is negative now </span><br><span class="line">    if (atomic_bit_test_set (mutex, 31) == 0)</span><br><span class="line">    	return;</span><br><span class="line">    // Not free </span><br><span class="line">    atomic_increment (mutex);</span><br><span class="line">    while (1) &#123;</span><br><span class="line">        // If bit 31 is still 0, there is no contention, acquire the mutex</span><br><span class="line">        if (atomic_bit_test_set (mutex, 31) == 0) &#123;</span><br><span class="line">            atomic_decrement (mutex);</span><br><span class="line">            return;</span><br><span class="line">    	&#125; </span><br><span class="line">        /* </span><br><span class="line">        	First to make sure futex value</span><br><span class="line">        	we are monitoring is negative (locked).</span><br><span class="line">        */ </span><br><span class="line">        v = *mutex;</span><br><span class="line">        if (v &gt;= 0)</span><br><span class="line">            continue;</span><br><span class="line">        futex_wait (mutex, v);// immediately return if v!= *mutex</span><br><span class="line"> 							  // otherwise sleep	</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void mutex_unlock (int *mutex) &#123;</span><br><span class="line">    /* Adding 0x80000000 to counter results in 0 if and</span><br><span class="line">       only if there are not other interested threads </span><br><span class="line">       returns (new_mutex == 0)*/</span><br><span class="line">    if (atomic_add_zero (mutex, 0x80000000))</span><br><span class="line">    	return;</span><br><span class="line"></span><br><span class="line">    // There are other threads waiting for this mutex,</span><br><span class="line">    // wake one of them up.</span><br><span class="line">    futex_wake (mutex);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<blockquote>
<p>它使用单个整数来跟踪锁是否被持有（整数最高位）以及锁上的等待者数量（所有其他位）。 如果整数为负，则保持该锁定（因为设置了高位，并且该位确定整数的符号）</p>
<p>加锁：</p>
<ol>
<li>整数的最高位用来标记锁是否被占用，其余位用来标记等待者数量</li>
<li>如果获取锁失败，说明锁被占用，则低位自增，等待者 + 1</li>
<li>随后再次尝试获取锁（spin for one time，Phase 1）<ul>
<li>如果成功，则低位自减，等待者 - 1</li>
<li>如果失败，即将进入下个阶段(Phase 2)</li>
</ul>
</li>
<li>再次检查锁的状态（避免竞态条件，如果在这期间锁被释放就应该重新尝试获取锁）</li>
</ol>
<p>解锁：</p>
<ol>
<li>检测低位等待者的同时，清除最高位，如果结果不为0，则返回false</li>
<li>false，唤醒等待的线程</li>
</ol>
</blockquote>
<blockquote>
<p><strong>Function Signature</strong>: <code>int futex_wait(int *uaddr, int val)</code></p>
<p><strong>Purpose</strong>: If the <strong>futex word</strong> equals to <strong>val</strong>, the thread is put to sleep. The thread remains asleep until another thread calls <code>futex_wake</code> on the same futex word, signaling that the condition has changed.</p>
<p><strong>Parameters</strong>:</p>
<ul>
<li><code>uaddr</code>: Pointer to the futex word in user space.</li>
<li><code>val</code>: The expected value of the futex word.</li>
</ul>
<p><strong>Return Value</strong>: Returns 0 on success, or an error code on failure.</p>
</blockquote>
<blockquote>
<p><strong>Function Signature</strong>: <code>int futex_wake(int *uaddr, int val)</code></p>
<p><strong>Parameters</strong>:</p>
<ul>
<li><code>uaddr</code>: Pointer to the futex word in user space.</li>
<li><code>val</code>: The number of threads to wake up.</li>
</ul>
<p><strong>Return Value</strong>: Returns the number of threads that were woken up, or an error code on failure.</p>
</blockquote>
<blockquote>
<p><strong>Function Signature</strong>: <code>int atomic_bit_test_set(int *ptr, int bit)</code></p>
<p><strong>Parameters</strong>:</p>
<ul>
<li><code>ptr</code>: Pointer to the integer variable.</li>
<li><code>bit</code>: The bit position to be tested and set.</li>
</ul>
<p><strong>Return Value</strong>: Returns the previous value of the bit (0 or 1).</p>
</blockquote>
<blockquote>
<p><strong>Function Signature</strong>: <code>bool atomic_add_zero(int *ptr, int value)</code></p>
<p><strong>Parameters</strong>:</p>
<ul>
<li><code>ptr</code>: Pointer to the integer variable.</li>
<li><code>value</code>: Value to be added.</li>
</ul>
<p><strong>Return Value</strong>: Returns <code>true</code> if the result is zero, otherwise <code>false</code>.</p>
</blockquote>
<p>一般来说，内核态同步机制需要调用系统调用，来确保只有一个线程能进入互斥区，但如果根本没有竞争对象，则系统调用浪费了性能。</p>
<p>Futex 是一种用户态和内核态混合的同步机制。首先，同步的进程间通过 mmap <strong>共享一段内存</strong>，futex 变量就位于这段共享的内存中，且操作是原子的，当进程尝试进入互斥区<code>lock()</code>或者退出互斥区<code>unlock()</code>的时候，先去查看共享内存中的 futex 变量，如果没有竞争发生，则只修改 futex，而不用再执行系统调用了。当通过访问 futex 变量告诉进程有竞争发生，则还是得执行系统调用去完成相应的处理（<code>wait</code> 或者 <code>wake</code>）</p>
<p>简单的说，futex 就是通过在用户态的检查，如果了解到当前没有竞争就不用陷入内核了，大大提高了低竞争情况下的效率。</p>
<p>假设地址处的值等于预期，对 <code>futex_wait(address,expected) </code>的调用将使调用线程进入睡眠状态。如果不相等，则调用立即返回。对例程 <code>futex_wake(address)</code> 的调用会唤醒正在队列中等待的一个线程。</p>
<ol>
<li><p>Futex 变量的特征：</p>
<p>1）位于共享的用户空间中；</p>
<p>2）是一个32位的整型；</p>
<p>3）对它的操作是原子的。</p>
</li>
<li><p>Futex 在程序 low-contention 的时候能获得比传统同步机制更好的性能。</p>
</li>
<li><p>不要直接使用 Futex 系统调用。</p>
</li>
<li><p>Futex 同步机制可以用于进程间同步，也可以用于线程间同步。</p>
</li>
</ol>
<h5 id="Two-Phase-Locks"><a href="#Two-Phase-Locks" class="headerlink" title="Two-Phase Locks"></a>Two-Phase Locks</h5><p>两阶段锁中，自旋被看作可能很有用，特别是在锁即将被释放的情况下。在 Phase 1，会自旋一段时间，希望能够获取到锁。 如果在 Phase 1 没有获取锁，则进入 Phase 2，调用者将进入睡眠状态，只有在锁稍后释放时才会被唤醒。</p>
<p>上面的 Linux Futex 实现的 Mutex 就是这种锁的一种形式，但它只<strong>自旋一次</strong>；更常见的是在循环中自旋固定的（fixed）次数</p>
<h2 id="Thread-Safe-Data-Structures"><a href="#Thread-Safe-Data-Structures" class="headerlink" title="Thread-Safe Data Structures"></a>Thread-Safe Data Structures</h2><h3 id="Concurrent-Counter"><a href="#Concurrent-Counter" class="headerlink" title="Concurrent Counter"></a>Concurrent Counter</h3><p><strong>Basic Mutex</strong></p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Concurrency.assets/image-20241224125018845.png" alt="image-20241224125018845"></p>
<p>简单给访问临界区加锁完全能够保证绝对的线程安全(thread safe)，但是锁的开销非常大</p>
<p><strong>Scalable Counting</strong></p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Concurrency.assets/image-20241224134929698.png" alt="image-20241224134929698"></p>
<p>近似计数器：每个CPU有一个局部计数器(local)，所有CPU共享一个全局计数器(global)，局部计数器加到全局计数器上的时候才加给全局计数器加锁，这就显著减少了加锁解锁的次数。</p>
<p>另外，局部锁也是需要的，因为我们假设每个核心上可能有多个线程。相反，如果每个核心上仅运行一个线程，则不需要局部所锁。</p>
<p>为了使全局计数器保持最新（如果线程希望读取其值），通过获取全局锁并将其增加局部计数器的值，局部值会定期传输到全局计数器；然后局部计数器归零。 这种局部到全局传输发生的频率由阈值 S 决定，当局部计数器达到 S 就向全局计数器写入。S 越小，计数器的行为就越像上面的不可扩展计数器； S 越大，计数器的可扩展性就越高，但全局值可能与实际计数相差越远。人们可以简单地获取所有局部锁和全局锁（以指定的顺序，以避免死锁）来获得精确的值，但这是不可扩展的：</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Concurrency.assets/image-20241224135017601.png" alt="image-20241224135017601"></p>
<p>图 29.6 显示了阈值 S 的重要性，其中有四个线程，每个线程在四个 CPU 上将计数器递增 100 万次。如果 S 较低，则性能较差（但全局计数总是相当准确）； 如果 S 较高，则性能出色，但全局计数滞后（最多为 CPU 数量乘以 S）。这种准确性/性能权衡正是近似计数器所实现的。</p>
<h3 id="Concurrent-Linked-List"><a href="#Concurrent-Linked-List" class="headerlink" title="Concurrent Linked List"></a>Concurrent Linked List</h3><p><strong>Basic Mutex</strong></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// basic list structure (one used per list)</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> __<span class="title">list_t</span> &#123;</span><span class="type">node_t</span> *head; <span class="type">pthread_mutex_t</span> lock;&#125; <span class="type">list_t</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">List_Insert</span><span class="params">(<span class="type">list_t</span> *L, <span class="type">int</span> key)</span> &#123;</span><br><span class="line">    <span class="type">node_t</span> *new = <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="type">node_t</span>));</span><br><span class="line">    <span class="keyword">if</span> (new == <span class="literal">NULL</span>) &#123;</span><br><span class="line">        perror(<span class="string">&quot;malloc&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span>; <span class="comment">// fail</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    new-&gt;key = key;</span><br><span class="line">    pthread_mutex_lock(&amp;L-&gt;lock);  <span class="comment">// lock</span></span><br><span class="line">    new-&gt;next = L-&gt;head;</span><br><span class="line">    L-&gt;head = new;</span><br><span class="line">    pthread_mutex_unlock(&amp;L-&gt;lock);<span class="comment">// unlock</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">List_Lookup</span><span class="params">(<span class="type">list_t</span> *L, <span class="type">int</span> key)</span> &#123;</span><br><span class="line">    <span class="type">int</span> rv = <span class="number">-1</span>;</span><br><span class="line">    pthread_mutex_lock(&amp;L-&gt;lock);</span><br><span class="line">    <span class="type">node_t</span> *curr = L-&gt;head;</span><br><span class="line">    <span class="keyword">while</span> (curr) &#123;</span><br><span class="line">        <span class="keyword">if</span> (curr-&gt;key == key) &#123;</span><br><span class="line">            rv = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    	curr = curr-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">    pthread_mutex_unlock(&amp;L-&gt;lock); <span class="comment">// failure</span></span><br><span class="line">	<span class="keyword">return</span> rv; <span class="comment">// rv = -1: </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>尽量缩小锁涵盖的范围（临界区大小）如果没有涉及到访问共享区域的就不要纳入范围</li>
<li>使用单一返回路径，减少代码中需要获取、释放锁的地方，降低了返回前忘记释放锁的可能</li>
</ul>
<p><strong>Lock and Control flow</strong>：</p>
<p>在并发编程中，函数通常在开始时获取锁或分配资源、更改状态。如果发生错误，函数必须在退出之前释放锁或释放资源。这个过程很容易出错，因为它需要仔细管理状态。为了避免这些问题，最好以一种尽量<strong>减少撤消状态更改</strong>的方式构建代码。这可以通过以下方式实现：</p>
<ul>
<li><strong>集中错误处理</strong>：谨慎处理导致函数返回、退出或其他停止执行的错误情况的更改，在函数中使用单个退出点来处理所有清理操作。 </li>
<li><strong>最小化模式</strong>：构造代码以尽量减少撤消状态更改的需要，从而降低出错风险。</li>
<li><strong>避免过早返回</strong>：减少函数中的返回语句数量，以确保执行所有必要的清理。 </li>
<li><strong>使用 RAII（资源获取即初始化）</strong>：在支持它的语言中，使用 RAII 自动管理资源。 </li>
</ul>
<p><strong>Hand-over-hand Locking</strong>: </p>
<p>每个节点都有一个锁，替代之前链表的整个链表一个锁，遍历链表时首先抢占下一个节点的锁，然后释放当前节点的锁，一定程度上增加了链表的并发能力，但是开销很大，</p>
<h3 id="Concurrent-Queue"><a href="#Concurrent-Queue" class="headerlink" title="Concurrent Queue"></a>Concurrent Queue</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> __<span class="title">queue_t</span> &#123;</span></span><br><span class="line">	<span class="type">node_t</span> *head; <span class="type">node_t</span> *tail; </span><br><span class="line">    <span class="type">pthread_mutex_t</span> head_lock, tail_lock;</span><br><span class="line">&#125;<span class="type">queue_t</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">Queue_Init</span><span class="params">(<span class="type">queue_t</span> *q)</span> &#123;</span><br><span class="line">    <span class="type">node_t</span> *tmp = <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="type">node_t</span>));</span><br><span class="line">    tmp-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">    q-&gt;head = q-&gt;tail = tmp;</span><br><span class="line">    pthread_mutex_init(&amp;q-&gt;head_lock, <span class="literal">NULL</span>);</span><br><span class="line">    pthread_mutex_init(&amp;q-&gt;tail_lock, <span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">Queue_Enqueue</span><span class="params">(<span class="type">queue_t</span> *q, <span class="type">int</span> value)</span> &#123;</span><br><span class="line">    <span class="type">node_t</span> *tmp = <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="type">node_t</span>));</span><br><span class="line">    assert(tmp != <span class="literal">NULL</span>);</span><br><span class="line">    tmp-&gt;value = value;</span><br><span class="line">    tmp-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    pthread_mutex_lock(&amp;q-&gt;tail_lock);<span class="comment">//在队尾加锁</span></span><br><span class="line">    q-&gt;tail-&gt;next = tmp;</span><br><span class="line">    q-&gt;tail = tmp;</span><br><span class="line">    pthread_mutex_unlock(&amp;q-&gt;tail_lock);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">Queue_Dequeue</span><span class="params">(<span class="type">queue_t</span> *q, <span class="type">int</span> *value)</span> &#123;</span><br><span class="line">    pthread_mutex_lock(&amp;q-&gt;head_lock);</span><br><span class="line">    <span class="type">node_t</span> *tmp = q-&gt;head;</span><br><span class="line">    <span class="type">node_t</span> *new_head = tmp-&gt;next;</span><br><span class="line">    <span class="keyword">if</span> (new_head == <span class="literal">NULL</span>) &#123;</span><br><span class="line">        pthread_mutex_unlock(&amp;q-&gt;head_lock);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>; <span class="comment">// queue was empty</span></span><br><span class="line">    &#125;</span><br><span class="line">    *value = new_head-&gt;value;</span><br><span class="line">    q-&gt;head = new_head;</span><br><span class="line">    pthread_mutex_unlock(&amp;q-&gt;head_lock);</span><br><span class="line">    <span class="built_in">free</span>(tmp);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>队列的加锁特点：</p>
<ul>
<li><p>入队只访问 <code>tail_lock</code> 出队只访问 <code>head_lock</code></p>
</li>
<li><p>在初始化阶段添加了 dummy node 假节点，不然空队列的情况需要同时处理 tail 和 head：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">Queue_Enqueue</span><span class="params">(<span class="type">queue_t</span> *q, <span class="type">int</span> value)</span> &#123;</span><br><span class="line">    <span class="type">node_t</span> *tmp = <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="type">node_t</span>));</span><br><span class="line">    assert(tmp != <span class="literal">NULL</span>);</span><br><span class="line">    tmp-&gt;value = value;</span><br><span class="line">    tmp-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    pthread_mutex_lock(&amp;q-&gt;tail_lock);</span><br><span class="line">    <span class="keyword">if</span> (q-&gt;tail == <span class="literal">NULL</span>) &#123;<span class="comment">// additional if-else!!!</span></span><br><span class="line">        q-&gt;head = q-&gt;tail = tmp;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        q-&gt;tail-&gt;next = tmp;</span><br><span class="line">        q-&gt;tail = tmp;</span><br><span class="line">    &#125;</span><br><span class="line">    pthread_mutex_unlock(&amp;q-&gt;tail_lock);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">Queue_Dequeue</span><span class="params">(<span class="type">queue_t</span> *q, <span class="type">int</span> *value)</span> &#123;</span><br><span class="line">    pthread_mutex_lock(&amp;q-&gt;head_lock);</span><br><span class="line">    <span class="keyword">if</span> (q-&gt;head == <span class="literal">NULL</span>) &#123;<span class="comment">// additional if-else!!!</span></span><br><span class="line">        pthread_mutex_unlock(&amp;q-&gt;head_lock);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>; <span class="comment">// queue was empty</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">node_t</span> *tmp = q-&gt;head;</span><br><span class="line">    <span class="type">node_t</span> *new_head = tmp-&gt;next;</span><br><span class="line">    <span class="keyword">if</span> (new_head == <span class="literal">NULL</span>) &#123;</span><br><span class="line">        pthread_mutex_unlock(&amp;q-&gt;head_lock);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>; <span class="comment">// queue was empty</span></span><br><span class="line">    &#125;</span><br><span class="line">    *value = new_head-&gt;value;</span><br><span class="line">    q-&gt;head = new_head;</span><br><span class="line">    pthread_mutex_unlock(&amp;q-&gt;head_lock);</span><br><span class="line">    <span class="built_in">free</span>(tmp);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="Concurrent-Hash-Table"><a href="#Concurrent-Hash-Table" class="headerlink" title="Concurrent Hash Table"></a>Concurrent Hash Table</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> BUCKETS (101)</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> __<span class="title">hash_t</span> &#123;</span><span class="type">list_t</span> lists[BUCKETS];&#125; <span class="type">hash_t</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">Hash_Init</span><span class="params">(<span class="type">hash_t</span> *H)</span> &#123;</span><br><span class="line">    <span class="type">int</span> i;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; BUCKETS; i++)</span><br><span class="line">    	List_Init(&amp;H-&gt;lists[i]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">Hash_Insert</span><span class="params">(<span class="type">hash_t</span> *H, <span class="type">int</span> key)</span> &#123;</span><br><span class="line">	<span class="keyword">return</span> List_Insert(&amp;H-&gt;lists[key % BUCKETS], key);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">Hash_Lookup</span><span class="params">(<span class="type">hash_t</span> *H, <span class="type">int</span> key)</span> &#123;</span><br><span class="line">	<span class="keyword">return</span> List_Lookup(&amp;H-&gt;lists[key % BUCKETS], key);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Concurrency.assets/image-20241224205440775.png" alt="image-20241224205440775"></p>
<p>如图所示，哈希表中，每个桶都是一个单独的链表，因此，比单独的大锁并发链表性能好很多。</p>
<h1 id="Condition-Variables"><a href="#Condition-Variables" class="headerlink" title="Condition Variables"></a>Condition Variables</h1><p>任何线程库的另一个主要组件是条件变量，主要用于线程间交互。</p>
<p>概念上，一个条件变量就是一个线程队列(thread queue)， 其中的线程正等待某个条件变为真，比如 <code>ready == 0</code>，每个条件变量$c$关联着一个<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%96%B7%E8%A8%80_(%E7%A8%8B%E5%BC%8F)">断言</a>，当一个线程等待时，该线程不算作占用了该管程，因而其它线程可以进入该管程执行，改变管程的状态，通知条件变量$c$其关联的断言$P_c$在当前状态下为真。</p>
<p>条件变量同锁一起使用使得线程可以以一种**<u>无竞争</u>**的方式等待任意条件的发生。所谓无竞争就是，条件改变之后这个信号会发送到所有等待这个信号的线程。而不是说一个线程接受到这个消息而其它线程就接收不到了。</p>
<h2 id="Precautions"><a href="#Precautions" class="headerlink" title="Precautions"></a>Precautions</h2><h3 id="“Wakeup”"><a href="#“Wakeup”" class="headerlink" title="“Wakeup”"></a>“Wakeup”</h3><p>线程状态:Ready, Run, Sleep</p>
<p><code>wait</code>: Run-&gt;Sleep</p>
<p><code>signal</code>: Sleep-&gt;Ready </p>
<h3 id="Specific-Condition"><a href="#Specific-Condition" class="headerlink" title="Specific Condition"></a>Specific Condition</h3><p>条件变量必须跟布尔条件挂钩，如果只是单纯地地像下面这样使用条件变量：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">thr_exit()&#123;</span><br><span class="line">	<span class="comment">// done = 1;</span></span><br><span class="line">	mutex_lock(&amp;m);</span><br><span class="line">	cond_signal(&amp;c);</span><br><span class="line">	mutex_unlock(&amp;m);</span><br><span class="line">&#125;</span><br><span class="line">thr_join()&#123;</span><br><span class="line">	mutex_lock(&amp;m);</span><br><span class="line">	<span class="comment">//while(done == 0)</span></span><br><span class="line">	cond_wait(&amp;c);</span><br><span class="line">	mutex_unlock(&amp;m);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在父线程调用join之前，子线程创建并运行了exit，就会导致空唤醒，父线程将持续睡下去。</p>
<h3 id="Recheck-While-Loop"><a href="#Recheck-While-Loop" class="headerlink" title="Recheck: While Loop"></a>Recheck: <strong>While</strong> Loop</h3><h4 id="Mesa-Semantic"><a href="#Mesa-Semantic" class="headerlink" title="Mesa Semantic"></a>Mesa Semantic</h4><p>发信号只是一个状态改变的暗示，并不能保证他运行之前的状态一直是期望的情况，线程的 Ready 和 Run 之间的状态转换是由调度程序决定的，<code>signal</code> 以后，Run 之前可能状态会发生变化。</p>
<p>另一个是Hoare Semantic 能直接唤醒线程立即执行，几乎所有系统都采用了前者的语义。</p>
<h4 id="Lost-Wakeup"><a href="#Lost-Wakeup" class="headerlink" title="Lost Wakeup"></a>Lost Wakeup</h4><p>条件变量代表的是一种条件，需要将 <code>pthread_cond_wait</code> 放在一个 while 循环，而不是 if 语句中，因为很可能会出现在wait之前正好切换走了，这时候signal信号就会丢失。所以线程被唤醒后必须重新检查当时的条件是否仍然满足，如若仍然满足 while 循环的条件，就不能继续执行。</p>
<p>假设线程 A 和线程 B 都在等待同一个条件变量，并且导致线程休眠的条件布尔值最初为 <code>false</code>：</p>
<ol>
<li>线程 A 进入等待状态：<ul>
<li><code>pthread_cond_wait(&amp;cond, &amp;mutex)</code> </li>
</ul>
</li>
<li>线程 B 也进入等待状态；</li>
<li>某个线程 C 修改了条件布尔值为 <code>true</code>，并通过条件变量发送信号唤醒线程：<ul>
<li><code>pthread_cond_signal(&amp;cond)</code>。</li>
</ul>
</li>
<li>线程 A 被唤醒，并退出等待。此时它执行任务后将条件变量重新置为 <code>false</code>。</li>
<li><strong>问题：</strong> 线程 B 也被唤醒，但条件变量已被线程 A 改回 <code>false</code>。<ul>
<li>如果使用 <code>if</code> 检查条件，线程 B 会直接跳过检查并继续执行任务，从而导致程序逻辑错误。</li>
</ul>
</li>
</ol>
<p><strong>解决方案：用 <code>while</code> 再次检查条件</strong>：</p>
<ul>
<li>当线程 B 被唤醒时，<code>while</code> 循环会再次检查条件变量，发现条件未满足，然后重新进入等待状态，确保安全。</li>
</ul>
<h4 id="Spurious-Wakeup"><a href="#Spurious-Wakeup" class="headerlink" title="Spurious Wakeup"></a>Spurious Wakeup</h4><p>有一些 pthread 实现可能会<strong>虚假地唤醒</strong>多个正在等待的线程；在这种情况下，在不重新检查的情况下，等待线程将继续认为条件已更改，即使它没有更改。因此，应该树立起一个恒等式:</p>
<p>被唤醒⇔条件确实已经改变</p>
<h3 id="Hold-the-Lock-When-signal-or-wait"><a href="#Hold-the-Lock-When-signal-or-wait" class="headerlink" title="Hold the Lock When signal() or wait()"></a>Hold the Lock When <code>signal()</code> or <code>wait()</code></h3><p> ==使用条件变量的前提是必须要持有这把锁== </p>
<p><strong>想象一下</strong>：一个线程是某个队列的消费者，它必须要等到队列中有数据时才能执行，如果队列为空，则会一直等待挂起，直到另外一个线程在队列中存入数据，并<strong>通知</strong>先前挂起的线程，该线程才会唤醒重新开始执行。在这个例子中，队列是否 空/满 是线程执行所依赖的状态，而这个状态是多个线程都可以访问的，所以需要加锁互斥访问，这种加锁模式与其他同步加锁略有不同：</p>
<p>锁在 <code>wait</code> 调用中，休眠前需要释放锁，唤醒之后，返回之前需要重新获取锁</p>
<h3 id="Covering-Conditions-broadcast"><a href="#Covering-Conditions-broadcast" class="headerlink" title="Covering Conditions: broadcast()"></a>Covering Conditions: <code>broadcast()</code></h3><p>考虑分配内存的场景：</p>
<ol>
<li>有多个想要申请不同空间的线程，但是此时没有足够空间，因此他们陷入了睡眠；</li>
<li>此时第三个线程释放了一定的空间，想要唤醒，但唤醒哪一个是不确定的，可能释放的空间不足以支持被唤醒者申请的空间；</li>
<li>因此需要唤醒所有在此CV上等待的线程：<code>broadcast()</code></li>
</ol>
<h2 id="Producer-Consumer-Problem"><a href="#Producer-Consumer-Problem" class="headerlink" title="Producer/Consumer Problem"></a>Producer/Consumer Problem</h2><p>生产者/消费者问题 或 有界缓冲区问题：</p>
<ul>
<li>生产者：从缓冲区中拿东西，如果没东西可拿就应该阻塞</li>
<li>消费者：向缓冲区中放东西，如果缓冲区满了就应当阻塞</li>
</ul>
<p>因此要注意如下事项：</p>
<ol>
<li>不能唤醒同类：生产者和消费者应该使用两个不同的条件变量</li>
<li>while 循环：重新检查条件，以防在 Run 之前，条件发生改变</li>
</ol>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> MAXSIZE 8</span></span><br><span class="line"><span class="type">int</span> buffer[MAXSIZE];</span><br><span class="line"><span class="type">int</span> fill_ptr = <span class="number">0</span>;</span><br><span class="line"><span class="type">int</span> use_ptr = <span class="number">0</span>;</span><br><span class="line"><span class="type">int</span> count = <span class="number">0</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">put</span><span class="params">(<span class="type">int</span> value)</span>&#123;</span><br><span class="line">    buffer[fill_ptr] = value;</span><br><span class="line">	fill_ptr = (fill_ptr + <span class="number">1</span>) % MAXSIZE;</span><br><span class="line">    count++;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">get</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> tmp = buffer[use_ptr];</span><br><span class="line">    fill_ptr = (fill_ptr + <span class="number">1</span>) % MAXSIZE;</span><br><span class="line">    count--;</span><br><span class="line">    <span class="keyword">return</span> tmp;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">cond_t</span> isEmpty,isFull;</span><br><span class="line"><span class="type">mutex_t</span> mutex;</span><br><span class="line"><span class="type">void</span> <span class="title function_">producer</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>;i &lt; loops;i++)&#123;</span><br><span class="line">        mutex_lock(&amp;mutex);</span><br><span class="line">        <span class="keyword">while</span>(count == MAXSIZE)</span><br><span class="line">            cond_wait(&amp;isFull, &amp;mutex);</span><br><span class="line">    	put(i);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;producer:%d puts value:%d&quot;</span>, gettid(), i);</span><br><span class="line">        cond_signal((&amp;isEmpty);</span><br><span class="line">    	mutex_unlock(&amp;mutex);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> consumer()&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>;i &lt; loops;i++)&#123;</span><br><span class="line">        mutex_lock(&amp;mutex);</span><br><span class="line">        <span class="keyword">while</span>(count == <span class="number">0</span>)</span><br><span class="line">            cond_wait(&amp;isEmpty, &amp;mutex);</span><br><span class="line">        <span class="type">int</span> value = get();</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;pid:%d gets value:%d&quot;</span>, gettid(), value);</span><br><span class="line">        cond_signal(&amp;isFull);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="Semaphores"><a href="#Semaphores" class="headerlink" title="Semaphores"></a>Semaphores</h1><p><strong>互斥</strong>：是指某一资源同时只允许一个访问者对其进行访问，具有唯一性和排它性。但互斥无法限制访问者对资源的访问顺序，即访问是无序的。 </p>
<p><strong>同步</strong>：指在互斥的基础上（大多数情况），通过其它机制实现访问者对资源的有序访问。在大多数情况下，同步已经实现了互斥，特别是所有写入资源的情况必定是互斥的。少数情况是指可以允许多个访问者同时访问资源</p>
<p>Semaphore <strong>支持跨进程的同步</strong>，是线程同步所有工作的单一原语，能够将其作为锁或条件变量</p>
<p>Condition Variable 只支持同一进程内部线程的同步</p>
<table>
<thead>
<tr>
<th>特性</th>
<th>信号量（Semaphore）</th>
<th>锁（Mutex）</th>
<th>条件变量（Condition Variable）</th>
</tr>
</thead>
<tbody><tr>
<td><strong>功能</strong></td>
<td>控制资源数量（同步和互斥）</td>
<td>提供互斥访问</td>
<td>等待特定条件满足后继续执行</td>
</tr>
<tr>
<td><strong>适用场景</strong></td>
<td>资源控制、多线程队列</td>
<td>保护临界区，单资源互斥</td>
<td>条件等待（生产者/消费者问题）</td>
</tr>
<tr>
<td><strong>能否跨进程</strong></td>
<td><strong>支持跨进程</strong></td>
<td>仅限线程同步（同一进程内）</td>
<td>仅限线程同步（同一进程内）</td>
</tr>
<tr>
<td><strong>是否需要互斥锁</strong></td>
<td><strong>不需要互斥锁</strong></td>
<td>自带互斥功能，不需要额外锁</td>
<td>必须依赖互斥锁来保护共享变量</td>
</tr>
<tr>
<td><strong>复杂条件判断</strong></td>
<td><strong>支持简单条件</strong>（通过计数控制）</td>
<td><strong>不支持条件判断</strong></td>
<td><strong>支持复杂条件</strong>判断和线程等待唤醒机制</td>
</tr>
</tbody></table>
<h2 id="POSIX-API"><a href="#POSIX-API" class="headerlink" title="POSIX API"></a>POSIX API</h2><p>POSIX API 给信号量添加了两个调用，这两个调用都是原子操作：</p>
<h3 id="sem-wait-sem-t-s-P"><a href="#sem-wait-sem-t-s-P" class="headerlink" title="sem_wait(sem_t *s)(P())"></a><code>sem_wait(sem_t *s)</code>(<code>P()</code>)</h3><p>信号量值减1，若变为负数，则阻塞在信号量上（信号量负数绝对值为阻塞的线程数量）</p>
<h3 id="sem-post-sem-t-s-V"><a href="#sem-post-sem-t-s-V" class="headerlink" title="sem_post(sem_t *s)(V())"></a><code>sem_post(sem_t *s)</code>(<code>V()</code>)</h3><p>将信号量的值加1，如果信号量值为负数，则肯定有线程正在此信号量上等待，唤醒其中一个线程</p>
<h2 id="Binary-Semaphores-Locks"><a href="#Binary-Semaphores-Locks" class="headerlink" title="Binary Semaphores: Locks"></a>Binary Semaphores: Locks</h2><p><strong>Workflow</strong>:</p>
<ol>
<li>信号量的初始值为 1，线程 A 调用 <code>sem_wait(*s)</code> 此时信号量为 0，直接返回，进入临界区</li>
<li>此时另一个线程 B 过来调用 <code>sem_wait(*s)</code> 此时信号量为 -1，休眠……</li>
<li>线程 A 完成临界区操作，调用 <code>sem_post(*s)</code> 此时信号量变成 0，唤醒线程 B </li>
<li>线程 B 从 <code>wait()</code> 返回，进入临界区</li>
</ol>
<p>因此二值信号量能够实现锁的功能。</p>
<h2 id="Semaphores-Condition-Variables"><a href="#Semaphores-Condition-Variables" class="headerlink" title="Semaphores: Condition Variables"></a>Semaphores: Condition Variables</h2><blockquote>
<p>给信号量设置初始值：在初始化之后愿意立即放弃的资源数量有多少？</p>
<ul>
<li><p>如果是锁，只有 1 把锁，那么就必须初始化为 1；</p>
</li>
<li><p>如果是用作任务排序，父进程等待子进程，没有能给出去的东西，那就只能初始化为 0</p>
</li>
<li><p>如果是消费者，一开始没有可以消费的东西，那就初始化为0；</p>
</li>
<li><p>如果是生产者，一开始可供生产的空间有MAXSIZE个，那就初始化为MAXSIZE。</p>
</li>
</ul>
</blockquote>
<h3 id="Mutex-Needed"><a href="#Mutex-Needed" class="headerlink" title="Mutex Needed"></a>Mutex Needed</h3><p>相当于将之前的 <code>count</code> 整合进条件变量中：</p>
<ul>
<li><code>sem_init(&amp;empty,0,MAXSIZE)</code> 空闲区域的大小为 MAXSIZE</li>
<li><code>sem_init(&amp;full,0,0)</code> 可消费区域大小为 0</li>
</ul>
<p><strong>Usage</strong>: </p>
<ul>
<li>生产者调用 <code>sem_wait(&amp;empty)</code> empty 自减，若为负数则生产者只能阻塞等待</li>
</ul>
<ul>
<li>消费者调用 <code>sem_wait(&amp;full)</code> full 自减，为负数则消费者需要阻塞等待</li>
</ul>
<ul>
<li><p>生产者操作完临界区， <code>sem_post(&amp;full)</code> 使 full 自增，某个消费者被唤醒并进入临界区</p>
</li>
<li><p>消费者操作完临界区， <code>sem_post(&amp;empty)</code> 使 empty 自增，某个生产者被唤醒并进入临界区</p>
</li>
</ul>
<p>这里没有锁，因此会出现并发问题：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> *<span class="title function_">producer</span><span class="params">(<span class="type">void</span> *arg)</span> &#123;</span><br><span class="line">    <span class="type">int</span> i;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; loops; i++) &#123;</span><br><span class="line">        sem_wait(&amp;mutex); <span class="comment">// Line P0 (NEW LINE) 加锁</span></span><br><span class="line">        sem_wait(&amp;empty); <span class="comment">// Line P1</span></span><br><span class="line">        put(i); <span class="comment">// Line P2</span></span><br><span class="line">        sem_post(&amp;full); <span class="comment">// Line P3</span></span><br><span class="line">        sem_post(&amp;mutex); <span class="comment">// Line P4 (NEW LINE) 解锁</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> *<span class="title function_">consumer</span><span class="params">(<span class="type">void</span> *arg)</span> &#123;</span><br><span class="line">	<span class="type">int</span> i;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; loops; i++) &#123;</span><br><span class="line">        sem_wait(&amp;mutex); <span class="comment">// Line C0 (NEW LINE) 加锁 </span></span><br><span class="line">        sem_wait(&amp;full); <span class="comment">// Line C1</span></span><br><span class="line">        <span class="type">int</span> tmp = get(); <span class="comment">// Line C2</span></span><br><span class="line">        sem_post(&amp;empty); <span class="comment">// Line C3</span></span><br><span class="line">        sem_post(&amp;mutex); <span class="comment">// Line C4 (NEW LINE) 解锁</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, tmp);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Deadlock"><a href="#Deadlock" class="headerlink" title="Deadlock"></a>Deadlock</h3><p>生产者加锁，进入临界区之前，调用empty发现缓冲区已满，遂休眠，此时生产者依然持有锁</p>
<p>切换到就绪的消费者，因为获取不到锁，只能休眠，这样就导致了死锁，因此需要缩小锁的范围:</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> *<span class="title function_">consumer</span><span class="params">(<span class="type">void</span> *arg)</span> &#123;</span><br><span class="line">	<span class="type">int</span> i;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; loops; i++) &#123;</span><br><span class="line">        sem_wait(&amp;full); <span class="comment">// Line C1</span></span><br><span class="line">        sem_wait(&amp;mutex); <span class="comment">// Line C1.5 (NEW LINE) 加锁 </span></span><br><span class="line">        <span class="type">int</span> tmp = get(); <span class="comment">// Line C2</span></span><br><span class="line">        sem_post(&amp;mutex); <span class="comment">// Line C2.5 (NEW LINE) 解锁</span></span><br><span class="line">        sem_post(&amp;empty); <span class="comment">// Line C3</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, tmp);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>最根本的区别在于，睡眠的线程不会释放锁，因此条件变量应该加到锁的外面</p>
<h2 id="Mutex-CV-amp-Semaphore"><a href="#Mutex-CV-amp-Semaphore" class="headerlink" title="Mutex + CV &amp; Semaphore"></a><code>Mutex + CV</code> &amp; <code>Semaphore</code></h2><table>
<thead>
<tr>
<th>特性</th>
<th>Mutex + Condition Variable</th>
<th>Semaphore</th>
</tr>
</thead>
<tbody><tr>
<td><strong>设计理念</strong></td>
<td>提供更高层次的<strong>条件等待机制</strong>，依赖互斥锁管理共享数据状态。</td>
<td>基于简单的<strong>计数器模型</strong>，直接控制资源可用数量。</td>
</tr>
<tr>
<td><strong>同步功能</strong></td>
<td>适合复杂条件等待或<strong>事件驱动</strong>的同步场景（例如生产者-消费者模型）。</td>
<td>控制固定数量的资源访问或线程数量（例如资源池管理）。</td>
</tr>
<tr>
<td><strong>互斥功能</strong></td>
<td>需要显式的 <code>Mutex</code> 实现互斥保护。</td>
<td>内部实现互斥，无需额外的互斥锁。</td>
</tr>
<tr>
<td><strong>跨进程支持</strong></td>
<td>仅支持线程级同步（同一进程内线程同步）。</td>
<td>支持跨进程和线程同步（POSIX 信号量支持跨进程）。</td>
</tr>
<tr>
<td><strong>复杂性</strong></td>
<td>支持复杂条件判断，但需要手动管理条件和唤醒逻辑。</td>
<td>简单直观，直接基于计数器操作，不需要条件管理。</td>
</tr>
<tr>
<td><strong>效率</strong></td>
<td>条件变量需要多步操作（加锁、解锁、条件检查、等待），效率略低。</td>
<td>基于计数器原子操作，性能较高，适合高并发场景。</td>
</tr>
<tr>
<td><strong>复杂条件处理</strong></td>
<td>支持复杂条件和多条件组合判断，适合生产者-消费者问题。</td>
<td>只能处理简单的资源计数条件，不适合复杂条件判断。</td>
</tr>
</tbody></table>
<h3 id="Mutex-Condition-Variable"><a href="#Mutex-Condition-Variable" class="headerlink" title="Mutex + Condition Variable"></a>Mutex + Condition Variable</h3><ol>
<li><strong>互斥锁（Mutex）：</strong><ul>
<li>提供临界区保护，确保线程在访问共享资源时互斥执行。</li>
<li>底层依赖于操作系统内核的<strong>互斥量数据结构</strong>（如 Linux 的 Futex 或信号量实现）。</li>
</ul>
</li>
<li><strong>条件变量（Condition Variable）：</strong><ul>
<li>条件变量不会保存条件状态，而是通过线程阻塞和唤醒机制等待条件变化。</li>
<li>必须与互斥锁配合使用，防止条件检查过程中出现竞争条件。</li>
</ul>
</li>
</ol>
<ul>
<li>条件变量使用<strong>等待队列（Wait Queue）</strong>机制管理线程。</li>
<li>当线程调用<code>pthread_cond_wait</code>，它会：<ol>
<li>释放锁（解锁 mutex）。</li>
<li>将线程放入条件变量的等待队列中，并进入<strong>阻塞状态</strong>（睡眠）。</li>
<li>等待其他线程通过 <code>pthread_cond_signal</code> 或 <code>pthread_cond_broadcast</code> 唤醒它。</li>
<li>被唤醒后，重新尝试获取互斥锁并继续执行。</li>
</ol>
</li>
</ul>
<figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">Thread</span> <span class="number">1</span><span class="operator">:</span>              <span class="built_in">Condition</span> <span class="variable">Variable</span><span class="operator">:</span></span><br><span class="line">  <span class="operator">-</span> <span class="variable">Acquire</span> <span class="variable">Lock</span>         <span class="punctuation">[</span> <span class="variable">Wait</span> <span class="variable">Queue</span> <span class="punctuation">]</span></span><br><span class="line">  <span class="operator">-</span> <span class="built_in">Check</span> <span class="built_in">Condition</span> <span class="operator">----&gt;</span> <span class="variable">Add</span> <span class="variable">to</span> <span class="variable">Queue</span></span><br><span class="line">  <span class="operator">-</span> <span class="variable">Wait</span> <span class="punctuation">(</span><span class="variable">Unlock</span><span class="punctuation">)</span>        <span class="punctuation">[</span> <span class="variable">Blocked</span> <span class="punctuation">]</span></span><br><span class="line">                         <span class="operator">&lt;-----</span> <span class="variable">Signal</span><span class="punctuation">(</span><span class="punctuation">)</span></span><br><span class="line"><span class="built_in">Thread</span> <span class="number">2</span><span class="operator">:</span>               <span class="variable">Wake</span> <span class="built_in">Up</span> <span class="built_in">Thread</span> <span class="number">1</span></span><br><span class="line">  <span class="operator">-</span> <span class="variable">Modify</span> <span class="built_in">Condition</span></span><br><span class="line">  <span class="operator">-</span> <span class="variable">Signal</span></span><br><span class="line">  <span class="operator">-</span> <span class="built_in">Release</span> <span class="variable">Lock</span></span><br></pre></td></tr></table></figure>

<ul>
<li><strong>条件变量没有条件状态：</strong> 共享条件需要程序员手动管理（例如标志位）。</li>
<li><strong>支持复杂条件判断：</strong> 等待某些条件的组合，例如缓冲区为空或满。</li>
<li><strong>虚假唤醒机制：</strong> 被唤醒后必须重新检查条件，避免不满足条件的线程继续执行。</li>
</ul>
<hr>
<h3 id="Semaphore"><a href="#Semaphore" class="headerlink" title="Semaphore"></a>Semaphore</h3><ul>
<li>信号量直接依赖<strong>原子操作</strong>（如 CPU 指令 <code>Test-And-Set</code> 或 <code>Compare-And-Swap</code>）更新计数器，确保多线程安全。</li>
<li>阻塞线程会进入<strong>等待队列</strong>，操作系统负责调度。</li>
</ul>
<ol>
<li>信号量内部维护一个<strong>计数器变量（Counter）</strong>，表示可用资源的数量。</li>
<li>当调用 <code>sem_wait</code> 时：<ul>
<li>如果计数器 &gt; 0，直接减 1，线程继续执行。</li>
<li>如果计数器 == 0，线程阻塞，进入等待队列。</li>
</ul>
</li>
<li>当调用 <code>sem_post</code> 时：<ul>
<li>增加计数器值。</li>
<li>如果等待队列中有线程，则唤醒其中一个线程。</li>
</ul>
</li>
</ol>
<figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">Semaphore</span> <span class="variable">Counter</span> <span class="operator">=</span> <span class="number">2</span></span><br><span class="line"><span class="built_in">Thread</span> <span class="number">1</span><span class="operator">:</span> <span class="variable">P</span><span class="punctuation">(</span><span class="punctuation">)</span> <span class="operator">----&gt;</span> <span class="variable">Counter</span><span class="operator">--</span> <span class="punctuation">(</span><span class="number">1</span><span class="punctuation">)</span></span><br><span class="line"><span class="built_in">Thread</span> <span class="number">2</span><span class="operator">:</span> <span class="variable">P</span><span class="punctuation">(</span><span class="punctuation">)</span> <span class="operator">----&gt;</span> <span class="variable">Counter</span><span class="operator">--</span> <span class="punctuation">(</span><span class="number">0</span><span class="punctuation">)</span></span><br><span class="line"><span class="built_in">Thread</span> <span class="number">3</span><span class="operator">:</span> <span class="variable">P</span><span class="punctuation">(</span><span class="punctuation">)</span> <span class="operator">----&gt;</span> <span class="variable">Blocked</span> <span class="punctuation">(</span><span class="variable">Counter</span> <span class="operator">==</span> <span class="number">0</span><span class="punctuation">)</span></span><br><span class="line"><span class="built_in">Thread</span> <span class="number">1</span><span class="operator">:</span> <span class="variable">V</span><span class="punctuation">(</span><span class="punctuation">)</span> <span class="operator">----&gt;</span> <span class="variable">Counter</span><span class="operator">++</span> <span class="punctuation">(</span><span class="number">1</span><span class="punctuation">)</span> <span class="operator">-&gt;</span> <span class="variable">Wake</span> <span class="built_in">Up</span> <span class="built_in">Thread</span> <span class="number">3</span></span><br></pre></td></tr></table></figure>

<ul>
<li>信号量管理的是资源数量，而不是条件状态。</li>
<li>自带互斥特性，适合多个线程访问有限资源。</li>
<li><strong>适合计数型条件：</strong> 一次允许多个线程执行，而不是简单的互斥。</li>
</ul>
<h3 id="Summary-1"><a href="#Summary-1" class="headerlink" title="Summary"></a>Summary</h3><ol>
<li><strong>Semaphore 更像一个通用工具：</strong><ul>
<li>适合管理固定资源数量，如线程池、连接池、令牌桶等。</li>
<li>更简单、更高效，适合需要资源计数的场景。</li>
<li>支持跨进程同步需求。</li>
</ul>
</li>
<li><strong>Mutex + Condition Variable 提供更高级的同步机制：</strong><ul>
<li>适合复杂条件判断或事件驱动模型，如生产者/消费者问题，依赖互斥锁保证数据一致性。</li>
<li>支持灵活的条件管理，适合多条件组合。</li>
<li>更适合线程间等待和唤醒机制，不适合跨进程同步。</li>
</ul>
</li>
</ol>
<ul>
<li>在实际开发中，如果场景简单且需求是资源访问控制，选择<strong>信号量</strong>；</li>
<li>如果需要更复杂的条件管理和线程间事件通知，则选择<strong>条件变量 + 锁</strong>。</li>
</ul>
<h2 id="Applications"><a href="#Applications" class="headerlink" title="Applications"></a>Applications</h2><h3 id="Reader-Writer-Lock"><a href="#Reader-Writer-Lock" class="headerlink" title="Reader/Writer Lock"></a>Reader/Writer Lock</h3><p>读者只读不写，写者才需要修改。类似 Shared/eXclusion 共享锁和独占锁</p>
<p>RW 锁支持一个写者或者多个读者：</p>
<ul>
<li>第一个读者首先获取lock（保护reader）增加reader，获取writelock，释放lock进入临界区</li>
<li>之后其他的读者只要获取lock后增加reader个数，直接访问临界区即可</li>
<li>写者需要等待最后一个读者释放writelock</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> _<span class="title">rwlock_t</span>&#123;</span></span><br><span class="line">    <span class="type">sem_t</span> lock; <span class="comment">// basic lock  INIT: 1</span></span><br><span class="line">    <span class="type">sem_t</span> writelock;<span class="comment">//allow 1 writer / many readers INIT: 1</span></span><br><span class="line">    <span class="type">int</span> readers;<span class="comment">//number of readers  INIT:0</span></span><br><span class="line">&#125;<span class="type">rwlock_t</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">rwlock_acquire_readlock</span><span class="params">(<span class="type">rwlock_t</span> *rw)</span>&#123;</span><br><span class="line">    sem_wait(rw-&gt;lock);</span><br><span class="line">    rw-&gt;readers++;</span><br><span class="line">    <span class="keyword">if</span>(readers == <span class="number">1</span>)</span><br><span class="line">        sem_wait(rw-&gt;writelock); <span class="comment">//第一个读者获取写锁</span></span><br><span class="line">    sem_post(rw-&gt;lock);</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">rwlock_release_readlock</span><span class="params">(<span class="type">rwlock_t</span> *rw)</span>&#123;</span><br><span class="line">    sem_wait(rw-&gt;lock);</span><br><span class="line">    rw-&gt;readers;</span><br><span class="line">    <span class="keyword">if</span>(readers == <span class="number">0</span>)</span><br><span class="line">        sem_post(rw-&gt;writelock);<span class="comment">//最后一个读者释放写锁</span></span><br><span class="line">    sem_post(rw-&gt;lock);</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">rwlock_acquire_readlock</span><span class="params">(<span class="type">rwlock_t</span> *rw)</span>&#123;</span><br><span class="line">    sem_wait(rw-&gt;lock);</span><br><span class="line">    rw-&gt;readers;</span><br><span class="line">    <span class="keyword">if</span>(readers == <span class="number">0</span>)</span><br><span class="line">        sem_post(rw-&gt;writelock);<span class="comment">//最后一个读者释放写锁</span></span><br><span class="line">    sem_post(rw-&gt;lock);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这种读写锁并不一定比自旋锁更快，并且公平性无法保证，过多读者通常会饿死写者，需要进一步进行优化。</p>
<h3 id="Dining-Philosopher’s-Problem"><a href="#Dining-Philosopher’s-Problem" class="headerlink" title="Dining Philosopher’s Problem"></a>Dining Philosopher’s Problem</h3><p><strong>问题描述</strong></p>
<ul>
<li>有 5 位哲学家围坐在一张圆桌旁，他们的生活方式是 <strong>思考</strong> 和 <strong>进餐</strong>。</li>
<li>桌子上摆放着 5 根筷子，每位哲学家左右各放一根。</li>
<li>哲学家要进餐时，需要同时拿起左右两根筷子。</li>
<li>哲学家只能在拿到两根筷子后才能吃饭，否则必须等待。</li>
</ul>
<p><strong>主要难题</strong>：</p>
<ul>
<li>**死锁 (Deadlock)**：所有哲学家都同时拿起左边的筷子，导致没有哲学家能拿到第二根筷子，进入无限等待状态。</li>
<li>**饥饿 (Starvation)**：某位哲学家可能永远无法获得两根筷子，从而无法进餐。</li>
<li><strong>并发控制</strong>：需要保证哲学家拿筷子和放筷子的动作是线程安全的。</li>
</ul>
<ul>
<li><strong>方案 1：引入顺序编号</strong><br>将哲学家编号为 0 到 4，规定编号为偶数的哲学家先拿左筷子，再拿右筷子；编号为奇数的哲学家先拿右筷子，再拿左筷子。或者，最后一个哲学家先拿右筷子，再拿左筷子。这样就不会互相卡住，打破了等待的循环。</li>
<li><strong>方案 2：限制最多 4 个哲学家进入用餐状态</strong><br>使用一个计数器，确保最多 4 位哲学家能尝试拿筷子，这样至少会有一根筷子空闲，避免死锁。</li>
</ul>
<h3 id="Thread-Throttling"><a href="#Thread-Throttling" class="headerlink" title="Thread Throttling"></a>Thread Throttling</h3><p>信号量比较适合<strong>资源数量有限制</strong>的情况：比如有一群线程，每个线程都需要申请一块很大的内存空间用于计算，用于计算的这片区域就是 <strong>内存密集型</strong> 区域，如果所有线程同时申请，就会造成内存抖动（不停地换出又换入页面导致程序以极慢的速度执行）。</p>
<p>一个简单的信号量就可以解决这个问题：通过将信号量的值初始化为您希望一次进入内存密集区域的最大线程数，然后在该区域周围放置 sem_wait() 和 sem_post()，信号量自然地限制那些并发地处于危险区域的线程数量。</p>
<h2 id="Implement-sem-using-mutex-amp-cond"><a href="#Implement-sem-using-mutex-amp-cond" class="headerlink" title="Implement sem using mutex &amp; cond"></a>Implement <code>sem</code> using <code>mutex</code> &amp; <code>cond</code></h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> _<span class="title">Zem_t</span>&#123;</span></span><br><span class="line">	<span class="type">int</span> value;</span><br><span class="line">	<span class="type">pthread_mutex_t</span> lock;</span><br><span class="line">	<span class="type">pthread_cond_t</span> cond;</span><br><span class="line">&#125; Zem_t;</span><br><span class="line"><span class="type">void</span> <span class="title function_">Zem_init</span><span class="params">(Zem_t *s, <span class="type">int</span> value)</span>&#123;</span><br><span class="line">	s-&gt;value = value;</span><br><span class="line">	Cond_init(s-&gt;cond);</span><br><span class="line">	Mutex_init(s-&gt;lock);</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">Zem_wait</span><span class="params">(Zem_t *s)</span>&#123;</span><br><span class="line">	Mutex_lock(&amp;s-&gt;lock);</span><br><span class="line">	<span class="keyword">while</span>(s-&gt;value &lt;= <span class="number">0</span>)</span><br><span class="line">		Cond_wait(&amp;s-&gt;cond, &amp;s-&gt;lock);</span><br><span class="line">	s-&gt;value--;</span><br><span class="line">	Mutex_unlock(&amp;s-&gt;lock);</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">Zem_post</span><span class="params">(Zem_t *s)</span>&#123;</span><br><span class="line">	Mutex_lock(&amp;s-&gt;lock);</span><br><span class="line">	s-&gt;value++;</span><br><span class="line">	Cond_signal(&amp;s-&gt;cond);</span><br><span class="line">	Mutex_unlock(&amp;s-&gt;lock);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="Common-Concurrency-Bugs"><a href="#Common-Concurrency-Bugs" class="headerlink" title="Common Concurrency Bugs"></a>Common Concurrency Bugs</h1><p>总的来说可以分为死锁(Deadlock)和非死锁(Non-deadlock)两种，其中后者占绝大多数</p>
<h2 id="Non-deadlock-Bugs"><a href="#Non-deadlock-Bugs" class="headerlink" title="Non-deadlock Bugs"></a>Non-deadlock Bugs</h2><h3 id="Atomicity-Violation-Lock"><a href="#Atomicity-Violation-Lock" class="headerlink" title="Atomicity-Violation(Lock)"></a>Atomicity-Violation(Lock)</h3><p>这种错误违反了<strong>原子性</strong>，下图的 <code>proc_info</code> 在刚进入 if 循环的时候被取消调度，线程2将其置为NULL，切换回去的时候导致空指针异常</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Concurrency.assets/image-20241225194108926.png" alt="image-20241225194108926"></p>
<p>解决方案：在访问共享资源的时候加锁</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Concurrency.assets/image-20241225194511624.png" alt="image-20241225194511624"></p>
<h3 id="Order-Violation-CV"><a href="#Order-Violation-CV" class="headerlink" title="Order-Violation(CV)"></a>Order-Violation(CV)</h3><p>模块化：不同线程承担不同职责，线程1负责初始化 <code>mThread</code> ，线程2访问 <code>mThread</code></p>
<p>如果<strong>乱序执行</strong>，就会出现线程2访问到空指针导致程序崩溃：</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Concurrency.assets/image-20241225194032626-1735126873754-1.png" alt="image-20241225194032626"></p>
<p>因此，用一个状态变量或者<code>mThread</code>本身来代表初始化是否成功，然后用条件变量解决问题：</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Concurrency.assets/image-20241225194350912.png" alt="image-20241225194350912"></p>
<h2 id="Deadlock-Bugs"><a href="#Deadlock-Bugs" class="headerlink" title="Deadlock Bugs"></a>Deadlock Bugs</h2><p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Concurrency.assets/image-20241225195039934.png" alt="image-20241225195039934"></p>
<p>死锁原因：获取锁的顺序相反</p>
<ol>
<li>在大型代码库中组件依赖复杂 循环依赖就会导致死锁的发生</li>
<li>模块化封装会隐藏底层的细节 <code>v1.addAll(v2)</code> <code>v2.addAll(v1)</code> 同时调用可能会发生死锁</li>
</ol>
<p>产生死锁的四个条件：</p>
<ol>
<li><strong>互斥</strong>：线程对资源进行互斥的访问</li>
<li><strong>持有并等待</strong>：线程在持有资源的同时也在等待其他资源</li>
<li><strong>非抢占</strong>：线程获得的资源（如锁）不能被抢占</li>
<li><strong>循环等待</strong>：线程之间存在环路，上面的每个线程都会额外持有下个线程想要申请的资源</li>
</ol>
<h3 id="Prevention"><a href="#Prevention" class="headerlink" title="Prevention"></a>Prevention</h3><h4 id="Circular-Wait-Forced-Order"><a href="#Circular-Wait-Forced-Order" class="headerlink" title="Circular Wait: Forced Order"></a>Circular Wait: Forced Order</h4><p>强制规定获取锁的顺序</p>
<p><strong>偏序锁：</strong>如果资源之间的依赖关系较少或依赖是局部的，偏序锁，提供更好的性能和灵活性。</p>
<p><strong>全序锁：</strong>如果资源之间的依赖关系复杂且必须确保一致性（如事务或分布式系统），全序锁更可靠</p>
<p>如果一个函数要抢多个锁，可以根据<strong>锁的地址</strong>作为锁的顺序：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">do_something(mutex *m1,mutex *m2)&#123;</span><br><span class="line">	<span class="keyword">if</span>(m1 &lt; m2)&#123;</span><br><span class="line">		pthread_mutex_lock(*m1);</span><br><span class="line">		pthread_mutex_lock(*m2);</span><br><span class="line">	</span><br><span class="line">	&#125; <span class="keyword">else</span>&#123;</span><br><span class="line">		pthread_mutex_lock(*m2);</span><br><span class="line">		pthread_mutex_lock(*m1);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这样可以保证 <code>do_something(&amp;m1,&amp;m2)</code> 和 <code>do_something(&amp;m2,&amp;m1)</code> 是同样的抢锁顺序</p>
<h4 id="Hold-and-wait-Atomic-Acquiring"><a href="#Hold-and-wait-Atomic-Acquiring" class="headerlink" title="Hold-and-wait: Atomic Acquiring"></a>Hold-and-wait: Atomic Acquiring</h4><p>在抢锁的最外层加一道锁（原子性抢锁）防止抢锁过程中突然被取消调度，切换到其他线程：</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Concurrency.assets/image-20241225203212407.png" alt="image-20241225203212407"></p>
<p>缺点：不适合封装，因为需要准确知道要抢哪些锁并提前全部抢到（即使当前并不需要）</p>
<h4 id="No-Preemption-trylock"><a href="#No-Preemption-trylock" class="headerlink" title="No Preemption:trylock"></a>No Preemption:<code>trylock</code></h4><p>可以通过<code>trylock</code>这种非阻塞式抢锁来避免死锁，但是这种方法会导致活锁，对封装的支持也不好，代码抢完锁中途获取的资源（比如申请的内存空间），如果抢锁失败，还应该释放</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Concurrency.assets/image-20241225204421920.png" alt="image-20241225204421920"></p>
<h5 id="Livelock"><a href="#Livelock" class="headerlink" title="Livelock"></a>Livelock</h5><p><strong>死锁：</strong> 所有线程都进入等待状态，完全停止运行。</p>
<p><strong>活锁：</strong> 所有线程仍然在运行，但因为不断调整状态，始终无法完成任务。</p>
<p>解决方案：</p>
<ol>
<li>退避算法（Backoff）:在循环结束的时候，先随机等待一段时间再重复</li>
<li>引入有限重试机制: 因为线程一直在运行，因此可以限制最大重试次数</li>
<li>使用更高层次的同步机制,结合条件变量或阻塞队列</li>
</ol>
<h4 id="Mutual-Exclusion-Lock-free-CAS"><a href="#Mutual-Exclusion-Lock-free-CAS" class="headerlink" title="Mutual Exclusion: Lock-free(CAS)"></a>Mutual Exclusion: Lock-free(CAS)</h4><p>利用硬件指令的原子性，完全避免互斥区的存在：CAS 失败就不断重试，直到成功为止（乐观锁）</p>
<p>COMPARE AND SWAP 加之前看看是不是对应的正确的值，是的话再赋值。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//自增:</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">CAS</span><span class="params">(<span class="type">int</span> *address, <span class="type">int</span> expected, <span class="type">int</span> new)</span>&#123;</span><br><span class="line">	<span class="keyword">if</span>(*address == expected)&#123;</span><br><span class="line">        *address = new;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">increment</span><span class="params">(<span class="type">int</span> *value, <span class="type">int</span> amount)</span>&#123;</span><br><span class="line">    <span class="type">int</span> old;</span><br><span class="line">    <span class="keyword">do</span>&#123;</span><br><span class="line">		old = *value;</span><br><span class="line">    &#125; <span class="keyword">while</span>(CAS(value, old, old + amount) == <span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//链表插入</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">CAS</span><span class="params">(<span class="type">node_t</span> **address, <span class="type">node_t</span> *expected, <span class="type">node_t</span> *new)</span>&#123;</span><br><span class="line">	<span class="keyword">if</span>(*address == expected)&#123;</span><br><span class="line">        *address = new;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">insert</span><span class="params">(<span class="type">int</span> value)</span> &#123;</span><br><span class="line">    <span class="type">node_t</span> *n = <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="type">node_t</span>));</span><br><span class="line">    assert(n != <span class="literal">NULL</span>);</span><br><span class="line">    n-&gt;value = value;</span><br><span class="line">    pthread_mutex_lock(listlock); <span class="comment">// begin critical section</span></span><br><span class="line">    n-&gt;next = head;</span><br><span class="line">    head = n;</span><br><span class="line">    pthread_mutex_unlock(listlock); <span class="comment">// end critical section</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">insert</span><span class="params">(<span class="type">int</span> value)</span>&#123;</span><br><span class="line">    <span class="type">node_t</span> *n = <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="type">node_t</span>));</span><br><span class="line">    assert(n!=<span class="literal">NULL</span>);</span><br><span class="line">    n-&gt;value = value;</span><br><span class="line">    <span class="keyword">do</span>&#123;</span><br><span class="line">        n-&gt;next = head;<span class="comment">//新节点的下一个应该是现在的头</span></span><br><span class="line">    &#125; <span class="keyword">while</span>(CAS(&amp;head, n-&gt;next, n) == <span class="number">0</span>);<span class="comment">//现在的头应该等于新节点的下一个,不等于</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Avoid-via-Scheduling"><a href="#Avoid-via-Scheduling" class="headerlink" title="Avoid via Scheduling"></a>Avoid via Scheduling</h3><p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Concurrency.assets/image-20241225213119760.png" alt="image-20241225213119760"></p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Concurrency.assets/image-20241225213105676.png" alt="image-20241225213105676"></p>
<p>不要同时并行执行需要获取完全相同锁的线程</p>
<h3 id="Detect-and-Recover"><a href="#Detect-and-Recover" class="headerlink" title="Detect and Recover"></a>Detect and Recover</h3><p>如果根除死锁实在很困难，可以定期检查死锁，并运行专门的程序来恢复</p>
<h1 id="Event-based-Concurrency"><a href="#Event-based-Concurrency" class="headerlink" title="Event-based Concurrency"></a>Event-based Concurrency</h1><p><strong>Event</strong> Loop: 等待事件-&gt;处理事件-&gt;等待事件，重点是如何获取事件？</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span>(<span class="number">1</span>)&#123;</span><br><span class="line">	events = getEvents();</span><br><span class="line">    <span class="keyword">for</span> (e in events)</span><br><span class="line">    	processEvent(e);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="select"><a href="#select" class="headerlink" title="select()"></a><code>select()</code></h2><h3 id="API-Usage"><a href="#API-Usage" class="headerlink" title="API Usage"></a>API Usage</h3><ul>
<li><strong>Purpose</strong>: 监视 FD 是否准备好接受 I/O 操作</li>
<li><strong>Function Signature</strong>: <code>int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *errorfds, struct timeval *timeout)</code></li>
<li><strong>Parameters</strong>:<ul>
<li><code>nfds</code>: 检查集合中 [0,nfds-1] 的 FD</li>
<li><code>readfds</code>: 监控 readfds 中的可读事件(新的数据包到达，准备处理)</li>
<li><code>writefds</code>: 监控 writefds 中的可写事件(服务器回复需要写入队列有空)</li>
<li><code>errorfds</code>: 监控 errorfds 中的错误事件</li>
<li><code>timeout</code>: 最大等待时间</li>
</ul>
</li>
<li><strong>Return Value</strong>: 返回准备好 I/O 的 FDs</li>
</ul>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Concurrency.assets/image-20241225225619265.png" alt="image-20241225225619265"></p>
<h3 id="Lock-free"><a href="#Lock-free" class="headerlink" title="Lock-free"></a>Lock-free</h3><p>有了单CPU和基于事件的应用程序，并发程序中的问题就不再存在。具体来说，因为一次只处理一个事件，所以不需要获取或释放锁；基于事件的服务器不能被另一个线程中断，因为它绝对是单线程的。因此，线程程序中常见的并发错误不会在基于事件的基本方法中体现出来。</p>
<h3 id="Problem-Blocking-Syscalls"><a href="#Problem-Blocking-Syscalls" class="headerlink" title="Problem: Blocking Syscalls"></a>Problem: Blocking Syscalls</h3><p>如果某个事件要求发出可能会阻塞的系统调用怎么办？ 例如，假设一个请求从客户端发送到服务器，以从磁盘读取文件并将其内容返回到请求客户端（非常类似于简单的 HTTP 请求）。为了服务这样的请求，某些事件处理程序最终必须发出 <code>open()</code> 系统调用来打开文件，然后执行一系列 <code>read()</code> 调用来读取文件。当文件被读入内存时，服务器可能会开始将结果发送到客户端。 <code>open()</code> 和 <code>read()</code> 调用都可能向存储系统发出 I/O 请求（当所需的元数据或数据尚未在内存中时），因此可能需要很长时间才能提供服务。对于基于线程的服务器，这不是问题：当发出 I/O 请求的线程挂起（等待 I/O 完成）时，其他线程可以运行，从而使服务器能够取得进展。事实上，I/O 和其他计算的这种自然重叠使得基于线程的编程变得非常自然和直接。</p>
<p>然而，使用基于事件的方法，没有其他线程可以运行：只有主事件循环。这意味着，如果事件处理程序发出阻塞调用，则整个服务器将执行此操作：阻塞直到调用完成。当事件循环阻塞时，系统处于空闲状态，因此潜在地浪费了巨大的资源。因此，我们在基于事件的系统中必须遵守一条规则：不允许阻塞调用。</p>
<h2 id="Asynchoronous-I-O"><a href="#Asynchoronous-I-O" class="headerlink" title="Asynchoronous I/O"></a>Asynchoronous I/O</h2><h3 id="API-Usage-1"><a href="#API-Usage-1" class="headerlink" title="API Usage"></a>API Usage</h3><p>要对文件发出异步读取，应用程序应首先使用相关信息填充此 AIO 控制块（aiocb）：</p>
<ul>
<li>要读取的文件的文件描述符 (aio fildes)</li>
<li>文件内的偏移量 (aio offset) </li>
<li>长度请求的长度 (aio nbytes)</li>
<li>读取结果应复制到的内存位置 (aio buf)</li>
</ul>
<p>填充该结构后，应用程序必须发出 AIO 来读取文件；在 Mac 上，此 API 是一个异步读取的 API： <code>int aio_read(struct aiocb *aiocbp</code>);  该调用尝试发出 I/O；如果成功，它会立即返回，并且应用程序（即基于事件的服务器）可以继续其工作。 </p>
<p>然而，我们必须解决最后一块难题。我们如何判断 I/O 何时完成，从而确定缓冲区（由 aiobuf 指向）现在已在其中包含所请求的数据？  还需要最后一个 API。在 Mac 上，它被称为 <code>aio_error()</code> API 如下所示： <code>int aio_error(const struct aiocb *aiocbp)</code>;  该系统调用检查 aiocbp 引用的请求是否已完成。如果是，则返回成功（用 0 表示）；  如果不是，则返回 <code>EINPROGRESS</code>。</p>
<h3 id="Poll-or-Interrupt"><a href="#Poll-or-Interrupt" class="headerlink" title="Poll or Interrupt"></a>Poll or Interrupt</h3><p>对于每个未完成的异步 I/O，应用程序可以通过调用 <code>aio_error()</code> 定期<strong>轮询</strong>系统，以确定所述 I/O 是否尚未完成。但是轮询很浪费CPU。为了解决这个问题，一些系统提供了基于中断的方法。此方法使用 UNIX Signals 来通知应用程序异步 I/O 何时完成，从而无需重复询问系统。</p>
<p>在没有异步I/O的系统中，无法实现纯粹的基于事件的方法。然而，出现了一些相当有效的混合方法。其中事件用于处理网络数据包，线程池用于管理未完成的 I/O。<strong>I/O 多路复用</strong></p>
<h4 id="UNIX-Signals"><a href="#UNIX-Signals" class="headerlink" title="UNIX Signals"></a>UNIX Signals</h4><p>所有现代 UNIX 变体中都存在一个巨大且令人着迷的基础设施，称为信号。最简单的是，信号提供了一种与进程通信的方式。具体来说，可以将信号传递给应用程序；这样做会阻止应用程序运行信号处理程序（即应用程序中处理该信号的某些代码）正在执行的任何操作。 完成后，该进程将恢复其之前的行为。 每个信号都有一个名称，如HUP（挂起）、INT（中断）、SEGV（分段违规）等</p>
<p>有趣的是，有时是内核本身发出信号。例如，当程序遇到 Segmentation Violation 时，操作系统会向其发送 <code>SIGSEGV</code>；如果程序调用了<code>signal(SIGSEV, handler)</code> 就可以运行一些代码（signal handler）来响应。当发送到没有配置响应信号的进程时，将执行默认行为；对于SEGV，该进程被终止。 </p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">handle</span><span class="params">(<span class="type">int</span> arg)</span> &#123;<span class="comment">//handler</span></span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">&quot;stop wakin’ me up...\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *argv[])</span> &#123;</span><br><span class="line">    signal(SIGHUP, handle);</span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>)</span><br><span class="line">        ; <span class="comment">// doin’ nothin’ except catchin’ some sigs</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> <code>./main &amp;</code> 后台运行进程，随后返回pid；</p>
<p><code>kill -HUP [pid]</code> 给进程发送 SIGHUP 信号：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">prompt&gt; ./main &amp;</span><br><span class="line">[<span class="number">3</span>] <span class="number">36705</span></span><br><span class="line">prompt&gt; <span class="built_in">kill</span> <span class="literal">-HUP</span> <span class="number">36705</span></span><br><span class="line">stop wakin’ me up...</span><br><span class="line">prompt&gt; <span class="built_in">kill</span> <span class="literal">-HUP</span> <span class="number">36705</span></span><br><span class="line">stop wakin’ me up...</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="Problem-State-Management"><a href="#Problem-State-Management" class="headerlink" title="Problem: State Management"></a>Problem: State Management</h3><p>在 Thread-based 服务器中，从<code>read</code>调用返回，程序可以直接从栈上知道 sd 是多少</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> rc = read(fd, buffer, size);</span><br><span class="line">rc = write(sd, buffer, size);</span><br></pre></td></tr></table></figure>

<p>而在 Event-based 服务器中，从 <code>aio_read</code> 返回后，应当记录下在处理<code>read</code>事件时必要的信息(continuation)，比如将套接字描述符（sd）记录在某种数据结构（例如哈希表）中，并由文件描述符（fd）索引。</p>
<p>当<code>aio_error</code>显示成功读取后，事件处理器将使用 FD 来查找 continuation，这会将 sd 的值返回给调用者。最终，服务器可以完成最后一点工作，将数据写入套接字。</p>
<h2 id="Other-Problems-with-Events"><a href="#Other-Problems-with-Events" class="headerlink" title="Other Problems with Events"></a>Other Problems with Events</h2><ol>
<li><p>单核到多核将会有多个事件处理器同步运行的情况，会产生同步问题。不再可能进行无锁的简单事件处理。</p>
</li>
<li><p>不能与某些类型的系统活动（例如分页）很好地集成。例如，如果事件处理器发生Page Fault，这就会导致阻塞，因此服务器在Page Fault完成处理之前会一直阻塞。</p>
</li>
<li><p>随着各种程序的确切语义发生变化，基于事件的代码可能很难管理超时。例如，如果例程从非阻塞更改为阻塞，则调用该例程的事件处理程序也必须通过将自身分成两部分来进行更改以适应其新性质。由于阻塞对基于事件的服务器来说是灾难性的，因此程序员必须始终留意每个事件使用的 API 语义中的此类变化。 </p>
</li>
<li><p>异步磁盘 I/O 并未实现与异步网络 I/O 完全集成。例如，虽然人们只想使用 select() 接口来管理所有未完成的 I/O，但通常需要用于网络的 select() 和用于磁盘 I/O 的 AIO 调用的某种组合。</p>
</li>
</ol>
<h1 id="Monitor"><a href="#Monitor" class="headerlink" title="Monitor"></a>Monitor</h1><h2 id="Semaphore-amp-Monitor"><a href="#Semaphore-amp-Monitor" class="headerlink" title="Semaphore &amp; Monitor"></a>Semaphore &amp; Monitor</h2><ul>
<li>**信号量(Semaphere)**：操作系统提供的一种协调共享资源访问的方法。和用软件实现的同步比较，软件同步是平等线程间的的一种同步协商机制，不能保证原子性。而信号量则由操作系统进行管理，地位高于进程，操作系统保证信号量的原子性。</li>
<li>**管程(Monitor)**：解决信号量在临界区的 PV 操作上的配对的麻烦，把配对的 PV 操作集中在一起，生成的一种并发编程方法。其中使用了条件变量这种同步机制。</li>
</ul>
<p><strong>所谓管程，指的是管理共享变量以及对共享变量的操作过程，让他们支持并发。</strong>翻译为 Java 领域的语言，就是管理类的成员变量和成员方法，让这个类是线程安全的。一般采用 Mesa Semantic</p>
<p><strong>说明：</strong> 信号量将共享变量 S 封装起来，对共享变量 S 的所有操作都只能通过 PV 操作进行，这是不是和面向对象的思想是不是很像呢？事实上，封装共享变量是并发编程的常用手段。</p>
<p>在信号量中，当 P 操作无法获取到锁时，将当前线程添加到**同步队列(syncQueue)<strong>中。当其余线程 V 释放锁时，从同步队列中唤醒等待线程。但当有多个条件通过信号量 PV 配对时会异常复杂，所以管程中引入了</strong>等待队列(waitQueue)**的概念，进一步封装这些复杂的操作。</p>
<p>在用信号量实现的阻塞队列中，为了实现阻塞队列的功能，即等待-通知(wait-notify)，除了使用互斥锁 mutex 外，还需要两个判断队满和队空的资源信号量 full 和 empty，使用起来不仅复杂，还容易出错。管程在信号量的基础上，更进一步，增加了条件同步，对多个条件变量使用多个等待队列，将上述复杂的操作封装起来: <code>wait()</code> <code>notifyAll()</code> <code>notify()</code></p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Concurrency.assets/1322310-20200320081430470-1065805408.png" alt=" "></p>
<h3 id="API-Usage-2"><a href="#API-Usage-2" class="headerlink" title="API Usage"></a>API Usage</h3><h4 id="While-Loop-wait"><a href="#While-Loop-wait" class="headerlink" title="While Loop wait()"></a>While Loop <code>wait()</code></h4><p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Concurrency.assets/250px-Monitor_(synchronization)-Mesa.png" alt="img"></p>
<p>MESA 管程里面，T2 通知完 T1 后，T2 还是会接着执行，T1 并不立即执行，仅仅是从条件变量的等待队列进到入口等待队列里面。这样做的好处是 notify() 不用放到代码的最后，T2 也没有多余的阻塞唤醒操作。但是也有个副作用，就是<strong>当 T1 再次执行的时候，可能曾经满足的条件现在已经不满足了</strong>，所以需要以while循环方式检验条件变量。</p>
<p><code>notify()</code> or <code>notifyAll()</code> ？什么时候可以使用 <code>notify()</code> 呢？需要满足以下三个条件：</p>
<ol>
<li>所有等待线程拥有相同的等待条件；</li>
<li>所有等待线程被唤醒后，执行相同的操作；</li>
<li>只需要唤醒一个线程。</li>
</ol>
<p><code>notify()</code> 一般只适用于只有一个条件变量的情况，生产者和消费者等待在同一个条件上会导致错误唤醒同类，造成死锁。<code>notifyAll()</code> 类似于 <code>pthread_cond_broadcast()</code> 都可以用于唤醒多个等待在同一个条件变量上的线程。重点是 <strong>while 里面的等待条件是完全相同的。</strong></p>
<h2 id="BlockingQueue-Producer-Consumer"><a href="#BlockingQueue-Producer-Consumer" class="headerlink" title="BlockingQueue: Producer/Consumer"></a>BlockingQueue: Producer/Consumer</h2><p>Condition 能够更细粒度地进行编程</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BlockedQueue</span>&lt;T&gt; &#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="type">Lock</span> <span class="variable">lock</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ReentrantLock</span>();</span><br><span class="line">    <span class="comment">// 条件变量：队列不满</span></span><br><span class="line">    <span class="keyword">final</span> <span class="type">Condition</span> <span class="variable">notFull</span> <span class="operator">=</span> lock.newCondition();</span><br><span class="line">    <span class="comment">// 条件变量：队列不空</span></span><br><span class="line">    <span class="keyword">final</span> <span class="type">Condition</span> <span class="variable">notEmpty</span> <span class="operator">=</span> lock.newCondition();</span><br><span class="line">    <span class="comment">// 入队</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">enq</span><span class="params">(T x)</span> &#123;</span><br><span class="line">        lock.lock();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">while</span> (队列已满) &#123;</span><br><span class="line">                <span class="comment">// 等待队列不满</span></span><br><span class="line">                notFull.await();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// add x to queue</span></span><br><span class="line">            <span class="comment">// 入队后,通知可出队</span></span><br><span class="line">            notEmpty.signal();</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            lock.unlock();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 出队</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">deq</span><span class="params">()</span> &#123;</span><br><span class="line">        lock.lock();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">while</span> (队列已空) &#123;</span><br><span class="line">                <span class="comment">// 等待队列不空</span></span><br><span class="line">                notEmpty.await();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// remove the first element from queue</span></span><br><span class="line">            <span class="comment">// 出队后，通知可入队</span></span><br><span class="line">            notFull.signal();</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            lock.unlock();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="AQS-amp-synchronized"><a href="#AQS-amp-synchronized" class="headerlink" title="AQS &amp; synchronized"></a>AQS &amp; synchronized</h2><p>JUC AQS 就是基于管程实现的，内部包含两个队列，一个是同步队列，一个是等待队列：</p>
<ol>
<li>同步队列：锁被占用时，会将该线程添加到同步队列中。当锁释放后，会从队列中唤醒一个线程，又分为公平和非公平两种。</li>
<li>等待队列：当调用 await 时，会将该线程添加到等待队列中。当其它线程调用 notify 时，会将该线程从等待队列移动到同步队列中，重新竞争锁。</li>
</ol>
<p>synchronized 也是基于管程实现的，核心的数据结构见 ObjectMonitor。AQS 和 synchronized 都是管程 MESA 模型在 Java 中的应用。一切都套路，有章可循。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://scatteredream.github.io/2025/01/18/OSTEP%20Virtualization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars.githubusercontent.com/u/62317679?s=400&v=4">
      <meta itemprop="name" content="碎梦">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="scatteredream's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | scatteredream's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/01/18/OSTEP%20Virtualization/" class="post-title-link" itemprop="url">虚拟化</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-01-18 00:00:00" itemprop="dateCreated datePublished" datetime="2025-01-18T00:00:00+08:00">2025-01-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-05-03 21:12:30" itemprop="dateModified" datetime="2025-05-03T21:12:30+08:00">2025-05-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/OS/" itemprop="url" rel="index"><span itemprop="name">OS</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="CPU-Virtualization"><a href="#CPU-Virtualization" class="headerlink" title="CPU Virtualization"></a>CPU Virtualization</h1><h2 id="进程（process）"><a href="#进程（process）" class="headerlink" title="进程（process）"></a>进程（process）</h2><p><strong>操作系统</strong>：早期是一些函数库，然后发展出了保护的作用（内核态与用户态），之后是多道程序（多进程、多线程）</p>
<p><strong>软件设计思维</strong>：分离机制与策略</p>
<ul>
<li>机制：如何进行上下文切换？</li>
<li>策略：什么情况下，应该切换到谁？</li>
</ul>
<p><strong>进程</strong>：程序没有运行的时候，就是硬盘中静态的代码，程序开始运行了，就在内存中开辟属于自己的空间，进程可以看作是操作系统对程序运行的一种抽象。</p>
<h3 id="进程创建"><a href="#进程创建" class="headerlink" title="进程创建"></a>进程创建</h3><ul>
<li>内存地址空间，特定CPU寄存器的值</li>
<li><strong>内存分配</strong>：程序代码、静态数据、运行时数据（包括堆栈和IO设置）</li>
<li><strong>栈空间</strong>（Stack）：可以由<code>main</code>传参进行初始化，主要存放局部变量、函数参数和返回地址</li>
<li><strong>用于IO的文件描述符</strong>（Descriptor）：默认开启<code>stdin</code> <code>stdout</code> <code>stderr</code>三个文件</li>
<li><strong>堆空间</strong>（Heap）：用于在程序运行时动态地向OS申请一片内存(<code>malloc</code>)</li>
<li>在进程创建之后，OS将CPU控制权给到程序，开始执行<code>main</code></li>
</ul>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241207204834626.png" alt="image-20241207204834626"></p>
<h3 id="进程状态"><a href="#进程状态" class="headerlink" title="进程状态"></a>进程状态</h3><p>加载到内存的进程基本状态如下三种</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241207204852570.png" alt="image-20241207204852570"></p>
<ul>
<li><strong>运行中</strong>：运行中的进程，也可以被反向调度</li>
<li><strong>待运行</strong>（就绪）：就绪的程序随时可以运行，等待调度</li>
<li><strong>阻塞</strong>：程序运行到不需要CPU的部分（比如IO）就会到阻塞状态，等IO任务完成会变成就绪</li>
<li>OS选择在进程发起IO时切换到别的进程，这样可以保持CPU繁忙，<strong>在IO结束时没有选择切换回去，这就是策略</strong></li>
</ul>
<h3 id="进程的数据结构"><a href="#进程的数据结构" class="headerlink" title="进程的数据结构"></a>进程的数据结构</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// the registers xv6 will save and restore</span></span><br><span class="line"><span class="comment">// to stop and subsequently restart a process</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">context</span> &#123;</span></span><br><span class="line">    <span class="type">int</span> eip;<span class="comment">//instruction ptr </span></span><br><span class="line">    <span class="type">int</span> esp;<span class="comment">//stack ptr</span></span><br><span class="line">    <span class="type">int</span> ebx;</span><br><span class="line">    <span class="type">int</span> ecx;</span><br><span class="line">    <span class="type">int</span> edx;</span><br><span class="line">    <span class="type">int</span> esi;</span><br><span class="line">    <span class="type">int</span> edi;</span><br><span class="line">    <span class="type">int</span> ebp;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// the different states a process can be in</span></span><br><span class="line"><span class="class"><span class="keyword">enum</span> <span class="title">proc_state</span> &#123;</span> UNUSED, EMBRYO, SLEEPING,</span><br><span class="line">RUNNABLE, RUNNING, ZOMBIE &#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// the information xv6 tracks about each process</span></span><br><span class="line"><span class="comment">// including its register context and state</span></span><br><span class="line"><span class="comment">// PCB</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">proc</span> &#123;</span></span><br><span class="line">    <span class="type">char</span> *mem; <span class="comment">// Start of process memory</span></span><br><span class="line">    uint sz; <span class="comment">// Size of process memory</span></span><br><span class="line">    <span class="type">char</span> *kstack; <span class="comment">// Bottom of kernel stack for this process</span></span><br><span class="line">    <span class="class"><span class="keyword">enum</span> <span class="title">proc_state</span> <span class="title">state</span>;</span> <span class="comment">// Process state</span></span><br><span class="line">    <span class="type">int</span> pid; <span class="comment">// Process ID</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">proc</span> *<span class="title">parent</span>;</span> <span class="comment">// Parent process</span></span><br><span class="line">    <span class="type">void</span> *chan; <span class="comment">// If !zero, sleeping on chan</span></span><br><span class="line">    <span class="type">int</span> killed; <span class="comment">// If !zero, has been killed</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">file</span> *<span class="title">ofile</span>[<span class="title">NOFILE</span>];</span> <span class="comment">// Open files</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">inode</span> *<span class="title">cwd</span>;</span> <span class="comment">// Current directory</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">context</span> <span class="title">context</span>;</span> <span class="comment">// Switch here to run process</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">trapframe</span> *<span class="title">tf</span>;</span> <span class="comment">// Trap frame for the current interrupt</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<blockquote>
<p> A process list contains information about all processes in the system. Each entry is found in what is sometimes called a process control block (<strong>PCB</strong>), which is really just a structure that contains information about a specific process. </p>
</blockquote>
<ul>
<li><strong>上下文</strong>：指令指针、栈指针等都是CPU物理寄存器的内容，指令得以继续执行的关键，在恢复进程时很重要。</li>
<li><strong>进程状态</strong></li>
<li><strong>其他的静态信息</strong>：进程地址空间，父进程、中断信息、打开的文件等。</li>
</ul>
<p><img src="https://cdn.mazhen.tech/images/202209241609976.png" alt="vfs"></p>
<h3 id="进程API"><a href="#进程API" class="headerlink" title="进程API"></a>进程API</h3><h4 id="fork-wait-exec"><a href="#fork-wait-exec" class="headerlink" title="fork wait exec"></a>fork wait exec</h4><ul>
<li><strong>fork</strong>：复制一个和父进程一样的子进程（子进程直接从fork返回然后继续执行）子进程的内存空间和父进程是独立的，并且变量的值大部分一样，</li>
<li><strong>wait</strong>：子进程创建后，根据OS调度（schedule）决定先后顺序，wait可以使父进程等子进程执行完再开始运行</li>
<li><strong>exec</strong>：当前进程不想运行和之前一样的代码，可以调用exec加参数运行其他代码，新的程序会替代原来进程的所有信息，因此exec后边的代码是不会被执行的。</li>
</ul>
<h4 id="shell"><a href="#shell" class="headerlink" title="shell"></a>shell</h4><ul>
<li>shell的基本原理就是主进程fork wait 子进程这边exec 运行其他程序，运行完成主进程wait结束，继续进行其他操作</li>
<li><strong>输出重定向</strong>（redirecting）：默认输出就是标准输出流，如果你想重定向到一个文件，应当关闭stdout然后重新打开一个你想要的文件描述符。</li>
<li><strong>管道</strong>（pipe）：也类似与输出重定向，上一个的输出无缝作为下一个的输入</li>
<li><strong>有用的cli工具</strong>：top(table of processes), ps(process status), man(manual)…</li>
</ul>
<h4 id="signals-and-users"><a href="#signals-and-users" class="headerlink" title="signals and users"></a>signals and users</h4><blockquote>
<p>For example, control-c sends a SIGINT (interrupt) to the process (normally terminating it) and control-z sends a SIGTSTP (stop) signal thus pausing the process in mid-execution (you can resume it later with a command, e.g., the fg built-in command found in many shells).</p>
<p>receive and process those signals within individual processes, and  send signals to individual processes as well as entire process groups.</p>
</blockquote>
<p><code>signal()</code>可以使进程能够监听到上述这些信号，暂停现有程序执行，然后对信号做出一定的响应</p>
<blockquote>
<p>Users generally can only control their own processes; it is the job of the operating system to parcel out resources (such as CPU, memory, and disk) to each user (and their processes) to meet overall system goals.</p>
</blockquote>
<p>用户等级决定他们是否有权利发出某些特定的信号</p>
<hr>
<h2 id="机制：受限-直接执行"><a href="#机制：受限-直接执行" class="headerlink" title="机制：受限 直接执行"></a>机制：受限 直接执行</h2><h3 id="Limited-Direct-Execution"><a href="#Limited-Direct-Execution" class="headerlink" title="Limited Direct Execution"></a>Limited Direct Execution</h3><p><strong>直接执行</strong>：直接在CPU上运行程序。</p>
<p><strong>受限</strong>：一个进程要调用I/O，但是还不能让进程完全控制系统。</p>
<p><strong>用户模式</strong>（user mode）：应用程序不能完全控制硬件资源，如果硬要发起IO请求，CPU会出现异常，OS将终止进程</p>
<p><strong>内核模式</strong>（kernel mode）：操作系统可以完全掌控硬件。</p>
<blockquote>
<p>When changing protection levels from user to kernel mode, the kernel shouldn’t use the stack of the user process, because it may not be valid. The user process may be <strong>malicious</strong> or <strong>contain an error that causes the user %esp to contain an address that is not part of the process’s user memory</strong>.</p>
</blockquote>
<h4 id="syscall-amp-trap"><a href="#syscall-amp-trap" class="headerlink" title="syscall &amp; trap"></a>syscall &amp; trap</h4><p><strong>系统调用</strong>（system call）：允许内核小心地向用户暴露某些关键功能。执行<strong>trap</strong>指令，进入操作系统内核，将特权级别提升至内核模式，完成之后return from trap，返回值并将特权级别降低至用户模式。</p>
<blockquote>
<p>Typical user applications run in user mode, and use a system call to trap into the kernel to request operating system services.</p>
</blockquote>
<p>系统调用的参数放到一个指定的寄存器处，系统调用号也放到指定寄存器，需要仔细遵循约定来正确处理参数与返回值，高级语言通常屏蔽了底层硬件细节，因此需要使用汇编语言：</p>
<ul>
<li><strong>系统调用</strong>：用户程序通过陷阱指令请求内核服务（如文件操作、进程管理）。例如，在x86中：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mov eax, 1   ; 系统调用号 (exit)</span><br><span class="line">mov ebx, 0   ; 参数 (退出码)</span><br><span class="line">int 0x80     ; 触发陷阱</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>中断处理</strong>：硬件设备通过中断向量触发陷阱，操作系统用汇编语言编写中断向量表。</li>
<li><strong>异常处理</strong>：陷阱用于处理非法操作（如除零或非法内存访问）。</li>
</ul>
<p><strong>陷阱表</strong>（trap table）：用户态不能执行io等直接操控底层硬件，否则就是非法的。进入内核态以后也不能随便寻址执行程序，必须跳到指定地址去执行对应的程序，这个指定的程序地址是<strong>内核</strong>（kernel）在启动时通过<strong>陷阱表</strong>告诉硬件的。用户程序也不能够识别陷阱表的内容。</p>
<blockquote>
<p>The trap instruction saves register state carefully, changes the hardware status to kernel mode, and jumps into the OS to a pre-specified destination: the trap table.</p>
<p>When the OS finishes servicing a system call, it returns to the user program via another special return-from-trap instruction, which reduces privilege and returns control to the instruction after the trap that jumped into the OS</p>
</blockquote>
<p>Limited Direct Execution Timeline：</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241207194358704.png" alt="image-20241207194358704"></p>
<ul>
<li><p>要么是内核态要么是用户态，在用户进程开始执行之前（main）的准备工作肯定是由内核态完成，因此就要return from trap，切换到用户态。跳转到main函数</p>
</li>
<li><p>执行系统调用或者响应中断时，通过trap指令，cpu控制权腾给os，陷入内核态，执行的是与之前不同的程序，就需要保存执行的现场以便之后继续执行，将cpu寄存器上的内容先保存到<strong>内核栈（kernel stack）</strong>。</p>
</li>
<li><p>在系统调用结束之后把内核栈的内容弹出恢复到CPU寄存器上，切换回用户模式，继续执行之前的内容，最后main函数返回，同时通过exit()进行trap，进入内核态，做清理工作。</p>
</li>
</ul>
<h3 id="Limited-Direct-Execution-Timer-Interrupt"><a href="#Limited-Direct-Execution-Timer-Interrupt" class="headerlink" title="Limited Direct Execution(Timer Interrupt)"></a>Limited Direct Execution(Timer Interrupt)</h3><p><strong>直接执行（Direct Execution）</strong>：用户进程占用CPU，OS作为一个程序并没有在运行。问题在于OS如何重新获得CPU的控制权，以便在操控程序运行取得主动权。</p>
<p><strong>协作</strong>：OS只能等待被动的系统调用或者触发异常才会重新获得CPU控制权。</p>
<p><strong>非协作</strong>：时钟硬件设备可以编程为若干毫秒产生一次中断信号，CPU 检测到时钟中断信号后，暂停当前正在运行的任务，跳转到内核中预定义的<strong>中断服务例程（ISR, Interrupt Service Routine）</strong>处理</p>
<p>CPU必须在硬件层面实现能够保存用户程序运行的现场（trap的精髓）</p>
<ul>
<li><p><strong>操作系统处理时钟中断</strong>操作系统在时钟中断处理程序中执行以下任务：</p>
<ul>
<li><p>更新系统时间。</p>
</li>
<li><p>检查是否需要切换任务（触发<strong>任务调度</strong>）。</p>
</li>
<li><p>处理延迟或周期性任务（如超时处理、定时器事件等）。</p>
</li>
</ul>
</li>
</ul>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241207200809875.png" alt="image-20241207200809875"></p>
<p>如图 hardware部分 需要在响应时钟中断时，把进程A的运行现场（寄存器）保存到内核栈中，然后跳转到trap处理程序。</p>
<h4 id="上下文切换（context-switch）"><a href="#上下文切换（context-switch）" class="headerlink" title="上下文切换（context switch）"></a>上下文切换（context switch）</h4><p>然后操作系统调用switch进行进程的切换A到B，因为一段时间内A都不会再运行，这时候就需要把A的寄存器内容保存到其进程空间（内存空间）</p>
<h5 id="kernel-stack-vs-Process-Control-Block"><a href="#kernel-stack-vs-Process-Control-Block" class="headerlink" title="kernel stack  vs Process Control Block"></a><code>kernel stack</code>  vs <code>Process Control Block</code></h5><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/likui360/p/6224624.html">Linux 系统中堆栈的使用方法 - 扫地猿 - 博客园</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/188577062">浅谈Linux 中的进程栈、线程栈、内核栈、中断栈 - 知乎</a></p>
<p>当进程在用户态运行时，使用的是用户栈，当进程陷入到内核态时，这些内核代码所使用的栈并不是原先进程用户空间中的栈，而是一个单独内核空间的栈，这个称作进程内核栈，内核栈保存进程在内核态运行的相关信息，一旦进程返回到用户态后，内核栈中保存的信息无效，会全部恢复，因此每次进程从用户态陷入内核的时候得到的内核栈都是空的。所以在进程陷入内核的时候，直接把内核栈的栈顶地址给堆栈指针寄存器就可以了。</p>
<p>当位于用户空间的进程进行系统调用时，进程用户栈的地址会被存进内核栈中，CPU堆栈指针寄存器中的内容也会变为内核栈的地址。当系统调用执行完毕，进程从内核栈找到用户栈的地址，继续在用户空间中执行，此时CPU堆栈指针寄存器就变为了用户栈的地址。各进程独立的。进程运行时分用户态跟内核态，所以需要有内核栈和常说的堆栈段，寻址方式是相同的，都是查LDT和页表进行地址映射，但二者段描述符里的特权级不同，为了区分用户态和内核态。</p>
<p>为什么每个进程都有一个内核栈，而不是所有进程共用一个。老的UNIX和Linux当时就是每个CPU只有一个内核栈，那个时候不会出现“执行到一半的时候上下文切换”，因为不允许用户态程序抢占正在执行系统调用的另一个用户态程序。后来每个进程一个内核栈了，就可以发生“执行到一半的时候上下文切换”了</p>
<p>语言书里面讲的堆、栈大部分都是用户态的概念，用户态的堆、栈对应用户进程虚拟地址空间里的一个区域，栈向下增长，堆用malloc分配，向上增长。</p>
<ul>
<li>中断发生时，寄存器先保存到内核栈；如果需要切换进程，内核会将内核栈中的寄存器内容转存到进程结构中。</li>
<li><strong>内核栈</strong>主要用于快速保存和恢复寄存器内容，适用于临时的上下文切换或中断处理。</li>
<li><strong>进程结构</strong>适用于更复杂的进程调度和长时间的上下文切换，提供长期的状态保存。proc结构体中的context字段就是用来保存寄存器信息的（xv6）</li>
</ul>
<table>
<thead>
<tr>
<th><strong>方面</strong></th>
<th><strong>内核栈</strong></th>
<th><strong>进程结构（PCB）</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>保存时机</strong></td>
<td>短暂事件（如中断、系统调用）</td>
<td>进程调度时</td>
</tr>
<tr>
<td><strong>存储位置</strong></td>
<td>当前进程的内核栈</td>
<td>PCB 或其他持久性数据结构</td>
</tr>
<tr>
<td><strong>存储时间</strong></td>
<td><strong>临时保存</strong>，内核处理结束后直接恢复</td>
<td><strong>长期保存</strong>，直至进程切换回来</td>
</tr>
<tr>
<td><strong>访问开销</strong></td>
<td>较低，直接访问内核栈</td>
<td>较高，涉及更多内存操作</td>
</tr>
<tr>
<td><strong>适用场景</strong></td>
<td>快速上下文切换、临时中断处理</td>
<td>进程调度或长时间上下文切换</td>
</tr>
<tr>
<td><strong>局限性</strong></td>
<td>不能长期存储</td>
<td>开销大，需要额外的数据结构</td>
</tr>
<tr>
<td>优点</td>
<td>连续内存块，访问效率较高，内核处理完直接恢复</td>
<td>寄存器信息可以跨多个调度周期存储</td>
</tr>
</tbody></table>
<p>进程调度，需要把B的现场信息从进程空间中恢复到寄存器里，然后恢复到用户态，跳转到B的PC，执行B的内容。</p>
<p><strong>并发</strong>：系统调用时触发中断。</p>
<hr>
<h2 id="策略：CPU-调度"><a href="#策略：CPU-调度" class="headerlink" title="策略：CPU 调度"></a>策略：CPU 调度</h2><h3 id="基本策略"><a href="#基本策略" class="headerlink" title="基本策略"></a>基本策略</h3><h4 id="批处理"><a href="#批处理" class="headerlink" title="批处理"></a>批处理</h4><p><strong>FIFO</strong>：先到先得，计算密集型会阻塞io密集型，降低效率</p>
<p><strong>SJF</strong>：Shortest Job First 最短工作优先，<u>同时到达</u>，先进行最短的工作</p>
<p><strong>STCF</strong>：Shortest Time-to-Complete First 最短完成时间优先，针对<u>随时到达</u>的情况，到达时比较里完成还有多少时间，首次出现了任务切换的概念。</p>
<h4 id="交互式"><a href="#交互式" class="headerlink" title="交互式"></a>交互式</h4><p>以上能够逐步优化 T<del>周转</del> = T<del>完成</del> - T<del>到达</del>，但是对于T<del>响应</del> = T<del>首次运行</del> - T<del>到达</del> 不友好，因为完成时间最长的必须等其他任务完成，自己才能继续。</p>
<p>交互式的任务对于响应时间很敏感。因此需要另外一种调度策略</p>
<p><strong>RR</strong>：Round-Robin 轮转，运行一个任务到时间片就切换到下一个任务（context switch）</p>
<ul>
<li>上下文的切换需要时间，因此时间片的大小也应该选择恰当</li>
</ul>
<p><strong>Overlap</strong>：重叠，如果A任务有IO，当A因为IO而空出CPU时，CPU就应该去服务B</p>
<p><strong>不可预知性</strong>：调度程序不知道到来的任务持续多长时间。</p>
<h4 id="实时系统"><a href="#实时系统" class="headerlink" title="实时系统"></a>实时系统</h4><p>准时比准确更加重要</p>
<h3 id="基于优先级且无需先验知识的调度：多级反馈队列-MLFQ"><a href="#基于优先级且无需先验知识的调度：多级反馈队列-MLFQ" class="headerlink" title="基于优先级且无需先验知识的调度：多级反馈队列 MLFQ"></a>基于优先级且无需先验知识的调度：多级反馈队列 MLFQ</h3><p>MLFQ：Multi-Level Feedback Queue，多级反馈队列</p>
<ul>
<li>设置不同的优先级，每个任务刚到达都是最高级</li>
<li>级别低的任务必须先让级别高的执行完</li>
<li>相同级别的任务轮转执行</li>
<li>在同一个优先级执行时间达到阈值就降低优先级：防止高优先级一直占据CPU，如果采用每次执行的计时方法可能会有恶意占据CPU的情况发生</li>
<li>每隔一段时间就重置所有任务的优先级为最高：防止低优先级变成饥饿状态</li>
</ul>
<h1 id="Memory-Virtualization"><a href="#Memory-Virtualization" class="headerlink" title="Memory Virtualization"></a>Memory Virtualization</h1><h2 id="每个程序员都应该知道的时延"><a href="#每个程序员都应该知道的时延" class="headerlink" title="每个程序员都应该知道的时延"></a>每个程序员都应该知道的时延</h2><p><img src="https://camo.githubusercontent.com/b425440f6447aded36e9e2dc9fcfd2e97dfaf9811b518d71fa92a5f3d94f9e07/687474703a2f2f692e696d6775722e636f6d2f6b307431652e706e67" alt="img"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">L1 cache reference ......................... 0.5 ns</span><br><span class="line">Branch mispredict ............................ 5 ns</span><br><span class="line">L2 cache reference ........................... 7 ns</span><br><span class="line">Mutex lock/unlock ........................... 25 ns</span><br><span class="line">Main memory reference ...................... 100 ns             </span><br><span class="line">Compress 1 KB with Zippy ................. 3,000 ns  =       3 µs</span><br><span class="line">Send 2 KB over 1 Gbps network ........... 20,000 ns  =      20 µs</span><br><span class="line">SSD random read ........................ 150,000 ns  =     150 µs</span><br><span class="line">Read 1 MB sequentially from memory ..... 250,000 ns  =     250 µs</span><br><span class="line">Round trip within same datacenter ...... 500,000 ns  =     500 µs  =  0.5 ms</span><br><span class="line">Read 1 MB sequentially from SSD ...... 1,000,000 ns  =   1,000 µs  =    1 ms</span><br><span class="line">Disk seek ........................... 10,000,000 ns  =  10,000 µs  =   10 ms</span><br><span class="line">Read 1 MB sequentially from disk .... 20,000,000 ns  =  20,000 µs  =   20 ms</span><br><span class="line">Send packet CA-&gt;Netherlands-&gt;CA .... 150,000,000 ns  = 150,000 µs  =  150 ms</span><br></pre></td></tr></table></figure>

<h2 id="地址空间、分段（segmentation）"><a href="#地址空间、分段（segmentation）" class="headerlink" title="地址空间、分段（segmentation）"></a>地址空间、分段（segmentation）</h2><p><img src="https://upload.wikimedia.org/wikipedia/commons/7/70/VirtualMem01.png" alt="img"></p>
<p><strong>地址空间</strong>：程序认为自己独占了这片内存空间，以为自己是连续的内存空间。低位是代码，堆往上递增，栈往下反向增长。</p>
<p>实际上是在物理内存中申请了一片连续的内存空间分配给进程，进程根据指令寻址的时候，操作系统将虚拟地址 <strong>重定位</strong> 到真正的物理地址。虚拟地址从0开始，因此虚拟地址实际上就是物理地址的偏移量。直接打印指针变量的值是虚拟地址而不是物理地址。</p>
<h3 id="虚拟内存的作用"><a href="#虚拟内存的作用" class="headerlink" title="虚拟内存的作用"></a>虚拟内存的作用</h3><p><strong>隔离进程</strong>：物理内存通过虚拟地址空间访问，虚拟地址空间与进程一一对应。每个进程都认为自己拥有了整个物理内存，进程之间彼此隔离，一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。</p>
<p><strong>提升物理内存利用率</strong>：有了虚拟地址空间后，操作系统只需要将进程当前正在使用的部分数据或指令加载入物理内存。</p>
<p><strong>简化内存管理</strong>：进程都有一个一致且私有的虚拟地址空间，程序员不用和真正的物理内存打交道，而是借助虚拟地址空间访问物理内存，从而简化了内存管理。</p>
<p><strong>多个进程共享物理内存</strong>：进程在运行过程中，会加载许多操作系统的动态库。这些库对于每个进程而言都是公用的，它们在内存中实际只会加载一份，这部分称为共享内存。</p>
<p><strong>提高内存使用安全性</strong>：控制进程对物理内存的访问，隔离不同进程的访问权限，提高系统的安全性。</p>
<p><strong>提供更大的可使用内存空间</strong>：可以让程序拥有超过系统物理内存大小的可用内存空间。这是因为当物理内存不够用时，可以利用磁盘充当，将物理内存页（通常大小为 4 KB）保存到磁盘文件（会影响读写速度），数据或代码页会根据需要在物理内存与磁盘之间移动。</p>
<hr>
<p>著作权归JavaGuide(javaguide.cn)所有 基于MIT协议 原文链接：<a target="_blank" rel="noopener" href="https://javaguide.cn/cs-basics/operating-system/operating-system-basic-questions-02.html">https://javaguide.cn/cs-basics/operating-system/operating-system-basic-questions-02.html</a></p>
<h3 id="重定位（relocation）"><a href="#重定位（relocation）" class="headerlink" title="重定位（relocation）"></a>重定位（relocation）</h3><p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241210205158811.png" alt="image-20241210205158811"></p>
<p><code>Virtual Address + Base = Physical Address</code> </p>
<p><strong>静态重定位</strong>：用软件实现，直接将指令中的虚拟地址用计算的真实物理地址覆盖。</p>
<ul>
<li>缺点：不安全，不方便更改。</li>
</ul>
<p><strong>动态重定位</strong>：用硬件实现，也就是CPU中的==MMU==，里面两个最基本的寄存器：<strong>基址寄存器</strong>、<strong>界限寄存器</strong>。将指令中的虚拟地址和基址相加得出真实物理地址，然后取得从硬件层面取得对应地址的值。这一切都是用硬件进行的。</p>
<ul>
<li>安全性：用界限（bound）和虚拟地址比较，如果超过了界限，说明虚拟地址访问越界，抛出异常</li>
<li>便于更改：改变寄存器的值即可实现基址的改变</li>
<li>性能高：硬件实现性能好</li>
</ul>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241210205227715.png" alt="image-20241210205227715"></p>
<h3 id="实现虚拟内存"><a href="#实现虚拟内存" class="headerlink" title="实现虚拟内存"></a>实现虚拟内存</h3><p><strong>实现虚拟内存机制的硬件支持：MMU</strong></p>
<ul>
<li><p>划分用户空间和内核空间</p>
</li>
<li><p>一对基址寄存器和界限寄存器，专门用来进行地址转换的电路</p>
</li>
<li><p>专门用来判断是否越界的电路，判断越界之后应当向CPU抛出异常</p>
</li>
<li><p>特权指令：操作系统应当能够设置上述寄存器的值</p>
</li>
<li><p>特权指令：操作系统应当告诉硬件发现异常应该执行哪些代码（Exception Handler）</p>
</li>
</ul>
<p><strong>实现虚拟内存机制的软件支持：OS</strong></p>
<ul>
<li>内存管理：分配机制、释放机制、空闲空间的管理——free list</li>
<li>切换上下文时正确设置对应的寄存器</li>
<li>抛出异常（内存访问越界、非法指令）时执行特定的处理代码</li>
</ul>
<p><strong>地址空间的不足</strong>：内部碎片（inner fragment）栈和堆之间未使用的空间也分配给整个地址空间，浪费较大</p>
<h3 id="分段"><a href="#分段" class="headerlink" title="分段"></a>分段</h3><h4 id="segmentation"><a href="#segmentation" class="headerlink" title="segmentation"></a>segmentation</h4><p><strong>段式管理</strong>：以段(—段连续的物理内存)的形式管理/分配物理内存。应用程序的虚拟地址空间被分为大小不等的段，段是有实际意义的，每个段定义了一组逻辑信息，例如有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。然后给每个段都配一对基址寄存器和界限寄存器。</p>
<p>例：0-16KB的虚拟地址空间，虚拟地址14位，高2位为段号，低12位为最大4KB的段空间。虚拟地址 = 段号 + 偏移 </p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// get top 2 bits of 14-bit VA</span></span><br><span class="line">Segment = (VirtualAddress &amp; SEG_MASK) &gt;&gt; SEG_SHIFT</span><br><span class="line"><span class="comment">// now get offset</span></span><br><span class="line">Offset = VirtualAddress &amp; OFFSET_MASK</span><br><span class="line"><span class="keyword">if</span> (Offset &gt;= Bounds[Segment])</span><br><span class="line">	RaiseException(PROTECTION_FAULT)<span class="comment">//抛出异常</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">	PhysAddr = Base[Segment] + Offset<span class="comment">//基址+偏移</span></span><br><span class="line">	Register = AccessMemory(PhysAddr)<span class="comment">//访存</span></span><br></pre></td></tr></table></figure>

<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241210205528802.png" alt="image-20241210205528802"></p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241210205438635.png" alt="image-20241210205438635"></p>
<table>
<thead>
<tr>
<th>段名称</th>
<th>段号</th>
<th>基址寄存器</th>
<th>界限寄存器</th>
<th>是否正向增长</th>
</tr>
</thead>
<tbody><tr>
<td>代码</td>
<td>00</td>
<td>26 KB</td>
<td>2 KB</td>
<td>1</td>
</tr>
<tr>
<td>堆</td>
<td>01</td>
<td>28 KB</td>
<td>2 KB</td>
<td>1</td>
</tr>
<tr>
<td>栈</td>
<td>11</td>
<td>18 KB</td>
<td>2 KB</td>
<td>0</td>
</tr>
</tbody></table>
<p>现在要判断虚拟地址15KB的真实地址：<code>11 11 00000 00000</code> 可见段号为 11，偏移 3 KB，栈空间反向增长，最大段空间为 4 KB，实际上就是计算15KB离全1有多远：3KB - 4KB = -1 KB,因此在基址寄存器减1KB即为实际物理地址。</p>
<h5 id="用于保护的额外状态字"><a href="#用于保护的额外状态字" class="headerlink" title="用于保护的额外状态字"></a>用于保护的额外状态字</h5><p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241211001125226.png" alt="image-20241211001125226"></p>
<h5 id="分段的问题"><a href="#分段的问题" class="headerlink" title="分段的问题"></a>分段的问题</h5><ul>
<li><strong>外部碎片</strong>：每个分段的大小不一致，因此产生了大小不一致的碎片，无法使空间得到有效利用。</li>
<li><strong>不支持稀疏的大堆</strong>：Another problem is that some segments could have a larger size and since this segment can’t be “broken” into smaller pieces, it must be fully allocated in memory. 分段大小是固定的，并不能将其拆成小段，申请了一段物理内存，寄存器的基址和界限已经确定好，这部分物理空间就不能再由其他的进程使用了，因此不支持按需分配。</li>
<li>Segments of unequal size not suited as well for swapping.</li>
</ul>
<h5 id="段表：更细粒度的分段"><a href="#段表：更细粒度的分段" class="headerlink" title="段表：更细粒度的分段"></a>段表：更细粒度的分段</h5><p>细粒度分段需要进一步硬件支持，并且在内存中存储 段表 （segment table）</p>
<p>分段机制下的虚拟地址由两部分组成：</p>
<ul>
<li><strong>段号</strong>：标识着该虚拟地址属于整个虚拟地址空间中的哪一个段。</li>
<li><strong>段内偏移量</strong>：相对于该段起始地址的偏移量。</li>
</ul>
<p>具体的地址翻译过程如下：</p>
<ol>
<li>MMU 首先解析得到虚拟地址中的段号；</li>
<li>通过段号去该应用程序的段表中取出对应的段信息（找到对应的段表项）；</li>
<li>从段信息中取出该段的起始地址（物理地址）加上虚拟地址中的段内偏移量得到最终的物理地址。</li>
</ol>
<p><img src="https://miro.medium.com/v2/resize:fit:1313/1*82aSNHRAkNNinGuPpsl6TQ.png" alt="img">分段机制下的地址翻译过程</p>
<p>段表中还存有诸如段长(可用于检查虚拟地址是否超出合法范围)、段类型（该段的类型，例如代码段、数据段等）等信息。</p>
<p><strong>通过段号一定要找到对应的段表项吗？得到最终的物理地址后对应的物理内存一定存在吗？</strong></p>
<p>不一定。段表项可能并不存在：</p>
<ul>
<li><strong>段表项被删除</strong>：软件错误、软件恶意行为等情况可能会导致段表项被删除。</li>
<li><strong>段表项还未创建</strong>：如果系统内存不足或者无法分配到连续的物理内存块就会导致段表项无法被创建。</li>
</ul>
<h4 id="减少碎片"><a href="#减少碎片" class="headerlink" title="减少碎片"></a>减少碎片</h4><ul>
<li><p><strong>内存紧缩</strong>（compact）：内存存储不下程序，会把暂时休息的第一个进程方法放入磁盘，过段时间移除进程b放入进程a，这样会让内存中出现空洞，所以要将进程整体往下移动。必须将运行中的进程中断，将所有分散的内存碎片压到连续的部分中，然后再将新的基址和界限移动到寄存器中，进程按照新的上下文继续执行。缺点是代价太高，性能不好</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20240922142056246.png" alt="image-20240922142056246"></p>
</li>
<li><p><strong>改善空闲列表</strong>（free list）：分配内存的时候采取一定的策略，尽量减轻内存碎片的现象，但也无法根除碎片的出现</p>
</li>
</ul>
<h2 id="空闲空间的管理"><a href="#空闲空间的管理" class="headerlink" title="空闲空间的管理"></a>空闲空间的管理</h2><p>维护一个空闲空间的列表（freelist）</p>
<h3 id="机制：分割与合并"><a href="#机制：分割与合并" class="headerlink" title="机制：分割与合并"></a>机制：分割与合并</h3><p>splitting</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241210222509968.png" alt="image-20241210222509968"></p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241210222527700.png" alt="image-20241210222527700"></p>
<p>coalescing</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241210222438918.png" alt="image-20241210222438918"></p>
<h3 id="内存-API"><a href="#内存-API" class="headerlink" title="内存 API"></a>内存 API</h3><h4 id="malloc"><a href="#malloc" class="headerlink" title="malloc"></a>malloc</h4><p><code>void* malloc(int size)</code> 申请大小为size的连续字节空间（虚拟意义上的连续），返回一个指向这个空间首部的指针</p>
<p>除了用户申请的空间之外，在malloc时还会申请一个头部Header，size用来表示申请空间的大小，magic魔数用来验证完整性<a target="_blank" rel="noopener" href="https://www.cnblogs.com/whiteBear/p/16729327.html">延迟分配：提供内存利用率的三种机制 - 牛犁heart - 博客园</a></p>
<ul>
<li>malloc只是分配了虚拟内存，程序真正访问才会触发页错误给这些虚拟页分配物理页框（demand paging）</li>
<li>在标准 C 库中，提供了 malloc / free 函数分配释放内存，这两个函数底层是由 brk，mmap，munmap 这些系统调用实现的。 (<em>详见Linux虚拟内存系统</em>) 不过跟直接调用还是有区别的。</li>
</ul>
<h4 id="free"><a href="#free" class="headerlink" title="free"></a>free</h4><p><code>void free(void* ptr)</code> 将指针ptr所指向的已分配空间释放掉，依据的信息是<strong>分配内存的Header部分</strong> ，因此malloc的size并不是真正的大小，还要分配头部<img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241210221647796.png" alt="image-20241210221647796"></p>
<h3 id="嵌入-free-list-到内存中"><a href="#嵌入-free-list-到内存中" class="headerlink" title="嵌入 free list 到内存中"></a>嵌入 free list 到内存中</h3><p>free list 本身也需要存储在内存中，这里我们知道：空闲的块作为空闲节点有额外的简单数据结构（int size, node* next），已分配的块同样也有简单的数据结构（int size, int magic），因此堆实际上是一个空闲内存和已分配的内存的混合。</p>
<ul>
<li>未分配空间</li>
</ul>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241210222820688.png" alt="image-20241210222820688"></p>
<ul>
<li>连续分配了3个100字节的空间</li>
</ul>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241210223130088.png" alt="image-20241210223130088"></p>
<ul>
<li>中间出现了空隙，可以看到空闲列表的头节点（head）发生了变化，两个空闲的块通过链表连接起来</li>
</ul>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241210223253160.png" alt="image-20241210223253160"></p>
<ul>
<li>全部释放之后，出现了4个空闲的块，但是还没有合并（merge）</li>
</ul>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241210223340586.png" alt="image-20241210223340586"></p>
<h3 id="策略：连续内存分配"><a href="#策略：连续内存分配" class="headerlink" title="策略：连续内存分配"></a>策略：连续内存分配</h3><h4 id="基本策略：空闲链表"><a href="#基本策略：空闲链表" class="headerlink" title="基本策略：空闲链表"></a>基本策略：空闲链表</h4><ul>
<li><strong>Best Fit</strong>：遍历整个列表，找到跟分配块大小最接近的空闲块，尽量减少碎片大小。细小碎片多，开销大。</li>
<li><strong>Worst Fit</strong>：遍历整个列表，找到跟分配块大小差距最大的，分割之后将剩余块加入空闲列表。碎片过量，开销大。</li>
<li><strong>First Fit</strong>：第一次找到足够大的块就直接分配。会让开头部分有许多小的碎片，可以通过按地址排序，便于合并操作。</li>
</ul>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20240922142709440.png" alt="image-20240922142709440"></p>
<ul>
<li><strong>Next Fit</strong>：每次查找都从上次结束的地方开始，剩下逻辑依然是首次匹配，可以减少开头部分过多的小碎片，将其分散到其他地方。</li>
</ul>
<p><strong>位图</strong>：</p>
<p><img src="https://pic4.zhimg.com/v2-ccf3e0ea94a135e7f8548f3e9ef42813_1440w.jpg" alt="img"></p>
<h4 id="内存池（memory-pool）"><a href="#内存池（memory-pool）" class="headerlink" title="内存池（memory pool）"></a>内存池（memory pool）</h4><p>如果能将一大块内存分成多个小内存（称为内存池），不同的内存池又按照不同的「尺寸」分成大小相同的内存块（比如分别按照32, 64, 128……字节），同一内存池中的空闲内存块按照free list的方式连接。每次分配的时候，选择和申请的的内存在「尺寸」上最接近的内存池，比如申请60字节的内存，就直接从单个内存块大小为64字节的内存池的free list上分配。</p>
<img src="https://pic4.zhimg.com/v2-12148c36cd07924a26e0ce35b67f29eb_1440w.jpg" alt="img" style="zoom:150%;" />

<p>需要结合系统实际的内存分配需求，对内存池的大小进行合理的划分。比如一个系统常用的是256字节以下的内存申请，那设置过多的256字节以上的内存池，就会造成内存资源的闲置和浪费。</p>
<h4 id="其他策略"><a href="#其他策略" class="headerlink" title="其他策略"></a>其他策略</h4><p>Linux 发展出两种基于内存池的分配策略，<em>详见 Linux 实现</em></p>
<ul>
<li><strong>Buddy system</strong>: 将内存池划分为以2^n^为大小的类型，同一内存池中的空闲块大小相同，如果空闲块是相邻的则合并，将合并后的块加入更大的内存池中</li>
<li><strong>SLAB</strong>: 伙伴系统是按页分配的，但内核经常会申请一些特定大小的内存，往往不到一页，如果仍然使用伙伴系统将造成很多内部碎片，SLAB为它们分配了内核对象缓存，专门的连续内存区，依然使用内存池的思路，但是池子变得比以前更小。</li>
</ul>
<h2 id="分页（paging）"><a href="#分页（paging）" class="headerlink" title="分页（paging）"></a>分页（paging）</h2><h3 id="虚拟——物理页号转换"><a href="#虚拟——物理页号转换" class="headerlink" title="虚拟——物理页号转换"></a>虚拟——物理页号转换</h3><h4 id="页帧、页帧号、虚拟页号"><a href="#页帧、页帧号、虚拟页号" class="headerlink" title="页帧、页帧号、虚拟页号"></a>页帧、页帧号、虚拟页号</h4><p><strong>分页机制</strong>：将虚拟的地址替换成物理地址，用大小相等的页代替大小不等的段。原来一个进程是代码段和数据段不等，分配的内存空间也不一样，现在将段继续拆分成大小相等的页表项，这样从根本上解决了外部碎片的问题。</p>
<p><strong>页帧（Page Frame）</strong>：物理内存中存放数据的最小单位。当一个虚拟页被映射到物理页时，数据会存放在对应的<strong>页帧</strong>中。假设一个进程的虚拟地址空间中有一个虚拟页，虚拟地址 <code>0x1000</code> 对应的虚拟页页号是 <code>0x1</code>，偏移量为0。此时，操作系统通过页表将虚拟页 <code>0x1</code> 映射到物理内存中的一个页帧 <code>0x3</code>，即物理地址为 <code>0x3000</code>。那么，当该进程访问虚拟地址 <code>0x1000</code> 时，CPU 会通过页表将其转换为物理地址 <code>0x3000</code>，并在页帧 <code>0x3</code> 中访问数据。页帧大小固定为PageSize</p>
<p><strong>虚拟地址（Virtual Address）= 虚拟页号（VPN, Virtual Page Number） + 偏移量（Offset）</strong></p>
<p><strong>页表项（Page Table Entry）= 物理页号（PFN, Page Frame Number）+ 保留的功能位</strong></p>
<p><strong>页表的物理地址</strong>：加载到<strong>页表基址寄存器（PTBR, Page Table Base Register）</strong>，一个<strong>页表项（PTE）</strong>分为<strong>物理页号（PFN）</strong>，有效位valid，读写权限位protection，内核模式位，脏位dirty，引用reference，存在位present等功能位。</p>
<h4 id="从虚拟地址访存基本步骤"><a href="#从虚拟地址访存基本步骤" class="headerlink" title="从虚拟地址访存基本步骤"></a>从虚拟地址访存基本步骤</h4><ul>
<li><p><code>VirtualAddress = VPN + Offset</code> </p>
</li>
<li><p><code>PTE Address(Physical) = VPN * PageSize + PTBR</code> PTE保存着PFN以及其他功能位</p>
</li>
<li><p><code>Physical Address = PFN * PageSize + Offset</code> </p>
</li>
<li><p>实际上VPN PFN Offset都是通过和MASK（作用和子网掩码相同）相与，然后PFN移位后和Offset相或。</p>
</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Extract the VPN from the virtual address</span></span><br><span class="line">VPN = (VirtualAddress &amp; VPN_MASK) &gt;&gt; SHIFT</span><br><span class="line"><span class="comment">// Form the address of the page-table entry (PTE)</span></span><br><span class="line">PTEAddr = PTBR + (VPN * <span class="keyword">sizeof</span>(PTE))</span><br><span class="line"><span class="comment">// Fetch the PTE</span></span><br><span class="line">PTE = AccessMemory(PTEAddr)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Check if process can access the page</span></span><br><span class="line"><span class="keyword">if</span> (PTE.Valid == False)<span class="comment">// Valid bit = 0</span></span><br><span class="line">	RaiseException(SEGMENTATION_FAULT) <span class="comment">//illegal memory access</span></span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (CanAccess(PTE.ProtectBits) == False)</span><br><span class="line">	RaiseException(PROTECTION_FAULT)</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="comment">// Access OK: form physical address and fetch it</span></span><br><span class="line">    offset = VirtualAddress &amp; OFFSET_MASK</span><br><span class="line">    PhysAddr = (PTE.PFN &lt;&lt; PFN_SHIFT) | offset</span><br><span class="line">    Register = AccessMemory(PhysAddr)</span><br></pre></td></tr></table></figure>

<p><strong>一些功能位</strong></p>
<ul>
<li>Protection bit：权限位，保护位 r w x，如果违反了越权访问，就要陷入OS</li>
<li>Valid bit：有效位，虚拟地址空间并不是全部都要分配，如果访问了还没有分配的（valid bit = 0）就是非法访问，将会抛出异常陷入OS</li>
<li>Dirty bit：脏位，页面带入内存之后是否被修改过</li>
<li>Present bit：存在位，表示内存页在内存中还是已经被换出</li>
<li>Reference bit：参考位，追踪页面是否被访问</li>
</ul>
<h4 id="页表开销"><a href="#页表开销" class="headerlink" title="页表开销"></a>页表开销</h4><ul>
<li><strong>内存开销</strong>：每个页表项需要4B，页大小（PageSize）是4KB，要虚拟出一个4GB的空间，就要有4GB/4KB * 4B =4MB 空间来存储。对每个进程操作系统都要有4MB的空间用于页表的储存，开销很大。页表是按照页号进行索引查找的，这就需要本身是一段连续的内存空间，页表就是一个大的数组，实际上页表在物理上也连续。</li>
<li><strong>性能开销</strong>：对于每个内存引用，都要额外引入一次内存引用，效率不高,每一次访存都多了一步访问页表，性能显著下降</li>
</ul>
<p><img src="https://img2018.cnblogs.com/blog/1075436/201908/1075436-20190809172852450-661010612.png" alt="img"></p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241212120853391.png" alt="image-20241212120853391"></p>
<h4 id="页表总结"><a href="#页表总结" class="headerlink" title="页表总结"></a>页表总结</h4><p><strong>Pros</strong>:</p>
<ul>
<li>No external fragments</li>
<li>Flexible, good support for sparse address space</li>
</ul>
<p><strong>Cons</strong>:</p>
<ul>
<li>Physical Space costs (Page table)</li>
<li>Speed Costs (extra memory access)</li>
</ul>
<h3 id="快表-TLB"><a href="#快表-TLB" class="headerlink" title="快表 TLB"></a>快表 TLB</h3><p><strong>如果想要快速的缓存，他就必须小，因为光速和其他物理限制会起作用</strong></p>
<p><strong>TLB</strong>：因为有二八定律，所以MMU要记下经常使用的虚拟页号，将VPN与PFN的映射关系存在 <strong>TLB</strong> 快表中（<strong>Translation Lookaside Buffer</strong> aka. <strong>Address Translation Cache</strong>）</p>
<h4 id="硬件实现-TLB-控制流"><a href="#硬件实现-TLB-控制流" class="headerlink" title="硬件实现 TLB 控制流"></a>硬件实现 TLB 控制流</h4><p>CISC 将tlb miss逻辑全权交给硬件负责，拿着虚拟页号 VPN 去 TLB 中查询</p>
<ul>
<li>TLB hit：直接访存(<code>AccessMemory</code>)</li>
<li><strong>TLB miss：查页表，查到PFN后写入TLB（<code>TLB_Insert</code>），重新执行TLB查询操作（<code>RetryInstruction</code>）</strong>  </li>
</ul>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241212122549686.png" alt="image-20241212122549686"></p>
<p>硬件实现：需要PTBR（x86架构中为CR3寄存器），页表的确切格式是写死在硬件里的（x86中为多级页表）</p>
<h4 id="软件实现-TLB-控制流"><a href="#软件实现-TLB-控制流" class="headerlink" title="软件实现 TLB 控制流"></a>软件实现 TLB 控制流</h4><p>RISC 将tlb miss看作一个异常，陷入OS，执行对应的处理程序</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241212124132429.png" alt="image-20241212124132429"></p>
<p><strong>软件实现的好处</strong>：可以随时更改，可扩展性强，页表的数据结构由操作系统自行决定，</p>
<p><strong>注意的问题</strong>：</p>
<ul>
<li>TLBmissHandler和一般的trap不同，一般return from trap 会从陷入后的地方继续执行，而TLBmiss则会从<strong>重试</strong>陷入之前的程序，因此保存的上下文很重要，尤其是程序计数器</li>
<li>TLBmissHandler也是代码，要访存，须谨防无限递归tlb miss的问题，可以专门把一块TLB的空间划给TLBmiss处理程序使用；或者也可以不使用虚拟内存，直接把代码物理地址告诉硬件（unmapped，陷阱表）</li>
</ul>
<h4 id="TLB-内容"><a href="#TLB-内容" class="headerlink" title="TLB 内容"></a>TLB 内容</h4><h5 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h5><p><code>VPN | PFN | other bits</code></p>
<p>是一个全相联（fully-associative）的cache结构，硬件会并行地查找这些项，</p>
<p><strong>other bits</strong>：</p>
<ul>
<li><p>protection：访问权限</p>
</li>
<li><p>valid：表示TLB是否记录着一个有效的<code>VPN-&gt;PFN</code>映射，PTE的有效位为0表示这是一个并未被应用申请过的非法地址</p>
</li>
<li><p>dirty：脏位</p>
</li>
<li><p>asid：access space id，地址空间id，用来标识不同进程的TLB条目<a target="_blank" rel="noopener" href="https://blog.csdn.net/Rong_Toa/article/details/110758233">Linux进程管理+内存管理：进程切换的TLB处理（ASID-address space ID、PCID-process context ID）_进程的asid-CSDN博客</a> </p>
</li>
</ul>
<h5 id="上下文切换"><a href="#上下文切换" class="headerlink" title="上下文切换"></a>上下文切换</h5><p>TLB集成在CPU内部的MMU，因此一定会有上下文切换的问题，VPN一样的条目会导致数据错误</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241212131757567.png" alt="image-20241212131757567"></p>
<p><strong>解决方案</strong>：</p>
<ul>
<li>上下文切换的时候将所有 TLB 条目的<strong>有效位</strong>置0（flush），下一个进程可以随便覆盖</li>
<li>使用ASID（类似于pid）记录这个TLB条目属于哪个进程</li>
</ul>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241212131846711.png" alt="image-20241212131846711"></p>
<p><strong>PFN一样的条目</strong>：可能是共享代码页，这样可以减少额外分配物理页</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241212131859962.png" alt="image-20241212131859962"></p>
<h5 id="例：MIPS-TLB-Entry"><a href="#例：MIPS-TLB-Entry" class="headerlink" title="例：MIPS TLB Entry"></a>例：MIPS TLB Entry</h5><p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241212134843225.png" alt="image-20241212134843225"></p>
<p>0-18 VPN  19 Global 进程间共享  24-31 ASID 进程空间 </p>
<h4 id="刷新、替换"><a href="#刷新、替换" class="headerlink" title="刷新、替换"></a>刷新、替换</h4><h5 id="TLB-flush"><a href="#TLB-flush" class="headerlink" title="TLB flush"></a>TLB flush</h5><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/66971714">TLB之flush操作[一] - 知乎</a> <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/66994486">TLB之flush操作[二] - 知乎</a> <a target="_blank" rel="noopener" href="https://blog.csdn.net/Rong_Toa/article/details/110760995">Linux内存管理：TLB flush操作-CSDN博客</a> </p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/Rong_Toa/article/details/110758233">Linux进程管理+内存管理：进程切换的TLB处理（ASID-address space ID、PCID-process context ID）_进程的asid-CSDN博客</a> </p>
<p>在页表PTE的内容出现变化时，比如page fault时页面被换出，munmap()时映射被解除，就需要invalidate对应的TLB entry，有时这个操作也被称为flush（以下的讨论将统一称为flush）。</p>
<p>当系统中各个cpu的TLB中的asid合起来不大于256个的时候，系统正常运行，一旦超过256的上限后，我们将全部TLB flush掉，并重新分配ASID，每达到256上限，都需要flush tlb并重新分配HW ASID。</p>
<p>在多核系统中，虽然每个核心的MMU是独立的，但它们在访问<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=695131149&content_type=Answer&match_order=1&q=%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98&zhida_source=entity">共享内存</a>时需要进行协调。共享内存区域允许多个核心同时访问相同的物理内存，这对于核心间的通信或共享数据非常关键。MMU可以通过为不同的内存区域设置权限和属性，确保多个核心在访问这些共享区域时不会出现数据冲突或不一致的情况。这在多线程或多进程系统中，尤其在同步和内存一致性方面，显得尤为重要。</p>
<h5 id="缓存更新策略"><a href="#缓存更新策略" class="headerlink" title="缓存更新策略"></a><a href="#eviction">缓存更新策略</a></h5><h2 id="优化分页"><a href="#优化分页" class="headerlink" title="优化分页"></a>优化分页</h2><h3 id="扩大页面大小（Bigger-Pages）"><a href="#扩大页面大小（Bigger-Pages）" class="headerlink" title="扩大页面大小（Bigger Pages）"></a>扩大页面大小（Bigger Pages）</h3><p>Linux</p>
<ul>
<li><p>对TLB更加友好，考虑到空间局部性，同一页能够访问更多数据，也就不用频繁地查页表了</p>
</li>
<li><p>增大页面大小，VPN<del>max</del>变小，每个虚拟页占空间4B，页表占用总空间减小；</p>
</li>
<li><p>但应用程序申请的并不一定是会充满整个页，所以会出现内部碎片（internal fragment）</p>
</li>
</ul>
<h3 id="分段-分页（Hybrid-Approach）"><a href="#分段-分页（Hybrid-Approach）" class="headerlink" title="分段 + 分页（Hybrid Approach）"></a>分段 + 分页（Hybrid Approach）</h3><h4 id="线性页表的局限"><a href="#线性页表的局限" class="headerlink" title="线性页表的局限"></a>线性页表的局限</h4><p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241212210406110.png" alt="image-20241212210406110"></p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241212210703824.png" alt="image-20241212210703824"></p>
<p>如图，虚拟空间是16KB，页面大小为1KB，因此页表共有16 entries，除去代码段，堆栈之间的空间是严重浪费的，就像分段会导致内部碎片一样，连续的线性页表也会导致内部碎片。</p>
<h4 id="段页结合"><a href="#段页结合" class="headerlink" title="段页结合"></a>段页结合</h4><p>VAX/VMS</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241212213305035-1734010396522-12.png" alt="image-20241212213305035"></p>
<p><img src="https://cdn.xiaolincoding.com//mysql/other/8904fb89ae0c49c4b0f2f7b5a0a7b099.png" alt="img"></p>
<p>可以根据代码、堆、栈对页表进行分类，然后使用三个base-bound寄存器对，上下文切换时保存、恢复寄存器内容。更细粒度的分段可以使用段表。base存储段在物理内存的位置，bound表示段大小。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SN  = (VirtualAddress &amp; SEG_MASK) &gt;&gt; SN_SHIFT</span><br><span class="line">VPN = (VirtualAddress &amp; VPN_MASK) &gt;&gt; VPN_SHIFT</span><br><span class="line">AddressOfPTE = Base[SN] + (VPN * <span class="keyword">sizeof</span>(PTE))</span><br></pre></td></tr></table></figure>

<h4 id="缺陷"><a href="#缺陷" class="headerlink" title="缺陷"></a>缺陷</h4><ul>
<li>与分段的缺陷一样，只不过是将真正的数据部分换成了页表</li>
<li>不灵活，假设地址空间有一定的使用模式，分段则需要为整个堆段预留连续空间，即使中间部分未使用也无法释放。<ul>
<li>a large but sparsely-used heap 仍然可能导致大量的页表浪费</li>
</ul>
</li>
<li>由于界限寄存器的存在，每个段有多少页是不确定的，因此每个段的页表大小也不确定，导致寻找足够的连续自由空间比较复杂。虽然节省内存但是有外部碎片问题</li>
</ul>
<h3 id="多级页表（Multi-level-Page-Tables）"><a href="#多级页表（Multi-level-Page-Tables）" class="headerlink" title="多级页表（Multi-level Page Tables）"></a>多级页表（Multi-level Page Tables）</h3><p>x86 ARM Linux Windows</p>
<p>减小页表占用的空间，分散成多个页表，<strong>每张页表大小==相同==<strong>，</strong>并且刚好能填满一整个内存页</strong>，消灭了外部碎片</p>
<p><strong>如果整页的PTE都是无效的（未分配），则完全不分配该页面的页表。</strong></p>
<ul>
<li>PDE的有效位：此条目指向的页是否有页表？PTE的有效位：此条目是否是一个有效的PFN映射？</li>
<li>树形结构，不用的可以不分配页表空间。支持稀疏空间：不用的就不分配物理内存页</li>
</ul>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241212214704876.png" alt="image-20241212214704876"></p>
<h4 id="页表目录-页表-内存"><a href="#页表目录-页表-内存" class="headerlink" title="页表目录-页表-内存"></a>页表目录-页表-内存</h4><p>CR3存的是页表目录（Page Directory）的基址，假设虚拟地址前4位是页表目录的编号，中间4位是页表（Page Table）编号，后12位为偏移。CR3找到了页表目录，根据前4位索引到PTE的PFN，根据中间4位找到页表中的PTE，PTE中存储着物理页的PFN。</p>
<ul>
<li><p>基本思想：基址 + 偏移 </p>
</li>
<li><p><code>VPN = PD_index | PT_index</code> </p>
</li>
<li><p><strong>页目录项</strong>地址: <code>PD_Entry_Addr = Page_Dir_Base + PD_index * sizeof(PD_Entry_Addr)</code> </p>
</li>
<li><p><strong>页表项</strong>地址：  <code>PT_Entry_Addr = PD_Entry.PFN &lt;&lt; SHIFT + PT_index * sizeof(PT_Entry_Addr)</code> </p>
</li>
<li><p>页面地址 ：<code>Page_Entry_Addr = PT_Entry.PFN &lt;&lt; SHIFT + Offset</code> </p>
</li>
</ul>
<p>以16位虚拟地址为例：</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20240924221042539.png" alt="image-20240924221042539"></p>
<ul>
<li><strong>虚拟内存的要求</strong>：每一层级内部必须是连续的，因为分配物理内存空间只能一次性分配连续的一段</li>
<li>单级页表要想实现页表只能一次性分配256个连续的entries。</li>
<li>多级页表如果<strong>真的只有</strong>这3个地址所在的physical page被用到，那么只需要48 个entries就可以了</li>
</ul>
<p>在32位系统中，进程的虚拟地址空间为4GB，但某个进程实际使用的页只占其中的一小部分，其分布是稀疏的，因此非常适合使用多级页表这种稀疏的级联数组(<a href="https://link.zhihu.com/?target=https://en.wikipedia.org/wiki/Radix_tree">radix tree</a>)来表示。</p>
<h4 id="fill-the-pages"><a href="#fill-the-pages" class="headerlink" title="fill the pages"></a>fill the pages</h4><h5 id="例：30位虚拟地址"><a href="#例：30位虚拟地址" class="headerlink" title="例：30位虚拟地址"></a>例：30位虚拟地址</h5><p>目标：每张表填满一整个内存页 Page Size = 2^7^ * 4 B = 512 B，二级页表不能刚好占满一页</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241213134804005.png" alt="image-20241213134804005"><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241213135215659.png" alt="image-20241213135215659"></p>
<h5 id="实际的32位和64位页表"><a href="#实际的32位和64位页表" class="headerlink" title="实际的32位和64位页表"></a>实际的32位和64位页表</h5><p>在32位处理器中，采用4KB的page大小，则虚拟地址中低12位为offest，剩下高20位给页表，<strong>分成两级</strong>，每个级别占10个bit（10+10）。为什么32位系统的页表每级占10位，每个页的大小被设定为<code>4KB</code>而不是2KB或者8KB？</p>
<p>如果index为10位，则其可索引的范围是1024个entris，32位系统中，每级页表的每个entry的大小为4个字节，则每个页表的大小刚好是4KB。页表首地址也是要按页对齐的，如果占不满一个页，页中剩下的空间也就浪费了。80386引入<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=102569108&content_type=Article&match_order=1&q=%E5%88%86%E9%A1%B5%E6%9C%BA%E5%88%B6&zhida_source=entity">分页机制</a>的时候应该就考虑过把页设置为多大是最合适的，显然4KB的页大小对内存的利用是最充分的。1024 * 4 = 4 K</p>
<p><img src="https://i.stack.imgur.com/R19zY.png" alt="memory management - Why 32-bit Windows can maximum have 16TB Page File ..."></p>
<p>为什么64位系统的页表<strong>每级占9位</strong>呢？为了和硬件配合，基于i386编写的linux也采用4KB的页大小作为<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=102569108&content_type=Article&match_order=1&q=%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86&zhida_source=entity">内存管理</a>的基本单位。处理器进入64位时代后，其实可以不再使用4KB作为一个页帧的大小，但可能为了提供硬件的向前兼容性以及和操作系统的兼容性吧，大部分64位处理器依然使用4KB作为默认的页大小（ARMv8-A还支持16KB和64KB的页大小）。因为64位系统中，每级页表的每个entry的大小为8个字节，如果index为9位，则每个页表的大小也刚好是4KB。</p>
<p>512 * 8 = 4K </p>
<p><img src="https://i.sstatic.net/Bswtz.png" alt="img"></p>
<h4 id="TLB-控制流"><a href="#TLB-控制流" class="headerlink" title="TLB 控制流"></a>TLB 控制流</h4><p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241213141353216.png" alt="image-20241213141353216"></p>
<p>依然是先查TLB，TLB没有再查页表，先用PDBR加偏移 算出PDE的物理地址得到PTE所在的PFN，找到PTE之后根据PTE里面的PFN加偏移算出真实的物理地址。</p>
<h3 id="倒排页表（Inverted-Page-Table）"><a href="#倒排页表（Inverted-Page-Table）" class="headerlink" title="倒排页表（Inverted Page Table）"></a>倒排页表（Inverted Page Table）</h3><p>PowerPC</p>
<p>页表的映射反过来，PFN-&gt;VPN，除了VPN，还有使用此页的进程标识。通常使用Hash散列表来加快搜索。</p>
<p><img src="https://images2015.cnblogs.com/blog/1006507/201612/1006507-20161224105816979-1390337413.png" alt="img"></p>
<h3 id="交换到磁盘（Swap）"><a href="#交换到磁盘（Swap）" class="headerlink" title="交换到磁盘（Swap）"></a>交换到磁盘（Swap）</h3><p>之前的页表都需要直接访问物理内存，页表本身并没有在程序的地址空间中，因此页表必须时时刻刻在物理内存中</p>
<p>VAX/VMS 把页表纳入内核的虚拟内存，允许在内存压力较大时将页表的一部分交换到磁盘。</p>
<h2 id="超越物理内存"><a href="#超越物理内存" class="headerlink" title="超越物理内存"></a>超越物理内存</h2><p>虚拟内存本质是虚的，实际数据可以存储在任何地方：<strong>寄存器（TLB）</strong>、<strong>物理内存（DRAM）</strong>，甚至是<strong>磁盘（HDD SSD）</strong>，因此虚拟内存大小跟物理内存大小并没有直接的关系，编程人员只需提供<code>Virtual Address</code>，由硬件和OS负责剩下的步骤，这就提升了程序的易用性，也提升了处理程序的多样性，考虑页表的数据结构，页表存储的位置等问题。</p>
<h3 id="机制"><a href="#机制" class="headerlink" title="机制"></a>机制</h3><h4 id="交换空间"><a href="#交换空间" class="headerlink" title="交换空间"></a>交换空间</h4><p>硬盘需要腾出一片专门的空间用来存放物理内存的内容，因此也需要进行编址。</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241213145818889.png" alt="image-20241213145818889"></p>
<blockquote>
<p>The code pages from this binary are initially found on disk, and when the program runs, they are loaded into memory (either all at once when the program starts execution, or, as in modern systems, one page at a time when needed). However, if the system needs to <strong>make room in physical memory for other needs</strong>, it can safely re-use the memory space for these code pages, knowing that it can later swap them in again from the on-disk binary in the file system.</p>
</blockquote>
<p><strong>虚拟内存提供了一种将磁盘和物理内存结合起来的方式</strong>：</p>
<ul>
<li>代码页从磁盘加载到内存，过一段时间被换出，随后在需要的时候又被换入。</li>
<li>操作系统将整个物理内存看作“缓存”。</li>
<li>当内存不足时，系统会将不常用的内存页换出到磁盘（称为交换或分页）。</li>
<li>反之，如果需要使用换出的页面，系统会从磁盘重新加载到内存。</li>
</ul>
<h4 id="页错误（page-fault）"><a href="#页错误（page-fault）" class="headerlink" title="页错误（page fault）"></a>页错误（page fault）</h4><p><strong>存在位（presentation bit）</strong>：用来标识一个页是否在物理内存中，如果不在，对此内存地址的访问就会触发page fault（实际上是page miss），陷入OS</p>
<p><strong>Why OS</strong> <strong>Handles This?：</strong>TLB miss可以由硬件实现，但是Page Fault并不需要，因为Page Fault的处理性能瓶颈在硬盘：硬盘的读写速度比内存慢很多，硬件处理性能提升并不明显，并且硬件必须添加其他复杂的机制（写死在硬件里）</p>
<p>硬盘IO完成，更新PTE的PFN和存在位（也可以同时写入TLB中）然后Retry Instruction，IO过程中进程处于<strong>阻塞状态（blocked state）</strong>，OS可以在这段时间内切换到其他进程以提高CPU利用率。</p>
<p><img src="https://media.geeksforgeeks.org/wp-content/uploads/121-1.png" alt="Lightbox"></p>
<p>上述是硬性的页错误（虚拟内存地址不在物理内存中），还有一种软性页错误（虚拟内存地址在物理内存中），<em>详见VAX/VMS</em></p>
<p><strong>控制流</strong>：</p>
<ul>
<li>错误的严重程度：<ol>
<li><code>segmentation fault</code>（<code>valid bit = 0</code>, 没有分配） </li>
<li><code>protection fault</code>（<code>protect bits</code>, 权限不够）</li>
<li><code>page fault</code>（<code>present bit = 0</code>, 不在内存里）</li>
</ol>
</li>
</ul>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241213153405737.png" alt="image-20241213153405737"><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241213153341054.png" alt="image-20241213153341054"></p>
<p><strong>Page-Fault Handler by OS</strong>：</p>
<ul>
<li>找空闲的物理内存，记录其PFN<ul>
<li>找不到就使用<strong>淘汰策略</strong>，把现在的物理内存页换一部分到磁盘里，腾出空间</li>
<li>如果找到了就进行磁盘 I/O，系统调用会<strong>休眠</strong>，直到 I/O 完成。</li>
</ul>
</li>
<li>换入完成就更新页表的存在位和PFN</li>
</ul>
<h4 id="访存机制总结"><a href="#访存机制总结" class="headerlink" title="访存机制总结"></a>访存机制总结</h4><p>首先到 MMU 集成的 TLB 中查询，TLB 中存储的是虚拟地址页号（VPN）和物理地址页号（PFN）的映射关系，TLB 命中则直接访问物理页框；之后就是之前正常的 CPU 访存过程，与操作系统没有关系。TLB 未命中则去找 CPU 集成的 Table Walk Unit，TWU 中的 CR3 寄存器存储着当前页目录（Page Directory）的物理地址页号PFN，如果内存中的页表没有对应的内容，则触发页错误（Page Fault）去磁盘中寻找，页表命中则更新 TLB，重试指令。</p>
<p><img src="https://slideplayer.com/4814084/15/images/slide_1.jpg" alt="Virtual to Physical Address Translation Effective Address TLB Lookup Page  Table Walk Update TLBPage Fault OS Table Walk Protection Check Physical  Address. - ppt download"></p>
<h3 id="Swap-页面置换策略"><a href="#Swap-页面置换策略" class="headerlink" title="Swap 页面置换策略"></a><span id="eviction">Swap 页面置换策略</span></h3><p>$$<br>AMAT=(P_\text{Hit} \cdot T_\text{Mem})+(P_\text{Miss} \cdot T_\text{Disk})<br>$$</p>
<p>Tmem = 100ns(100个时钟周期) Tdisk = 10ms（10000个时钟周期） 对性能影响极大</p>
<h4 id="基本策略-1"><a href="#基本策略-1" class="headerlink" title="基本策略"></a>基本策略</h4><p>将物理内存看作虚拟内存的缓存，置换策略实际上就是缓存淘汰策略</p>
<p><strong>局部性原理</strong></p>
<p><a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000043722445">缓存算法：LRU、LFU、随机替换等常见算法简介 - 个人文章 - SegmentFault 思否</a> </p>
<p>我们能不能既享受 CPU Cache 的速度，又享受内存、硬盘巨大的容量和低廉的价格呢？前辈们已经探索出了答案，那就是，存储器中数据的局部性原理（Principle of Locality）</p>
<ul>
<li><p>**时间局部性(temporal locality)**：如果一个数据被访问了，那么它在短时间内还会被再次访问。如 LRU 缓存机制，将频繁访问的数据保存在内存中。</p>
</li>
<li><p>**空间局部性(spatial locality)**：如果一个数据被访问了，那么和它相邻的数据也很快会被访问。如果数组的 CPU 预读功能。</p>
</li>
<li><p><strong>OPT 最优</strong>：事先知道缓存的访问顺序（不可能）但是可以作为一个比较指标。</p>
</li>
<li><p><strong>无状态策略</strong>：</p>
<ul>
<li><p>FIFO：先进先出</p>
</li>
<li><p>Random：随机</p>
</li>
</ul>
</li>
<li><p><strong>LRU</strong>(Recently)基于上次被访问时间，<strong>LFU</strong>(Frequently)基于被访问的频率</p>
</li>
</ul>
<p>基本有LRU FIFO Random，时钟算法（近似LRU），SecondChance（完善的FIFO），2Q（LRU+FIFO）</p>
<p>LFU：当使用 mmap() 访问文件缓存页面时，无法计数，实现较为复杂，不适合操作系统对虚拟内存的管理</p>
<h4 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a>性能比较</h4><h5 id="完全随机访问"><a href="#完全随机访问" class="headerlink" title="完全随机访问"></a>完全随机访问</h5><p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241213175231404.png" alt="image-20241213175231404"></p>
<h5 id="二八定律"><a href="#二八定律" class="headerlink" title="二八定律"></a>二八定律</h5><p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241213175332544.png" alt="image-20241213175332544"></p>
<h5 id="循环顺序访问"><a href="#循环顺序访问" class="headerlink" title="循环顺序访问"></a>循环顺序访问</h5><p>依次引用第0到第49页，LRU和FIFO，缓存在50以内，命中率为0</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241213175411886.png" alt="image-20241213175411886"></p>
<ul>
<li><p>LRU，基于<strong>时间局部性</strong>的策略，<strong>预测性强</strong>：对于访问频繁的页表项保留效果好。</p>
<ul>
<li>循环访问 n+1 页，但TLB只有n页容量，第一次TLB空的，全部 miss，由于空间限制，最后第n+1页会覆盖第1页。下一个循环开始第1页又 miss，第1页覆盖第2页内容，连锁的 miss</li>
</ul>
</li>
<li><p>Random，实现简单，避免出现极端情况下LRU命中率极低的情况，<strong>不可预测</strong>：无法优化特定程序的访问模式。</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>策略</th>
<th>优点</th>
<th>缺点</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td><strong>LRU</strong></td>
<td>高命中率，适应访问局部性</td>
<td>实现复杂，硬件成本高</td>
<td>对性能敏感的高端系统</td>
</tr>
<tr>
<td><strong>随机</strong></td>
<td>实现简单，硬件成本低，性能稳定</td>
<td>命中率较低，忽略访问规律</td>
<td>简单的嵌入式系统或硬件资源有限的场景</td>
</tr>
</tbody></table>
<h4 id="LRU-实现"><a href="#LRU-实现" class="headerlink" title="LRU 实现"></a>LRU 实现</h4><ul>
<li>可以对每一页添加时间字段，可以在页表中也可以专门在物理内存中的一片区域（redis就是这么做的），但代价高。</li>
</ul>
<p>添加一个 <strong>reference bit</strong> 使用位（用页表或者bitmap存储）当页被访问（读或写）时，由硬件（MMU）将其置1，操作系统负责将其置0，1代表最近用过了，0代表最近没用过</p>
<h5 id="近似-LRU：时钟算法"><a href="#近似-LRU：时钟算法" class="headerlink" title="近似 LRU：时钟算法"></a>近似 LRU：时钟算法</h5><p>维护一个循环列表，里面放着所有页的使用情况，时钟指针指向其中的一页，当需要替换页，如果use bit=1，将其置0，然后移动到下一页，直到寻找到第一个use bit = 0的页，将其换出</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241213184105746.png" alt="image-20241213184105746"></p>
<h5 id="脏位"><a href="#脏位" class="headerlink" title="脏位"></a>脏位</h5><p>dirty bit的优先级大于use bit 也由MMU维护，硬件会在发生<strong>写操作</strong>时自动设置脏位，页面换出首先考虑的是未被访问过的干净页，然后是被访问过的干净页。</p>
<ol>
<li><strong>标记页面是否被修改过</strong><ul>
<li>当一个页面被写入（例如进程对该页面的内容进行了修改），操作系统会将该页面的脏位置为 <code>1</code>。</li>
<li>如果页面从加载到内存以来未被修改，脏位保持为 <code>0</code>。</li>
</ul>
</li>
<li><strong>决定页面是否需要写回磁盘</strong><ul>
<li>如果一个页面需要被换出（从内存移到磁盘），操作系统会检查其脏位：<ul>
<li><strong>脏位为 1</strong>：表示页面内容已被修改，需要将修改后的内容写回磁盘（例如文件或交换区）。</li>
<li><strong>脏位为 0</strong>：页面未被修改，可以直接丢弃内存中的内容，因为磁盘上已有最新副本。</li>
</ul>
</li>
</ul>
</li>
<li><strong>减少不必要的磁盘写入</strong><ul>
<li>通过脏位的判断，可以避免无意义的磁盘写入操作，提高性能。例如，如果页面内容没有修改，就无需将内存中的数据写回磁盘。</li>
</ul>
</li>
</ol>
<h5 id="LRU-K"><a href="#LRU-K" class="headerlink" title="LRU-K"></a>LRU-K</h5><p>LRU-K中的K代表最近使用的次数，因此LRU可以认为是LRU-1。LRU-K的主要目的是为了解决LRU算法“缓存污染”的问题，其核心思想是将“最近使用过1次”的判断标准扩展为“最近使用过K次”。相比LRU，LRU-K需要多维护一个队列，用于记录所有缓存数据被访问的历史。只有当数据的访问次数达到K次的时候，才将数据放入缓存。当需要淘汰数据时，LRU-K会淘汰第K次访问时间距当前时间最大的数据。</p>
<img src="https://i-blog.csdnimg.cn/blog_migrate/41aee01a98aa03f4c3d75ef4c2c7749a.png" alt="img" style="zoom:200%;" /> 

<ol>
<li>数据第一次被访问，加入到访问历史列表；</li>
<li>如果数据在访问历史列表里后没有达到K次访问，则按照一定规则（FIFO，LRU）淘汰；</li>
<li>当访问历史队列中的数据访问次数达到K次后，将数据索引从历史队列删除，将数据移到缓存队列中，并缓存此数据，缓存队列重新按照时间排序；</li>
<li>缓存数据队列中被再次访问后，重新排序；</li>
<li>需要淘汰数据时，淘汰缓存队列中排在末尾的数据，即：淘汰“倒数第K次访问离现在最久”的数据。</li>
</ol>
<p>LRU-K具有LRU的优点，同时能够避免LRU的缺点，实际应用中LRU-2是综合各种因素后最优的选择，LRU-3或者更大的K值命中率会高，但适应性差，需要大量的数据访问才能将历史访问记录清除掉。</p>
<h3 id="其他-Swap-策略"><a href="#其他-Swap-策略" class="headerlink" title="其他 Swap 策略"></a>其他 Swap 策略</h3><p><strong>页面置换策略</strong>：<u>which</u> page to <u>swap out</u>?</p>
<p><strong>页面选择策略</strong>：when to <u>swap in</u> which page? </p>
<ul>
<li>OS决定何时将页面载入内存，大多数页面是按需载入(demand paging)</li>
<li>有时会提前载入(prefetching)马上可能要被访问的页面，比如连续的代码页</li>
</ul>
<p><strong>写入磁盘策略</strong>：when and how to <u>swap out</u>? or not?</p>
<ul>
<li>不一定是内存满了才会开始交换，OS预留部分空闲空间，设置HW和LW，当可用页少于LW，就swap out，直到可用页数达到HW，有一个守护进程 <code>swapd</code> 专门做这件事情。</li>
<li>交换本身是IO操作，可以通过聚集/分组的方式将多个等待写入写出的页合并操作，提高硬盘效率，执行单次大的写操作比许多小的写操作有效。</li>
<li>数据一致性：脏页需要被换出（刷盘, sync）</li>
</ul>
<p><strong>颠簸（thrashing）</strong>: 内存被超额请求，os需要不断进行页面的置换，此时可能会考虑终止一些进程(linux oom killer会杀死内存密集型，一般这些都是低优先级的，也有一定的风险)</p>
<h2 id="完整的虚拟内存系统"><a href="#完整的虚拟内存系统" class="headerlink" title="完整的虚拟内存系统"></a>完整的虚拟内存系统</h2><h3 id="VAX-VMS-虚拟内存系统"><a href="#VAX-VMS-虚拟内存系统" class="headerlink" title="VAX/VMS 虚拟内存系统"></a>VAX/VMS 虚拟内存系统</h3><h4 id="地址空间"><a href="#地址空间" class="headerlink" title="地址空间"></a>地址空间</h4><h5 id="应用进程共享内核空间"><a href="#应用进程共享内核空间" class="headerlink" title="应用进程共享内核空间"></a>应用进程共享内核空间</h5><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241213214150106.png" alt="image-20241213214150106" style="zoom:150%;" />

<ul>
<li>地址空间的下半部分称为进程空间，前半段是代码和向下增长的堆（P0），后半段是向上增长的堆（P1），<strong>各自拥有一个页表</strong>，减少了内部碎片。</li>
<li>地址空间的上半段称为系统空间S，只使用其中一半</li>
</ul>
<p>内核段包含在用户空间中，是所有的进程共享的，这样使得内核与用户程序之间数据交互更加方便，OS可以轻松地解析用户程序传入的指针。通过给系统空间设置保护位来确保内核的安全。</p>
<h5 id="优化页表"><a href="#优化页表" class="headerlink" title="优化页表"></a>优化页表</h5><ul>
<li>分出来的两个段，各自有一个页表[段页式管理]，减少了内部碎片 </li>
<li>进程的虚拟地址空间也包含了内核段，因此可以把用户<strong>页表纳入受保护的内核虚拟内存</strong>中，当存储压力巨大时可以将页表换出到磁盘，有一定的访问性能开销。</li>
</ul>
<h5 id="空指针"><a href="#空指针" class="headerlink" title="空指针"></a>空指针</h5><p>NULL是一个宏，实际上就是0，虚拟地址0有效位始终是0，因此试图访问这个有效位会出现段错误异常，陷入OS终止进程</p>
<h4 id="惰性优化（Lazy）"><a href="#惰性优化（Lazy）" class="headerlink" title="惰性优化（Lazy）"></a>惰性优化（Lazy）</h4><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/whiteBear/p/16729327.html">延迟分配：提供内存利用率的三种机制 - 牛犁heart - 博客园</a> </p>
<h5 id="写入时复制-copy-on-write"><a href="#写入时复制-copy-on-write" class="headerlink" title="写入时复制 copy-on-write"></a>写入时复制 copy-on-write</h5><p>如果要将一个页面从一个地址空间复制到另一个地址空间，会获取相同的指针，指向相同的资源。这个资源或许是内存中的数据，又或许是硬盘中的文件，直到某个应用真正需要<strong>修改某一页</strong>时，操作系统才会（惰性地）<strong>复制一份该页的专用副本</strong>给该应用，填充数据而其他所见的最初资源仍然保持不变。</p>
<p>COW的优点：<strong>如果应用没有修改该资源，就不会产生副本，因此多个应用只是在读取操作时可以共享同一份资源，从而节省内存空间。</strong> <strong>fork 会复制应用 A 的很多关键数据，但不会复制应用 A 对应的物理内存页面，而是要监测这些物理内存的读写，只有这样才能让应用 A 和应用 B 正常运行</strong></p>
<ul>
<li>fork但未写入</li>
</ul>
<p><img src="https://img2022.cnblogs.com/blog/1059417/202209/1059417-20220925215845353-1129676397.png" alt="image"></p>
<ul>
<li>fork后写入</li>
</ul>
<p><img src="https://img2022.cnblogs.com/blog/1059417/202209/1059417-20220925221038426-1637796167.png" alt="image"></p>
<p>fork()需要复制整个地址空间的内容，如果fork之后还调用了exec，这些地址空间内容又会被马上覆盖，做无用功，cow避免了大量不必要的复制操作，仍然保留正确的语义。</p>
<h5 id="按需调页-demand-paging"><a href="#按需调页-demand-paging" class="headerlink" title="按需调页 demand paging"></a>按需调页 demand paging</h5><ul>
<li><p><strong>按需调页</strong>是一种<strong>动态内存分配技术</strong>，更是一种优化技术，它把<strong>物理内存页面的分配推迟到不能再推迟为止</strong>。之所以能实现，是因为应用程序开始运行时，并不会访问虚拟内存空间中的全部内容。</p>
</li>
<li><p>由于<strong>程序的局部性原理</strong>，使得应用程序在执行的每个阶段，真正使用的内存页面只有一小部分，对于暂时不用的物理内存页，就可以分配由其他应用程序使用。因此，在不改变物理内存页面数量的情况下，请求调页能够提高系统的吞吐量。</p>
</li>
</ul>
<p>当页添加到地址空间时，会在页表做一个标记（保留的操作系统字段），当进程真正访问到这个虚拟页时，操作系统才会真正寻找物理页并将其置零，映射到地址空间，这样就避免了申请了但是从来不访问 导致浪费的情况。</p>
<h4 id="SWAP-策略"><a href="#SWAP-策略" class="headerlink" title="SWAP 策略"></a>SWAP 策略</h4><h5 id="替换策略：Second-Chance-FIFO"><a href="#替换策略：Second-Chance-FIFO" class="headerlink" title="替换策略：Second Chance FIFO"></a>替换策略：Second Chance FIFO</h5><p>利用的是软性的页错误</p>
<ul>
<li>用RSS(Resident Set Size)限制每个进程可以保存在内存中的最大页数，超过RSS就要“First out”，防止自私进程</li>
<li>引入两个全局的页面表，一个记录空闲干净页，另一个记录脏页</li>
<li>First Out 被换出的页面根据脏位添加到 干净页列表 或 脏页列表 的<strong>末尾</strong> </li>
<li>另一个进程需要空闲页，会先去干净页列表中取出<strong>第一个</strong>空闲页</li>
<li>如果换出页面的进程触发了page fault，则会从表中重新回收页，避免磁盘I/O </li>
</ul>
<h5 id="批量换出：page-clustering"><a href="#批量换出：page-clustering" class="headerlink" title="批量换出：page clustering"></a>批量换出：page clustering</h5><p>把大批量的页从上述的全局脏页列表中分组聚集到一起，一起写入到磁盘中，使IO次数减少，单次IO写入量更大，提高性能</p>
<h3 id="Linux-虚拟内存系统"><a href="#Linux-虚拟内存系统" class="headerlink" title="Linux 虚拟内存系统"></a>Linux 虚拟内存系统</h3><p><strong>Linux 系统主要采用了分页管理，但是由于 Intel 处理器的发展史，Linux 系统无法避免分段管理</strong>。于是 Linux 就把所有段的基地址设为 <code>0</code>，也就意味着所有程序的地址空间都是线性地址空间（虚拟地址），相当于屏蔽了 CPU 逻辑地址的概念，所以段只被用于访问控制和内存保护。虚拟空间分布可分为<strong>用户态</strong>和<strong>内核态</strong>两部分</p>
<h4 id="地址空间-1"><a href="#地址空间-1" class="headerlink" title="地址空间"></a>地址空间</h4><p><img src="https://pica.zhimg.com/v2-50e72a482d4b10604708f5e6a6c76435_r.jpg?source=1940ef5c" alt="img"></p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241213232325106.png" alt="image-20241213232325106"></p>
<ul>
<li>0-3GB是用户空间，其中用户态的分布：代码段(.ELF)、全局变量（初始化的数据段）、BSS（未初始化的数据段）、堆内存（Heap）、映射区（mmap）、函数栈（Stack）、初始化参数（argument, environment）</li>
<li>最高1GB为内核空间，存放内核的代码以及其他受保护的数据；像VAX/VMS一样，每个用户的进程空间内有着相同的内核。</li>
<li>64位的地址空间：低128T为用户空间，高128T为内核空间，中间未定义</li>
</ul>
<h5 id="逻辑内核空间（kmalloc）"><a href="#逻辑内核空间（kmalloc）" class="headerlink" title="逻辑内核空间（kmalloc）"></a>逻辑内核空间（kmalloc）</h5><ul>
<li><p>内核代码需要调用<code>kmalloc</code>申请，内核栈、页表等数据结构存储在这里</p>
</li>
<li><p>只能在物理内存中，不能被换出到磁盘</p>
</li>
<li><p><strong>严格的一对一直接映射</strong>：<code>0xC0000000</code> to <code>0x00000000</code>, <code>0xC0000FFF</code> to <code>0x00000FFF</code></p>
<ul>
<li><p>不需要进行复杂地址转换，直接将其当成物理地址即可，因此也不需要页表结构</p>
</li>
<li><p>连续的虚拟地址在物理上也一定是连续的</p>
</li>
<li><p>适合DMA</p>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>This makes memory allocated in this part of the kernel’s address space suitable for operations which need contiguous physical memory to work correctly, such as I/O transfers to and from devices via <strong>direct memory access (DMA)</strong></p>
</blockquote>
<h5 id="虚拟内核空间（vmalloc）"><a href="#虚拟内核空间（vmalloc）" class="headerlink" title="虚拟内核空间（vmalloc）"></a>虚拟内核空间（vmalloc）</h5><ul>
<li>内核代码需要调用<code>vmalloc</code>申请，returns 指向连续虚拟内存区域的指针</li>
<li>不是直接映射，因此连续的虚拟地址在物理上并不一定连续</li>
<li>容易分配(easy to allocate), 因此适合大块缓冲区，因为连续的大块物理内存显然不容易找到</li>
</ul>
<p>在32位Linux中，虚拟内核空间可以让内核空间大于1GB</p>
<blockquote>
<p>Kernel virtual addresses, and their disconnection from <strong>a strict one-to-one mapping to physical memory</strong>, make this possible. However, with the move to 64-bit Linux, the need is less urgent, because the kernel is not confined to only the last 1 GB of the virtual address space. （64位就没那么重要了）</p>
</blockquote>
<h4 id="内存分配"><a href="#内存分配" class="headerlink" title="内存分配"></a>内存分配</h4><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/overview.png" style="zoom:150%;" />

<h5 id="虚拟内存管理"><a href="#虚拟内存管理" class="headerlink" title="虚拟内存管理"></a>虚拟内存管理</h5><h6 id="malloc-1"><a href="#malloc-1" class="headerlink" title="malloc"></a>malloc</h6><ul>
<li><p>在不同OS中，malloc的实现也不同，有 dlmalloc, jemalloc, tcmalloc等实现</p>
</li>
<li><p>Linux中，用户可以显式调用mmap或者malloc分配，malloc底层基于mmap（大于128K）或brk（小于128K）</p>
</li>
<li><p>这两种方式分配的都是虚拟内存，没有分配物理内存。在第一次访问已分配的虚拟地址空间的时候，发生缺页中断，操作系统负责分配物理内存，然后建立虚拟内存和物理内存之间的映射关系。</p>
</li>
<li><p>大部分不建议使用brk，brk和sbrk分配的堆空间类似于缓冲池，调用它相当于增大缓冲池。用malloc可以重用前面空闲的内存空间，每次malloc从缓冲池获得内存，如果缓冲池不够了，malloc才会调用brk或sbrk扩充缓冲池，直到达到缓冲池大小的上限，free则将应用程序使用的内存空间归还给缓冲池。而free mmap会直接释放，将空间给操作系统，无法复用，一定会触发缺页中断。</p>
</li>
</ul>
<h6 id="brk"><a href="#brk" class="headerlink" title="brk"></a>brk</h6><p>brk 的实现方式是移动Program break，将数据段的最高地址指针 _edata(end of data) 往高地址推（分配的内存小于 128KB），sbrk是通过增量来控制的，原理类似。</p>
<ul>
<li><p>同一个程序bss的结束地址是固定的，而heap的起始地址在每次运行的时候都会改变 <strong>ASLR</strong>。</p>
</li>
<li><p>当<a target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Address_space_layout_randomization">ASLR</a>（Address Space Layout Randomization）关闭时，<code>start_brk</code>和brk同时指向<code>data/bss</code>段的结束位置（<a target="_blank" rel="noopener" href="http://lxr.free-electrons.com/source/include/linux/mm_types.h?v=3.8#L364">end_data</a>）。</p>
</li>
<li><p>当ASLR打开时，<code>start_brk</code>和brk同时指向<code>data/bss</code>段的结束位置（<code>end_data</code>）再加上一个随机的brk偏移。</p>
</li>
</ul>
<img src="https://pengrl.com/images/post/20032_0.png" alt="img" style="zoom:150%;" />

<p>brk的问题：</p>
<p>使用brk连续申请了10K, 20K, 30K内存，前两部分释放了，但是不会归还给操作系统，如果再次申请内存小于30K，就可以复用空闲区域，但是如果申请40K，就会出现内部碎片问题，只能继续新申请40K内存，导致大量内存碎片问题</p>
<h6 id="mmap"><a href="#mmap" class="headerlink" title="mmap"></a>mmap</h6><p>在用户进程空间内的内存映射段找一块空闲的虚拟内存（分配的内存大于 128k））—匿名空间，具体使用可见: <em>Memory-mapped I/O</em> </p>
<h5 id="物理内存管理"><a href="#物理内存管理" class="headerlink" title="物理内存管理"></a>物理内存管理</h5><h6 id="伙伴系统（Buddy-system）"><a href="#伙伴系统（Buddy-system）" class="headerlink" title="伙伴系统（Buddy system）"></a>伙伴系统（Buddy system）</h6><p>Buddy分配系统在普通内存池的基础上，允许两个<strong>大小相同且相邻</strong>的内存块合并，合并之后的内存块的「尺寸」增大，因而将被移动到另一个内存池的free list上。</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241210230312259.png" alt="image-20241210230312259"></p>
<p>总空间为2^N^，按照递归二分法分配内存，直到块大小刚好满足要求（显然这会导致内部碎片）当一个块释放的时候，allocator会检验与他相同大小的相邻块（buddy）是否空闲，若是则将二者合并，直到合并全部空闲内存。</p>
<p>优点：buddy的地址很容易确认，既然是相邻，说明首部地址只差一位，这个位决定了他们在整个数中的层次</p>
<p>在 Linux 系统中，连续内存管理采用了 <strong>伙伴系统（Buddy System）算法</strong> 来实现，对于内部碎片的问题，采用了SLAB进行解决。</p>
<p>它把所有的空闲页放到11个链表中，每个链表分别管理大小为1，2，4，8，16，32，64，128，256，512，1024个页的内存块。当系统需要分配内存时，就可以从buddy系统中获取。当分配内存时，会优先从需要分配的内存块链表上查找空闲内存块，当发现对应大小的内存块都已经被使用后，那么会从更大一级的内存块上分配一块内存，并且分成一半给我们使用，剩余的一半释放到对应大小的内存块链表上。</p>
<p>想要分配一个8KB大小的内存，但是发现对应大小的内存已经没有了，那么伙伴系统会从16KB的链表中查找一个空闲内存块，分成两个8KB大小，把其中的一个8KB大小返回给申请者使用，剩下的8KB放到8KB对应的内存块链表中进行管理。更坏的一种情况是，系统发现16KB大小的连续内存页已经没有了，那么以此会向更高的32KB链表中查找，如果找到了空闲内存块，那么就把32KB分成一个16KB和两个8KB，16KB的内存块放到16KB的链表进行管理，两个8KB的内存块一个返回给申请者，另一个放到8KB大小的链表进行管理。</p>
<p>当释放内存时，会扫描对应大小的内存块链表，查看是否存在地址能够连续在一起的内存块，如果发现有，那么就合并两个内存块放置到更大一级的内存块链表上，以此类推。比如我们释放8KB大小的内存，那么会从对应的链表扫描是否有能够合并的内存块，如果有另一个8KB大小的内存和我们使用的内存地址连续，那么就合并它们组成一个16KB大小的内存块，然后接着扫描16KB大小的内存块链表，继续查找合并的可能，以此类推下去。</p>
<p>操作系统的内存管理通常是基于<strong>页（page）</strong>的概念，即操作系统将物理内存分为固定大小的页。页是内存管理的基本单位，这样可以统一管理和访问内存。页的大小通常是2的幂次方，例如4KB、8KB或16KB等。</p>
<ul>
<li><strong>操作系统需要高效地管理内存</strong>，而将内存管理的单位限定为页大小可以简化这一过程。每一页都有一个对应的页表项，操作系统只需要管理页而不是单个字节或更小的单位。这减少了管理开销。</li>
</ul>
<h6 id="分离空闲列表（SLAB-segregated-free-lists）"><a href="#分离空闲列表（SLAB-segregated-free-lists）" class="headerlink" title="分离空闲列表（SLAB, segregated free lists）"></a>分离空闲列表（SLAB, segregated free lists）</h6><img src="https://hammertux.github.io/img/slab-org.png" alt="slab org" style="zoom:150%;" />



<p>为了方便管理，Linux中的buddy allocator以物理页框为最小粒度，而现实的应用中，操作系统作为一个一直在运行的程序，多是以<strong>内核objects</strong>（比如描述文件的”struct inode”）的大小来申请和释放内存的，这些内核objects的大小通常从几十字节到几百字节不等，远远小于一个page的大小。如果程序固定分配一个或者几个大小的的内存，那就专门给他分配一块内存用于分配这些固定大小空间，减少了大小上的差异，碎片自然也就少了</p>
<p>在内核启动时，为诸如锁、文件inode之类频繁请求的内核object分配 <strong>Object cache</strong>，他们的对象缓存分离了特定大小的空闲列表，获得了性能上的提升，当cache将要耗尽时从通用的内存分配程序申请slab（总量是page size和object size的最小公倍数）例如，2.5KB objectsize, 4KB pagesize 就去申请5个页, 专门用来放这种object,一个页能放5个</p>
<p>当cache中内核object的引用计数变为0，通用的内存分配程序会从专用的分配器中回收这些资源。同时还使空闲对象保持在预初始化的状态，避免频繁销毁、初始化的开销。</p>
<p>Linux实现</p>
<img src="https://www.kernel.org/doc/gorman/html/understand/understand-html037.png" alt="img" style="zoom:150%;" />

<img src="https://picx.zhimg.com/v2-90fe0938cf0c8ab8836257ed587654d1_1440w.jpg" alt="img" style="zoom:150%;" />

<p>每个<code>kmem_cache</code>都是链接在一起形成一个全局的双向链表，系统可以从Cache_chain开始扫描每个<code>kmem_cache</code>（相当于上面说的内存池, fixed size）</p>
<p><code>slab</code>是内存池从系统申请内存的最小单位，在实现上一个<code>slab</code>有一个或多个连续的物理页组成（通常只有一页）单个<code>slab</code>可以在<code>slab</code>链表之间移动，例如如果一个<code>slabs_partial</code>中的slab被分配了对象后变满了，就要从<code>slabs_partial</code>中被删除，同时插入到<code>slabs_full</code>中去。</p>
<h4 id="页表结构"><a href="#页表结构" class="headerlink" title="页表结构"></a>页表结构</h4><p>虚拟地址：</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241214003409861.png" alt="image-20241214003409861"></p>
<p>4KB的页大小对应12位offset，共四级页表，每级索引为9位，一个表条目占用4B空间，一张表正好占满一页</p>
<h4 id="更大的页大小（huge-pages）"><a href="#更大的页大小（huge-pages）" class="headerlink" title="更大的页大小（huge pages）"></a>更大的页大小（huge pages）</h4><blockquote>
<p>Specifically, recent designs support 2-MB and even 1-GB pages in hardware. Thus, over time, Linux has evolved to allow applications to utilize these <strong>huge pages</strong> (as they are called in the world of Linux).</p>
</blockquote>
<h5 id="提升-TLB-命中率"><a href="#提升-TLB-命中率" class="headerlink" title="提升 TLB 命中率"></a>提升 TLB 命中率</h5><p>一方面是减少了页表项数，更重要的是<strong>提升了TLB的命中率（hit rate）</strong>：</p>
<ul>
<li><strong>TLB的条目数(slots)是固定的，因为空间局部性，同一页放更多数据，将更多的物理内存空间纳入到TLB中</strong></li>
<li>换个角度，如果发生TLBmiss，因为页表项数的减少，遍历速度就会加快</li>
<li>与此同时，某些情况下也可以加快分配内存</li>
</ul>
<h5 id="如何申请"><a href="#如何申请" class="headerlink" title="如何申请"></a>如何申请</h5><p>一些对性能要求严格的应用如大型数据库应该使用更大的页大小，用来提高性能，必须通过<code>mmap</code>或者<code>shmget</code>进行显式申请，因此其他正常使用4KB页大小的程序不受影响。</p>
<p>**透明大页(transparent huge pages)**：不需要应用程序修改源代码，OS 会自动根据情况决定是否分配大页。</p>
<h5 id="缺陷-1"><a href="#缺陷-1" class="headerlink" title="缺陷"></a>缺陷</h5><blockquote>
<p>Huge pages are not without their costs. The biggest potential cost is <strong>internal fragmentation</strong>, i.e., a page that is large but sparsely used. This form of waste can fill memory with large but little used pages. <strong>Swapping</strong>, if enabled, also does not work well with huge pages, sometimes greatly amplifying the amount of I/O a system does.</p>
</blockquote>
<ol>
<li><strong>内部碎片</strong>：由于各种内存操作基本都要求按照page对齐，比如一个可执行文件映射到进程地址空间，根据文件大小的不同，平均算下来会浪费掉半个page size的物理内存，使用large page的话这个消耗就显得比较大了。</li>
<li><strong>需要连续大块的物理内存</strong>：系统运行一段时间后，会很难再也大块的连续物理内存，这时分配large page将会变的很困难，所以通常需要在系统初始化的时候就划分出一段物理内存给large page用（类似于DMA的内存分配），这样就减少了一些灵活性。</li>
<li><strong>swap开销大</strong>：动态large page（THP）在换出到外部的flash/disk和从flash/disk换入物理内存的过程会比normal size的page带来更大的开销（可参考<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/117239320">这篇文章</a>）。</li>
</ol>
<h4 id="Page-Cache-Disk-Cache"><a href="#Page-Cache-Disk-Cache" class="headerlink" title="Page Cache/Disk Cache"></a>Page Cache/Disk Cache</h4><p><a target="_blank" rel="noopener" href="https://www.mazhen.tech/p/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-page-cache/">深入理解 Page Cache</a></p>
<p><strong>Page Cache</strong> 是由内核管理的内存，位于 <a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/latest/filesystems/vfs.html">VFS(Virtual File System)</a> 层和具体文件系统层（例如ext4，ext3）之间。应用进程使用 <code>read</code>/<code>write</code> 等文件操作，通过系统调用进入到 <strong>VFS</strong> 层，根据 <strong>O_DIRECT</strong> 标志，可以使用 <strong>Page Cache</strong> 作为文件内容的缓存，也可以跳过 <strong>Page Cache</strong> 不使用内核提供的缓存功能</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/vzb3z8uo.png" alt="vzb3z8uo"></p>
<blockquote>
<p>aggressive caching subsystem to <strong>keep popular data items from persistent storage</strong> in memory</p>
</blockquote>
<ul>
<li><p><strong>Buffered I/O</strong>: IO缓存 (<code>read()</code>, <code>write()</code>) [<code>dentry, inode cache</code>]</p>
</li>
<li><p><strong>Memory-mapped I/O</strong>: 内存映射 mmap()</p>
<ul>
<li><strong>File-backed 文件映射</strong>: 其可以将文件内容映射到用户空间，虚拟内存和磁盘文件中间通过 Page Cache 进行数据中转，因此可以像普通虚拟内存一样访问文件，这些虚拟内存<strong>在磁盘中有对应的文件</strong>，读取这部分内容就像是文件I/O一样</li>
<li><strong>Anonymous Mapping 匿名映射</strong>: mmap以<code>MAP_ANONYMOUS</code>方式申请内存，这些虚拟内存在磁盘中<strong>没有确切的文件，持久化到swap space</strong>，全部初始化为0，</li>
</ul>
</li>
<li><p>通过<code>page_cache_hashtable</code>搜索，加快访问速度。</p>
</li>
</ul>
<h5 id="Memory-mapped-I-O"><a href="#Memory-mapped-I-O" class="headerlink" title="Memory-mapped I/O"></a>Memory-mapped I/O</h5><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/longerzone/article/details/12948925#">Linux 下的两个特殊的文件 – /dev/null 和 /dev/zero 简介及对比_linux空洞文件null-CSDN博客</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/yangle4695/article/details/52139585">Linux 内存映射函数 mmap（）函数详解_mmap fb-CSDN博客</a>  </p>
<ul>
<li><code>void* mmap(void* start, size_t length, int prot, int flags, int fd, off_t offset);</code> </li>
<li><code>int munmap(void* start, size_t length);</code> <ul>
<li><code>prot:</code> 保护位 <code>PROT_EXEC</code>, <code>PROT_READ</code> , <code>PROT_WRITE</code> , <code>PROT_NONE</code></li>
<li><code>flags:</code> <code>MAP_SHARED</code>共享模式 <code>MAP_PRIVATE</code>写时复制，不共享 <code>MAP_ANONYMOUS</code>匿名模式fd无效</li>
<li><code>fd:</code> 文件描述符，如果是匿名模式可以置为<code>-1</code>，或者打开<code>/dev/zero</code>获取其fd</li>
<li><code>offset:</code>文件映射的偏移量，通常设置为0，代表从文件最前方开始对应，offset必须是分页大小的整数倍。</li>
</ul>
</li>
</ul>
<ol>
<li><code>fopen()</code> 系统调用打开文件，并返回描述符 <code>fd</code>。</li>
<li><code>mmap(start,...)</code>建立内存映射并返回映射首地址指针 <code>start</code>参数start可以是空指针，系统自动分配地址</li>
<li>通过对<code>start</code> 对文件进行各种操作，首次访问start指向的内容会触发页错误(demand paging)</li>
<li><code>munmap (start,...)</code> 关闭内存映射</li>
<li><code>fclose(fd)</code> 系统调用关闭文件 <code>fd</code> </li>
</ol>
<img src="https://miro.medium.com/v2/resize:fit:1313/0*DgRx8tGpS1T0St_b.png" alt="img" style="zoom:150%;" />

<p>通过对一个打开的FD调用<code>mmap()</code>，进程能够获得一个指向内存映射区的指针，内存映射区是一个独立区域，因此可以独立释放。通过这个指针就能够对文件进行操作。这里采用了demand paging——<strong>懒加载</strong>的策略，直到第一次访问触发页错误，才会真正把文件内容分配到物理页中。</p>
<p>数据一致性：</p>
<ul>
<li><strong>files</strong>：程序通过 <code>mmap</code> 映射文件时，如果页面未修改（脏位为 <code>0</code>），无需将内存中的数据写回磁盘</li>
<li><strong>Swap space</strong>：当内存不足时，未被修改的页面无需写回磁盘的 Swap space，节省时间和空间</li>
</ul>
<p>即使不显式调用<code>mmap</code>也会使用这个共享的文件映射区域，比如从可执行文件中加载的代码、进程之间共享的库代码</p>
<p>使用<code>pmap</code>分析<code>tcsh</code>进程的虚拟内存映射情况如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Virtual Address  	Size  	Protection  Source</span><br><span class="line">0000000000400000 	372K  	r-x--       tcsh</span><br><span class="line">00000000019d5000 	1780K 	rw---       [anon ]</span><br><span class="line">00007f4e7cf06000 	1792K 	r-x--       libc-2.23.so</span><br><span class="line">00007f4e7d2d0000	36K   	r-x--       libcrypt-2.23.so</span><br><span class="line">00007f4e7d508000	148K  	r-x--       libtinfo.so.5.9</span><br><span class="line">00007f4e7d731000 	152K  	r-x--       ld-2.23.so</span><br><span class="line">00007f4e7d932000 	16K   	rw---       [stack ]</span><br></pre></td></tr></table></figure>

<p>除了<code>tcsh</code>自己的代码，<code>libc, libcrypt, libtinfo</code> 这些共享库代码也被加载到tcsh的虚拟地址空间中，连接器<code>ld</code>的可执行代码也在其中。[anon]表示自己的heap堆空间，[stack]表示自己的stack栈空间</p>
<p>和 <strong>shmem</strong> 的区别：</p>
<p>System V 共享内存是持久的：除非被进程显式删除，否则它会保留在内存中并保持可用，直到系统关闭。 mmap 内存在应用程序的执行之间不是持久的（除非它由文件支持，<code>MAP_SHARED</code>）</p>
<h5 id="Buffered-I-O"><a href="#Buffered-I-O" class="headerlink" title="Buffered I/O"></a>Buffered I/O</h5><p><strong>Buffered I/O</strong> 与 <strong>内存映射文件</strong> 的区别：</p>
<p><img src="https://cdn.mazhen.tech/images/202209241611674.png" alt="d"></p>
<h6 id="读取机制"><a href="#读取机制" class="headerlink" title="读取机制"></a>读取机制</h6><ol>
<li><p><code>int fd = open(file_path)</code></p>
<ul>
<li>fd是内核对打开的文件的编号，通过fd就可以操作文件</li>
</ul>
</li>
<li><p><code>int c = read(fd, buf, 512)</code>  </p>
<ul>
<li>由内核负责将 fd 翻译成 inode+offset</li>
<li>读取inode，如果page cache没有就从磁盘读，然后写入inode到Page cache中</li>
<li>读取对应偏移的block，如果page cache没有就从磁盘读，然后写入block到Page cache中</li>
<li>从内存中的 cached block 复制 512 B 到 buf 中</li>
</ul>
</li>
</ol>
<h6 id="写入机制"><a href="#写入机制" class="headerlink" title="写入机制"></a>写入机制</h6><p><strong>Write-back (default)</strong> </p>
<p>write back 写回 只对缓存进行操作 read-allocate 先把数据读取到Cache中，再从Cache中读数据</p>
<blockquote>
<p>By default, kernel marks written pages dirty and flushes after a delay:</p>
</blockquote>
<ol>
<li><p><code>int fd = open(&quot;myfile&quot;);</code> </p>
</li>
<li><p><code>write(fd, &quot;hello world&quot;, 11)</code></p>
<ul>
<li>内核将hello world字符串写入到 cached block 对应的 page cache 页中</li>
<li>内核将被修改的页加入脏页列表中</li>
<li>按照一定的策略进行刷盘</li>
</ul>
</li>
</ol>
<p>在系统发生宕机的情况下无法确保数据已经落盘，因此存在数据丢失的问题。不过，在程序挂了，例如被 kill -9，Page Cache 中的数据操作系统还是会确保落盘；</p>
<p><strong>Write-through</strong></p>
<p>直写，在更改page cache的<strong>同时</strong>刷盘(synchoronized)</p>
<blockquote>
<p><strong>O_SYNC</strong> flag converts file descriptor to write-through</p>
</blockquote>
<ul>
<li><code>int fd = open(&quot;myfile&quot;, O_SYNC |...); </code></li>
<li><code>write(fd, &quot;hello world&quot;, 11);</code> <ul>
<li>This affects all accesses to the same disk blocks</li>
</ul>
</li>
</ul>
<p>以牺牲系统 I/O 吞吐量作为代价，向上层应用确保一旦写入，数据就已经落盘，不会丢失</p>
<h5 id="脏页刷盘"><a href="#脏页刷盘" class="headerlink" title="脏页刷盘"></a>脏页刷盘</h5><p>Page cache 追踪脏页，保存一个脏文件inode链表，脏页需要写入到磁盘的文件或者swap space中，确保内存数据的持久化，可以由叫做<code>pdflush</code>的后台线程，唤醒方式有如下</p>
<ul>
<li><p><strong>定期</strong>唤起<code>pdflush</code>，确保不会有脏页驻留时间过长</p>
</li>
<li><p>在脏页比例达到<strong>阈值</strong>时，按照一定速率刷盘（1024）</p>
</li>
<li><p>内存可用空间低到一定<strong>阈值</strong>，刷脏页释放内存</p>
</li>
<li><p>响应特定的系统调用</p>
<ul>
<li><p><code>fsync(int fd)</code> 将fd的脏数据和所有脏元数据刷盘</p>
</li>
<li><p><code>fdatasync(int fd)</code> 将fd的脏数据和必要的脏元数据刷盘</p>
</li>
<li><p><code>sync()</code> 将全部脏页刷盘</p>
</li>
<li><p><code>O_SYNC</code> 文件打开方式要求同步写操作</p>
</li>
</ul>
</li>
</ul>
<p><strong>应用</strong></p>
<ul>
<li><strong>文件映射</strong>：程序通过 <code>mmap</code> 映射文件时，如果页面未修改（脏位为 <code>0</code>），无需将内存中的数据写回磁盘。</li>
<li><strong>交换区</strong>：当内存不足时，未被修改的页面无需写回交换区，节省时间和空间。</li>
</ul>
<h5 id="Direct-I-O"><a href="#Direct-I-O" class="headerlink" title="Direct I/O"></a>Direct I/O</h5><p>Buffered I/O要在磁盘和VFS之间加一层Page cache，对于写入操作，需要在cache中开辟新页，然后将其标记为脏。</p>
<p>OS cache提供的这些预读取、顺序读取等特性，这些特性并不适用于所有的场景，比如数据库，数据库通常都有自己的一套缓存机制，就像mysql的innodb存储引擎，它有自己的缓存页，有自己的落盘机制，如果不使用directIO，这明显就会存在双重的cache，一个是OS设计的，一个是DB设计的，而通常，DB需要更加符合自己使用的cache机制，而非OS提供的通用化的缓存机制。直接写入不会将要写入的数据先从磁盘读到cache，而是直接将要写的数据写入磁盘。</p>
<p>O_DIRECT 下的 I/O 操作是直达磁盘的，用户空间通过 DMA 的方式与磁盘以及网卡进行数据拷贝。</p>
<h4 id="页面置换：2Q"><a href="#页面置换：2Q" class="headerlink" title="页面置换：2Q"></a>页面置换：2Q</h4><p>关键词：<strong>预读失效 + 缓存污染</strong> </p>
<ul>
<li><strong>预读失效：提前加载到内存，但是并没有访问</strong></li>
<li><strong>缓存污染：加载到内存，但是只访问一次</strong></li>
</ul>
<p><strong>LRU</strong>：如果打开一个非常大的文件，LRU会把其他在内存中的文件都淘汰掉，但是写入这个文件到内存中并没有什么用，就和循环访问一样，文件之前的数据在被淘汰掉之前再也被访问。</p>
<p><strong>Linux的2Q(Two queue)策略</strong></p>
<p>该算法类似于LRU-2，不同点在于2Q将LRU-2算法中的访问历史队列（注意这不是缓存数据的）改为一个FIFO缓存队列，即：2Q算法有两个缓存队列，一个是FIFO队列，一个是LRU队列。</p>
<img src="https://i-blog.csdnimg.cn/blog_migrate/73bc553b295b04f7a2bc634b6bd10ab9.png" alt="img" style="zoom:200%;" />

<p>Linux对于2Q的实现，只淘汰FIFO队列里面的数据：</p>
<p>Page cache（Buffered I/O或mmap）维护两个队列:</p>
<p><code>inactive list(FIFO), active list(LRU)</code> </p>
<ul>
<li>第一次被访问，将页面加入<code>inactive list</code></li>
<li>之后的访问，将页面升至<code>active list</code> </li>
<li>需要进行替换时，<code>inactive list</code>进行FIFO</li>
<li><code>active list</code>对定期 LRU 到<code>inactive list</code>，使<code>active list</code>占 Page cache 的2/3左右。</li>
<li>循环访问大文件时，大文件的页面不会跑到<code>active list</code>中，因此原来<code>active list</code>的页面就不会被迫换出</li>
</ul>
<h4 id="其他策略-1"><a href="#其他策略-1" class="headerlink" title="其他策略"></a>其他策略</h4><ul>
<li><code>fork()</code> 采用COW写时复制的策略，减少无效的复制</li>
<li><code>swapd</code> 可以监控内存状况，内存占用过高（watermark）换出页面，释放到安全水平（异步）</li>
<li><strong>swappiness</strong>：修改换出页面的积极性，0为不主动换出</li>
<li><strong>关闭swap</strong>：服务器内存本身足够大，不需要换出操作，因为会降低效率</li>
<li><strong>内存颠簸（thrashing）</strong> 虚拟内存申请，但是物理内存几乎占满，导致同时出现大量缺页错误，此时linux oom killer会杀死内存密集型，一般这些都是低优先级的，也有一定的风险)</li>
</ul>
<h3 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h3><p>现代操作系统最大的一个特点就是对安全的注重，仅仅使用内核</p>
<h4 id="针对用户程序：缓冲区溢出攻击"><a href="#针对用户程序：缓冲区溢出攻击" class="headerlink" title="针对用户程序：缓冲区溢出攻击"></a>针对用户程序：缓冲区溢出攻击</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">some_function</span><span class="params">(<span class="type">char</span> *input)</span> &#123;</span><br><span class="line">    <span class="type">char</span> dest_buffer[<span class="number">100</span>];</span><br><span class="line">    <span class="built_in">strcpy</span>(dest_buffer, input); <span class="comment">// oops, unbounded copy!</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果输入超过缓冲区，input就会开始覆盖其他数据，攻击者可以利用缓冲区溢出注入他们的恶意代码，在页表中引入<code>NX</code>bit能够在一定程度上解决问题，但是黑客可以更改函数的执行栈，将函数的返回值指向恶意代码的地址。</p>
<p>return-to-libc attack:==ROP==</p>
<blockquote>
<p>Thus, an attacker can overwrite the stack such that the <strong>return address in the currently executing function</strong> points to <strong>a desired malicious instruction (or series of instructions)</strong>, followed by a return instruction.</p>
<p>By stringing together a large number of gadgets (i.e., ensuring each return jumps to the next gadget), the attacker can execute arbitrary code. Amazing!</p>
</blockquote>
<p>address space layout randomization:==ASLR==</p>
<blockquote>
<p>Instead of placing code, stack, and the heap <strong>at fixed locations</strong> within the virtual address space, the OS <strong>randomizes their placement</strong>, thus making it quite challenging to craft the intricate code sequence required to implement this class of attacks.</p>
</blockquote>
<p>ASLR可以确保客户的程序只崩溃不执行恶意代码，ASLR将brk、mmap、stack的开始段加一些随机数，</p>
<p>由此衍生出了KASLR，内核的地址空间也可以随机生成</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//random.c</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *argv[])</span> &#123;</span><br><span class="line">    <span class="type">int</span> <span class="built_in">stack</span> = <span class="number">0</span>;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%p\n&quot;</span>, &amp;<span class="built_in">stack</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/* </span></span><br><span class="line"><span class="comment">    prompt&gt; ./random</span></span><br><span class="line"><span class="comment">    0x7ffd3e55d2b4</span></span><br><span class="line"><span class="comment">    prompt&gt; ./random</span></span><br><span class="line"><span class="comment">    0x7ffe1033b8f4</span></span><br><span class="line"><span class="comment">    prompt&gt; ./random</span></span><br><span class="line"><span class="comment">    0x7ffe45522e94</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>

<h4 id="针对内核程序：Meltdown-amp-Spectre"><a href="#针对内核程序：Meltdown-amp-Spectre" class="headerlink" title="针对内核程序：Meltdown &amp; Spectre"></a>针对内核程序：Meltdown &amp; Spectre</h4><p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/23973128">CPU 的分支預測器是怎樣工作的？ - 知乎</a> </p>
<p>利用了 CPU 预测执行的漏洞，分支预测将串行的程序变成了并行的，而前后数据依赖，不可避免地在硬件上留下了踪迹，造成了并发安全问题</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mov rax byte[x]  ; 非法操作 将x的数据拷贝到rax</span><br><span class="line">shl rax 0xC  ; rax * 4096, 页对齐</span><br><span class="line">mov rbx qword [rbx + rax]  ; [rbx] 为用户空间的一个array，合法操作</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/32757727">解读 Meltdown &amp; Spectre CPU 漏洞 - 知乎</a> </p>
<p>操作系统会事先标注好内核的内存地址范围，如果 x 在内核的这个地址范围内，并且 CPU 不是以内核模式运行的话，那么该指令会被 CPU 标注为非法，引起异常，异常处理程序会将 rax 清空为0，并且终结此程序，这样后续指令再来读 rax 的时候就只能读到0了。</p>
<p>理论上讲，在执行第二条指令之前，rax应该已经被清零了。然而在实际的 CPU 运行中，为了达到更好的性能，第二条和第三条指令在异常处理生效之前都会被<strong>部分执行</strong>，直到异常处理时 rax 和 rbx 被清零。</p>
<p>但问题的关键就在第三行指令：<strong>如果地址 rbx + rax 不在cache中的话，CPU 会自动将这一地址调入cache中，以便之后访问时获得更好的性能，然而异常处理并不会将这个cache flush掉。而这条 cache 的地址是和 rax 直接相关的，这样就相当于在 CPU 硬件中留下了和rax 相关的信息。</strong>  </p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OSTEP%20Virtualization.assets/image-20241214175132236.png" alt="image-20241214175132236"></p>
<p>那么如何还原 rbx + rax 这个被cache的地址呢？这时候需要用到的原理就是利用cache的访问延时，即已经被cache的数据访问时间短，没有被cache的数据访问时间长。由于[rbx]这个array是在用户地址空间内的，可以自由操作，首先我们要确保整个 [rbx]这个array 都是没有被cache的，然后执行上述攻击代码，这时候 rbx + rax 这个地址就已经被cache了，接下来遍历整个[rbx] array，来测量访问时间，访问时间最短的那个 page 就可以确定为 rbx + rax。</p>
<p>对于个人终端用户，利用Meltdown与Spectre漏洞，低权限用户可以访问内核的内容，泄露本地操作系统底层的信息、秘钥信息等，通过获取泄露的信息，可以绕过内核的隔离防护;如果配合其它漏洞，可以利用该漏洞泄露内核模块地址绕过KASLR等防护机制实现其他类型的攻击进行提权。另外，利用浏览器JIT特性预测执行特殊的JIT代码，从而读取整个浏览器内存中的数据，泄露用户帐号，密码，邮箱, cookie等隐私信息。</p>
<p>因此，增强内核保护的一种途径是从每个用户进程中删除尽可能多的内核地址空间，并为大多数内核数据提供单独的内核页表（称为内核页表隔离，或 KPTI）[G+17]。因此，不是将内核的代码和数据结构映射到每个进程中，而是只保留最低限度的代码和数据结构；当切换到内核时，现在需要切换到内核页表。这样做可以提高安全性并避免一些攻击媒介，但代价是：性能。切换页表的成本很高。</p>
<h2 id="内存虚拟化总结"><a href="#内存虚拟化总结" class="headerlink" title="内存虚拟化总结"></a>内存虚拟化总结</h2><ul>
<li><p>虚拟地址的作用</p>
</li>
<li><p>虚拟地址的翻译（重定位）</p>
<ul>
<li>段式 base+bound, bound varies from each other</li>
<li>页式 fixed bound</li>
<li>段页式 </li>
<li>多级页表 fill one page with one table, hi-level table points to low-level table</li>
<li>TLB：翻译缓存</li>
</ul>
</li>
<li><p>Swap：将物理内存看作虚拟内存的缓存</p>
<ul>
<li>机制：Page Fault &amp; Disk I/O </li>
<li>策略：<ul>
<li>是否需要SWAP？物理内存充足就没必要开启</li>
<li>具体换<strong>出</strong>哪一页？LRU, FIFO, Random, Second Chance, LRU-K, 2Q, Clock</li>
<li>何时换<strong>出</strong>？(被动watermark、主动swappiness&gt;0)</li>
<li>一次 I/O 换<strong>出</strong>多少页？(clustering)</li>
<li>何时换<strong>入</strong>？(lazy aka. demand paging)</li>
<li>一次 I/O 只换<strong>入</strong>一页<strong>吗</strong>？(prefetching)</li>
</ul>
</li>
</ul>
</li>
<li><p>内存分配:</p>
<ul>
<li>机制：空闲空间链表节点的分割与合并</li>
<li>物理：Buddy, SLAB</li>
<li>虚拟：mmap malloc brk</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://scatteredream.github.io/2025/01/14/L4%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars.githubusercontent.com/u/62317679?s=400&v=4">
      <meta itemprop="name" content="碎梦">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="scatteredream's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | scatteredream's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/01/14/L4%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82/" class="post-title-link" itemprop="url">应用层</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-01-14 00:00:00" itemprop="dateCreated datePublished" datetime="2025-01-14T00:00:00+08:00">2025-01-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-05-03 21:01:06" itemprop="dateModified" datetime="2025-05-03T21:01:06+08:00">2025-05-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%A1%E7%BD%91/" itemprop="url" rel="index"><span itemprop="name">计网</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="域名系统（DNS）"><a href="#域名系统（DNS）" class="headerlink" title="域名系统（DNS）"></a>域名系统（DNS）</h1><p>Domain Name System based on UDP port 53 </p>
<h2 id="域名-名字空间"><a href="#域名-名字空间" class="headerlink" title="域名 名字空间"></a>域名 名字空间</h2><p><strong>层次结构</strong>：………三级域名.二级域名.顶级域名</p>
<p><strong>根</strong>：无名字</p>
<p><strong>顶级域名</strong>：国家、组织</p>
<p><strong>二级域名</strong>（我国）：类别域名、行政区域名</p>
<p>属于不同父亲的孩子节点可以有相同的名称: <a target="_blank" rel="noopener" href="http://www.example.cn/">www.example.cn</a>  <a target="_blank" rel="noopener" href="http://www.example.com/">www.example.com</a> </p>
<h2 id="域名服务器"><a href="#域名服务器" class="headerlink" title="域名服务器"></a>域名服务器</h2><p>DNS服务器实际是一个分布式的数据库。主从复制，读写分离，增强可用性。服务器可以采用anycast任播技术，多台服务器使用同一IP地址，路由自动选择最近的服务器。</p>
<p>分类：</p>
<ul>
<li><strong>根域名服务器</strong>（Root）：所有的根域名服务器都知道所有顶级域名服务器的IP地址和域名<ul>
<li>根域名有13个，分布于全球的若干根域名服务器，使用IP anycast技术，每个域名有多个物理实例，但对外展示同一个 IP。</li>
</ul>
</li>
<li><strong>顶级域名服务器</strong>（Top Level Domain）：管辖属于自己的二级域名</li>
<li><strong>权限域名服务器</strong>（Authoriative Name Server）：管辖区内的域名，一个服务器管一个域名，效率比较低，所以采用 <strong>区</strong> 的概念，区是域的子集。</li>
<li><strong>本地域名服务器</strong>：不在上述层次中，但是离客户最近的DNS服务器。</li>
</ul>
<h2 id="DNS-查询顺序"><a href="#DNS-查询顺序" class="headerlink" title="DNS 查询顺序"></a>DNS 查询顺序</h2><h3 id="先查缓存的查询流程"><a href="#先查缓存的查询流程" class="headerlink" title="先查缓存的查询流程"></a>先查缓存的查询流程</h3><p><img src="C:/Users/Lenovo/Pictures/markdownfile/L4%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82.assets/image-20241129143353140.png" alt="image-20241129143353140"></p>
<ol>
<li>浏览器 DNS 缓存：首先，浏览器会检查自己的缓存中是否已经有该域名的IP地址记录。如果有，则直接使用这个IP地址，而不会发起DNS查询</li>
<li>操作系统 DNS 缓存：如果浏览器缓存中没有找到，浏览器会请求操作系统进行DNS解析。操作系统会先检查自己的DNS缓存。大多数现代操作系统都会维护一个 DNS 缓存来存储最近解析过的域名和对应的IP地址</li>
<li>本地 hosts 文件：如果操作系统缓存中也没有找到对应的记录，并且您使用的是Unix-like系统（如Linux或macOS），操作系统会查询本地的/etc/hosts文件。这个文件通常包含静态的IP地址到域名的映射</li>
<li>路由器DNS缓存：我们常用的路由器也带有自动缓存功能，路由器DNS被篡改会造成<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=216036547&content_type=Article&match_order=1&q=%E5%9F%9F%E5%90%8D%E5%8A%AB%E6%8C%81&zhida_source=entity">域名劫持</a>，将访问网址定位到另外一个服务器；</li>
<li>本地DNS服务器（递归查询，本地DNS服务器替主机查询，主机作为DNS客户端向DNS服务器请求服务）：如果/etc/hosts文件中也没有找到，操作系统会向配置的本地DNS服务器发送查询请求。这个本地DNS服务器可能是您的网络服务提供商提供的，或者是您在公司或学校网络中配置的，也具有缓存功能。本地DNS将解析结果告知客户端的同时，将记录缓存下来，当下次请求同一个域名时，直接会将记录返回，而无需再进行全球查询。</li>
<li>根域名服务器（迭代查询，从此开始就是本地DNS服务器反复查询）：如果本地DNS服务器无法解析该域名，它会向根域名服务器发送查询请求。根域名服务器会返回负责顶级域名（如.com）的权威DNS服务器的地址</li>
<li>顶级域名服务器：本地DNS服务器然后会向顶级域名服务器发送查询请求，获取该域名的权威DNS服务器的地址</li>
<li>权威DNS服务器：最后，本地DNS服务器会向权威DNS服务器发送查询请求，获取该域名的IP地址</li>
<li>返回IP地址：一旦本地DNS服务器从权威DNS服务器那里获得了IP地址，它就会将这个IP地址返回给操作系统，操作系统再返回给浏览器。浏览器最后使用这个IP地址来建立与服务器的连接</li>
</ol>
<p>在查询的过程中，一旦在某一环节找到有效的IP地址记录，就会停止后续的查询。而且，为了提高效率，本地DNS服务器和操作系统通常会对查询结果进行缓存，以便在后续请求中直接使用，减少网络延迟</p>
<h3 id="DNS-缓存"><a href="#DNS-缓存" class="headerlink" title="DNS 缓存"></a>DNS 缓存</h3><p>所谓DNS缓存是指DNS返回正确的IP地址之后，系统会将这个结果临时储存起来，并为缓存设定一个失效时间（<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=216036547&content_type=Article&match_order=1&q=TTL%E5%80%BC&zhida_source=entity">TTL值</a>），在TTL失效前，当再次访问这个网站，系统就会直接从<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=216036547&content_type=Article&match_order=1&q=DNS+%E7%BC%93%E5%AD%98&zhida_source=entity">DNS 缓存</a>中将结果返回，而不必再次委托递归服务器进行全球解析查询，加快了<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=216036547&content_type=Article&match_order=4&q=DNS%E8%A7%A3%E6%9E%90&zhida_source=entity">DNS解析</a>的流程。</p>
<p>当然TTL值失效后，系统还会自动再次询问DNS服务器以获取最新的解析结果。</p>
<h4 id="DNS-污染"><a href="#DNS-污染" class="headerlink" title="DNS 污染"></a>DNS 污染</h4><p>在中国大陆，对所有经过<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%98%B2%E7%81%AB%E9%95%B7%E5%9F%8E">防火长城</a>（英语：Great Firewall，常用简称：GFW）的在<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%8D%8F%E8%AE%AE">UDP</a>的53<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%80%9A%E4%BF%A1%E7%AB%AF%E5%8F%A3">端口</a>上的域名查询进行IDS<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%85%A5%E4%BE%B5%E6%A3%80%E6%B5%8B">入侵检测</a>，一经发现与黑名单关键词相匹配的域名查询请求，会马上伪装成目标解析服务器注入伪造的查询结果。攻击仅出现在DNS查询之路由经过防火长城时。伪造的查询结果中的IP地址不是一成不变的，在一段时间后会更新。</p>
<p>对于TCP协议下的域名查询，防火长城可使用<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/TCP%E9%87%8D%E7%BD%AE%E6%94%BB%E5%87%BB">TCP重置攻击</a>的方法进行干扰。</p>
<blockquote>
<p>重置（reset）是<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE">传输控制协议</a>（TCP）的一种消息，例如服务器端在没有客户端请求的端口或者其它连接信息不符时，系统的TCP协议栈就会给客户端回复一个重置通知消息，该功能本来用于应对例如服务器意外重启等情况，而防火长城阻止TCP连接的技术实际上就是比连接双方更快地发送连接重置消息，使连接双方以为对方终止了连接[<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%98%B2%E7%81%AB%E9%95%BF%E5%9F%8E#cite_note-clayton2006-66">65]</a>。</p>
</blockquote>
<h1 id="动态主机配置协议（DHCP）"><a href="#动态主机配置协议（DHCP）" class="headerlink" title="动态主机配置协议（DHCP）"></a>动态主机配置协议（DHCP）</h1><p>Dynamic Host Configuration Protocol based on <code>UDP</code> port <code>68</code> for <code>client</code>, <code>67</code> for <code>server</code></p>
<p>采用C/S通信模式，由客户端（DHCP Client）向服务器（DHCP Server）提出配置申请</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/L4%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82.assets/image-20241129172615802.png" alt="image-20241129172615802"></p>
<h2 id="报文格式"><a href="#报文格式" class="headerlink" title="报文格式"></a><a target="_blank" rel="noopener" href="https://blog.csdn.net/scanf_linux/article/details/89415965#t2">报文格式</a></h2><p><strong>dhcp offer</strong>:</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/L4%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82.assets/image-20241129175130504.png" alt="image-20241129175130504"></p>
<ul>
<li>Relay Agent 中继</li>
<li>Next Server 其他DHCP服务器</li>
<li>Client MAC Address 之前 Discover含有 客户端的MAC地址</li>
<li>bootp flags unicast 单播</li>
</ul>
<p><strong>dhcp offer:</strong></p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/L4%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82.assets/image-20241129175445723.png" alt="image-20241129175445723"></p>
<h2 id="分配IP"><a href="#分配IP" class="headerlink" title="分配IP"></a>分配IP</h2><p>  <strong>内网 使用DHCP协议</strong></p>
<ul>
<li><p>首次接入网络的DHCP客户端不知道DHCP服务器的<a target="_blank" rel="noopener" href="https://info.support.huawei.com/info-finder/encyclopedia/zh/IPv4.html">IP地址</a>，为了学习到DHCP服务器的IP地址，DHCP客户端以广播方式发送<code>DHCP DISCOVER</code>报文（目的IP地址为255.255.255.255）给同一网段内的所有设备（包括DHCP服务器或中继）。<code>DHCP DISCOVER</code>报文中携带了客户端的MAC地址（<a target="_blank" rel="noopener" href="https://support.huawei.com/hedex/pages/EDOC1100087046AZJ0324D/10/EDOC1100087046AZJ0324D/10/resources/dc/dc_cfg_dhcp_6005.html#ZH-CN_CONCEPT_0176371535__c1">chaddr字段</a>）、需要请求的参数列表选项（<a target="_blank" rel="noopener" href="https://support.huawei.com/hedex/pages/EDOC1100087046AZJ0324D/10/EDOC1100087046AZJ0324D/10/resources/dc/dc_cfg_dhcp_6005.html#ZH-CN_CONCEPT_0176371535__op55">Option55</a>）、广播标志位（<a target="_blank" rel="noopener" href="https://support.huawei.com/hedex/pages/EDOC1100087046AZJ0324D/10/EDOC1100087046AZJ0324D/10/resources/dc/dc_cfg_dhcp_6005.html#ZH-CN_CONCEPT_0176371535__f1">flags字段</a>）等信息。源IP 地址0.0.0.0   目的IP:255.255.255.255</p>
</li>
<li><p>某个（可能有多个服务器）DHCP服务器A监听到了DHCP请求，能够<strong>动态</strong>管理自己的IP池，通过<code>DHCP Offer</code>给计算机分配IP地址和默认网关（用于访问外部地址）以及子网掩码和<strong>DNS</strong>、租约信息，注意并不一定要全部提供。源IP为DHCP服务器的IP  目的IP:分配给客户端的IP，里面也有客户端的MAC地址。</p>
</li>
<li><p>设备收到以后会正式提出租用请求，<code>DHCP Request</code>，源IP为0.0.0.0  目的IP:255.255.255.255，==广播==形式可以告诉其他可能存在的DHCP服务器已经向DHCP服务器A提出租用请求，。</p>
</li>
<li><p>路由器收到以后发送<code>DHCP ACK</code>，确认分配并连接成功。源IP为DHCP服务器的IP  目的IP:分配给</p>
</li>
<li><p>客户端收到<code>DHCP ACK</code>报文，会广播发送<a target="_blank" rel="noopener" href="https://info.support.huawei.com/info-finder/encyclopedia/zh/ARP.html">免费ARP</a>报文，探测本网段是否有其他终端使用服务器分配的IP地址，如果在指定时间内没有收到回应，表示客户端可以使用此地址。如果收到了回应，说明有其他终端使用了此地址，客户端会向服务器发送<code>DHCP DECLINE</code>报文，并重新向服务器请求IP地址，同时，服务器会将此地址列为冲突地址。当服务器没有空闲地址可分配时，再选择冲突地址进行分配，尽量减少分配出去的地址冲突。</p>
</li>
<li><p>设备使用某个IP地址的时间有限，==单播==发送<code>DHCP Request</code>报文进行续约，如果收到<code>DHCP NAK</code>报文说明续租失败；如果到时间如果设备不再续用发送<code>DHCP Release</code>报文进行释放，DHCP服务器会回收，设备收到<code>DHCP</code>。某些设备可能需要为静态的IP，这个可以通过MAC绑定也可以手动配置。</p>
</li>
</ul>
<p><strong>宽带</strong>：</p>
<ul>
<li><p><strong>静态IP</strong>：根据运营商提供的静态IP，子网掩码，网关，DNS手动配置，是固定的IP。</p>
</li>
<li><p><strong>动态DHCP</strong> ：自动从ISP获取IP地址等网络配置信息。</p>
</li>
<li><p><strong>ADSL虚拟拨号</strong> ：使用PPPoE协议向运营商动态租用（PPPoE提供了身份验证功能，也就是宽带账号)。</p>
</li>
</ul>
<h2 id="典型场景"><a href="#典型场景" class="headerlink" title="典型场景"></a>典型场景</h2><ol>
<li><p>路由器从运营商的网络获取一个公网IP地址（通过运营商的DHCP服务器分配）。</p>
</li>
<li><p>路由器在局域网内充当DHCP服务器，为局域网设备分配私有IP地址（如192.168.0.x）。</p>
</li>
</ol>
<h2 id="RARP-协议"><a href="#RARP-协议" class="headerlink" title="RARP 协议"></a>RARP 协议</h2><p>RARP（反向地址转换协议，Reverse Address Resolution Protocol）是局域网的物理机器从网关服务器的ARP表或者缓存上根据MAC地址请求IP地址的协议。它的功能与ARP协议相反。</p>
<ol>
<li><strong>请求IP地址</strong>：当局域网中的某个物理机器只知道自己的MAC地址而不知道IP地址时，它可以通过RARP协议向RARP服务器发送一个请求，请求分配一个IP地址。</li>
<li><strong>服务器响应</strong>：RARP服务器在收到请求后，会查找其RARP列表或ARP表，查找该MAC地址对应的IP地址。如果找到匹配的MAC地址，RARP服务器就会将对应的IP地址发送给请求者。</li>
<li><strong>获取IP地址并通信</strong>：请求者在收到RARP服务器的响应后，就可以利用得到的IP地址进行网络通信。</li>
</ol>
<p><strong>RARP</strong>（Reverse Address Resolution Protocol）和<strong>DHCP</strong>（Dynamic Host Configuration Protocol）是两种网络协议，它们都可以为某个刚接入网络的设备提供IP地址以实现互联通信。区别主要有以下几点：</p>
<ol>
<li>RARP是数据链路层的协议，无法跨路由器和网段工作，每个本地网络都必须配置一台RARP服务器；而DHCP属于应用层协议，可以跨路由器和网段工作，因此多个网段可以共享同一个DHCP服务器。</li>
<li>RARP协议中，必须提前在RAPR服务器中手工配置好MAC地址和IP地址之间的映射；而DHCP允许动态的分配IP，更适应当前网络的需求。</li>
<li>RARP协议仅仅是分配IP地址，而DHCP协议不仅提供IP地址，还提供其他网络配置信息，如子网掩码、网关、DNS服务器</li>
</ol>
<h1 id="万维网（WWW）"><a href="#万维网（WWW）" class="headerlink" title="万维网（WWW）"></a>万维网（WWW）</h1><p>World Wide Web</p>
<h2 id="超文本传输协议（HTTP）"><a href="#超文本传输协议（HTTP）" class="headerlink" title="超文本传输协议（HTTP）"></a>超文本传输协议（HTTP）</h2><p><strong>HyperText Transfer Protocol</strong> based on TCP port 80</p>
<p>TCP/IP 协议四层架构的最上层 规定了服务器和浏览器之间传输数据的规则</p>
<p><a target="_blank" rel="noopener" href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP">HTTP | MDN (mozilla.org)</a></p>
<p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%B6%85%E6%96%87%E6%9C%AC%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE">超文本传输协议 - 维基百科，自由的百科全书 (wikipedia.org)</a> </p>
<h3 id="超文本"><a href="#超文本" class="headerlink" title="超文本"></a>超文本</h3><h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ul>
<li>基于TCP，面向连接，安全</li>
<li>基于请求-响应模型：1Request1Response</li>
<li>HTTP是无状态协议，对事务处理没有记忆能力，每次RR都是独立的<ul>
<li>多次请求之间不能共享数据，用会话技术（cookie session）解决这个问题</li>
<li>优点：速度快</li>
</ul>
</li>
</ul>
<p>HTTP 协议基于 TCP 协议，发送 HTTP 请求之前首先要建立 TCP 连接也就是要经历 3 次握手。目前使用的 HTTP 协议大部分都是 1.1。在 1.1 的协议里面，默认是开启了 Keep-Alive 的，这样的话建立的连接就可以在多次请求中被复用了。</p>
<h3 id="请求数据"><a href="#请求数据" class="headerlink" title="请求数据"></a>请求数据</h3><p><strong>请求行</strong>：第一行，<code>GET</code>(请求方式) 后面的<code>/</code>表示请求资源的路径，HTTP/1.1表示协议版本</p>
<p><strong>请求头</strong>：第二行开始 key: value形式</p>
<p><strong>请求体</strong>：POST请求的最后一部分，存放请求参数</p>
<p>GET请求参数在请求行中，没有请求体，参数大小有限制(URL长度限制) POST请求的参数在请求体中，参数大小无限制</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/L4%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82.assets/image-20240926220614547.png" alt="image-20240926220614547"></p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/L4%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82.assets/image-20240926221417729.png" alt="image-20240926221417729"></p>
<p><strong>Host</strong>: 请求的主机名</p>
<p><strong>User-Agent</strong>: 浏览器版本</p>
<p><strong>Accept</strong>: 浏览器能接受的资源类型，如text/* image/* */* </p>
<p><strong>Accept-Language</strong>: 浏览器的偏好语言</p>
<p><strong>Accept-Encoding</strong>: 浏览器支持的压缩类型</p>
<h3 id="响应数据"><a href="#响应数据" class="headerlink" title="响应数据"></a>响应数据</h3><p><strong>响应行</strong>：响应数据的第一行，HTTP/1.1表示协议版本，下一个是响应状态码，OK表示状态码描述</p>
<p><strong>响应头</strong>：key value</p>
<p><strong>响应体</strong>：最后一部分，存放响应数据</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/L4%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82.assets/image-20240926221630980.png" alt="image-20240926221630980"></p>
<p><strong>Content-Type</strong>：响应内容类型，比如text/html image/jpeg</p>
<p><strong>Content-Length</strong>：响应内容长度（bytes）</p>
<p><strong>Content-Encoding</strong>：响应压缩算法 gzip等</p>
<p><strong>Cache-Control</strong>: 指示客户端如何缓存，例如max-age=300 表示最多缓存300s</p>
<h4 id="状态码"><a href="#状态码" class="headerlink" title="状态码"></a>状态码</h4><p><a target="_blank" rel="noopener" href="https://javaguide.cn/cs-basics/network/http-status-codes.html">HTTP 常见状态码总结（应用层） | JavaGuide</a> </p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/L4%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82.assets/image-20240926222005460.png" alt="image-20240926222005460"></p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/L4%EF%BC%9A%E5%BA%94%E7%94%A8%E5%B1%82.assets/image-20240926222320894.png" alt="image-20240926222320894"></p>
<p>200 OK 404资源不存在 500 服务器异常</p>
<p>Java程序中，如果直接用自带的javawebsocketAPI 代码会变得异常繁琐，要注意请求和响应的格式要求，因此要用web服务器软件进行开发—-Tomcat</p>
<h3 id="其他特性"><a href="#其他特性" class="headerlink" title="其他特性"></a>其他特性</h3><h4 id="HTTP-缓存"><a href="#HTTP-缓存" class="headerlink" title="HTTP 缓存"></a>HTTP 缓存</h4><p>cache-control 强缓存</p>
<p>还有在协商缓存：条件get，Etag与modified同理，优先级高于modified</p>
<ul>
<li>服务器响应中带上Last-Modified:x </li>
<li>客户端下次请求就带上If-Modified-Since:x</li>
<li>如果服务器看没有过期，回复一个HTTP 304 允许使用缓存，过期了就回复HTTP 200把新的数据发过来。</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://xiaolincoding.com/network/2_http/http_interview.html#http-%E7%BC%93%E5%AD%98%E6%8A%80%E6%9C%AF">HTTP 缓存 - 小林 coding</a>  </p>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/network/http/http%E7%BC%93%E5%AD%98.png" alt="img"></p>
<h4 id="HTTPS"><a href="#HTTPS" class="headerlink" title="HTTPS"></a>HTTPS</h4><p><a target="_blank" rel="noopener" href="https://javaguide.cn/cs-basics/network/http-vs-https.html">HTTP vs HTTPS（应用层） | JavaGuide</a> </p>
<h4 id="HTTP-1-0-到-HTTP-3"><a href="#HTTP-1-0-到-HTTP-3" class="headerlink" title="HTTP/1.0 到 HTTP/3"></a>HTTP/1.0 到 HTTP/3</h4><p><a target="_blank" rel="noopener" href="https://javaguide.cn/cs-basics/network/http1.0-vs-http1.1.html">HTTP 1.0 vs HTTP 1.1（应用层） | JavaGuide</a> </p>
<p><strong>HTTP/1.1 长连接/持续连接默认开启</strong> </p>
<ul>
<li><p>每个请求的时延都要算上额外的 TCP 握手所占用的 1 RTT</p>
</li>
<li><p>维护 TCP 连接的各种缓存和变量都需要占用资源</p>
</li>
<li><p>长连接，会复用一个 TCP 连接</p>
</li>
</ul>
<p><strong>HTTP</strong>/<strong>2</strong></p>
<p><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1573513">白话http2的多路复用-腾讯云开发者社区-腾讯云</a></p>
<ul>
<li><p>封装成帧，二进制编码</p>
<ul>
<li>将一个帧分为数据帧和头帧，将HttpHeader中的重复出现的部分进行编码，取代之前的ASCII文本编码，也就是压缩了头部称为头帧。</li>
<li>并且帧有编号，帧与帧之间可以乱序传输，减轻队头阻塞</li>
</ul>
</li>
<li><p><img src="https://ask.qcloudimg.com/http-save/yehe-5837318/qsm44wuriu.jpeg" alt="img"></p>
</li>
<li><p>全双工通信</p>
<ul>
<li>浏览器针对同一个域名的资源，只建立一个tcp连接通道，所有的针对这个域名的请求全部在这个通道中完成，并且引入了流的机制，这条通道可以同时处理多个request，这不同于http1.1的pepeline，http2的多路复用，对于request的响应并不会因为上一个request的响应未完成而阻塞</li>
<li>HTTP 1,1 Pipeline 虽然在一个tcp通道中实现了多个http并发，但是返回的时候是会阻塞的，谁先到达，谁先返回，顺序绝对不能乱，这就是http1.1pipeline的弊端。还有另一个pipeline的限制，只能是幂等请求（get、head等）才能应用pipeline，大部分浏览器默认是关闭pipeline的。</li>
</ul>
</li>
<li><p>服务器推和响应优先级</p>
<ul>
<li>HTTP1.1对于连续多个请求可能会开启并行的多个TCP连接，用来提高发送的效率</li>
<li>服务器根据HTML的内容解析需要发送哪些内容，在接收到HTTP请求</li>
</ul>
</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://xiaolincoding.com/network/2_http/http_interview.html#http-1-1%E3%80%81http-2%E3%80%81http-3-%E6%BC%94%E5%8F%98">HTTP/1.1、HTTP/2、HTTP/3 演变 - 小林 coding</a> </p>
<h2 id="WebSocket"><a href="#WebSocket" class="headerlink" title="WebSocket"></a><a target="_blank" rel="noopener" href="https://xiaolincoding.com/network/2_http/http_websocket.html">WebSocket</a></h2><p>WebSocket 是一种基于 TCP 连接的全双工通信协议，即客户端和服务器可以同时发送和接收数据。</p>
<p>WebSocket 协议在 2008 年诞生，2011 年成为国际标准，几乎所有主流较新版本的浏览器都支持该协议。不过，WebSocket 不只能在基于浏览器的应用程序中使用，很多编程语言、框架和服务器都提供了 WebSocket 支持。</p>
<p>WebSocket 协议本质上是应用层的协议，用于弥补 HTTP 协议在持久通信能力上的不足。客户端和服务器仅需一次握手，两者之间就直接可以创建持久性的连接，并进行双向数据传输。</p>
<p><img src="https://oss.javaguide.cn/github/javaguide/system-design/web-real-time-message-push/1460000042192394.png" alt="Websocket 示意图"></p>
<p>下面是 WebSocket 的常见应用场景：</p>
<ul>
<li>视频弹幕</li>
<li>实时消息推送，详见<a target="_blank" rel="noopener" href="https://javaguide.cn/system-design/web-real-time-message-push.html">Web 实时消息推送详解</a>这篇文章</li>
<li>实时游戏对战</li>
<li>多用户协同编辑</li>
<li>社交聊天</li>
<li>……</li>
</ul>
<p>WebSocket 的工作过程可以分为以下几个步骤：</p>
<ol>
<li>客户端向服务器发送一个 HTTP 请求，请求头中包含 <code>Upgrade: websocket</code> 和 <code>Sec-WebSocket-Key</code> 等字段，表示要求升级协议为 WebSocket；</li>
<li>服务器收到这个请求后，会进行升级协议的操作，如果支持 WebSocket，它将回复一个 HTTP 101 状态码，响应头中包含 ，<code>Connection: Upgrade</code>和 <code>Sec-WebSocket-Accept: xxx</code> 等字段、表示成功升级到 WebSocket 协议。</li>
<li>客户端和服务器之间建立了一个 WebSocket 连接，可以进行双向的数据传输。数据以帧（frames）的形式进行传送，WebSocket 的每条消息可能会被切分成多个数据帧（最小单位）。发送端会将消息切割成多个帧发送给接收端，接收端接收消息帧，并将关联的帧重新组装成完整的消息。</li>
<li>客户端或服务器可以主动发送一个关闭帧，表示要断开连接。另一方收到后，也会回复一个关闭帧，然后双方关闭 TCP 连接。</li>
</ol>
<p>另外，建立 WebSocket 连接之后，通过心跳机制来保持 WebSocket 连接的稳定性和活跃性。</p>
<h2 id="内容分发网络（CDN）"><a href="#内容分发网络（CDN）" class="headerlink" title="内容分发网络（CDN）"></a>内容分发网络（CDN）</h2><p><strong>Content Distribution Network</strong></p>
<p><strong>push</strong>： 源服务器将内容推送给CDN</p>
<p><strong>pull</strong>：CDN遇到自己没有的资源就从源服务器pull过来</p>
<p><strong>anycast</strong>: 任播，与DNS服务器类似，很多CDN具有相同的IP地址，可以负载均衡。</p>
<p>CDN所需要的节点数量随着需求而不同，依照所需要服务的对象大小，有可能有数万台服务器。</p>
<p>服务器的运作方式一般是基于<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/Nginx">nginx</a>的模式，通过HTTP头的Host字段等方式区分服务域名来提供HTTP服务。不过，随着2017年世界各地CDN服务商纷纷推出<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/HTTPS">HTTPS</a>加速功能，运作方式也变得略有不同，变成了nginx+<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%90%8D%E7%A7%B0%E6%8C%87%E7%A4%BA">SNI</a>模式，同一个CDN节点上可以借此机制绑定多个域名而为不同域名提供HTTPS服务。同时，<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/BGP">BGP</a>的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/Anycast">anycast</a>技术也逐渐引入了CDN领域中。</p>
<p>P2P CDN(PCDN)：用户自愿以PC或专用设备利用闲置上行带宽充当CDN缓存节点</p>
<h1 id="进程间通信（IPC）"><a href="#进程间通信（IPC）" class="headerlink" title="进程间通信（IPC）"></a>进程间通信（IPC）</h1><p><a target="_blank" rel="noopener" href="https://xiaolincoding.com/network/2_http/http_rpc.html">既然有 HTTP 协议，为什么还要有 RPC？</a> </p>
<h1 id="P2P"><a href="#P2P" class="headerlink" title="P2P"></a>P2P</h1><h1 id="文件传送协议（FTP）"><a href="#文件传送协议（FTP）" class="headerlink" title="文件传送协议（FTP）"></a><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE">文件传送协议（FTP）</a></h1><p><strong>FTP 协议</strong> 基于 TCP 协议，是一种用于在计算机之间传输文件的协议，可以屏蔽操作系统和文件存储方式。</p>
<p>FTP 是基于客户—服务器（C/S）模型而设计的，在客户端与 FTP 服务器之间建立两个连接。如果我们要基于 FTP 协议开发一个文件传输的软件的话，首先需要搞清楚 FTP 的原理。关于 FTP 的原理，很多书籍上已经描述的非常详细了：</p>
<blockquote>
<p>FTP 的独特的优势同时也是与其它客户服务器程序最大的不同点就在于它在两台通信的主机之间使用了两条 TCP 连接（其它客户服务器应用程序一般只有一条 TCP 连接）：</p>
<ol>
<li>控制连接：用于传送控制信息（命令和响应）</li>
<li>数据连接：用于数据传送；</li>
</ol>
<p>这种将命令和数据分开传送的思想大大提高了 FTP 的效率。</p>
</blockquote>
<p><img src="https://oss.javaguide.cn/github/javaguide/cs-basics/network/ftp.png" alt="FTP工作过程">FTP工作过程</p>
<p>注意 ：FTP 是一种不安全的协议，因为它在传输过程中不会对数据进行加密。因此，FTP 传输的文件可能会被窃听或篡改。建议在传输敏感数据时使用更安全的协议，如 SFTP（SSH File Transfer Protocol，一种基于 SSH 协议的安全文件传输协议，用于在网络上安全地传输文件）。</p>
<h1 id="电子邮件"><a href="#电子邮件" class="headerlink" title="电子邮件"></a>电子邮件</h1><h2 id="SMTP"><a href="#SMTP" class="headerlink" title="SMTP"></a><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%AE%80%E5%8D%95%E9%82%AE%E4%BB%B6%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE#%E7%9B%B8%E5%85%B3_RFC">SMTP</a></h2><p><strong>简单邮件传输(发送)协议（SMTP，Simple Mail Transfer Protocol）</strong> 基于 TCP 协议，是一种用于发送电子邮件的协议</p>
<p><img src="https://oss.javaguide.cn/github/javaguide/cs-basics/network/what-is-smtp.png" alt="SMTP 协议">SMTP 协议</p>
<p>注意 ⚠️：<strong>接受邮件的协议不是 SMTP 而是 POP3 协议。</strong></p>
<p>SMTP 协议这块涉及的内容比较多，下面这两个问题比较重要：</p>
<ol>
<li>电子邮件的发送过程</li>
<li>如何判断邮箱是真正存在的？</li>
</ol>
<p><strong>电子邮件的发送过程？</strong></p>
<p>比如我的邮箱是“<a href="mailto:dabai@cszhinan.com">dabai@cszhinan.com</a>”，我要向“<a href="mailto:xiaoma@qq.com">xiaoma@qq.com</a>”发送邮件，整个过程可以简单分为下面几步：</p>
<ol>
<li>通过 <strong>SMTP</strong> 协议，我将我写好的邮件交给 163 邮箱服务器（邮局）。</li>
<li>163 邮箱服务器发现我发送的邮箱是 qq 邮箱，然后它使用 SMTP 协议将我的邮件转发到 qq 邮箱服务器。</li>
<li>qq 邮箱服务器接收邮件之后就通知邮箱为“<a href="mailto:xiaoma@qq.com">xiaoma@qq.com</a>”的用户来收邮件，然后用户就通过 <strong>POP3/IMAP</strong> 协议将邮件取出。</li>
</ol>
<p><strong>如何判断邮箱是真正存在的？</strong></p>
<p>很多场景(比如邮件营销)下面我们需要判断我们要发送的邮箱地址是否真的存在，这个时候我们可以利用 SMTP 协议来检测：</p>
<ol>
<li>查找邮箱域名对应的 SMTP 服务器地址</li>
<li>尝试与服务器建立连接</li>
<li>连接成功后尝试向需要验证的邮箱发送邮件</li>
<li>根据返回结果判定邮箱地址的真实性</li>
</ol>
<p>推荐几个在线邮箱是否有效检测工具：</p>
<ol>
<li><a target="_blank" rel="noopener" href="https://verify-email.org/">https://verify-email.org/</a></li>
<li><a target="_blank" rel="noopener" href="http://tool.chacuo.net/mailverify">http://tool.chacuo.net/mailverify</a></li>
<li><a target="_blank" rel="noopener" href="https://www.emailcamel.com/">https://www.emailcamel.com/</a></li>
</ol>
<h2 id="IMAP-POP3"><a href="#IMAP-POP3" class="headerlink" title="IMAP/POP3"></a><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%9B%A0%E7%89%B9%E7%BD%91%E4%BF%A1%E6%81%AF%E8%AE%BF%E9%97%AE%E5%8D%8F%E8%AE%AE">IMAP</a>/<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%83%B5%E5%B1%80%E5%8D%94%E5%AE%9A">POP3</a></h2><p>这两个协议没必要多做阐述，只需要了解 <strong>POP3 和 IMAP 两者都是负责邮件接收的协议</strong> 即可（二者也是基于 TCP 协议）。另外，需要注意不要将这两者和 SMTP 协议搞混淆了。<strong>SMTP 协议只负责邮件的发送，真正负责接收的协议是 POP3/IMAP。</strong></p>
<p>IMAP 协议是比 POP3 更新的协议，它在功能和性能上都更加强大。IMAP 支持邮件搜索、标记、分类、归档等高级功能，而且可以在多个设备之间同步邮件状态。几乎所有现代电子邮件客户端和服务器都支持 IMAP。</p>
<h2 id="E-mail-on-WWW"><a href="#E-mail-on-WWW" class="headerlink" title="E-mail on WWW"></a>E-mail on WWW</h2><h2 id="MIME"><a href="#MIME" class="headerlink" title="MIME"></a>MIME</h2><p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%BA%92%E8%81%94%E7%BD%91%E5%AA%92%E4%BD%93%E7%B1%BB%E5%9E%8B">MIME</a>改善了由 <a target="_blank" rel="noopener" href="https://tools.ietf.org/html/rfc822">RFC 822</a> 转变而来的 <a target="_blank" rel="noopener" href="https://tools.ietf.org/html/rfc2822">RFC 2822</a> ，这些旧标准规定<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%9B%BB%E5%AD%90%E9%83%B5%E4%BB%B6">电子邮件</a>标准并不允许在邮件消息中使用7位ASCII字符集以外的字符。正因如此，一些非英语字符消息和二进制文件，图像，声音等非文字消息原本都不能在电子邮件中传输（MIME可以）。MIME规定了用于表示各种各样的数据类型的符号化方法。此外，在<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%B8%87%E7%BB%B4%E7%BD%91">万维网</a>中使用的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/HTTP">HTTP协议</a>中也使用了MIME的框架，标准被扩展为<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%BA%92%E8%81%94%E7%BD%91%E5%AA%92%E4%BD%93%E7%B1%BB%E5%9E%8B">互联网媒体形式</a>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Content-Type: [type]/[subtype]; parameter</span><br></pre></td></tr></table></figure>

<h1 id="Telnet-amp-SSH"><a href="#Telnet-amp-SSH" class="headerlink" title="Telnet &amp; SSH"></a>Telnet &amp; SSH</h1><p><strong><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/Telnet">Telnet</a> 协议</strong> 基于 TCP 协议，用于通过一个终端登陆到其他服务器。Telnet 协议的最大缺点之一是所有数据（包括用户名和密码）均以明文形式发送，这有潜在的安全风险。这就是为什么如今很少使用 Telnet，而是使用一种称为 SSH 的非常安全的网络传输协议的主要原因。</p>
<p><img src="https://oss.javaguide.cn/github/javaguide/cs-basics/network/Telnet_is_vulnerable_to_eavesdropping-2.png" alt="Telnet:远程登陆协议"></p>
<p><strong><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/Secure_Shell">SSH</a> （Secure Shell）</strong> 基于 TCP 协议，通过加密和认证机制实现安全的访问和文件传输等业务。</p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV13P4y1o76u">SSH 握手详解 - bilibili 技术蛋老师</a> </p>
<p>SSH 的经典用途是登录到远程电脑中执行命令。除此之外，SSH 也支持隧道协议、端口映射和 X11 连接（允许用户在本地运行远程服务器上的图形应用程序）。借助 SFTP（SSH File Transfer Protocol） 或 SCP（Secure Copy Protocol） 协议，SSH 还可以安全传输文件。</p>
<p>SSH 使用客户端-服务器模型，默认端口是 22。SSH 是一个守护进程，负责实时监听客户端请求，并进行处理。大多数现代操作系统都提供了 SSH。</p>
<p>如下图所示，SSH Client（SSH 客户端）和 SSH Server（SSH 服务器）通过公钥交换生成共享的对称加密密钥，用于后续的加密通信。</p>
<p><img src="https://oss.javaguide.cn/github/javaguide/cs-basics/network/ssh-client-server.png" alt="SSH:安全的网络传输协议"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://scatteredream.github.io/2025/01/13/%E7%89%A9%E8%81%94%E7%BD%91%E8%A1%8C%E4%B8%9A%E6%A6%82%E5%86%B5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars.githubusercontent.com/u/62317679?s=400&v=4">
      <meta itemprop="name" content="碎梦">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="scatteredream's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | scatteredream's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/01/13/%E7%89%A9%E8%81%94%E7%BD%91%E8%A1%8C%E4%B8%9A%E6%A6%82%E5%86%B5/" class="post-title-link" itemprop="url">物联网就业</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-01-13 00:00:00" itemprop="dateCreated datePublished" datetime="2025-01-13T00:00:00+08:00">2025-01-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-05-03 22:46:01" itemprop="dateModified" datetime="2025-05-03T22:46:01+08:00">2025-05-03</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="物联网"><a href="#物联网" class="headerlink" title="物联网"></a>物联网</h1><ul>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/331782286">物联网专业好就业吗？ - 知乎 (zhihu.com)</a></li>
</ul>
<p>物联网行业很有前景，但不代表<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E7%89%A9%E8%81%94%E7%BD%91%E4%B8%93%E4%B8%9A&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2767766898%7D">物联网专业</a>好，两者不是一码事。</p>
<p>从实际情况看，物联网不应该也没办法成为一个具体的专业。</p>
<p>物联网涵盖的内容太多，许多大学在本科开设物联网专业确实有点坑。</p>
<p>物联网和人工智能和金融很像，没有具体的、统一的概念，没有具体的指向。就像一个金融业人士自我介绍，如果是对非业内人士一般就说我是做金融的，对业内人士一般会说我是做量化的、做风头的、做<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E7%A7%81%E5%8B%9F&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:%223041148568%22%7D">私募</a>的、做基金的、做行研的、做柜员的、做大堂经理、做理财的、做风控的……</p>
<p>人工智能也是这样，对非业内人士一般就说我是做人工智能的的，对业内人士一般会说做<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E7%AE%97%E6%B3%95%E4%BC%98%E5%8C%96&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2767766898%7D">算法优化</a>、做<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E8%BF%90%E7%AD%B9%E6%8E%A7%E5%88%B6&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2632452604%7D">运筹控制</a>、做计算机<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2915052959%7D">神经网络</a>、做<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2632452604%7D">自然语言处理</a>（比如语言识别、自动翻译）、做机器学习（深度学习）、做<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%BD%B1%E5%83%8F%E5%AD%A6&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2632452604%7D">计算机影像学</a>（比如人脸、虹膜和指纹识别）……</p>
<p>物联网也是如此，对非业内人士一般就说我是做物联网的，对业内人士一般会说做<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%BC%80%E5%8F%91&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2767766898%7D">嵌入式开发</a>、做信号处理、做传感技术、做<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2767766898%7D">网络技术</a>、做RFID技术……</p>
<p>所以物联网能包含的范围太大，而且作为一项新兴科技是不断变化和延伸的，根本不是固有的、静态的。以上任何一个方向、岗位都是博大精深探索无止境的，跟很多岗位都是有密切关系的，很多专业都可以从事的。</p>
<p>所以这些工作根本不是你学了物联网就可以做的，学物联网和做物联网是两码事，学很多专业都可以做物联网，学物联网的反而因为学的多而杂不知道怎么定位自己了。比如你学<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E7%94%B5%E5%AD%90%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2632452604%7D">电子科学与技术</a>、<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E7%94%B5%E5%AD%90%E4%BF%A1%E6%81%AF%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2632452604%7D">电子信息科学与技术</a>、<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E7%BD%91%E7%BB%9C%E5%B7%A5%E7%A8%8B&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2632452604%7D">网络工程</a>、嵌入式开发、<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2915052959%7D">信息工程</a>（信息技术）、<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E7%94%B5%E5%AD%90%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2915052959%7D">电子信息工程</a>、电波传导和天线、<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E7%94%B5%E7%A3%81%E5%9C%BA%E4%B8%8E%E6%97%A0%E7%BA%BF%E6%8A%80%E6%9C%AF&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2632452604%7D">电磁场与无线技术</a>、自动化都可以从事物联网相关工作，毕竟物联网的范围太大了，涉及的专业、行业、岗位、工种太多了。</p>
<p>一些儿可行性建议：</p>
<p><strong>1.明确正确的技术观</strong>，物联网是一个行业，而不是一个专业。学好物联网里任何一项技术，都可以独当一面，迅速实现个人<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E4%BB%B7%E5%80%BC%E7%A7%AF%E7%B4%AF&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:3024228794%7D">价值积累</a>。如果贪多贪快，除了给自己带来无尽的失望和打击，没什么好处。</p>
<p><strong>2.明确正确的发展方向</strong>，物联网涉及软硬件、互联网、App等多个领域，作为个人而言，只可能精其一样。如果是做硬件，那就好好学数电模电、<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E5%BA%94%E7%94%A8%E7%94%B5%E8%B7%AF&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:3024228794%7D">应用电路</a>、布线画板、传感器特性等等。如果是做软件，明确方向，一般建议本科阶段学好<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E5%8D%95%E7%89%87%E6%9C%BA&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2915052959%7D">单片机</a>编程、熟悉一两种传感器或应用，做一两款小产品即可。毕业后，可逐步过渡，学会和其他工程师配合，学会<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E7%BB%84%E7%BD%91&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:3024228794%7D">组网</a>应用，多出作品练手。</p>
<p><strong>3.实践大于理论</strong>，学物联网或者嵌入式一定要勤上手，多出作品。多出作品，不仅可以增长技术能力、了解物联网构架，最重要的是可以提高自信心。人与人的区别，大部分都在教育，而教育成功与否，自信是非常重要的评估法则。当然，由于物联网一般都是系统产品，建议学习者可以基于成熟的构架去做产品，这样容易成功做出完整产品。</p>
<p><strong>4.毕业后，尽量不要去初创公司</strong>，一定要去中型企业或大企业的核心团队，哪怕打杂都行。无论未来是打算做市场还是做技术，一定要记得毕业招工作的时候，要想办法进企业的核心研发团队，大公司进不了，就进小一点的，再进不了，就再小一点。可能有人会问，人家不一定要我啊。对，人家不一定要你，你本科期间作出的物联网作品，就是敲门砖。</p>
<p><strong>5. 就业后，不要急于成功，闷下心思，跟着团队技术带头人做技术</strong>。有什么做什么，尽多培养不同领域的应用，多结实靠谱的技术朋友。三五年后，某一天，你会发现你自己有技术、有团队，可以做任何产品的时候，你的路也会宽阔起来。</p>
<p>人才有两种，一种是<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E5%BA%94%E7%94%A8%E5%9E%8B%E4%BA%BA%E6%89%8D&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2767766898%7D">应用型人才</a>，把各种技术结合起来，组装成一样东西解决某个问题：例如硬件方面，第一境界是使用各种模块接线；第二境界是使用万用板自己焊接；第三境界是自己画电路图和PCB图打板；软件方面，第一境界，抄别人的代码；第二境界，移植别人的代码然后修改；第三境界，调用库的代码，如果没有就抄；第四境界，熟知各种库的API，自己写代码；应用型人才找工作是最方便的，大公司小公司都会要，只要老板请你做并你愿意做，就会给你开工资。</p>
<p>第二种是是理论型人才，理论知识非常强，数学非常棒，使用<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E4%BB%BF%E7%9C%9F%E8%BD%AF%E4%BB%B6&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2767766898%7D">仿真软件</a>验证了一遍，还会拿纸和笔自己再算一遍。一般这样人才不是考研就是去国企等大型企业或<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E7%A0%94%E7%A9%B6%E6%89%80&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2915052959%7D">研究所</a>从事理论性非常强的工作，比如算法、 <a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E9%AB%98%E9%A2%91%E7%94%B5%E8%B7%AF&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:3019505700%7D">高频电路</a>、芯片研发、<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2632452604%7D">信号处理</a>等。</p>
<p>物联网的真正技术，大学是学不完的，它是一个庞大的体系，研究生的话会细分方向，让你更加清晰自己在做什么。大学学习的大多数理论知识，一定要私下多多学点儿东西，没有坏处。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/551003511">物联网工程以后就业前景怎么样? - 知乎 (zhihu.com)</a></li>
</ul>
<p>就业前景很好，跟计算机专业的就业前景差不多。</p>
<p>可以从事纯硬件工作，比如画PCB电路板，画<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E5%8E%9F%E7%90%86%E5%9B%BE&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:%222654139657%22%7D">原理图</a>等。可以从事纯软件工作，比如做网页，做APP等。还可以从事嵌入式行业，嵌入式行业分类很多，我所熟悉的是<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E5%B5%8C%E5%85%A5%E5%BC%8F%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%B8%88&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:%222654139657%22%7D">嵌入式软件工程师</a>，该类工程师不仅需要懂硬件原理图，还需要会编程，编写程序来操作硬件。</p>
<p>总之，选<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E7%89%A9%E8%81%94%E7%BD%91%E5%B7%A5%E7%A8%8B&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:%222654139657%22%7D">物联网工程</a>专业，可以从事的行业很多，并不用害怕找不到工作。希望对题主有所帮助。</p>
<p>其实一个行业的前景不代表个人的前景，一个人在这个行业里面发展的怎么样，能走多远看的是个人能力和付出了多少努力。</p>
<p>但是物联网这个领域本身还是可以的，现在万物互联，发展肯定是可以的。</p>
<p>唯一的问题是大学里面学的知识比较乱，也比较基础，加上物联网的市场需求还没有那么高，所以在找工作的时候机会少一些。</p>
<p>物联网也算是计算机的相关专业，你可以选择一门编程语言深入学习之后就业的。</p>
<p>这么跟你说吧，物联网是一个行业不是一个专业，是行业就有很多岗位，所以物联网找工作不上不下的，软件有软工，硬件有电气，学的东西太杂乱，好像什么都会一点，但多数企业要的是一个方面专精的，如果真想读物联网一定要大一就确定一门语言去学精他，真不好找工作</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/64290050">各位前辈，请问一下为什么有的人说物联网工程是个坑，学的杂而不精，然而它的就业平均薪酬还那么高呢？ - 知乎 (zhihu.com)</a></li>
</ul>
<p>简答：物联网工程是坑，行业平均薪资也确实有竞争力</p>
<p>原因：物联网工程其实也属于工程技术，只是它属于近代技术广泛应用，你去学这个。</p>
<p>打个比方你要搞特斯拉，其实这玩意并没有啥高精尖的技术，大部分还是原来传统车积累下来的。真正变更的是类似特斯拉自动驾驶以及电池管理技术：对比物联网中云技术以及射频技术。</p>
<p>如果你在物联网行业，并没有负责核心技术抑或不能有独特竞争力，那么与其他行业没有太多变化。只是公司如果发展好，你的待遇可能会跟上。</p>
<p>现在物联网行业比传统企业待遇个人觉得是会好一点，因为缺口稍微大一点。毕竟搞智能硬件的需要一批新人才，也比传统硬件复杂一点。</p>
<p>而且物联网技术人员是跟互联网大厂抢人，能搞云架构，云安全，语音，嵌入式，前后端这些哪些不是本来就高待遇。</p>
<p>认清物联网本质，这个问题就好理解了。</p>
<p>谢邀，15年某211物联网毕业生，女生，同班同学，包括上一届学长学姐，没有说哪个毕业后是以物联网相关岗位进去工作的，要么硬件工程师要么软件，只要有一项精通的，进去做技术之后再慢慢转，而且国内大部分都是打着物联网的旗号该干嘛还是干嘛，真正做的好的就是小米智能家居，据我所知，没有应届生能进得去，都是个行业的大牛，加油吧</p>
<p>大四二本物联网工程在读，这就是个通信软硬件杂交专业，还是不建议你选择这个专业，目前我们班44人就业选择：Java、C++、前端、测试、运维、嵌入式、大数据、Android，射频工程师，你可以看出就业方向五花八门，但都是互联网计算机岗位，所以薪资还是不错的。这个专业怎么说呢。你只要不是太划水。懂点物联网知识，对于你找你自己选择的方向很有帮助。因为物联网工程归根究底还是属于工科计算机学科，算科班。我自己是选择了Java，拿了3，4个工业软件和物联网方向公司的Java offer</p>
<p>16年电子信息工程专业学生，19年开始北漂，目前在做数字智能化的相关业务。</p>
<p>当时我们的系叫做计算机科学与技术专业，然后分三个通信工程，物联网，和电信。然后上了半学期大家觉得都挺坑的，课程很难且不专一，一开始我认为我是一个很喜欢创造的人，我想借此学习很多知识然后去做一个什么事情，但是我被这一堆课程以及每周日一整天的实验课给干趴下了，到大三还有实验课。然后成绩一般，也少了跟老师做项目的机会，我记得当时系里面有一个电脑鼠竞速比赛的项目，就是一个电子老鼠跑迷宫。算是国际上相对知名的智能电子开发的比赛了。然后很多同学都参与了一开始学校的内选，但是物联的队伍就很突出。</p>
<p>他们的队伍有几个特点，你问的所谓杂而不精，其实在大多数时候，杂与精的距离没那么远，而且一个团队大家可以相互配合，你清楚所有的链路之后就可以衔接各位在各方面有突出的队员去实现一个目标。</p>
<p>而且真正在毕业之后还在做这一行的同学，他们的薪酬影响因素根本就不是专业什么的，就他们的技术能力，对于技术开发的热情，学校时期就一屁股的参赛奖项，他的工资就低不了，老板太清楚什么事人才了。</p>
<p>这些长期坚持的兄弟要么之后自己创业搞个小队伍自己创造去了，要么一早靠着奖项进大厂深造去了，去其他厂的时候面试的时候知识面也足够应对大多数问题了，凭啥薪资不高。</p>
<p>我一开始去干市场，干媒体，最后回到这个行业做解决方案的时候，才后悔，当初要是认真学点技术，现在焊面包板一定比写PPT有趣多了。</p>
<p>选专业什么的不用想那么多，如果奔着薪资去的，那努力就好。</p>
<p>各位学弟，看看up“01星球”的吧，没必要焦虑具体的专业是什么，尽管学习内容有偏差，说实话，计算机类包括计科和互联网在内的许多细分专业，但大学的课都比较水（名校除外），其核心是围绕计算机4大件展开的，只不过有些具体的专业内容更深入（比如计科要学硬件，软件工程主要是软件，很少设计到硬件，除非以后你去人家公司做别的复杂点的项目)，其实本科选什么专业差别对你以后所想去的具体岗位影响不大，关键是看你们在学校有没有好好“自学”（尽早出去实习给自己接触社会的机会）.好好学习热爱技术，把技术学精湛，管你什么专业，只要你给企业带来价值，走什么技术岗位人家都要你的</p>
<p>后端springboot springcloud netty，数据库Redis MySQL influxdb，运维docker Jenkins，嵌入式 rtthread stm32， 4g模组 蓝牙WiFi模组，电源设计，还能画下原理图和pcb，阁下又如何应对呢？</p>
<p>真正在班上拔尖的同学，参加比赛，研究代码年年拿奖学金。软硬件虽说不特别牛逼，但是做项目刚刚好，学完Linux环境编译，<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E5%A4%9A%E7%BA%BF%E7%A8%8B&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2630753191%7D">多线程</a>。真的，每次做成功一个属于自己的项目真的特别开心。特别是在硬件和软件结合起来用。</p>
<p>真正看的还是自学能力，难道到了计科就完美了吗，不计科还要拉跨，我有接触过计科的教学大纲和她们也有朋友，毕竟之前还是一个宿舍，换校区就不是了。计科也要学硬件和软件。我们的大纲还重合了很多，只是在某些硬件上更加仔细。<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E7%89%A9%E7%90%86%E7%BD%91&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2630753191%7D">物理网</a>工程的话，因为要上云服务，所以还要学习Java，Javaweb，Python。不做网页，所以这些不用特别专业。更加注重是<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E5%BC%80%E5%8F%91%E7%89%88&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2630753191%7D">开发版</a>驱动和传感器方面，是我们核心专业课。还有物联网控制技术，各种组网ZIgbee，wife，蓝牙，也是重点。</p>
<p>往下阅读之前，先问问自己，BATD四大厂，工农建交四大行，快手华为爱奇艺，京东网易拼夕夕，还有哔哩哔哩和滴滴……这些大厂都投完简历了么？</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://scatteredream.github.io/2025/01/12/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars.githubusercontent.com/u/62317679?s=400&v=4">
      <meta itemprop="name" content="碎梦">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="scatteredream's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | scatteredream's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/01/12/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/" class="post-title-link" itemprop="url">计算机网络安全</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-01-12 00:00:00" itemprop="dateCreated datePublished" datetime="2025-01-12T00:00:00+08:00">2025-01-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-05-03 21:01:27" itemprop="dateModified" datetime="2025-05-03T21:01:27+08:00">2025-05-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%A1%E7%BD%91/" itemprop="url" rel="index"><span itemprop="name">计网</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="计算机面临的安全威胁"><a href="#计算机面临的安全威胁" class="headerlink" title="计算机面临的安全威胁"></a>计算机面临的安全威胁</h1><h2 id="攻击类型"><a href="#攻击类型" class="headerlink" title="攻击类型"></a>攻击类型</h2><p><a target="_blank" rel="noopener" href="https://javaguide.cn/cs-basics/network/network-attack-means.html">网络攻击常见手段总结 | JavaGuide</a> </p>
<p><strong>被动攻击</strong>：也叫截获，流量分析。</p>
<p><strong>主动攻击</strong>：</p>
<ul>
<li><p><strong>篡改报文</strong>。</p>
</li>
<li><p><strong>恶意程序</strong>（病毒、蠕虫、木马、流氓软件、漏洞入侵、逻辑炸弹）</p>
</li>
<li><p><strong>拒绝服务</strong>（DoS, Denial of Service）：从互联网的一个服务器A发送大量信息到另一个服务器B，使得服务器B崩溃，拒绝服务。从多个服务器发分组又叫做分布式拒绝服务（DDoS, Distributed DoS）。负载均衡（anycast…）</p>
</li>
<li><p><strong>交换机中毒</strong>：发送大量伪造MAC帧，迅速填满交换机的交换表，使交换机无法正常提供服务。</p>
</li>
</ul>
<h2 id="安全措施"><a href="#安全措施" class="headerlink" title="安全措施"></a>安全措施</h2><ul>
<li><strong>机密性</strong>：密码技术，加密报文信息；对称加密</li>
<li><strong>信息完整性</strong>：防止报文信息被篡改；非对称加密，签名-鉴别</li>
<li><strong>端点鉴别</strong>（Authentication）：鉴别对方的真实身份；</li>
</ul>
<ul>
<li><strong>访问控制</strong>（Authorization）：确认用户的权限级别，能够进行什么样的操作。</li>
</ul>
<h3 id="Authentication（身份验证）"><a href="#Authentication（身份验证）" class="headerlink" title="Authentication（身份验证）"></a>Authentication（身份验证）</h3><p>确认用户的身份，确保用户是他声称的那个人。</p>
<p>验证用户的凭证（如用户名/密码、指纹、OTP 等）。</p>
<h4 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h4><ul>
<li>登录网站时输入用户名和密码。</li>
<li>使用指纹、面部识别或其他生物识别方式解锁设备。</li>
<li>输入短信验证码进行二次验证。</li>
</ul>
<h4 id="重点"><a href="#重点" class="headerlink" title="重点"></a>重点</h4><ul>
<li>“你是谁？”</li>
<li>解决的是<strong>身份问题</strong>。</li>
</ul>
<h3 id="Authorization（授权）"><a href="#Authorization（授权）" class="headerlink" title="Authorization（授权）"></a>Authorization（授权）</h3><p>确定已经通过身份验证的用户是否有权访问某资源或执行某操作。</p>
<p>控制用户能访问的资源或功能。</p>
<h4 id="例子-1"><a href="#例子-1" class="headerlink" title="例子"></a>例子</h4><ul>
<li>一个普通用户登录后不能访问管理员控制面板。</li>
<li>文件系统中，只有特定权限的用户可以修改文件。</li>
<li>云服务中，用户可能只能管理自己的项目，不能访问其他人的数据。</li>
</ul>
<h4 id="重点-1"><a href="#重点-1" class="headerlink" title="重点"></a>重点</h4><ul>
<li>“你可以做什么？”</li>
<li>解决的是<strong>权限问题</strong>。</li>
</ul>
<h3 id="区别与联系"><a href="#区别与联系" class="headerlink" title="区别与联系"></a>区别与联系</h3><table>
<thead>
<tr>
<th><strong>对比项</strong></th>
<th><strong>Authentication（身份验证）</strong></th>
<th><strong>Authorization（授权）</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>目的</strong></td>
<td>确认用户身份</td>
<td>确定用户访问权限</td>
</tr>
<tr>
<td><strong>处理对象</strong></td>
<td>用户的身份</td>
<td>用户的权限</td>
</tr>
<tr>
<td><strong>执行顺序</strong></td>
<td>先进行身份验证</td>
<td>只有通过身份验证后才能进行授权</td>
</tr>
<tr>
<td><strong>核心问题</strong></td>
<td>用户是否真实有效？</td>
<td>用户能访问哪些资源或执行哪些操作？</td>
</tr>
<tr>
<td><strong>技术示例</strong></td>
<td>密码验证、2FA、OAuth 登录</td>
<td>角色权限分配（RBAC）、ACL、API Token</td>
</tr>
</tbody></table>
<p><code>Authentication</code> 是 <code>Authorization</code> 的前提。<br> 一个用户必须先证明“自己是谁”，然后才能被系统允许或限制访问某些资源或执行操作。</p>
<h1 id="加密算法"><a href="#加密算法" class="headerlink" title="加密算法"></a>加密算法</h1><h2 id="两类密钥体制"><a href="#两类密钥体制" class="headerlink" title="两类密钥体制"></a>两类密钥体制</h2><h3 id="对称加密"><a href="#对称加密" class="headerlink" title="对称加密"></a><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%B0%8D%E7%A8%B1%E5%AF%86%E9%91%B0%E5%8A%A0%E5%AF%86">对称加密</a></h3><p>双方使用同一把密钥，不对外公开，使用密钥将报文信息进行加密或者进行解密。</p>
<ul>
<li><p><strong>DES</strong>：密钥共64位，8位用于奇偶校验，实际为56位有效。</p>
</li>
<li><p><strong>3DES</strong>：使用两个DES密钥，先用K1加密，再用K2解密，再用K1加密</p>
</li>
<li><p><strong>AES</strong>：使用分组加密，密钥长度为128 192 256三种</p>
</li>
<li><p><strong>一个传统保管箱，开门和关门都是使用同一条钥匙，这是对称加密</strong> </p>
</li>
<li><p>只支持一对一通信。</p>
</li>
</ul>
<h3 id="公钥加密（非对称加密）"><a href="#公钥加密（非对称加密）" class="headerlink" title="公钥加密（非对称加密）"></a><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%85%AC%E5%BC%80%E5%AF%86%E9%92%A5%E5%8A%A0%E5%AF%86">公钥加密（非对称加密）</a></h3><ul>
<li>使用密钥生成器生成密钥对，一个是公钥（对外公开），一个是私钥（自己保留）。</li>
<li>已知其中一个密钥的情况下，几乎不可能知道另外一个密钥。</li>
<li>私钥加密的数据，只能用公钥解密。公钥加密的数据，只能用私钥解密。<ul>
<li>其实不应该叫做加密和解密，应该称作D运算和E运算这两个互逆的运算，没有规定他们谁先谁后。</li>
<li>更准确的说法是私钥参与D运算，公钥参与E运算。</li>
</ul>
</li>
<li><strong>一个公开的邮箱，投递口是任何人都可以寄信进去的，这可视为公钥；</strong></li>
<li><strong>而只有信箱主人拥有钥匙可以打开信箱，这就视为私钥。</strong></li>
<li>支持多对一的通信。</li>
</ul>
<h2 id="鉴别（Authentication）"><a href="#鉴别（Authentication）" class="headerlink" title="鉴别（Authentication）"></a>鉴别（Authentication）</h2><h3 id="报文鉴别"><a href="#报文鉴别" class="headerlink" title="报文鉴别"></a>报文鉴别</h3><p>主要是鉴别报文是否被篡改。</p>
<h4 id="数字签名"><a href="#数字签名" class="headerlink" title="数字签名"></a>数字签名</h4><p>decryption and encryption</p>
<p>A要发出信息，并进行数字签名，将报文用私钥SK<del>A</del>进行D运算（签名），其他人只能用公钥PK<del>A</del>进行E运算（鉴别）。</p>
<ul>
<li><strong>防止篡改报文</strong>：没人知道A的私钥SK<del>A</del>，窃听者使用公钥PK<del>A</del>进行E运算得出明文，篡改报文之后再D运算，另一边使用公钥PK<del>A</del>解析出的明文将会是不可读的，因此不会被欺骗。</li>
<li><strong>不可否认</strong>：既然信息明文可读，就说明没有被篡改过，而拥有私钥的只有A一个人，A就不能抵赖自己曾经的签名。</li>
</ul>
<p>上述方法是对报文本身进行了私钥加密，公钥直接可以解出报文具体内容，如果要用非对称加密实现报文内容的保密，可以在A用私钥D运算之后，再用B的公钥E运算，这样就彻底加密了报文内容，B收到以后先用B的私钥D运算，再用A的公钥E运算。</p>
<h4 id="哈希函数"><a href="#哈希函数" class="headerlink" title="哈希函数"></a><a href="../../Hash.md">哈希函数</a></h4><p>是一种摘要算法，将任意长度的报文经过哈希函数可以的到固定长度的字符串。</p>
<h4 id="结合报文鉴别码（MAC）实现数字签名报文鉴别"><a href="#结合报文鉴别码（MAC）实现数字签名报文鉴别" class="headerlink" title="结合报文鉴别码（MAC）实现数字签名报文鉴别"></a>结合报文鉴别码（MAC）实现数字签名报文鉴别</h4><p>Message Authentication Code, MAC</p>
<p>H(X) 代表 X 的哈希值；D(X) 代表 X 经过私钥的D运算以后的结果；E(X) 代表 X 经过 公钥的E运算之后的结果</p>
<p>$D(E(X)) = X$          $E(D(X)) = X$ </p>
<p>扩展报文实现的数字签名可以分为三类：</p>
<p>$A + H(A)$ ：只篡改报文A或者H(A)可以鉴别出来，但是直接换一个 X + H(X) 直接会蒙混过关，由此引出了使用密钥K来进行哈希运算的方法。</p>
<p>$A + H(A,K)$： 使用对称密钥$K$，如果报文$A$被篡改成$X$，但是攻击者不知道密钥，因此无法伪造出哈希值$H(X,K)$，另一边根据密钥计算出$H(X,K)$，就能发现报文被篡改过。这样将密钥拼接在正文之后，得出的散列值就是<strong>HMAC</strong>。JWT(Json Web Token)采用的数字签发就可以采用这样的方式 （HS256 代表 HMAC 散列函数为SHA-256）**对密钥K<u>严格要求保密</u>**。<a target="_blank" rel="noopener" href="https://ryan4yin.space/posts/jwt-algorithm-key-generation/">JWT 签名算法 HS256、RS256 及 ES256 及密钥生成 - This Cute World</a> </p>
<p>$A + D(H(A))$：使用私钥对报文的哈希进行D运算，其他人使用公钥对密文进行E运算能够得出哈希值，将这个哈希值和报文段的哈希值比较即可。如果$A$被篡改为$X$，攻击者因为不知道发送者的私钥，因此无法得出一个正确的$D(H(X))$，这时候发给接收者，接受者再对攻击者伪造的哈希值密文进行E运算，得出哈希值肯定和真正的$H(X)$不同，这就是RS256和ES256的原理。**由此方法扩展出的报文<u>不可伪造，也不可否认</u>**，同时可以运用到分布式架构中，一个服务签发，其他服务验证只需要公钥即可。ES256（ECDSA）使用椭圆曲线计算公钥。</p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/kirito-c/p/12402066.html">JWT 签名算法 HS256、RS256 及 ES256 及密钥生成 - 於清樂 - 博客园</a> </p>
<h3 id="实体鉴别"><a href="#实体鉴别" class="headerlink" title="实体鉴别"></a>实体鉴别</h3><h4 id="对称密钥"><a href="#对称密钥" class="headerlink" title="对称密钥"></a>对称密钥</h4><p>主要是验证来访者的确是访问者，也就是鉴别身份。</p>
<p>相比于报文鉴别，实体鉴别只需要鉴别一次发送者即可，后续传输不需要鉴别，使用<strong>共享对称密钥</strong>，如果第三方C截获了A发给B的验证信息，并未破译报文，而是直接伪装成A给B发消息，这样B就会错误地与C建立起联系。把以前窃听到的数据原封不动地重新发送给接收方，这就叫 <strong>重放攻击</strong>。</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E9%87%8D%E6%94%BE%E6%94%BB%E5%87%BB/2229240">重放攻击_百度百科</a> </p>
<p>重放攻击的基本原理就是把以前<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E7%AA%83%E5%90%AC/1624599?fromModule=lemma_inlink">窃听</a>到的数据原封不动地重新发送给接收方。很多时候，网络上传输的数据是<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E5%8A%A0%E5%AF%86/752748?fromModule=lemma_inlink">加密</a>过的，此时窃听者无法得到数据的准确意义。但如果他知道这些数据的作用，就可以在不知道数据内容的情况下通过再次发送这些数据达到愚弄接收端的目的。例如，有的系统会将鉴别信息进行简单加密后进行传输，这时攻击者虽然无法窃听<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E5%AF%86%E7%A0%81/65553?fromModule=lemma_inlink">密码</a>，但他们却可以首先截取加密后的口令然后将其重放，从而利用这种方式进行有效的攻击。再比如，假设网上存款系统中，一条消息表示用户支取了一笔存款，攻击者完全可以多次发送这条消息而偷窃存款。</p>
</blockquote>
<p>因此采取的措施就是尽量能够让B端验证清楚A的身份。K(X)表示用密钥加密过的X</p>
<p>A先发身份信息 + 一个大随机不重复数<code>RA</code>，B收到后响应一个<code>RB</code>和<code>K(RA)</code>，因此对于A端而言B端是可信的；A端再发送<code>K(RB)</code>，因此对于B端而言A端是可信的。需要注意的是每次会话都都需要重新验证，并且需要有足够的空间存储不同会话的不同随机数。</p>
<h4 id="非对称密钥"><a href="#非对称密钥" class="headerlink" title="非对称密钥"></a>非对称密钥</h4><p>对于上文的不重复随机数，B可以用B自己的私钥加密RA，A用B的公钥解密得出RA；A用自己的私钥加密RB，B用A的公钥解密RB。这里C可以生成自己的私钥和公钥，分别截获RA和RB，仍然能够冒充A，与B进行通信。不过A与B根本没有进行通信，A端很容易察觉到。</p>
<p><strong>中间人攻击</strong>：假设AB通信双方并没有提前知道对方的公钥是什么。</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8.assets/image-20241129155621051.png" alt="image-20241129155621051"></p>
<p>C截获A的身份验证信息和RB，用自己的私钥加密RB得到D<del>C</del>(RB)返回给B，同时把RB转发给A，A向对方索取公钥，C就把自己的公钥发给A，但是仍然把公钥的请求转发给A，A发出了自己的D<del>A</del>(RB)和公钥，但均被C所截获。</p>
<p>A跟B开始建立通信，B就把发送的数据用C的公钥加密，C直接可以用自己的私钥解密，解密出来以后再用A的公钥加密，发给A，看似A和B建立了保密通信，实际上C能够神不知鬼不觉地窃取信息。</p>
<blockquote>
<p>SSL劫持</p>
<p>当今绝大部分网站采用HTTPS方式进行访问，也就是用户与网站服务器间建立<a target="_blank" rel="noopener" href="https://info.support.huawei.com/info-finder/encyclopedia/zh/SSL.html">SSL</a>连接，基于SSL证书进行数据验证和加密。HTTPS可以在一定程度上减少中间人攻击，但是攻击者还是会使用各种技术尝试破坏HTTPS，SSL劫持就是其中的一种。SSL劫持也称为SSL证书欺骗，攻击者伪造网站服务器证书，公钥替换为自己的公钥，然后将虚假证书发给用户。此时用户浏览器会提示不安全，但是如果用户安全意识不强继续浏览，攻击者就可以控制用户和服务器之间的通信，解密流量，窃取甚至篡改数据。</p>
</blockquote>
<h2 id="密钥分配与管理"><a href="#密钥分配与管理" class="headerlink" title="密钥分配与管理"></a>密钥分配与管理</h2><h3 id="对称密钥交换"><a href="#对称密钥交换" class="headerlink" title="对称密钥交换"></a>对称密钥交换</h3><h4 id="RSA"><a href="#RSA" class="headerlink" title="RSA"></a>RSA</h4><h5 id="难点：大数因式分解"><a href="#难点：大数因式分解" class="headerlink" title="难点：大数因式分解"></a>难点：大数因式分解</h5><p>公开的数字：公钥D，N</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8.assets/image-20241129230424076-1732894652386-1.png" alt="image-20241129230424076"></p>
<p>难点：算出T的值，也就是要分解N。</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8.assets/image-20241129230521315-1732944264022-8.png" alt="image-20241129230521315"></p>
<h5 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h5><ul>
<li>使用场景较广泛，适合需要加密数据、验证签名的场合。</li>
<li>不适合直接交换大数据（效率较低）。</li>
</ul>
<h5 id="RSA-的缺陷"><a href="#RSA-的缺陷" class="headerlink" title="RSA 的缺陷"></a>RSA 的缺陷</h5><p>没有前向保密性，所有的数字（质数乘积N，公钥E）必须提前沟通好，依赖于长期的静态密钥对（公钥和私钥）来交换对称密钥，而没有使用每次会话生成的临时密钥对。在 RSA 密钥交换过程中，如果服务器的私钥被泄露，攻击者可以解密所有使用该私钥加密的对称密钥，进而恢复以前的会话数据，从而破坏了前向保密性。</p>
<h4 id="Diffle-Hellman-密钥交换"><a href="#Diffle-Hellman-密钥交换" class="headerlink" title="Diffle-Hellman 密钥交换"></a>Diffle-Hellman 密钥交换</h4><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/599518034">一文搞懂Diffie-Hellman密钥交换协议 - 知乎</a> </p>
<h5 id="难点：离散对数"><a href="#难点：离散对数" class="headerlink" title="难点：离散对数"></a>难点：离散对数</h5><p>公开的数字：P、G、双方的公钥。</p>
<ul>
<li><p>正向计算简单，逆向计算难（即在有限域上计算  $g^x \mod p$ 的逆运算很难）</p>
</li>
<li><p>依赖于离散对数的计算难度，使用的素数位数越长，安全性越高。</p>
</li>
<li><p>易受中间人攻击，因此通常结合认证机制（如数字签名）使用。</p>
</li>
</ul>
<h5 id="使用场景-1"><a href="#使用场景-1" class="headerlink" title="使用场景"></a>使用场景</h5><ul>
<li>专用于安全密钥交换，通常与对称加密算法结合使用。</li>
<li>不支持数据加密或签名。</li>
</ul>
<p>由8和19无法逆推回x与y，由$19^x \mod 23 = 8^y \mod 23$ 也无法推出x和y的值</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8.assets/image-20241129230002490.png" alt="image-20241129230002490"></p>
<h5 id="ECDHE"><a href="#ECDHE" class="headerlink" title="ECDHE"></a>ECDHE</h5><p>static DH算法 – &gt; DHE算法 – &gt; ECDHE算法</p>
<p><strong>static DH</strong> 算法里有一方的私钥是静态的，也就说每次密钥协商的时候有一方的私钥都是一样的，一般是服务器方固定，即 a 不变，客户端的私钥则是随机生成的。 于是，DH 交换密钥时就只有客户端的公钥是变化，而服务端公钥是不变的，那么随着时间延长，黑客就会截获海量的密钥协商过程的数据，因为密钥协商的过程有些数据是公开的，黑客就可以依据这些数据暴力破解出服务器的私钥，然后就可以计算出会话密钥了，于是之前截获的加密数据会被破解，所以 static DH 算法<strong>不具备前向安全性</strong>。</p>
<p><strong>DHE</strong> </p>
<ul>
<li><strong>Ephemeral（临时密钥）</strong>：在 DHE 中，”Ephemeral” 表示每次会话都生成新的密钥对（临时密钥）。因此，即使密钥在某一时刻被泄露，它也无法用于恢复以前的通信，增强了前向保密性（forward secrecy）。</li>
</ul>
<p>G、P可以固定，DHE 每次需要传递的数据就是计算出来的公钥，不过大数乘除性能不好，于是有了ECDHE，用ECC提高性能。</p>
<p><strong>ECDHE</strong>（Elliptic Curve Diffie-Hellman Ephemeral） 是 Diffie-Hellman 协议的椭圆曲线版本，使用椭圆曲线加密（ECC，Elliptic Curve Cryptography）来代替传统的基于大数的计算。椭圆曲线加密在相同的安全级别下，所需的密钥长度比传统的 DH 小得多，从而提高了计算效率。</p>
<h4 id="密钥分发中心（KDC）"><a href="#密钥分发中心（KDC）" class="headerlink" title="密钥分发中心（KDC）"></a>密钥分发中心（KDC）</h4><p>Key Distribution Center</p>
<h3 id="公钥体制：CA"><a href="#公钥体制：CA" class="headerlink" title="公钥体制：CA"></a>公钥体制：CA</h3><p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%85%AC%E9%96%8B%E9%87%91%E9%91%B0%E8%AA%8D%E8%AD%89">Certificate Authority 证书权威机构</a></p>
<p>除非A与B线下沟通好公钥，不然总是有可能会被中间人攻击（即中间人会截获请求者的公钥，替换成自己的公钥），那么如何保证B的公钥能准确无误传到A手上不被篡改呢？需要第三方进行数字签名，CA用自己的私钥将报文信息数字签名，也就是MAC报文鉴别码。最终报文鉴别码附在报文后面$B + D(H(B))$</p>
<p>这里的报文B包含：</p>
<ul>
<li>B的身份验证信息（我是B）</li>
<li>B的公钥（我的公钥是xxx）</li>
</ul>
<p>因此，B需要提供证书，A需要把证书的报文部分进行哈希运算，然后用报文中B提供的公钥进行E运算，看得出的结果是否相同，如果不同说明证书被篡改，不可信。一切的基础是建立在CA上面，CA是一个大家都认可的权威机构</p>
<h4 id="CA-标准：X-509（PKI）"><a href="#CA-标准：X-509（PKI）" class="headerlink" title="CA 标准：X.509（PKI）"></a>CA 标准：X.509（PKI）</h4><p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%85%AC%E9%96%8B%E9%87%91%E9%91%B0%E8%AA%8D%E8%AD%89">公开密钥认证 - 维基百科，自由的百科全书</a> Public Key Infrastructure</p>
<p><strong>数字证书标准</strong>：</p>
<ul>
<li>X.509 版本</li>
<li>数字证书名称、序列号</li>
<li>本数字签名证书使用的签名算法（CA进行数字签名的非对称算法）</li>
<li>数字签名的公钥（私钥由签发者保存）</li>
<li>签发者的唯一标识符</li>
<li>数字证书的有效期</li>
<li>数字证书的主体名（数字证书拥有者及其拥有的公钥的唯一标识符）</li>
</ul>
<h4 id="CA-信任链：多级认证系统"><a href="#CA-信任链：多级认证系统" class="headerlink" title="CA 信任链：多级认证系统"></a>CA 信任链：多级认证系统</h4><p>万一中级证书不能信任了，还可以让根证书再找一个中级证书，因为信任根证书，也自然信任这个新的中级证书，但如果根证书直接信任某个网站的证书，万一根证书被攻破不能信任了，那就找不到可以信任的了。</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8.assets/image-20241129222025691.png" alt="image-20241129222025691"></p>
<p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%A0%B9%E8%AF%81%E4%B9%A6">根证书</a>：所有信任链的起点，使用私钥自签。根证书获得广泛认可，通常已预先安装在各种软件（包括<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F">操作系统</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%BD%91%E9%A1%B5%E6%B5%8F%E8%A7%88%E5%99%A8">浏览器</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%9B%BB%E5%AD%90%E9%83%B5%E4%BB%B6%E7%94%A8%E6%88%B6%E7%AB%AF">电邮软件</a>等），作为<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%BF%A1%E4%BB%BB%E9%8F%88">信任链</a>的起点，来自于公认可靠的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%94%BF%E5%BA%9C%E6%9C%BA%E5%85%B3">政府机关</a>（如<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%A6%99%E6%B8%AF%E9%83%B5%E6%94%BF">香港邮政</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%8F%B0%E7%81%A3%E7%B6%B2%E8%B7%AF%E8%B3%87%E8%A8%8A%E4%B8%AD%E5%BF%83">台湾网络信息中心</a>）、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%AF%81%E4%B9%A6%E9%A2%81%E5%8F%91%E6%9C%BA%E6%9E%84">证书颁发机构</a>公司（如<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/DigiCert">DigiCert</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/Google">Google</a>）、非营利组织（如<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/Let's_Encrypt">Let’s Encrypt</a>）等，与各大软件商透过严谨的核认程序才在不同的软件广泛部署。由于部署程序复杂费时，需要行政人员的授权及机构法人身份的核认，一张根证书有效期可能长达二十年以上。在某些企业，也可能会在内部电脑自行安装企业自签的根证书，以支持<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%86%85%E9%83%A8%E7%BD%91">内部网</a>的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%BC%81%E4%B8%9A%E7%BA%A7%E8%BD%AF%E4%BB%B6">企业级软件</a>；但是这些证书可能未被广泛认可，只在企业内部适用。</p>
<p><strong>中介证书</strong>：认证机构的一个重要任务就是为客户签发证书，虽然广泛认可的认证机构都已拥有根证书，相对应的私钥可用以签署其他证书，但因为<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%AF%86%E9%92%A5%E7%AE%A1%E7%90%86">密钥管理</a>和行政考虑，一般会先行签发中介证书，才为客户作数字签署。中介证书的有效期会较根证书为短，并可能对不同类别的客户有不同的中介证书作分工。</p>
<p><strong>TLS 服务器证书</strong>：服务器通常以域名形式在互联网上提供服务，服务器证书上<strong>主体</strong>的<strong>通用名称</strong>就会是相应的域名，相关机构名称则写在<strong>组织</strong>或<strong>单位</strong>一栏上。服务器证书（包括公钥）和私钥会安装于服务器（例如<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/Apache_HTTP_Server">Apache</a>），等待客户端连接时<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%8F%A1%E6%89%8B_(%E6%8A%80%E6%9C%AF)">协议加密细节</a>。客户端的软件（如浏览器）会执行<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/w/index.php?title=%E8%AA%8D%E8%AD%89%E8%B7%AF%E5%BE%91%E9%A9%97%E8%AD%89%E7%AE%97%E6%B3%95&action=edit&redlink=1">认证路径验证算法</a>以确保安全，如果未能肯定加密通道是否安全（例如证书上的主体名称不对应网站域名、服务器使用了自签证书、或加密算法不够强），可能会警告用户。</p>
<p><strong>TLS 客户端证书</strong>：有时候，某些TLS服务器可能会在建立加密通道时，要求客户端提供客户端证书，以验证<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%95%B0%E5%AD%97%E8%BA%AB%E4%BB%BD">身份</a>及<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%AD%98%E5%8F%96%E6%8E%A7%E5%88%B6">控制访问权限</a>。客户端证书包含电子邮件地址或个人姓名，而不是主机名。但客户端证书比较不常见，因为考虑到技术门槛及成本因素，通常都是由服务提供者验证客户身份，而不是依赖第三方认证机构。通常，需要使用到客户端证书的服务都是内部网的企业级软件，他们会设立自己的内部根证书，由企业的技术人员在企业内部的电脑安装相关客户端证书以便使用。在公开的互联网，大多数网站都是使用<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%AF%86%E7%A2%BC_(%E8%AA%8D%E8%AD%89)">登录密码</a>和<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/Cookie">Cookie</a>来验证用户，而不是客户端证书。客户端证书在<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%81%A0%E7%A8%8B%E9%81%8E%E7%A8%8B%E8%AA%BF%E7%94%A8">RPC系统</a>中更常见，用于验证连接设备的许可授权。</p>
<p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6">自签证书</a>：在用于小范围测试等目的的时候，用户也可以自己生成数字证书，但没有任何可信赖的人签名，这种自签名证书通常不会被广泛信任，使用时可能会遇到电脑软件的安全警告。</p>
<h4 id="CA-撤销名单"><a href="#CA-撤销名单" class="headerlink" title="CA 撤销名单"></a>CA 撤销名单</h4><p>CA 撤销名单：尚未到期就被<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%AF%81%E4%B9%A6%E9%A2%81%E5%8F%91%E6%9C%BA%E6%9E%84">证书颁发机构</a>吊销的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6">数字证书</a>的名单。</p>
<ul>
<li>吊销：该证书被不可逆的吊销。例如，它被不当的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%AF%81%E4%B9%A6%E9%A2%81%E5%8F%91%E6%9C%BA%E6%9E%84">证书颁发机构</a>颁发了证书，或者私钥被认为已经破坏。被吊销的最常见的原因是用户不再独有私钥，而私钥则被窃取。</li>
<li>吊扣：这个状态是可逆的。</li>
</ul>
<p>每个CA都有对应的CA证书撤销名单，里面包含着证书的序列号。有 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%9C%A8%E7%BA%BF%E8%AF%81%E4%B9%A6%E7%8A%B6%E6%80%81%E5%8D%8F%E8%AE%AE">OCSP</a> 和 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%AF%81%E4%B9%A6%E5%90%8A%E9%94%80%E5%88%97%E8%A1%A8">CRL</a> 两种形式</p>
<blockquote>
<p>非关键 CA 颁发者: URI: <a target="_blank" rel="noopener" href="http://secure.globalsign.com/cacert/gsrsaovsslca2018.crt">http://secure.globalsign.com/cacert/gsrsaovsslca2018.crt</a> </p>
<p>OCSP 响应者: URI: <a target="_blank" rel="noopener" href="http://ocsp.globalsign.com/gsrsaovsslca2018">http://ocsp.globalsign.com/gsrsaovsslca2018</a></p>
</blockquote>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/crl.png" alt="img"></p>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/ocsp.png" alt="img"></p>
<h1 id="HTTPS-SSL-TLS"><a href="#HTTPS-SSL-TLS" class="headerlink" title="HTTPS (SSL/TLS)"></a>HTTPS (SSL/TLS)</h1><p><a target="_blank" rel="noopener" href="https://xiaolincoding.com/network/2_http/http_interview.html#http-%E4%B8%8E-https">HTTPS  HTTP</a> </p>
<h2 id="传输层安全（TLS）"><a href="#传输层安全（TLS）" class="headerlink" title="传输层安全（TLS）"></a>传输层安全（TLS）</h2><p>Transport Layer Security</p>
<h3 id="TLS-握手（TLS-1-2）"><a href="#TLS-握手（TLS-1-2）" class="headerlink" title="TLS 握手（TLS 1.2）"></a>TLS 握手（TLS 1.2）</h3><p>在TCP threeway handshake之后，就会开始TLS handshake</p>
<p>两种交换会话密钥的算法：<a target="_blank" rel="noopener" href="https://xiaolincoding.com/network/2_http/https_rsa.html#rsa-%E6%8F%A1%E6%89%8B%E8%BF%87%E7%A8%8B">RSA 握手</a> 和 <a target="_blank" rel="noopener" href="https://xiaolincoding.com/network/2_http/https_ecdhe.html">ECDHE 握手</a> 后者支持前向安全，现在使用更加广泛</p>
<h4 id="RSA-握手"><a href="#RSA-握手" class="headerlink" title="RSA 握手"></a>RSA 握手</h4><p><img src="C:/Users/Lenovo/Pictures/markdownfile/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8.assets/image-20241130161720294.png" alt="image-20241130161720294"></p>
<ol>
<li><strong>ClientHello</strong>: 客户端向服务器发送随机数<code>client random</code>，TLS版本，支持的加密套件列表。</li>
<li><strong>ServerHello</strong>: 服务器响应随机数<code>server random</code>，确认好加密套件，下发服务器证书(<code>Certificate</code>)。<ul>
<li>证书里有用于<code>premaster</code>加密的服务器公钥</li>
</ul>
</li>
<li><strong>Client Key Exchange</strong>: 客户端证书验证通过后，生成另一个随机数<code>premaster secret</code>，通过<strong>服务器证书的公钥</strong>加密</li>
<li>服务器用私钥解密获取<code>premaster secret</code>，双方根据<code>premaster secret</code>和两个随机数生成<code>session key</code> </li>
<li><strong>Change Cipher Spec</strong>: 客户端通知接下来要使用会话密钥进行通信了，之前都是明文通信。切换加密标准</li>
<li><strong>Finishd</strong>: 客户端计算之前发出的明文消息的摘要（Hash），再用<code>session key</code>加密后发给服务端</li>
<li>服务端重复5,6步，双方认证加解密无问题，则可以开始正式发送用<code>session key</code>加密后的<code>application data</code> </li>
</ol>
<p><img src="https://ask.qcloudimg.com/http-save/4069756/e6zkf4qwi7.jpeg" alt="img"></p>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/https_rsa.png" alt="img"> </p>
<h5 id="加密套件（Cipher-Suite）"><a href="#加密套件（Cipher-Suite）" class="headerlink" title="加密套件（Cipher Suite）"></a>加密套件（Cipher Suite）</h5><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43408952/article/details/124715927">TLS 各种加密套件_tls加密套件-CSDN博客</a> </p>
<p><strong>TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256</strong> </p>
<ul>
<li><strong>密钥交换策略</strong>（Key Exchange/Arrangement）：用于交换对称密钥。<strong>RSA</strong>、DH、DHE、<strong>ECDHE</strong>、PSK</li>
<li><strong>数字签名算法</strong>（Authentication）：用于验证证书。<strong>RSA</strong>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D%E7%AE%97%E6%B3%95"><strong>DSA</strong></a> 、ECDSA</li>
<li><strong>对称加密算法</strong>（Block/stream ciphers）：用于加密消息流。<strong>ChaCha20</strong>、<strong>AES</strong>、DES等</li>
<li><strong>MAC 算法</strong>（Message authentication）：用于创建报文鉴别码，例如<strong>SHA-256</strong>，MD5，消息流每个<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%95%B0%E6%8D%AE%E5%9D%97">数据块</a>的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%8A%A0%E5%AF%86%E6%95%A3%E5%88%97">加密散列</a>。(分块加密信息以后的报文摘要)</li>
</ul>
<h5 id="前向安全性（Forward-Secrecy）"><a href="#前向安全性（Forward-Secrecy）" class="headerlink" title="前向安全性（Forward Secrecy）"></a>前向安全性（Forward Secrecy）</h5><p>共享密钥被攻破不会导致之前的会话信息全部泄露。Perfect Forward Secrecy</p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/45203206">如何理解前向安全性？和完美前向保密（perfect forward secrecy）区别？ - 知乎</a> </p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/348420897">有了共享密钥为什么还需要会话密钥？ - 知乎</a> </p>
<p><strong>有了premaster key为什么要session key？</strong> </p>
<p>RSA握手中不把premaster key直接当做对称密钥，单次session key泄露不会造成之前的会话信息都泄露。</p>
<p>前向安全性问题出在共享密钥上，RSA握手的共享公-私密钥对是长期不变的，也就是说如果服务端用于RSA加密的私钥泄露会导致之前的会话信息全部暴露。如果对每次会话都生成一对RSA密钥对，理论可行，但是性能不如后面要介绍的ECDHE。</p>
<p> 双<strong>RSA</strong>虽然也能实现<strong>PFS</strong>，但是效率太差，没有公司会采用， 基本都是<strong>RSA + ECDHE</strong>。 </p>
<h4 id="ECDHE-握手"><a href="#ECDHE-握手" class="headerlink" title="ECDHE 握手"></a>ECDHE 握手</h4><p>椭圆曲线最重要的参数是<strong>椭圆曲线类型</strong>（基点G）[RSA 算法的替代品：X25519/Ed25519 使用记录 | 存在感消失的地方|ω•`)](<a target="_blank" rel="noopener" href="https://akarin.dev/2021/09/16/a-taste-of-curve25519/">https://akarin.dev/2021/09/16/a-taste-of-curve25519/</a>)  </p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8.assets/image-20241130165130228.png" alt="image-20241130165130228"></p>
<ol>
<li><strong>ClientHello</strong>: 客户端向服务器发送<strong>随机数</strong>client random，TLS版本，支持的加密套件列表</li>
<li><strong>ServerHello</strong>: 服务器响应<strong>随机数</strong>server random，确认好双方都支持的加密套件，同时下发服务器<strong>证书</strong>(<code>certificate</code>)<ul>
<li>证书中的公钥用于鉴别自己发出的签名有效。</li>
</ul>
</li>
<li><strong>Server Key Exchange</strong>: 生成随机数作为<strong>临时私钥</strong>，保留在本地。公开<strong>椭圆曲线</strong>基点G，一般是X25519，根据G和临时生成的私钥，算出<strong>公钥</strong>发给客户端。为了保证公钥不被篡改，同时会使用RSA进行数字签名。</li>
<li><strong>Client Key Exchange</strong>: 客户端验证通过后，生成自己临时私钥，根据基点G算出<strong>公钥</strong>，发送给服务器。</li>
<li>这样，双方知道了对方的公钥，就可以开始算共享密钥了。</li>
<li>之后的步骤就是互相发送change cipher spec+finished，ECDHE可以在客户端发完信息之后可以直接开始发送<code>application data</code> </li>
</ol>
<p><img src="https://ask.qcloudimg.com/http-save/4069756/0mhr8kq63w.jpeg" alt="img"></p>
<p>==抓包实战== </p>
<p><u>搭建https server（springboot）</u></p>
<ol>
<li><strong>生成自签名证书</strong>，使用jdk的keytool生成证书</li>
</ol>
<figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keytool -genkey -<span class="keyword">alias</span> wxl -keyalg RSA -keysize <span class="number">2048</span> -storetype PKCS12 -keystore wxl-ssl-<span class="keyword">key</span>.p12 -validity <span class="number">3650</span></span><br></pre></td></tr></table></figure>

<ul>
<li>-genkey：表示要创建一个新的密钥</li>
<li>-alias：keystore别名</li>
<li>-keyalg：加密算法</li>
<li>-keysize：密钥长度</li>
<li>-storetype：密钥类型</li>
<li>-keystore：文件存放位置</li>
<li>-validity：密钥有效期，单位为天</li>
</ul>
<ol start="2">
<li><strong>springboot配置https</strong></li>
</ol>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line">  <span class="attr">port:</span> <span class="number">8443</span></span><br><span class="line">  <span class="attr">ssl:</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">key-store:</span> <span class="string">classpath:wxl-ssl-key.p12</span></span><br><span class="line">    <span class="attr">key-store-password:</span> <span class="number">123456</span></span><br><span class="line">    <span class="attr">key-store-type:</span> <span class="string">PKCS12</span></span><br><span class="line">    <span class="attr">enabled-protocols:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">TLSv1.2</span></span><br></pre></td></tr></table></figure>

<ul>
<li>enabled-protocols表示支持启用的TLS版本，这里配置仅TLS1.2</li>
</ul>
<p><u>请求并抓包</u></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl https://localhost:8443/hello -k</span><br></pre></td></tr></table></figure>

<p>tcp.port == 8443</p>
<h5 id="TLS-False-Start"><a href="#TLS-False-Start" class="headerlink" title="TLS False Start"></a>TLS False Start</h5><p><a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000004003319">https - TLS False Start究竟是如何加速网站的 - 野狗科技官方专栏 - SegmentFault 思否</a> </p>
<p><img src="https://ask.qcloudimg.com/http-save/4069756/0mhr8kq63w.jpeg" alt="img"></p>
<blockquote>
<p>The recommended whitelists are such that if cryptographic algorithms suitable for forward secrecy would possibly be negotiated, no False Start will take place if the current handshake fails to provide forward secrecy.</p>
<p><a target="_blank" rel="noopener" href="https://datatracker.ietf.org/doc/html/rfc7918">RFC 7918 - Transport Layer Security (TLS) False Start</a> </p>
</blockquote>
<p>ECDHE和DHE支持前向保密，所以可以使用TLS抢跑。</p>
<p><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1420297">90%的人都不懂的TLS握手优化-腾讯云开发者社区-腾讯云</a> </p>
<h3 id="TLS-记录"><a href="#TLS-记录" class="headerlink" title="TLS 记录"></a>TLS 记录</h3><p>TLS 握手主要用来解决服务器的可信度问题，TLS 记录可以解决报文的压缩、加密和数据认证的问题。</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8.assets/image-20241130224715135.png" alt="image-20241130224715135"></p>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/%E8%AE%B0%E5%BD%95%E5%8D%8F%E8%AE%AE.png" alt="img"></p>
<h3 id="TLS-漏洞"><a href="#TLS-漏洞" class="headerlink" title="TLS 漏洞"></a>TLS 漏洞</h3><hr>
<p><u><strong>协议设计上的漏洞</strong></u>：一些漏洞源于TLS协议本身的设计缺陷，通常会在新版本中修复：</p>
<p><strong>BEAST（Browser Exploit Against SSL/TLS）</strong></p>
<ul>
<li><strong>描述</strong>：BEAST 攻击利用 TLS 1.0 中的 CBC 模式实现的设计缺陷，通过中间人攻击窃取加密数据。</li>
<li><strong>修复</strong>：TLS 1.1 和更高版本已经修复了该问题，同时推荐使用 AES-GCM 等替代的加密模式。</li>
</ul>
<p><strong>CRIME（Compression Ratio Info-leak Made Easy）</strong></p>
<ul>
<li><strong>描述</strong>：通过利用TLS压缩功能，攻击者可以猜测敏感数据（如会话Cookie）。</li>
<li><strong>修复</strong>：禁用TLS压缩功能。</li>
</ul>
<p><strong>POODLE（Padding Oracle On Downgraded Legacy Encryption）</strong></p>
<ul>
<li><strong>描述</strong>：POODLE 利用 SSL 3.0 中的填充漏洞进行攻击，针对使用CBC模式的实现。</li>
<li><strong>修复</strong>：废弃 SSL 3.0 并采用更安全的协议版本（如 TLS 1.2+）。</li>
</ul>
<p><strong>Downgrade Attacks</strong></p>
<ul>
<li><strong>描述</strong>：攻击者通过中间人攻击强制客户端和服务器降级到不安全的协议版本（如 SSL 3.0 或早期 TLS 版本）。</li>
<li><strong>修复</strong>：使用 <strong>TLS_FALLBACK_SCSV</strong> 标记防止协议降级攻击。</li>
</ul>
<p><strong>Logjam</strong></p>
<ul>
<li><strong>描述</strong>：Logjam 攻击利用 Diffie-Hellman 密钥交换中的弱参数（512位素数），允许攻击者破解加密。</li>
<li><strong>修复</strong>：升级到更强的密钥（2048位或以上），并禁用弱算法。</li>
</ul>
<hr>
<p><u><strong>实现上的漏洞</strong></u>：许多漏洞是由于TLS库实现中存在的错误或疏漏，而不是协议本身的问题。</p>
<p><strong>Heartbleed</strong></p>
<ul>
<li><strong>描述</strong>：这是 OpenSSL 的实现漏洞，允许攻击者通过 Heartbeat 扩展读取服务器内存中的敏感数据（如私钥）。</li>
<li><strong>修复</strong>：修复受影响的 OpenSSL 版本，更新到无漏洞的版本。</li>
</ul>
<p><strong>ROBOT（Return Of Bleichenbacher’s Oracle Threat）</strong></p>
<ul>
<li><strong>描述</strong>：利用某些TLS实现中的 RSA 加密模式缺陷，通过构造恶意数据包破解私钥。</li>
<li><strong>修复</strong>：修复实现并采用更安全的加密模式。</li>
</ul>
<p><strong>Zero-Length Padding</strong></p>
<ul>
<li><strong>描述</strong>：某些TLS实现接受零长度的填充，可能被攻击者利用进行漏洞利用。</li>
<li><strong>修复</strong>：严格遵循协议规范，确保填充字段符合要求。</li>
</ul>
<hr>
<p><u><strong>配置和使用上的问题</strong></u>：即使TLS协议和实现没有漏洞，不当的配置或使用也可能导致安全隐患。</p>
<p><strong>弱密码套件</strong></p>
<ul>
<li>使用已知不安全的加密算法或过短的密钥长度（如RC4或1024位RSA）。</li>
<li><strong>解决方法</strong>：禁用弱密码套件，使用推荐的安全算法（如 AES-GCM、ChaCha20-Poly1305）。</li>
</ul>
<p><strong>过期或伪造的证书</strong></p>
<ul>
<li>如果服务器使用过期、伪造或不可信的证书，攻击者可以进行中间人攻击。</li>
<li><strong>解决方法</strong>：确保证书可信且未过期，并使用 Certificate Transparency 来检测伪造证书。</li>
</ul>
<p><strong>主机名验证问题</strong></p>
<ul>
<li>一些TLS实现未正确验证证书中的主机名，可能导致攻击者伪装成合法服务器。</li>
<li><strong>解决方法</strong>：强制严格的主机名验证。</li>
</ul>
<p><strong>会话恢复漏洞</strong></p>
<ul>
<li>TLS会话恢复功能（如会话ID或会话票据）在设计或实现上可能存在漏洞，导致会话劫持。</li>
<li><strong>解决方法</strong>：确保会话恢复机制的实现安全，并定期刷新密钥。</li>
</ul>
<hr>
<p><u><strong>环境相关漏洞</strong></u></p>
<p><strong>硬件漏洞</strong></p>
<ul>
<li>硬件加速器或HSM（硬件安全模块）可能存在漏洞，攻击者可以利用其生成弱密钥或泄露数据。</li>
</ul>
<p><strong>随机数生成问题</strong></p>
<ul>
<li>如果随机数生成器的质量不足，攻击者可能预测到密钥。</li>
<li><strong>解决方法</strong>：使用高质量的随机数生成器（如 /dev/urandom 或硬件随机数生成器）。</li>
</ul>
<p><strong>中间人攻击</strong></p>
<ul>
<li>攻击者通过篡改DNS或ARP欺骗迫使客户端连接到恶意服务器，伪装成合法的TLS服务。</li>
<li><strong>解决方法</strong>：使用 HSTS（HTTP Strict Transport Security）和证书锁定（Certificate Pinning）。</li>
</ul>
<hr>
<p><u><strong>社会工程和弱安全操作</strong></u>：即使TLS协议本身非常安全，攻击者可能利用社会工程或操作疏漏来绕过安全机制</p>
<ul>
<li>攻击者诱骗用户接受不可信的证书。</li>
<li>管理员错误配置服务器，允许使用过时的协议版本。</li>
</ul>
<hr>
<h4 id="如何应对TLS漏洞？"><a href="#如何应对TLS漏洞？" class="headerlink" title="如何应对TLS漏洞？"></a>如何应对TLS漏洞？</h4><ol>
<li><strong>升级协议和实现</strong><ul>
<li>确保使用最新版本的TLS（推荐TLS 1.2或TLS 1.3）。</li>
<li>定期更新TLS库（如OpenSSL、BoringSSL、GnuTLS）。</li>
</ul>
</li>
<li><strong>禁用弱配置</strong><ul>
<li>禁用SSL 2.0、SSL 3.0和TLS 1.0。</li>
<li>禁用RC4和其他已知不安全的密码套件。</li>
</ul>
</li>
<li><strong>安全的服务器配置</strong><ul>
<li>强制使用强加密算法。</li>
<li>使用2048位以上的密钥和推荐的椭圆曲线（如 P-256）。</li>
</ul>
</li>
<li><strong>监控和检测</strong><ul>
<li>定期扫描服务器的TLS配置，使用工具如 SSL Labs 的服务器测试工具。</li>
<li>监控网络流量中的潜在攻击行为。</li>
</ul>
</li>
</ol>
<h3 id="TLS-1-3"><a href="#TLS-1-3" class="headerlink" title="TLS 1.3"></a>TLS 1.3</h3><p><img src="https://cdn.xiaolincoding.com//mysql/other/0877fe78380bf34ad3b28768e59fb53a.png" alt="图片"></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/28850798">TLS 1.3科普——新特性与协议实现 - 知乎</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/187262056">TLS 1.3 进行时 - 知乎</a> </p>
<h4 id="2-RTT（TLS-1-2）"><a href="#2-RTT（TLS-1-2）" class="headerlink" title="2-RTT（TLS 1.2）"></a>2-RTT（TLS 1.2）</h4><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/wusanga/p/17386098.html">TLS1.2握手流程分析（RSA，ECDHE），和TLS1.3区别 - wuworker - 博客园</a> </p>
<p><img src="https://pic2.zhimg.com/v2-485b564d2209a3108575a1b13a52d715_1440w.jpg" alt="img"></p>
<h4 id="1-RTT"><a href="#1-RTT" class="headerlink" title="1-RTT"></a>1-RTT</h4><p>TLS1.2 为了考虑各种兼容性，保留了许多加密套件，这就使得客户端必须提前和服务端协商好用哪一种加密套件，这也导致了必须空出一个RTT专门协商，因此变成2-RTT。1.3只剩下5种，省去协商步骤，变成了1-RTT。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">TLS_AES_256_GCM_SHA384</span><br><span class="line">TLS_CHACHA20_POLY1305_SHA256</span><br><span class="line">TLS_AES_128_GCM_SHA256</span><br><span class="line">TLS_AES_128_CCM_8_SHA256</span><br><span class="line">TLS_AES_128_CCM_SHA256</span><br></pre></td></tr></table></figure>

<p>TLS 1.3 在之前版本的基础上删除了那些不安全的加密算法，这些加密算法包括：</p>
<ul>
<li>RSA 密钥传输 —— 不支持前向安全性</li>
<li>CBC 模式密码 —— 易受 BEAST 和 Lucky 13 攻击</li>
<li>RC4 流密码 —— 在 HTTPS 中使用并不安全</li>
<li>SHA-1 哈希函数 —— 建议以 SHA-2 取而代之</li>
<li>任意 Diffie-Hellman 组—— CVE-2016-0701 漏洞</li>
<li>输出密码 —— 易受 FREAK 和 LogJam 攻击</li>
</ul>
<p>TLS 1.3 只支持<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%AE%A4%E8%AF%81%E5%8A%A0%E5%AF%86">AEAD认证模式</a> 同时完成加密和完整性校验，不再允许对加密报文进行压缩、不再允许双方发起重协商，密钥的改变不再需要发送change_cipher_spec报文给对方。对称加密算法只有AES，Chacha20，摘要算法只有 SHA，密钥交换算法只有ECDHE。</p>
<p><img src="https://pic2.zhimg.com/v2-91669b8728eb5b0fa2d88730425f9391_1440w.jpg" alt="img"></p>
<h4 id="0-RTT"><a href="#0-RTT" class="headerlink" title="0-RTT"></a>0-RTT</h4><p><img src="https://pic4.zhimg.com/v2-083c00146d71e75adbcab401e57c90e1_1440w.jpg" alt="img"></p>
<p><img src="https://cdn.xiaolincoding.com//mysql/other/59539201f006d7dc0a06333617e5ea85.png" alt="图片"></p>
<h2 id="HTTPS-优化（TLS-性能优化）"><a href="#HTTPS-优化（TLS-性能优化）" class="headerlink" title="HTTPS 优化（TLS 性能优化）"></a><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1420297">HTTPS 优化（TLS 性能优化）</a></h2><p>上文的TLS漏洞已经说明了提高安全性的措施，下列措施为提高TLS性能的措施</p>
<h3 id="硬件优化"><a href="#硬件优化" class="headerlink" title="硬件优化"></a>硬件优化</h3><ul>
<li>计算密集型任务，升级的是<strong>CPU</strong>而不是网卡等IO设备，如果CPU有针对 <strong>AES-NI</strong> 的特性，可以使用AES，否则可以选择chacha20</li>
</ul>
<h3 id="软件优化"><a href="#软件优化" class="headerlink" title="软件优化"></a>软件优化</h3><ul>
<li>升级Linux，升级OpenSSL</li>
</ul>
<h3 id="协议优化：节省RTT"><a href="#协议优化：节省RTT" class="headerlink" title="协议优化：节省RTT"></a>协议优化：节省RTT</h3><p>（整体的握手过程还是需要的）</p>
<ul>
<li><strong>密钥交换算法</strong>：使用<code>ECDHE</code>而不是<code>RSA</code>，<code>ECDHE</code>支持前向安全，因此也支持 <code>TLS False Start</code>，发送ClientKeyExchange的同时可以开始发送<code>application data</code>节省 <code>1 RTT</code>。</li>
<li><strong>升级TLS版本</strong>：TLS 1.3 相比于 TLS 1.2 废除了不安全的加密套件，总数变少，因此不需要协商套件的过程，可以节省<code>1 RTT</code>。</li>
</ul>
<h3 id="证书优化：节省客户端验证时间"><a href="#证书优化：节省客户端验证时间" class="headerlink" title="证书优化：节省客户端验证时间"></a>证书优化：节省客户端验证时间</h3><ul>
<li><strong>证书类型</strong>：在相同的安全强度下，<code>ECDSA</code> 椭圆曲线证书相比于 <code>RSA</code> 证书的密钥长度减少很多，减少了验证证书完整性的时间。</li>
<li><strong>证书验证流程</strong>：验证证书信任链的时候，<code>OCSP</code> 相比于 <code>CRL</code> 实时性更高，不用逐行读取文件；<ul>
<li>进一步提升性能可以启用<code>OCSP Stapling</code>，服务器周期性地向 CA 获取证书状态，CA会在状态上签名防止篡改，在发出ServerHello的同时也把有效信息发给客户端。</li>
</ul>
</li>
</ul>
<h3 id="会话复用：复用会话密钥"><a href="#会话复用：复用会话密钥" class="headerlink" title="会话复用：复用会话密钥"></a>会话复用：复用会话密钥</h3><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/mrpre/article/details/77868669">TLS/SSL 协议详解 (22)会话复用_ssl会话复用-CSDN博客</a> 抓包</p>
<p><strong>以下技术都是建立在已经建立过一次连接的基础上的，可以节省第一次以后会话的RTT，是用来免去握手过程的</strong></p>
<ul>
<li><strong>Session ID</strong>：将与每个客户端的会话密钥缓存在服务器内存里，形成 id-key的键值对形式，ClientHello带上session id，节省<code>1 RTT</code>，缺点是不支持分布式和消耗服务器内存。</li>
</ul>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/sessionid.png" alt="img"></p>
<ul>
<li><strong>Session Ticket</strong>：服务器可以将会话密钥再次用<strong>只有自己知道的密钥</strong>加密，然后附上有效期进行签发，以session ticket的形式交给客户端进行缓存，ClientHello带上ticket，服务器验证有效期（类似JWT）也能节省 <code>1 RTT</code> ，分布式之间需要共享这个密钥。</li>
</ul>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/ticket.png" alt="img"></p>
<ul>
<li><strong>Pre-shared Key</strong>：TLS 1.3 引入的新特性，将 Session Ticket 和 早期的 application data 一并发送给服务器 直接变成<code>0-RTT</code> ，因为不用协商套件。</li>
</ul>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8.assets/image-20241130172210036.png" alt="image-20241130172210036"></p>
<p>会话复用会影响前向安全性，还可能会受到重放攻击，解决方案：</p>
<ul>
<li>只对幂等请求（GET）开放0-RTT；</li>
<li>对session ticket添加有效期；</li>
</ul>
<h1 id="SSH"><a href="#SSH" class="headerlink" title="SSH"></a>SSH</h1><p><strong><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/Secure_Shell">SSH</a> （Secure Shell）</strong> 基于 TCP 协议，通过加密和认证机制实现安全的访问和文件传输等业务。</p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV13P4y1o76u">SSH 握手详解 - bilibili 技术蛋老师</a> </p>
<p>SSH 的经典用途是登录到远程电脑中执行命令。除此之外，SSH 也支持隧道协议、端口映射和 X11 连接（允许用户在本地运行远程服务器上的图形应用程序）。借助 SFTP（SSH File Transfer Protocol） 或 SCP（Secure Copy Protocol） 协议，SSH 还可以安全传输文件。</p>
<p>SSH 使用客户端-服务器模型，默认端口是 22。SSH 是一个守护进程，负责实时监听客户端请求，并进行处理。大多数现代操作系统都提供了 SSH。</p>
<p>如下图所示，SSH Client（SSH 客户端）和 SSH Server（SSH 服务器）通过公钥交换生成共享的对称加密密钥，用于后续的加密通信。</p>
<p><img src="https://oss.javaguide.cn/github/javaguide/cs-basics/network/ssh-client-server.png" alt="SSH:安全的网络传输协议"></p>
<p>SSH以<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86">非对称加密</a>实现<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%BA%AB%E4%BB%BD%E9%AA%8C%E8%AF%81">身份验证</a>：</p>
<p>身份验证有多种途径，例如其中一种方法是使用自动生成的公钥-私钥对来简单地加密网络连接，随后使用密码认证进行登录；另一种方法是人工生成一对公钥和私钥，通过生成的密钥进行认证，这样就可以在不输入密码的情况下登录。任何人都可以自行生成密钥。公钥需要放在待访问的电脑之中，而对应的私钥需要由用户自行保管。认证过程基于生成出来的私钥，但整个认证过程中私钥本身不会传输到网络中。</p>
<h1 id="IPsec"><a href="#IPsec" class="headerlink" title="IPsec"></a>IPsec</h1><img src="https://download.huawei.com/mdl/image/download?uuid=17c579f40e0b440e98a35544fcbbd3dc" alt="IPsec加密验证过程" style="zoom:150%;" />


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://scatteredream.github.io/2025/01/10/L3%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars.githubusercontent.com/u/62317679?s=400&v=4">
      <meta itemprop="name" content="碎梦">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="scatteredream's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | scatteredream's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/01/10/L3%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82/" class="post-title-link" itemprop="url">传输层</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-01-10 00:00:00" itemprop="dateCreated datePublished" datetime="2025-01-10T00:00:00+08:00">2025-01-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-05-03 20:59:50" itemprop="dateModified" datetime="2025-05-03T20:59:50+08:00">2025-05-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%A1%E7%BD%91/" itemprop="url" rel="index"><span itemprop="name">计网</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>LAB：<a target="_blank" rel="noopener" href="https://media.pearsoncmg.com/ph/esm/ecs_kurose_compnetwork_8/cw/">Student Resources | Kurose/Ross, Computer Networking: a Top-Down Approach, 8/e</a> </p>
<h1 id="端口"><a href="#端口" class="headerlink" title="端口"></a>端口</h1><h2 id="port"><a href="#port" class="headerlink" title="port"></a>port</h2><p>0-65536 TCP Header中为16位无符号整数</p>
<p>IP地址能够标识主机，但是通信是由主机中的应用进程发起和接收的，必须让应用进程拥有一个标识，而本地进程ID（PID）在各个OS之间并不统一（因为要写入TCP头部，而各个OS发送的TCPHeader必须统一），如果是给特定的应用进程分配一个特定的ID，显然也不行，因为通信双方并不必须知道对方的真正身份，因此，最后的结果就是在传输层和应用层的界面上开一些特定的“门”，进程需要的时候就分配给他，这就是软件端口（port）的由来。</p>
<h3 id="服务器端口号"><a href="#服务器端口号" class="headerlink" title="服务器端口号"></a>服务器端口号</h3><ul>
<li>1-1023: 标准规定的应用强制占用。</li>
</ul>
<table>
<thead>
<tr>
<th>HTTP</th>
<th>HTTPS</th>
<th>DNS</th>
<th>RIP</th>
<th>BGP</th>
<th>Telnet</th>
<th>FTP</th>
<th>SMTP</th>
<th>SSH</th>
<th>RMI</th>
</tr>
</thead>
<tbody><tr>
<td>80</td>
<td>443</td>
<td>53</td>
<td>520</td>
<td>179</td>
<td>23</td>
<td>21</td>
<td>25</td>
<td>22</td>
<td>111</td>
</tr>
</tbody></table>
<ul>
<li>1024-49151: 登记端口。</li>
</ul>
<h3 id="客户端端口"><a href="#客户端端口" class="headerlink" title="客户端端口"></a>客户端端口</h3><ul>
<li><p>49152-65535(16384个): 客户端发起connect动态分配，属于临时端口号，断开连接或者通信结束就会收回。</p>
</li>
<li><p>一些系统中可能会出现超过65536的情况，但是由于TCP Header的限制，必须要对端口号 % 65536</p>
</li>
</ul>
<h4 id="如何提高服务器并发能力"><a href="#如何提高服务器并发能力" class="headerlink" title="如何提高服务器并发能力"></a>如何提高服务器并发能力</h4><p>一般来讲，通过增加服务器内存、修改最大FD个数等，可以做到单台服务器支持10万+的TCP并发。当然，在真实的商用场景下，单台服务器都会编入<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=231771466&content_type=Article&match_order=1&q=%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4&zhida_source=entity">分布式集群</a>，通过负载均衡算法动态的调度不同用户的请求给最空闲的服务器，如果服务器平均内存使用超过80%的警戒线，那么就会及时采用限流或者扩展集群的方式来保证服务，绝对不会出现服务器的内存被耗尽的情况，那样就算事故了。</p>
<h2 id="TCP-UDP绑定相同端口"><a href="#TCP-UDP绑定相同端口" class="headerlink" title="TCP UDP绑定相同端口"></a>TCP UDP绑定相同端口</h2><p>IP数据报中的协议字段可以区分TCP还是UDP，因此靠这个字段就能将IP数据报准确交给对应的协议软件实现，然后软件根据抽象的端口找到应用进程，两个协议的端口并不是一个域。</p>
<h2 id="多个TCP-服务进程绑定相同端口"><a href="#多个TCP-服务进程绑定相同端口" class="headerlink" title="多个TCP 服务进程绑定相同端口"></a>多个TCP 服务进程绑定相同端口</h2><p>IP不同，端口相同，也是可以的。</p>
<p>0.0.0.0:8888 表示监听所有IP地址的8888端口</p>
<h2 id="客户端端口的复用"><a href="#客户端端口的复用" class="headerlink" title="客户端端口的复用"></a>客户端端口的复用</h2><p>可以，因为TCP连接有4个元素才能唯一确定，只要有一个不一样就是不同的TCP连接</p>
<h1 id="UDP"><a href="#UDP" class="headerlink" title="UDP"></a>UDP</h1><p><a target="_blank" rel="noopener" href="https://xiaolincoding.com/network/3_tcp/quic.html">4.17 如何基于 UDP 协议实现可靠传输？ | 小林coding</a> </p>
<p>User Datagram Protocol 用户数据报协议</p>
<h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><ul>
<li><strong>无连接</strong>：传输数据之前不需要建立起连接，直接发送即可，可以是一对一，多对一，一对多，多对多。</li>
<li><strong>不可靠</strong>：可能出现差错，丢失，重复，不能保证按序到达，也就是<strong>尽最大努力交付</strong>，这也使得首部开销比较小。</li>
<li><strong>面向数据报</strong>：无论应用层交给 UDP 多长的报文，UDP 都照样发送，即一次发送一个报文。对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的边界。而接收方在接收数据报的时候，也不会像面对 TCP 无穷无尽的二进制流那样不清楚啥时候能结束。</li>
<li>没有拥塞控制</li>
</ul>
<p>优点还有可扩展性强：TCP实现固化在操作系统中，有时性能可能不能满足部分需求，开发者可以利用UDP的特性，在应用层实现可靠传输，比如QUIC协议</p>
<h2 id="UDP-Datagram"><a href="#UDP-Datagram" class="headerlink" title="UDP Datagram"></a>UDP Datagram</h2><p>总长度8B，源端口和目的端口各占2B，然后是UDP的PDU长度（2B），最后是检验和（2B）。</p>
<ul>
<li><strong>udp长度</strong>：max: 65535B min: 8B 整个UDP数据报的长度</li>
<li><strong>检验和</strong>：添加伪首部[<strong>源IP</strong>(4B), <strong>目的IP</strong>(4B), <strong>全0</strong>(1B), <strong>17</strong>[1B,表示UDP协议类型], <strong>UDP长度</strong>(2B)]，计算检验和先将检验和位置0，然后将添加了伪首部的<strong>整个UDP数据报</strong>划分成若干个16位字，不够补零，最后将这些字按位相加，高位进位溢出进到低位，最后取反码放到检验和。IP packet只检验首部，而UDP datagram全部都检验。</li>
</ul>
<table>
<thead>
<tr>
<th>源端口</th>
<th>目的端口</th>
<th>UDP数据报长度</th>
<th>检验和</th>
</tr>
</thead>
<tbody><tr>
<td>2B</td>
<td>2B</td>
<td>2B</td>
<td>2B</td>
</tr>
</tbody></table>
<p>如果UDP发现检验和不正确，就直接丢弃数据报</p>
<p>如果UDP发现目的端口不准确，就丢弃数据报，随后由ICMP发送一条“终点不可达”的差错报告报文（traceroute）</p>
<h1 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h1><p>Transmission Control Protocol，传输控制协议</p>
<h2 id="特点-1"><a href="#特点-1" class="headerlink" title="特点"></a>特点</h2><ul>
<li><strong>面向连接</strong>：传输数据之前必须建立起双方的连接，传输完双方应该断开连接，只能是点对点通信。</li>
<li><strong>可靠</strong>：通过TCP传送的数据，无差错，不丢失，不重复，按序到达，这也使得首部开销比较大。</li>
<li><strong>全双工</strong>：双方可以同时收发信息，设有接收和发送缓冲区</li>
<li><strong>面向字节流</strong>：将应用层交下来的数据不是以<strong>消息报为单位</strong>向目的主机发送，而是看作无结构的字节流，TCP不懂字节流的含义是什么，这些数据可能被<strong>切割和组装</strong>成各种数据包，但是发送者发出的字节流和接受者收到的字节流必须一样，并且应用能够正确识别这些无意义字节流的含义，将其还原为有意义的应用层数据。接收端收到这些数据包后没有正确还原原来的消息，就会有“粘包”的现象。</li>
</ul>
<h2 id="可靠传输协议：ARQ"><a href="#可靠传输协议：ARQ" class="headerlink" title="可靠传输协议：ARQ"></a>可靠传输协议：ARQ</h2><p>ARQ（Automatic Repeat reQuest，自动重传请求）是计算机网络中用于确保数据可靠传输的一种关键技术。它主要通过确认（ACK）和超时重传两种机制，在不可靠的网络服务上实现可靠的数据传输。当发送方在一定时间内未收到确认帧时，它会自动重发数据包，直到收到确认为止。ARQ协议分为<strong>停止等待ARQ</strong>和<strong>连续ARQ</strong>两种类型，每种都有其特定的应用场景和优缺点。</p>
<ol>
<li>ARQ是一种可以在不可靠的数据通道上可靠地传输数据的方案，所以其实链路层和传输层都用了ARQ，并不专属某一层。</li>
<li>并不是一条连接只要有一层用了ARQ，它的上层的通信就是可靠的。因为ARQ只保证使用它的点到点是可靠的，比如数据链路层只保证你和你的路由器通信可靠，你的路由器到小区的路由器通信也可靠， 但是路由器本身会故障，会拥塞丢包，也就是点本身会产生问题。</li>
<li>所以需要在传输层或者应用层再加一层ARQ保障整条数据通道的可靠性。比如你自己写程序要在应用层通信，但传输层不用tcp想用udp，也可以在你程序里用ARQ协来实现可靠性。</li>
<li><strong>注意：</strong> 在发送完一个分组后，必须暂时保留已发送的分组的副本，以备重发。<ul>
<li>分组和确认分组都必须进行编号。</li>
<li>超时计时器的重传时间应当比数据在分组传输的平均往返时间更长一些。</li>
</ul>
</li>
</ol>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/L3%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82.assets/image-20241203213134835.png" alt="image-20241203213134835"></p>
<h3 id="停止-等待ARQ的逐步优化"><a href="#停止-等待ARQ的逐步优化" class="headerlink" title="停止-等待ARQ的逐步优化"></a>停止-等待ARQ的逐步优化</h3><h4 id="v2-x"><a href="#v2-x" class="headerlink" title="v2.x"></a>v2.x</h4><h5 id="v2-0：给数据包加上校验和，防止数据包出现比特差错"><a href="#v2-0：给数据包加上校验和，防止数据包出现比特差错" class="headerlink" title="v2.0：给数据包加上校验和，防止数据包出现比特差错"></a>v2.0：给数据包加上校验和，防止数据包出现比特差错</h5><ul>
<li>2.0的第一个问题：<strong>接收方的ACK可能有比特差错</strong></li>
<li>2.0的第二个问题：<strong>发送方未正确接收ACK直接重发，接收方不会区分是不是重传的包，导致交给上层重复的数据。</strong></li>
</ul>
<h5 id="v2-1如何解决v2-0问题？"><a href="#v2-1如何解决v2-0问题？" class="headerlink" title="v2.1如何解决v2.0问题？"></a>v2.1如何解决v2.0问题？</h5><ol>
<li><strong>给ACK加一个校验和。</strong></li>
</ol>
<ul>
<li>发送方收到ACK，说明是接收方正确收到了，发送下一个数据包。</li>
<li>发送方收到NAK或者校验和出错的包，选择重发这个数据包。</li>
</ul>
<p>此时还没有解决第二个问题，接收方正常接收发出ACK，如果发送方收到一个校验和错误的响应（本来应该是ACK）然后重传，但是接收方会把重传的包当成全新的，这样就导致了重复的问题。</p>
<ol start="2">
<li><strong>在不丢包的情况下，给数据包附上一bit标识符，让接收方区分是否为重发的数据包。</strong></li>
</ol>
<ul>
<li>发送方发的时候就注明是0号数据包，接收方鉴别无误就可以转换到准备接收下一个数据包的状态并发送ACK，如果发送方收到了ACK，皆大欢喜继续发下一个数据包</li>
<li>如果发送方并未正确收到ACK，则需要重发此包，而接收方早就转换到准备接收新数据包的状态了，再次接收到旧数据包直接选择丢弃，但也要记得再发一下ACK，提醒发送者可以发送新数据包了。</li>
</ul>
<h5 id="v2-2：改善接收方的响应结构"><a href="#v2-2：改善接收方的响应结构" class="headerlink" title="v2.2：改善接收方的响应结构"></a>v2.2：改善接收方的响应结构</h5><p><strong>去除NAK，在ACK内部用一个比特位表示ACK或者NAK</strong></p>
<ul>
<li>接收方准备接收0号，如果出错，则发送ACK<del>1</del>，发送方仍处于等待ACK<del>0</del>的状态，收到的只要不是ACK<del>0</del>，就会重发。</li>
<li>接收方准备接收0号，如果正确，则发送ACK<del>0</del>，准备接收新数据包，而发送方如果没有正确收到这个ACK<del>0</del>，会再次重发，这时候接收方会再次发送ACK<del>0</del>让发送方知晓 上个数据包已经被正确接收，提醒发送者可以开始新数据包，然后把这个重复的丢弃。</li>
</ul>
<h5 id="v2-x的问题"><a href="#v2-x的问题" class="headerlink" title="v2.x的问题"></a>v2.x的问题</h5><p>如果<strong>数据包丢了</strong>，接收方收不到自然也谈不上响应，再如果，<strong>响应丢了</strong>，<strong>响应迟到了</strong>，发送者就会陷入空等状态</p>
<h4 id="v3-0：比特交换协议"><a href="#v3-0：比特交换协议" class="headerlink" title="v3.0：比特交换协议"></a>v3.0：比特交换协议</h4><p>可靠的传输协议，也叫比特交换协议，在在v2可以解决丢包和迟到的问题。</p>
<ol>
<li>从<strong>发送方角度</strong>考虑，<strong>把超时作为重传的唯一根据</strong>。</li>
</ol>
<ul>
<li><p>如果在准备接收ACK<del>1</del>的情况下收到<strong>错误响应</strong>（ACK<del>0</del>或者校验和错误），则什么也不做，等待超时重发</p>
</li>
<li><p>发出分组即启动timer，一定时间内没有收到<strong>正确的响应</strong>到了timeout，则重发并重启timer；</p>
</li>
<li><p><strong>收到正确的响应</strong>就停止timer，转换到准备发下一个分组的状态，如果有这个如果这时有响应发来，肯定是迟到的响应，不予理会。</p>
</li>
</ul>
<ol start="2">
<li>因为有传播时延和排队处理时延，所以可能会出现过早超时然后重发的情况</li>
</ol>
<ul>
<li><p>接受者的角度肯定是收到1，ACK<del>1</del>然后准备接收0，这时候再次接到1，此时回答一个ACK<del>1</del>，然后丢弃重复的1。</p>
</li>
<li><p>发送者如果在等待上方传下来数据的情况下收到了响应，说明这肯定是一个迟到的响应，不予理会。</p>
</li>
</ul>
<p>v3总结：</p>
<p>发一个数据包，等对应的ACK，超时了就重发，必须且只能收到一次对应的ACK，收到就转变状态不等了，来再多也没用。</p>
<h5 id="v3-0的问题"><a href="#v3-0的问题" class="headerlink" title="v3.0的问题"></a>v3.0的问题</h5><ul>
<li>时间利用上不如v2，但是基于时间的重传和基于ACK比特位的重传是冲突的，因此问题不算大。</li>
<li>最根本的还是停止等待对时间资源的浪费。</li>
</ul>
<h3 id="Go-Back-N（回退N步）：流水线式的发送与接收"><a href="#Go-Back-N（回退N步）：流水线式的发送与接收" class="headerlink" title="Go Back N（回退N步）：流水线式的发送与接收"></a>Go Back N（回退N步）：流水线式的发送与接收</h3><p>Go Back N：发送窗口，累计确认，超时重传。</p>
<p><strong>发送方</strong>：</p>
<ol>
<li>维护一个发送窗口(N)，用来限制一次最多发送的包数目，基于超时重传</li>
</ol>
<ul>
<li>在窗口以前的默认已经成功发送了(0-base)，窗口内部有的已经发送处于等待响应的状态(base-nextseqnum)，有的还没有发送过(nextseqnum+1 - base+N-1)。</li>
<li>应用层传下来的data，如果分配到的序号超过窗口，拒绝（或者缓存一下），在窗口内，填到nextseqnum++处。</li>
<li>在发送窗口中的包，发送base时start timer，一直把从base到nextseqnum的包都发出去，如果timeout就把这些包全部重发一遍。</li>
</ul>
<ol start="2">
<li>接收ACK</li>
</ol>
<ul>
<li>根据ACK中的编号滑动窗口边缘(base=getacknum+1) 这里的ACK包含的序号是接收方封装的，接收方的逻辑可以保证此序号之前的全部正确传输。</li>
<li>如果滑动窗口之后，base = nextseqnum 说明窗口内已经没有要发送的分组，stop timer，如果还有，那就restart timer，继续等待。</li>
</ul>
<p><strong>接收方</strong>：</p>
<ol>
<li><strong>累计确认</strong>：只需要维护一个序号expectedseqnum，顾名思义，接收方必须按序ACK，按序递交给上层。</li>
</ol>
<ul>
<li>收到的包确实是自己想要的，于是就发一个ACK<del>expectedseqnum</del>，随后递交给应用层，然后ex…num自增，表明自己要接收下一个包<ul>
<li>假定ACK响应中的序号N，对于接收方来说序号&lt;=N的全部正确递交给上层了。</li>
</ul>
</li>
<li>没有收到自己想要的包，就丢弃，并把上次制作好的ACK重新发送，提醒发送方该滑动窗口了。（<strong>可能是因为发送方没有正确识别ACK造成的冗余分组</strong>）</li>
</ul>
<p>意味着即使之前已经接受过正确的分组也要丢弃，expectedseqnum之后的情况是未知的，因此只能回退重传。</p>
<p>单个分组的错传，会引起之后的大量分组重传。</p>
<h3 id="Selective-Repeat（选择重传）：无需按序ACK，不累计确认"><a href="#Selective-Repeat（选择重传）：无需按序ACK，不累计确认" class="headerlink" title="Selective Repeat（选择重传）：无需按序ACK，不累计确认"></a>Selective Repeat（选择重传）：无需按序ACK，不累计确认</h3><p>Selective Repeat 特点：接收窗口，乱序ACK，按序交付上层</p>
<p>接收方不丢弃正确的乱序分组，而是先进行ACK然后缓存，并不直接交给上层。</p>
<ul>
<li>对于发送方来说，对方对base序号的ACK是发送窗口滑动的唯一标准。</li>
<li>对于接收方来说，成功按序递交给上层是接收窗口滑动的唯一标准。</li>
</ul>
<p><strong>发送方</strong>：</p>
<ol>
<li>维护发送窗口：</li>
</ol>
<ul>
<li>对于应用层传下来的数据，仍然不变。</li>
<li>在发送窗口的包，为每一个包都设置一个timer，单独计时。</li>
</ul>
<ol start="2">
<li>接收ACK：</li>
</ol>
<ul>
<li>ACK对应编号标记为已ACK，</li>
<li>如果ACKnum = send_base，则说明可以移动了，移动到第一个未ACK的序号处<ul>
<li>例子：窗口变成OOOOXXXXOXX，则滑动后的窗口为XXXXOXXXXXX</li>
</ul>
</li>
</ul>
<p><strong>接收方</strong>：可以不按序ACK，但是递交给上层需要按序，维护一个接收窗口</p>
<ul>
<li>序号在窗口里面的，没问题的就发个ACK<ul>
<li>失序的（在窗口中间的）先缓存好，等于rcv_base则准备交付给应用层，将从rcv_base开始所有缓存好的包 连续、按序交给应用层</li>
</ul>
</li>
</ul>
<p><strong>冗余分组</strong>：</p>
<p>对于接收者来说，ACKnum=rcv_base就可以开始滑动了，表明rcv_base之前的数据肯定已经正确交付给应用层了，但是并不能保证这个ACK就一定能被正确解析，因此发送窗口可能会迟迟不滑动导致一直重传（冗余分组）</p>
<ul>
<li>如果序号是[base-N 到 base-1]的，即使之前ACK过了，也还是会回复ACK，不断尝试提醒发送方滑动发送窗口。</li>
</ul>
<h4 id="窗口注意事项"><a href="#窗口注意事项" class="headerlink" title="窗口注意事项"></a>窗口注意事项</h4><ul>
<li><strong>接收窗口与发送窗口并不总是完全的同步，可能会错开一部分，不过接收窗口的base也不会完全超过发送窗口，毕竟如果还没发送，也就谈不上接收过了。</strong></li>
</ul>
<ul>
<li><p><strong>序号范围与窗口大小</strong>序号是循环利用的，如果窗口太大，序号范围太小，就有可能发生重传的分组被当成是新分组的情况</p>
<ul>
<li><p>序号是0~3 窗口大小为3，0 1 2 ACK过了传给上层，接收窗口滑动变成 3 0 1</p>
</li>
<li><p>ACK没有被正确接收，因此0,1,2重传，此时0和1就被当成是<strong>全新</strong>的数据了。</p>
</li>
</ul>
</li>
</ul>
<p><strong>窗口大小与序号的关系计算</strong></p>
<p>假设序号0-N-1，窗口大小为M，M &lt;= N 发送窗口为序号0到M-1</p>
<ul>
<li>对于SR来说，最坏的情况，接收窗口为序号M到M+M-1(一共M个)，而2M-1不能超过序号N-1，否则就会有上面的问题，因此$M\le \frac{N}{2}$ </li>
<li>对于GBN来说，窗口只有一个宽度，因此$M\le N-1$ </li>
</ul>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/L3%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82.assets/image-20241203204645293.png" alt="image-20241203204645293"></p>
<h3 id="可靠传输协议的关键"><a href="#可靠传输协议的关键" class="headerlink" title="可靠传输协议的关键"></a>可靠传输协议的关键</h3><ul>
<li><p>确认机制：没差错要ACK</p>
<ul>
<li>保证没有比特差错：分组和ACK都要有校验位。</li>
</ul>
</li>
<li><p>对于超时（未得到正确的ACK）重传</p>
<ul>
<li>发送时使用timer进行计时，超时则重传，</li>
<li>可能带来的冗余分组问题，要让接收方能分辨出冗余分组<ul>
<li>接收方如何对待冗余分组：发送者给分组添加序号，接收方根据序号分辨这是一个重传的还是新的分组。<ul>
<li>并且发出的ACK也要携带序号，提醒哪个分组被正确收到了</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>窗口、流水线发送：提高信道利用率</p>
<ul>
<li>窗口大小：窗口之间不同步（无法避免）但是窗口太大，导致重传分组被当做新的分组。</li>
</ul>
</li>
</ul>
<p>一个默认的假设：除了丢包，包并不会被重新排序。</p>
<p>而现实是传输层下方是不可靠信道，并不保证数据准确无误并且一定按序到达，因此应当将互联网看成是一个不定时发送的缓存，由于序号复用，这样可能会有相同序列号的分组出现在信道中，产生冲突。假定一个分组在网络中有TTL，超过TTL，序号就一定能够被再次使用。</p>
<h3 id="GBN-vs-SR"><a href="#GBN-vs-SR" class="headerlink" title="GBN vs SR"></a>GBN vs SR</h3><table>
<thead>
<tr>
<th>特性</th>
<th>GBN</th>
<th>SR</th>
</tr>
</thead>
<tbody><tr>
<td>重传策略</td>
<td>从丢失的分组开始，重新发送整个窗口</td>
<td>仅重传出错或超时的分组</td>
</tr>
<tr>
<td>接收端处理</td>
<td>按顺序接收分组，否则丢弃</td>
<td>接收乱序分组并缓存</td>
</tr>
<tr>
<td>计时器数量</td>
<td>1 个计时器</td>
<td>N 个计时器（每个分组一个计时器）</td>
</tr>
<tr>
<td>适用场景</td>
<td>高丢包率但传输顺序严格的环境</td>
<td>低丢包率，允许乱序接收的环境</td>
</tr>
<tr>
<td>发送窗口</td>
<td>N</td>
<td>N</td>
</tr>
<tr>
<td>接收窗口</td>
<td>1</td>
<td>N</td>
</tr>
</tbody></table>
<h4 id="Go-Back-N-GBN"><a href="#Go-Back-N-GBN" class="headerlink" title="Go-Back-N (GBN)"></a>Go-Back-N (GBN)</h4><ul>
<li><strong>特点</strong>：<ol>
<li>发送端最多可以连续发送 <strong>N 个未确认的分组</strong>。</li>
<li>如果在超时时间内没有收到某个分组的确认，应从该分组开始 <strong>重新发送其后所有分组</strong>。</li>
</ol>
</li>
<li><strong>计时器需求</strong>：<br>GBN 协议只需要一个 **==全局计时器==**，用于跟踪 <strong>最早发送但尚未确认的分组（窗口起点）</strong>。<ul>
<li>一旦计时器超时，直接 <strong>回退到该分组并重传整个窗口</strong>，不需要为每个分组单独计时。</li>
<li>原因是 GBN 要求分组必须 <strong>按顺序到达</strong>，只要有一个分组超时，所有后续分组都需要重发。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="Selective-Repeat-SR"><a href="#Selective-Repeat-SR" class="headerlink" title="Selective Repeat (SR)"></a>Selective Repeat (SR)</h4><ul>
<li><strong>特点</strong>：<ol>
<li>支持接收端 <strong>乱序接收</strong>，允许正确接收的分组先缓存。</li>
<li>发送端只重传超时或出错的分组，而不是整个窗口。</li>
</ol>
</li>
<li><strong>计时器需求</strong>：<br>由于 SR 可以 <strong>选择性重传特定分组</strong>，每个分组都需要一个 **==独立的计时器==**。<ul>
<li>如果某个分组超时，只重传该分组，而不影响其他分组。</li>
<li>因此，发送端必须为 <strong>窗口内的每个分组维护单独的计时器</strong>，以便精确控制每个分组的超时和重传行为。</li>
</ul>
</li>
</ul>
<h2 id="基于字节流"><a href="#基于字节流" class="headerlink" title="基于字节流"></a>基于字节流</h2><h3 id="数据包分片"><a href="#数据包分片" class="headerlink" title="数据包分片"></a>数据包分片</h3><ul>
<li>以太网帧总长度至少64B，数据负载不能超过MTU，首部+FCS 18 因此要求 IP数据报长度在 <code>46~1500</code>Byte</li>
</ul>
<ul>
<li><p>IP首部至少20B，因此传输层数据包为<code>26~1480</code> Byte</p>
</li>
<li><p>TCP首部20B TCP报文段的数据部分为<code>6~1460</code>Byte</p>
</li>
<li><p>UDP首部8B UDP数据报的数据部分为<code>18~1472</code>Byte</p>
</li>
<li><p>这些都是为了迎合以太网帧的帧大小限制。当超过了这个限制，就要对IP数据包进行分片。</p>
</li>
</ul>
<h3 id="UDP：无法在传输层分片"><a href="#UDP：无法在传输层分片" class="headerlink" title="UDP：无法在传输层分片"></a>UDP：无法在传输层分片</h3><p>超过了数据部分的大小只能通过IP进行分片，分多个IP数据报发送。</p>
<p>它并没有协商的能力，所以它只能直接把用户发送的数据，传给网络层（<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=105481550&content_type=Article&match_order=1&q=IP%E5%B1%82&zhida_source=entity">IP层</a>），由网络层来进行分片。</p>
<p>对 网络层（IP层）来说：它并不知道上层传过来的数据，到底是 TCP 还是 UDP，它并不关心也没有能力区分。</p>
<p>如果发现数据过大，那么 IP 层会自动对数据进行切割，分片。用 UDP 协议发送，那么如果网络发生了波动，丢失了某个 IP 包分片， 对于 UDP 而言， 它没有反馈丢失了哪个分片给发送方的能力，这就意味着：50k 的数据全都丢失了，如果需要重传，就得再次完整的传递这 50k 的数据。</p>
<blockquote>
<p>UDP 协议头有 2 byte 表示长度的字段。所以实际 UDP 数据包的长度不能超过65507字节（65,535 − 8字节UDP报头 − 20字节IP头部）</p>
<p>TCP 是<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=105481550&content_type=Article&match_order=1&q=%E6%B5%81%E6%95%B0%E6%8D%AE&zhida_source=entity">流数据</a>，没有该限制。</p>
</blockquote>
<p>而 TCP 只会重传这一个丢失的分片包。</p>
<p>所以如果一个应用采用 UDP 来通讯，一般都会特意控制下单个包体的大小，从而提高传输效率。</p>
<h3 id="TCP：可以在传输层协商自行分片"><a href="#TCP：可以在传输层协商自行分片" class="headerlink" title="TCP：可以在传输层协商自行分片"></a>TCP：可以在传输层协商自行分片</h3><h4 id="最大分段大小（Maxitum-Segment-Size-MSS）"><a href="#最大分段大小（Maxitum-Segment-Size-MSS）" class="headerlink" title="最大分段大小（Maxitum Segment Size, MSS）"></a>最大分段大小（Maxitum Segment Size, MSS）</h4><p>这里首先要说下：MSS（Maxitum Segment Size）最大分段大小，它是 TCP 协议里面的一个概念。</p>
<p>MSS 要保证一个TCP报文段，加上TCPIP首部长度以后，适合单个链路层帧。</p>
<p>TCP 在建立连接的时候，会协商双方的MSS值，通常这个 MSS 会控制在 MTU 以内：最大 IP 包大小减去 IP 和 TCP 协议头的大小。（其最终目的：<strong>就是尽量避免 IP 分片</strong>）1500-20-20 = 1460 </p>
<p>这样 TCP 就可以在自己这一层，把用户发送的数据，预先分成多个大小限制在 MTU 里的 TCP 包。每个 TCP 的分片包，都完整了包含了 TCP 头信息，方便在接收方重组。</p>
<blockquote>
<p>如果某些情况导致：已经分好的 TCP 分片，还是大于了 MTU，那就在 IP 层中，再执行一次分片。<br>这个时候如果数据丢了，那也只需要重传这一个 TCP 的分片，而不是整个原始的 50k 数据。</p>
</blockquote>
<p>而 IP（<a target="_blank" rel="noopener" href="https://datatracker.ietf.org/doc/html/rfc791#section-3.1">RFC 791</a>）中规定所有主机或路由器必须能够接受576字节以内的数据报，576字节以上不保证能接受，有一定可能会分片。<a target="_blank" rel="noopener" href="https://blog.csdn.net/BuquTianya/article/details/88136381">RFC791（IP协议）——协议格式_rfc 791-CSDN博客</a> </p>
<p>严格讲，这并非是协商出来一个统一的MSS值，TCP允许连接两端使用各自不同的MSS值。例如，这会发生在参与TCP连接的一台设备使用非常少的内存处理到来的TCP分组。</p>
<h4 id="基于字节流的解决方案"><a href="#基于字节流的解决方案" class="headerlink" title="基于字节流的解决方案"></a>基于字节流的解决方案</h4><p>应用层传到 TCP 协议的数据，不是以<strong>数据报为单位</strong>向目的主机发送，而是以<strong>字节流</strong>的方式发送到下游，这些数据可能被<strong>切割和组装</strong>成各种数据包，接收端（应用层）收到这些数据包后没有正确还原原来的消息，因此出现粘包现象。</p>
<p>正因为<strong>基于数据报</strong>和<strong>基于字节流</strong>的差异，<strong>TCP 发送端发 10 次字节流数据，而这时候接收端可以分 100 次去取数据，每次取数据的长度可以根据处理能力作调整；但 UDP 发送端发了 10 次数据报，那接收端就要在 10 次收完，且发了多少，就取多少，确保每次都是一个完整的数据报。</strong></p>
<p>根本原因是应用层不知道消息的边界在哪里，不知道字节流的开始和结束位置，错误地划分了数据包序列中间的边界</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/%E4%BC%A0%E8%BE%93%E5%B1%82.assets/image-20241127185012804.png" alt="image-20241127185012804"></p>
<ul>
<li>定长：FTP</li>
</ul>
<ul>
<li><p>分隔符：SMTP HTTP</p>
<p>可以通过特殊的标志作为头尾，比如当收到了<code>0xfffffe</code>或者回车符，则认为收到了新消息的头，此时继续取数据，直到收到下一个头标志<code>0xfffffe</code>或者尾部标记，才认为是一个完整消息。类似的像 HTTP 协议里当使用 <strong>chunked 编码</strong> 传输时，使用若干个 chunk 组成消息，最后由一个标明长度为 0 的 chunk 结束。</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/L3%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82.assets/image-20241127215347024.png" alt="image-20241127215347024"></p>
</li>
<li><p>TLV：HTTP Content-Length  WebSocket Protobuf Thrift</p>
<p>这个一般配合上面的特殊标志一起使用，在收到头标志时，里面还可以带上消息长度，以此表明在这之后多少 byte 都是属于这个消息的。如果在这之后正好有符合长度的 byte，则取走，作为一个完整消息给应用层使用。在实际场景中，HTTP 中的<code>Content-Length</code>就起了类似的作用，当接收端收到的消息长度小于 Content-Length 时，说明还有些消息没收到。那接收端会一直等，直到拿够了消息或超时，关于这一点<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzAwMDAxNjU4Mg==&mid=2247484204&idx=1&sn=0e83aabb2a48570b5bec563a777f4d26&scene=21#wechat_redirect">上一篇文章</a>里有更详细的说明</p>
<p>基于<a target="_blank" rel="noopener" href="https://search.bilibili.com/all?from_source=webcommentline_search&keyword=TLV&seid=7175035739223351950">TLV</a>的协议，接收段不断的检查Tag，如果收到tag就会去取length，这里面有一个点就是tag和length是定长的，比如tag是四个字符，length占4个字节。取到length以后就读取length个字节的<a target="_blank" rel="noopener" href="https://search.bilibili.com/all?from_source=webcommentline_search&keyword=value&seid=7175035739223351950">value</a>。理论上value后面接着的就是下一个tag</p>
</li>
</ul>
<p>Netty <strong>解决方案</strong></p>
<ul>
<li><p>定长解码器 <code>FixedLengthFrameDecoder</code> </p>
</li>
<li><p>分割字符解码器 <code>DelimeterBasedFrameDecoder</code></p>
</li>
<li><p>长度字段解码器 <code>LengthFieldBasedFrameDecoder</code></p>
</li>
</ul>
<h2 id="面向连接的-TCP-协议实现"><a href="#面向连接的-TCP-协议实现" class="headerlink" title="面向连接的 TCP 协议实现"></a>面向连接的 TCP 协议实现</h2><p>TCP连接可以由一个四元组（源IP, 源PORT, 目的IP, 目的PORT）唯一确定服务器的目的IP, 目的PORT一般是不会变化的，因此理论上TCP最大支持的连接数是 $2^{32} \times 2^{16} = 2^{48}$个，而TCP在linux系统中的实现用的是一个叫socket的编程接口实现的，socket本身就是一个文件，一个TCP连接就创建一个SOCKET FD因此还应该考虑服务器最大的内存大小。</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/L3%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82.assets/31b78572f43299995ba9b1b2988928c5.jpg" alt="31b78572f43299995ba9b1b2988928c5"></p>
<h3 id="TCP-Segment"><a href="#TCP-Segment" class="headerlink" title="TCP Segment"></a>TCP Segment</h3><p><img src="C:/Users/Lenovo/Pictures/markdownfile/L3%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82.assets/image-20241204212832687.png" alt="image-20241204212832687"></p>
<p>PSH = 1，数据不会缓存，立即交给上层（PUSH）</p>
<p>URG = 1，紧急数据指针指定了</p>
<h3 id="可靠传输（reliable-transmission）"><a href="#可靠传输（reliable-transmission）" class="headerlink" title="可靠传输（reliable transmission）"></a>可靠传输（reliable transmission）</h3><p>一个TCP报文段中的数据部分长度不能超过MSS，可以包含若干字节。</p>
<h4 id="累积确认（cumulative-acknowledgement）"><a href="#累积确认（cumulative-acknowledgement）" class="headerlink" title="累积确认（cumulative acknowledgement）"></a>累积确认（cumulative acknowledgement）</h4><p>在TCP中并无数据长度的说法，在接收端和发送端眼中数据是没有边界、没有长度、但<strong>有序</strong>的字节流，用序号来标识字节。</p>
<ul>
<li>TCP Segment中的<strong>序号</strong>（Seq）<strong>代表第一个字节在<u>发送端</u>的序号</strong>。<ul>
<li>初始序号可以是随机的</li>
</ul>
</li>
<li><u>发送者</u>用<strong>确认号</strong>（ACK）来提醒对方，<strong>自己下一个想要接收对方的Seq = ACK的字节</strong>。</li>
</ul>
<h5 id="按序接收"><a href="#按序接收" class="headerlink" title="按序接收"></a>按序接收</h5><p>TCP只记录第一个字节流是有序的，因此TCP也应按序接收，ACK = n，代表着序号n以前的数据都被正确接收。只确认到第一个丢失字节为止的位置。</p>
<p><strong>失序</strong>：回顾可靠传输协议GBN与SR，一个重要的区别就是SR对于失序的报文会选择先缓存再发送ACK，而GBN会直接丢弃，TCP的实现就是先保留，然后等待缺少的字节填补间隔</p>
<p><strong>捎带确认</strong>：发送数据方同时也可以是接收数据方，这样可以在携带数据的报文中捎带进行确认。比如 Telnet <code>echo</code> 功能中，服务端会把确认号装在回复给客户端的报文中，与此同时还运输了数据</p>
<p><strong>无数据的ACK报文</strong>：有的报文只是有一个确认的功能，没有带任何数据，但是Seq字段也不能空，所以还是会填Seq字段，只是一个逻辑上的标号</p>
<h4 id="超时重传（timeout-retransmission）"><a href="#超时重传（timeout-retransmission）" class="headerlink" title="超时重传（timeout retransmission）"></a>超时重传（timeout retransmission）</h4><ul>
<li><p>RTO（Retransmission Time Out）：重传超时时间，即从数据发送时刻算起，超过这个时间便执行重传。</p>
</li>
<li><p>RTO 的确定是一个关键问题，因为它直接影响到 TCP 的性能和效率。如果 RTO 设置得太小，会导致不必要的重传，增加网络负担；如果 RTO 设置得太大，会导致数据传输的延迟，降低吞吐量。因此，RTO 应该根据网络的实际状况，动态地进行调整。</p>
</li>
<li><p>RTT 的值会随着网络的波动而变化，所以 TCP 不能直接使用 RTT 作为 RTO。为了动态地调整 RTO，TCP 协议采用了一些算法，如加权移动平均（EWMA）算法，Karn 算法，Jacobson 算法等，这些算法都是根据往返时延（RTT）的测量和变化来估计 RTO 的值。</p>
</li>
<li><p>超时间隔是通过统计学加上适当的估计算出来的，但是必须大于 1 RTT+路由器处理时延。</p>
</li>
<li><p>不采用重传后的样本（Karn 算法）因为不知道这个ACK是对重传的ACK还是迟到的ACK，因此不统计重传的RTT</p>
</li>
<li><p>如果突然变得拥塞，导致大量超时重传，无法统计样本的RTT，造成RTT无法及时更新，因此每次重传都把RTO翻倍，也是一种拥塞控制的机制，防止过度阻塞</p>
</li>
</ul>
<h5 id="快速重传（fast-retransmit）"><a href="#快速重传（fast-retransmit）" class="headerlink" title="快速重传（fast retransmit）"></a>快速重传（fast retransmit）</h5><p>防止间隔加倍导致网络时延过大，<strong>乱序到达则发送冗余ACK</strong>，收到3次冗余ACK，就重传一次对应ACK序号的数据。</p>
<table>
<thead>
<tr>
<th>事件</th>
<th>TCP 接收方操作</th>
</tr>
</thead>
<tbody><tr>
<td>收到按顺序的分段，其序列号是接收方期望的。所有数据的序列号都小于或等于期望的序列号并已被确认。</td>
<td>延迟发送ACK。等待最多500毫秒以接收下一个按顺序到达的分段。如果在此时间间隔内未接收到下一个分段，则发送一个ACK。</td>
</tr>
<tr>
<td>收到按顺序的分段，其序列号是接收方期望的，并且有另一个按顺序的分段正在等待ACK发送。</td>
<td>立即发送单个累计ACK，确认两个按顺序的分段。</td>
</tr>
<tr>
<td>收到乱序的分段，其序列号大于期望的序列号。检测到数据的缺口（gap）。</td>
<td>立即发送冗余ACK，表明<strong>下一期望接收的字节的序列号</strong>（即<strong>缺口的起始序列号</strong>）。</td>
</tr>
<tr>
<td>收到的分段能够部分或完全填补接收数据中的缺口。</td>
<td>立即发送ACK，前提是该分段的起始序列号正好是<strong>缺口的起始序列号</strong>。</td>
</tr>
</tbody></table>
<p>GBN协议中，用变量expectedseqnum表示expectedseqnum以前的数据都已经正确接收， 接收方将不停发送具有expectedseqnum<del>1</del>的ACK（之前已经发过了，因此是冗余ACK），直到正确收到具有expectedseqnum<del>1</del>的数据。==GBN== </p>
<h5 id="选择重传-SACK"><a href="#选择重传-SACK" class="headerlink" title="选择重传 SACK"></a>选择重传 SACK</h5><p>改进的方法就是 SACK（Selective Acknowledgment），简单来讲就是在快速重传的基础上，<strong>返回最近收到的报文段的序列号范围</strong>，这样客户端就知道，哪些数据包已经到达服务器了。</p>
<p>**冗余SACK ** </p>
<p>DSACK，即重复 SACK，这个机制是在 SACK 的基础上，额外携带信息，<strong>告知发送方有哪些数据包自己重复接收了</strong>。DSACK 的目的是帮助发送方判断，是否发生了包失序、ACK 丢失、包重复或伪重传。让 TCP 可以更好的做网络流控。</p>
<h4 id="GBN-or-SR"><a href="#GBN-or-SR" class="headerlink" title="GBN or SR?"></a>GBN or SR?</h4><p><strong>累计确认</strong></p>
<p>TCP实现中包含了累计确认这个GBN的要素，但是TCP对于失序的部分不会直接丢弃，也不回复ACK，而是暂存形成一个数据缺口。</p>
<p>对于超时重传，TCP只会让流水线发送中第一个未确认的字节重传，并且如果接受到了序号更大的ACK，连重传也不需要；而GBN规定只要没有收到第一个的ACK，后面不管是否收到必须全部重传。</p>
<p>一些TCP实现中也可以采用SR，不必使用累计确认。</p>
<p><strong>接收窗口</strong></p>
<p>TCP有接收窗口，GBN的接收窗口宽度只有1，SR也有接收窗口，但是SR并不是累计确认。</p>
<h3 id="流量控制（flow-control）"><a href="#流量控制（flow-control）" class="headerlink" title="流量控制（flow control）"></a>流量控制（flow control）</h3><p>不同于网络中的拥塞控制机制，流量控制是用来使发送方与接收方速率相匹配的机制，提醒发送方能发多少避免接收方缓冲区溢出。</p>
<h4 id="接收窗口（rwnd）"><a href="#接收窗口（rwnd）" class="headerlink" title="接收窗口（rwnd）"></a>接收窗口（rwnd）</h4><ul>
<li><p>TCP接收方维护 <code>lastByteRcvd</code>（最后一个递交给应用进程的）与 <code>lastByteRead</code>（最后一个确认的，rcv_base或expectedseqnum）二者差值即为接收缓冲区中的现有字节数，由此可以计算出缓冲区的可用字节数字rwnd。<code>rwnd = RcvBufferSize - (lastByteRcvd - lastByteRead)</code> </p>
</li>
<li><p>TCP发送方维护<code>lastByteSent</code>（最后一个发送的nextSeqnum，）与<code>lastByteAck</code>（最后一个确认的，send_base）二者差值即为所有已发送但未收到确认的字节数，<code>lastByteSent - lastByteAck &lt;= rwnd</code> 否则就阻塞发送方，也就是说发送窗口和接收窗口是一个概念。</p>
</li>
</ul>
<h5 id="TCP-零窗口探测"><a href="#TCP-零窗口探测" class="headerlink" title="TCP 零窗口探测"></a>TCP 零窗口探测</h5><ul>
<li>如果rwnd = 0，发送方仍会发送一个特殊的1字节的段（就是下一字节的数据，没新的数据段发送的时候发一个ack），强制接收端重新宣布下一个期望的字节和窗口大小（rwnd），与此同时启动一个探测定时器（persistence timer）</li>
<li>如果接收方回复的窗口rwnd仍然为0，则发送方的探测定时器加倍。</li>
<li>没有收到ACK，在发送探测包的最大次数之后连接超时（Reset或者关闭TCP连接）</li>
</ul>
<h4 id="传输效率"><a href="#传输效率" class="headerlink" title="传输效率"></a>传输效率</h4><h5 id="Nagle-算法"><a href="#Nagle-算法" class="headerlink" title="Nagle 算法"></a>Nagle 算法</h5><p>如果数据段只有1个字符，21字节的报文段只有1B的数据，带宽利用率就很低</p>
<p>Nagle算法：如果连续发字节，先发一个，收到确认之后把缓存的一连串一起发出去；一旦到达发送窗口或者MSS就立即发出。</p>
<h5 id="糊涂窗口综合征"><a href="#糊涂窗口综合征" class="headerlink" title="糊涂窗口综合征"></a>糊涂窗口综合征</h5><ul>
<li>接收窗口空出1字节就急忙通知对方，对方发过来1字节又占满缓冲区</li>
<li>接收方有足够的接收缓存再去通知，rwnd = Rcvbuffer/2 或 MSS即可通知</li>
<li>尽可能地在MSS范围内提升报文段内数据的比例，提升利用率</li>
</ul>
<h3 id="连接管理（connection-management）"><a href="#连接管理（connection-management）" class="headerlink" title="连接管理（connection management）"></a>连接管理（connection management）</h3><h4 id="连接建立：三次握手（three-way-handshake）"><a href="#连接建立：三次握手（three-way-handshake）" class="headerlink" title="连接建立：三次握手（three-way handshake）"></a>连接建立：三次握手（three-way handshake）</h4><p>ACK比特用于表示ACK确认号字段有效</p>
<ol>
<li>客户端发送<strong>SYN</strong>报文：Seq = x，SYN = 1 (ACK比特 = 0) </li>
<li>服务器<strong>SYNACK</strong>报文：Seq = y，SYN = 1，ACK确认号 = x + 1 (ACK比特 = 1)</li>
<li>客户端<strong>ACK</strong>报文 ：Seq = x + 1，SYN = 0，ACK确认号 = y + 1 (ACK比特 = 1)</li>
</ol>
<h5 id="SYN-泛洪-SYN-cookie"><a href="#SYN-泛洪-SYN-cookie" class="headerlink" title="SYN 泛洪: SYN cookie"></a>SYN 泛洪: SYN cookie</h5><p>服务器收到SYN报文将会缓存y，用于核对下一个ACK的值是否为y+1，存到内存中，SYN攻击的原理就是不发送ACK，因此服务器会不断缓存y，建立许多半连接，最终不堪重负。解决方法就是服务器不去储存y，而是用特别的方法生成，y = H(IP1, IP2, key) 关键在于只有服务器知道的key，而合法的客户端会回复ACK报文，服务端接收以后只需要用相同的哈希函数再次计算y，看看是不是和ACK报文中的y相同，如果相同，则建立连接。</p>
<h5 id="RST-连接重置"><a href="#RST-连接重置" class="headerlink" title="RST 连接重置"></a>RST 连接重置</h5><p>用于强制中断当前的连接，如果SYN报文的目的端口并未有套接字在监听，说明这个请求非法，于是响应报文RST置1</p>
<p>在 <strong>TCP</strong> 重置攻击中，攻击者通过向通信的一方或双方发送伪造的消息，告诉它们立即断开连接，从而使通信双方连接中断。正常情况下，如果客户端收发现到达的报文段对于相关连接而言是不正确的，<strong>TCP</strong> 就会发送一个重置报文段，从而导致 <strong>TCP</strong> 连接的快速拆卸。</p>
<p><strong>TCP</strong> 重置攻击利用这一机制，通过向通信方发送伪造的重置报文段，欺骗通信双方提前关闭 TCP 连接。如果伪造的重置报文段完全逼真，接收者就会认为它有效，并关闭 <strong>TCP</strong> 连接，防止连接被用来进一步交换信息。服务端可以创建一个新的 <strong>TCP</strong> 连接来恢复通信，但仍然可能会被攻击者重置连接。万幸的是，攻击者需要一定的时间来组装和发送伪造的报文，所以一般情况下这种攻击只对长连接有杀伤力，对于短连接而言，你还没攻击呢，人家已经完成了信息交换。</p>
<p>从某种意义上来说，伪造 <strong>TCP</strong> 报文段是很容易的，因为 <strong>TCP/IP</strong> 都没有任何内置的方法来验证服务端的身份。有些特殊的 IP 扩展协议（例如 <code>IPSec</code>）确实可以验证身份，但并没有被广泛使用。客户端只能接收报文段，并在可能的情况下使用更高级别的协议（如 <code>TLS</code>）来验证服务端的身份。但这个方法对 <strong>TCP</strong> 重置包并不适用，因为 <strong>TCP</strong> 重置包是 <strong>TCP</strong> 协议本身的一部分，无法使用更高级别的协议进行验证</p>
<h4 id="连接断开：四次挥手（four-way-handshake）"><a href="#连接断开：四次挥手（four-way-handshake）" class="headerlink" title="连接断开：四次挥手（four-way handshake）"></a>连接断开：四次挥手（four-way handshake）</h4><p>FIN比特 置1</p>
<ol>
<li>客户端发送FIN，提醒服务器要断开连接，</li>
<li>服务器随即回复ACK，表示已经收到消息准备断开，发送完剩余数据之后，在发送FIN并关闭连接，告知客户端，服务器这边已经关闭了，服务器等待最后一个ACK</li>
<li>客户端收到FIN以后开始定时并回复ACK，超时即CLOSED。服务端收到客户端ACK之后正式CLOSED</li>
</ol>
<p>TIME-WAIT timer：如果客户端发的ack丢失，服务器还得重传Fin，如果客户端这边早早CLOSED，就收不到服务器Fin，也就发不出ack，服务器的套接字状态无法正式CLOSED</p>
<h4 id="TCP-状态转换"><a href="#TCP-状态转换" class="headerlink" title="TCP 状态转换"></a>TCP 状态转换</h4><h5 id="Client"><a href="#Client" class="headerlink" title="Client"></a>Client</h5><p><img src="C:/Users/Lenovo/Pictures/markdownfile/L3%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82.assets/10d2447d4713399745cdb4937cf56a41.jpg" alt="10d2447d4713399745cdb4937cf56a41"></p>
<h5 id="Server"><a href="#Server" class="headerlink" title="Server"></a>Server</h5><p><img src="C:/Users/Lenovo/Pictures/markdownfile/L3%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82.assets/05f6445ba70b616b59a5c690c306d522.jpg" alt="05f6445ba70b616b59a5c690c306d522"></p>
<h3 id="拥塞控制（congestion-control）"><a href="#拥塞控制（congestion-control）" class="headerlink" title="拥塞控制（congestion control）"></a>拥塞控制（congestion control）</h3><h4 id="拥塞窗口（cwnd）"><a href="#拥塞窗口（cwnd）" class="headerlink" title="拥塞窗口（cwnd）"></a>拥塞窗口（cwnd）</h4><ul>
<li><strong>拥塞窗口</strong>（congestion window, cwnd）：取决于中间的网络条件，由发送方控制，cwnd/RTT就是发送速率。</li>
<li><strong>接收窗口</strong>（receive window, rwnd）：由接收方可用缓存控制的，限制发送速率。</li>
<li><strong>对于发送方</strong>：<code>lastByteSent - lastByteAck &lt;= min(cwnd,rwnd)</code>  </li>
</ul>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/L3%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82.assets/image-20241205212918399.png" alt="image-20241205212918399"></p>
<p>下面为了方便研究，将cwnd作为TCP发送的主要瓶颈。</p>
<h4 id="基于丢包的拥塞控制（loss-based）"><a href="#基于丢包的拥塞控制（loss-based）" class="headerlink" title="基于丢包的拥塞控制（loss-based）"></a>基于丢包的拥塞控制（loss-based）</h4><p>TCP 对于拥塞控制给出如下三个<strong>指导性原则</strong>：</p>
<ul>
<li><p>如果出现丢包（冗余ACK或超时重传），那说明网络可能出现了拥塞状况，将缩短拥塞窗口，限制发送量</p>
</li>
<li><p>如果出现正常ACK，说明对方正确接收了，网络状况良好，将扩大拥塞窗口，增加发送量</p>
</li>
<li><p>带宽探测：探测拥塞开始的速率，增加发送速率以与ACK匹配，出现丢包则从该速率回退，然后继续探测。</p>
</li>
</ul>
<p>拥塞控制算法有慢启动-拥塞避免-快速恢复三个状态，下图为FSM:</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/L3%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82.assets/image-20241205213030112.png" alt="image-20241205213030112"></p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/L3%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82.assets/image-20241205212615649.png"></p>
<h5 id="慢启动（slow-start）"><a href="#慢启动（slow-start）" class="headerlink" title="慢启动（slow-start）"></a>慢启动（slow-start）</h5><p>初始cwnd = 1 MSS，发送1个字节，得到1 ACK, cwnd增大1 MSS，第二次发送2个字节，1个ACK增大1 MSS，呈<strong>指数增长</strong>。（2^n^ MSS per RTT）</p>
<p>cwnd是动态变化的，只要接收到ACK就会让cwnd增大，即使上一个RTT的ACK还没接收完，也对下一个RTT的能发送的字节数影响不大，因为接收完上一个RTT的所有ACK，意味着cwnd已经在上一RTT的基础上翻倍了，而此时肯定CWND还没被占满。</p>
<p>慢启动阈值ssthresh：阈值内部慢启动，超出阈值则拥塞避免</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/L3%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82.assets/image-20241205220630888.png" alt="image-20241205220630888"></p>
<p><strong>三种结束慢启动的方式</strong>：</p>
<ul>
<li><p><strong>超时重传</strong>：<strong>timeout</strong>，则将 <strong>ssthresh</strong>(slow-start threshold)设置为cwnd/2，重置 cwnd = 1 MSS，重新开始<strong>慢启动过程</strong>，然后执行重传。</p>
</li>
<li><p><strong>可能再次发生拥塞</strong>： <strong>cwnd &gt;= ssthresh</strong>，说明再增大可能就要再次拥塞了，应该更加谨慎地增加cwnd，进入<strong>拥塞避免</strong>模式。</p>
</li>
<li><p><strong>快速重传</strong>：<strong>冗余ACK = 3</strong>（连续收到4个相同的ACK）触发快速重传<u>之前</u>，ssthresh设置为cwnd/2，cwnd减半并加上3 MSS，进入<strong>快速恢复</strong>模式。</p>
</li>
</ul>
<p>因此，cwnd &lt; ssthresh 仍然处于慢启动的状态。</p>
<h5 id="拥塞避免（congestion-avoidance）"><a href="#拥塞避免（congestion-avoidance）" class="headerlink" title="拥塞避免（congestion avoidance）"></a>拥塞避免（congestion avoidance）</h5><p>ssthresh 是导致拥塞的cwnd / 2，因此到了第二次cwnd增大到ssthresh就应当减小增加的速度，呈<strong>线性增长</strong>（1 MSS per RTT）</p>
<p>如果cwnd是10个MSS大小，则在一次 RTT中发10MSS字节，假如一个报文段是1MSS，每个ACK加十分之一MSS，这些报文段全部确认之后，cwnd总共加了1MSS </p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/L3%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82.assets/image-20241205215843491-1733407571075-4.png" alt="image-20241205215843491"></p>
<p><strong>两种结束拥塞避免的方式</strong>：</p>
<ul>
<li><strong>超时重传</strong>：<strong>timeout</strong>，则将ssthresh(slow-start threshold)设置为cwnd/2，重置 cwnd = 1 MSS，重新开始<strong>慢启动过程</strong>，然后执行重传。重新回到<strong>慢启动</strong>。</li>
<li><strong>快速重传</strong>：<strong>冗余ACK = 3</strong>（连续收到4个相同的ACK）触发快速重传<u>之前</u>，ssthresh设置为cwnd/2，cwnd减半并加上3 MSS，进入<strong>快速恢复</strong>模式。</li>
</ul>
<h5 id="快速恢复（fast-recovery）"><a href="#快速恢复（fast-recovery）" class="headerlink" title="快速恢复（fast recovery）"></a>快速恢复（fast recovery）</h5><p>快速重传以后进入快速恢复状态，既然发的是冗余ACK，说明收到的是失序的正确报文段，加3MSS更加接近实际结果。</p>
<h6 id="TCP-Reno-vs-TCP-Tahoe"><a href="#TCP-Reno-vs-TCP-Tahoe" class="headerlink" title="TCP Reno vs TCP Tahoe"></a>TCP Reno vs TCP Tahoe</h6><ul>
<li>Tahoe: Cut to 1 MSS when loss detected (either t-d-ACK or timeout)</li>
<li>Reno: Cut to roughly half on loss detected by triple duplicate ACK </li>
</ul>
<p>TCP Reno会在快速重传之后进入快速恢复状态，TCP Tahoe则没有快速恢复状态</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/L3%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82.assets/image-20241205223629221.png" alt="image-20241205223629221"></p>
<h6 id=""><a href="#" class="headerlink" title=""></a></h6><h5 id="AIMD：加性增乘性减"><a href="#AIMD：加性增乘性减" class="headerlink" title="AIMD：加性增乘性减"></a>AIMD：加性增乘性减</h5><p>Additive-Increase, Multiplicative-Decrease 增加是一个一个加上去的，减少是立马减半的。</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/L3%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82.assets/image-20241205225111917.png" alt="image-20241205225111917"></p>
<h5 id="TCP-CUBIC：更加激进但有效地探测带宽"><a href="#TCP-CUBIC：更加激进但有效地探测带宽" class="headerlink" title="TCP CUBIC：更加激进但有效地探测带宽"></a>TCP CUBIC：更加激进但有效地探测带宽</h5><p><img src="C:/Users/Lenovo/Pictures/markdownfile/L3%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82.assets/image-20241205225702555.png" alt="image-20241205225702555"></p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/L3%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82.assets/image-20241205225712876.png" alt="image-20241205225712876"><br>$$<br>W = { \vert K - t \vert } ^3+W_{max}<br>$$<br>在Linux默认开启，在拥塞避免阶段，用一个立方函数来代替线性增长，能够在即将可能发生拥塞（到达上次开始丢包的cwnd）时放慢增长速率</p>
<h4 id="其他拥塞控制方法"><a href="#其他拥塞控制方法" class="headerlink" title="其他拥塞控制方法"></a>其他拥塞控制方法</h4><h5 id="基于时延的拥塞控制（delay）"><a href="#基于时延的拥塞控制（delay）" class="headerlink" title="基于时延的拥塞控制（delay）"></a>基于时延的拥塞控制（delay）</h5><p>Loss-based: Increase sending rate until a loss (timeout) and then cut back</p>
<p>Delay-based: Do the same until RTT reaches RTTcongested</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/L3%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82.assets/image-20241206202843219.png" alt="image-20241206202843219"></p>
<h5 id="基于网络协作的拥塞控制（network-assisted）"><a href="#基于网络协作的拥塞控制（network-assisted）" class="headerlink" title="基于网络协作的拥塞控制（network-assisted）"></a>基于网络协作的拥塞控制（network-assisted）</h5><p><img src="C:/Users/Lenovo/Pictures/markdownfile/L3%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82.assets/image-20241206202921921.png" alt="image-20241206202921921"></p>
<h5 id="TCP-公平性"><a href="#TCP-公平性" class="headerlink" title="TCP 公平性"></a>TCP 公平性</h5><p>if $K$ TCP sessions share same bottleneck link  of bandwidth $R$, each should have average rate of $R/K$</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/L3%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82.assets/image-20241206203243736.png" alt="image-20241206203243736"></p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/L3%EF%BC%9A%E4%BC%A0%E8%BE%93%E5%B1%82.assets/image-20241206203312056.png" alt="image-20241206203312056"></p>
<h2 id="杂项"><a href="#杂项" class="headerlink" title="杂项"></a>杂项</h2><p><a target="_blank" rel="noopener" href="https://xiaolincoding.com/network/3_tcp/tcp_optimize.html">如何优化 TCP? | 小林coding</a> </p>
<p><a target="_blank" rel="noopener" href="https://xiaolincoding.com/network/3_tcp/tcp_problem.html">TCP 协议有什么缺陷？ | 小林coding</a> </p>
<p><a target="_blank" rel="noopener" href="https://xiaolincoding.com/network/3_tcp/tcp_http_keepalive.html">TCP Keepalive 和 HTTP Keep-Alive 是一个东西吗？ | 小林coding</a></p>
<p><a target="_blank" rel="noopener" href="https://xiaolincoding.com/network/3_tcp/tcp_drop.html">用了 TCP 协议，数据一定不会丢吗？ | 小林coding</a></p>
<p><a target="_blank" rel="noopener" href="https://xiaolincoding.com/network/3_tcp/tcp_tls.html#tcp-fast-open">HTTPS 中 TLS 和 TCP 能同时握手吗？TCP FastOpen  | 小林coding</a></p>
<p><a target="_blank" rel="noopener" href="https://xiaolincoding.com/network/3_tcp/tcp_unplug_the_network_cable.html">拔掉网线后， 原本的 TCP 连接还存在吗？ | 小林coding</a> </p>
<p><a target="_blank" rel="noopener" href="https://xiaolincoding.com/network/3_tcp/tcp_down_and_crash.html">TCP 连接，一端断电和进程崩溃有什么区别？ | 小林coding</a></p>
<p><a target="_blank" rel="noopener" href="https://xiaolincoding.com/network/3_tcp/tcp_queue.html">TCP 半连接队列和全连接队列 | 小林coding</a></p>
<p><a target="_blank" rel="noopener" href="https://xiaolincoding.com/network/3_tcp/tcp_interview.html">4.1 TCP 三次握手与四次挥手面试题 | 小林coding</a> </p>
<p><a target="_blank" rel="noopener" href="https://xiaolincoding.com/network/3_tcp/tcp_three_fin.html">TCP 四次挥手，可以变成三次吗？ | 小林coding</a></p>
<p><a target="_blank" rel="noopener" href="https://xiaolincoding.com/network/3_tcp/out_of_order_fin.html">四次挥手中收到乱序的 FIN 包会如何处理？ | 小林coding</a></p>
<p><a target="_blank" rel="noopener" href="https://xiaolincoding.com/network/3_tcp/isn_deff.html">为什么 TCP 每次建立连接时，初始化序列号都要不一样呢？ | 小林coding</a></p>
<p><a target="_blank" rel="noopener" href="https://xiaolincoding.com/network/3_tcp/syn_drop.html">SYN 报文什么时候情况下会被丢弃？ | 小林coding</a></p>
<p><a target="_blank" rel="noopener" href="https://xiaolincoding.com/network/3_tcp/time_wait_recv_syn.html#%E5%85%88%E8%AF%B4%E7%BB%93%E8%AE%BA">在 TIME_WAIT 状态的 TCP 连接，收到 SYN 后会发生什么？ | 小林coding</a></p>
<p><a target="_blank" rel="noopener" href="https://xiaolincoding.com/network/3_tcp/tcp_tw_reuse_close.html">tcp_tw_reuse 为什么默认是关闭的？ | 小林coding</a></p>
<p><a target="_blank" rel="noopener" href="https://xiaolincoding.com/network/3_tcp/quic.html">如何基于 UDP 协议实现可靠传输？ | 小林coding</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://scatteredream.github.io/2025/01/06/OS%20Booting%20&%20Operating%20Modes/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars.githubusercontent.com/u/62317679?s=400&v=4">
      <meta itemprop="name" content="碎梦">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="scatteredream's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | scatteredream's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/01/06/OS%20Booting%20&%20Operating%20Modes/" class="post-title-link" itemprop="url">操作系统启动 CPU模式</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-01-06 00:00:00" itemprop="dateCreated datePublished" datetime="2025-01-06T00:00:00+08:00">2025-01-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-05-03 21:13:49" itemprop="dateModified" datetime="2025-05-03T21:13:49+08:00">2025-05-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/OS/" itemprop="url" rel="index"><span itemprop="name">OS</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Operating-Modes"><a href="#Operating-Modes" class="headerlink" title="Operating Modes"></a>Operating Modes</h1><p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241219213730449.png" alt="image-20241219213730449"></p>
<ul>
<li>x86-64 架构的处理器正常工作在 <u>Long Mode</u>，支持 64 位 OS/UEFI，有两个子模式<ul>
<li><u>64-bit Mode</u>: 只能运行 64 位软件，32 位软件需要重新编译</li>
<li><u>Compatibility Mode</u>: 兼容 32 位和 16 位保护模式软件，不支持实模式/虚拟86</li>
</ul>
</li>
<li>IA-32 或 x86 架构的处理器(i286后)正常工作在 <u>Protected Mode</u>，支持 32 位 OS/UEFI<ul>
<li><u>Protected Mode</u>: 支持运行 32 位 和 16 位保护模式的软件</li>
<li><u>Virtual 8086 Mode</u>: 类似 Compatibility Mode，可直接向下兼容运行 real mode 软件</li>
</ul>
</li>
<li>8086 处理器的 <u>Real Mode</u>，最高支持 16 位的操作系统，只能运行实模式软件</li>
</ul>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220141424897.png" alt="image-20241220141424897"></p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/80186">80186</a> 和早期的 CPU 仅仅只有一种操作模式，也就是相当于后来芯片的这种 Real Mode；</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/80286">80286</a> 和之后的 x86 CPU 都是以 Real Mode 开机，然后经过 BIOS/UEFI, Bootloader 等引导程序切换到 Protected Mode 或 Long Mode，以便运行 32 或 64 位的操作系统。</p>
</li>
<li><p>启动操作系统之后，通常是在对应模式下运行，如果要运行向前兼容的程序只能使用子模式，切换模式需要重新初始化 CPU 代价太大</p>
</li>
</ul>
<h2 id="Real-Mode"><a href="#Real-Mode" class="headerlink" title="Real Mode"></a>Real Mode</h2><p>80286 以前：</p>
<p><strong>Intel 80186</strong>是<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/Intel">Intel</a>针对<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%B7%A5%E4%B8%9A%E6%8E%A7%E5%88%B6">工业控制</a>／<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%80%9A%E4%BF%A1">通信</a>等嵌入式市场，于1982年推出的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/8086">8086</a>处理器的扩展产品，除8086内核，另外包括了中断控制器、定时器、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%9B%B4%E6%8E%A5%E8%A8%98%E6%86%B6%E9%AB%94%E5%AD%98%E5%8F%96">DMA</a>、I/O、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/UART">UART</a>、片选电路等外设。</p>
<p><strong>实模式</strong>，Real mode[Real-Address Mode]，是Intel <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/80286">80286</a>和之后的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/X86">x86</a>兼容<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/CPU">CPU</a>的操作模式。实模式的特性是20位寻址空间，最大寻址空间1MB，最大分段64KB，可以直接软件访问<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/BIOS">BIOS</a>以及周边硬件，没有任何硬件等级的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%A8%98%E6%86%B6%E9%AB%94%E4%BF%9D%E8%AD%B7">保护</a>观念或<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%A4%9A%E5%B7%A5">多任务</a>支持。所有的80286系列和之后的x86 CPU都是以实模式下开机；<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/80186">80186</a>和早期的CPU仅仅只有一种操作模式，也就是相当于后来芯片的这种实模式。CPU <a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E5%A4%8D%E4%BD%8D/6156307?fromModule=lemma_inlink">复位</a>（reset）或加电（power on）的时候以实模式启动。</p>
<p>实模式出现于早期 8088 CPU 时期。当时由于 CPU 的性能有限，一共有 20 位<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=8464187&content_type=Article&match_order=1&q=%E5%9C%B0%E5%9D%80%E7%BA%BF&zhida_source=entity">地址线</a>（所以地址空间只有1MB），以及 8 个 16 位的通用寄存器，以及 4 个 16 位的段寄存器。16 位寄存器只能支持64KB的线性地址空间，需要使用另外一个寄存器配合才能利用所有的地址线，因此这种管理内存的方式称为<strong>段式管理</strong>（segmentation）由于 80286 以前只有实模式一种，当时并不叫实模式，286 以后出现保护模式才给以前这个模式取名叫实模式，而硬件上有一定改进，因此 8086 和 80286 的实模式还有有一些细微区别的。详见A20 Gate</p>
<h3 id="x86-Registers"><a href="#x86-Registers" class="headerlink" title="x86 Registers"></a>x86 Registers</h3><p>图中绿色标记为 8086 的 4 个段寄存器，还有剩下的 16 位寄存器</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Booting%20&%20Operating%20Modes.assets/image-20241221225031752.png" alt="image-20241221225031752"></p>
<ul>
<li>4 个段寄存器 <strong>CS</strong>、<strong>SS</strong>、<strong>DS</strong> 和 <strong>ES</strong>，用来描述特定段的基址，不能混用，都是 16 位；</li>
<li>1 个指令指针寄存器 <strong>IP</strong> ， 用于和 CS 组成 <strong>CS:IP</strong> 逻辑地址，指向下一条要执行的指令，16 位；</li>
<li>8 个通用寄存器，其中 <strong>SP</strong> 一般固定用于保存堆栈指针，其他可以任意混用，16 位；</li>
<li>1 个程序状态字 <strong>FLAGS</strong>(<strong>PSW</strong>, Program Status Word) 16 位，保存当前程序执行的一些状态和结果的某些信息</li>
</ul>
<h3 id="Segmentation-before-80286"><a href="#Segmentation-before-80286" class="headerlink" title="Segmentation before 80286"></a>Segmentation before 80286</h3><p><img src="C:/Users/Lenovo/Pictures/markdownfile/Bootloader.assets/20131020015240765.jpeg" alt="img"></p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220001927471.png" alt="image-20241220001927471"></p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220141646817.png" alt="image-20241220141646817"></p>
<p>当某个指令想要访问某个内存地址时，它通常需要用下面的这种格式来表示：(段基址：段偏移量) </p>
<ul>
<li><p>段基址：它的值是由<strong>段寄存器</strong>提供的(一般来说，段寄存器有6种，分别为cs，ds，ss，es，fs，gs，这几种段寄存器都有自己的特殊意义，这里不做介绍)</p>
<ul>
<li>段寄存器除了有 16 位的可见部分，还有不可见的隐藏部分：描述符缓存“descriptor cache”或隐藏寄存器“shadow register” 当一个段选择子装入段寄存器的可见部分，处理器同时也把它指向的段表内容缓存cache中，避免在翻译逻辑地址时花费额外的开销去访问段表。处理器指令中可以明示使用哪些段寄存器，这将替换掉默认使用的段寄存器。</li>
</ul>
</li>
<li><p>段内偏移量：代表你要访问的这个内存地址距离这个段基址的偏移。它的值由<strong>通用数据寄存器</strong>来提供的，所以也是 16 位。那么两个 16 位的值如何组合成一个20位的地址呢？CPU采用的方式是把段寄存器所提供的段基址先向左移4位。这样就变成了一个20位的值，然后再与段偏移量相加。段偏移量16位，因此最大分段为 64 KB</p>
</li>
<li><p><code>物理地址 = 段基址 &lt;&lt; 4 位 + 段内偏移</code> </p>
<ul>
<li>段寄存器是0xff00，段偏移量为0x0110，物理地址 0xff00&lt;&lt;4 + 0x0110 = 0xff110</li>
</ul>
</li>
</ul>
<p>实模式的”实”更多地体现在其地址是<strong>真实的物理地址</strong>(Real-Address Mode)</p>
<p>段基址 + 偏移，Segmentation 分段的雏形，逻辑地址</p>
<h3 id="Limitations"><a href="#Limitations" class="headerlink" title="Limitations"></a>Limitations</h3><p>由于程序可以任意修改当前的 CS/DS 值，所有程序可以使用全部  1 MB 的内存，所以这个CPU几乎没有办法有效地支持多任务，因为两个程序一起运行的话很容易互相踩到内存。所以当时的使用的方式系统中同时运行的只有一个应用程序和一个DOS操作系统。操作系统和应用规定了各自能使用的内存地址范围，比如说DOS只使用高 64KB 的内存，其它的内存给应用程序使用。这样就可以互不影响。要想运行另一个应用程序必须先退出当前运行的应用程序。</p>
<h3 id="A20-Gate"><a href="#A20-Gate" class="headerlink" title="A20 Gate"></a>A20 Gate</h3><p>在 8086 时代使用CS&lt;&lt; 4 + IP计算物理地址， 从理论上讲，最大可以表示的数值是 0xFFFF0 + 0xFFFF = 0x10FFEF，即大约1M+64KB-16B,然而由于当时的地址线只有 20 根（A0~A19)，这个地址最前面的1无法被表示，当CS=0xFFFF时，实际访问的地址0x10FFEF就变成了0xFFEF，这也导致当时程序编写者为了适应这个问题使用了特殊的技巧。到了80286，地址线变成24位，此时0x10FFEF可以访问到了。为了兼容性考虑，由A20 Gate来控制第21根地址总线的开关。能够在实模式下增加了对额外 65,520 字节（64 KB - 16 字节）内存的访问，而无需进行重大软件更改。</p>
<ul>
<li>开关打开：实模式能访问10000-10FFEF的高地址</li>
<li>开关关闭：实模式无法访问10000-10FFEF，保护模式只能访问 0到1M，2M到3M，寻址空间减少一半。</li>
</ul>
<p>另外实模式和8086还有中断向量的区别，详见虚拟 86 模式</p>
<h2 id="Protected-Mode"><a href="#Protected-Mode" class="headerlink" title="Protected Mode"></a>Protected Mode</h2><p>80286 到 80386 开始：<br><strong>保护模式</strong>，Protected Mode，内存保护模式，寻址采用32位段和偏移量，最大寻址空间为4GB，最大分段4GB 。保护模式拥有内存保护，分页系统，以及硬件支持的虚拟内存等功能，支持抢占式多任务调度，CPU 特权模式。在保护模式下，进行寻址时，段寄存器值不再被简单的解析为段基址，而是全局/局部描述符表（GDT/LDT）的索引，也即是所谓的段选择子。</p>
<p>80286 开始支持保护模式，但是寄存器仍然是 16 位，属于 16 位的保护模式。</p>
<p>80386 以后，CPU 寄存器变成 32 位，IA-32 的保护模式寻址发生了一定变化: 地址线的个数从原来的20根变为现在的32根，所以可以访问的内存空间也从 1 MB 变为 4 GB。实模式下的内存地址计算方式就已经不再适合了。</p>
<h3 id="80286-Protected-Mode-16-bit"><a href="#80286-Protected-Mode-16-bit" class="headerlink" title="80286 Protected Mode(16-bit)"></a>80286 Protected Mode(16-bit)</h3><p><img src="C:/Users/Lenovo/Pictures/markdownfile/Bootloader.assets/080810-protected-286-segments.png" alt="undefined"></p>
<h4 id="New-Features-of-80286"><a href="#New-Features-of-80286" class="headerlink" title="New Features of 80286"></a>New Features of 80286</h4><ul>
<li><p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/80286">Intel 80286</a> 的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%9C%B0%E5%9D%80%E7%B8%BD%E7%B7%9A">地址总线</a>增加到 24 位，物理最大可寻址空间为 2^24^（即16 MB）</p>
</li>
<li><p>寄存器：</p>
<ul>
<li><p>通用寄存器的位数仍为 16 位，只能使用段式管理，增加了保护模式通过段表间接访存</p>
</li>
<li><p>引入了 机器状态字 <strong>MSW</strong>(Machine Status Word)寄存器用来控制处理器整体的状态，比如保护模式与实模式的切换</p>
</li>
<li><p>引入 <strong>GDTR</strong> <strong>LDTR</strong> <strong>IDTR</strong> <strong>TR</strong>，工作在保护模式，为分段服务，是多任务实现的基础</p>
</li>
</ul>
</li>
<li><p>80286 保护模式下的应用程序能访问的内存<strong>线性地址空间仅为 64 KB</strong>，非常有限。所以程序员编写使用大内存的应用程序时还必须使用远指针、近指针，相当繁琐。这影响了 80286 保护模式的推广使用。</p>
</li>
</ul>
<h4 id="x86-Segmentation"><a href="#x86-Segmentation" class="headerlink" title="x86 Segmentation"></a>x86 Segmentation</h4><h5 id="Descriptor-Table"><a href="#Descriptor-Table" class="headerlink" title="Descriptor Table"></a>Descriptor Table</h5><p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220142126857-1734679595859-13-1734679601817-15.png" alt="image-20241220142126857"></p>
<p>在80286中，CS/DS/ES/FS寄存器存储的内容变成了选择子。使用段表管理之后，CPU 使用的就是逻辑地址（段选择子+偏移量），经过段表翻译才能有实际物理地址，而段描述符表只有系统内核才能修改。这就保证了一个进程只能访问内核分配给他的段上的物理内存。寻址时，依然是 base and bound 的思想，只不过要先去段表中查找段表项，里面有对应段的物理地址以及界限以及权限位，这里就体现出了虚拟内存的保护作用，之前偏移量受位数限制，现在偏移量不能超过界限，并且必须通过权限鉴别。</p>
<p>下图为段表（描述符表）的基本情况：共 3 个，可直接访问的有 GDT 与 LDT 两个，IDT 是中断表，里面的描述符指向的都是特定的段，也叫 Gate</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220152155629.png" alt="image-20241220152155629"></p>
<p>选择子一共有 16 位：</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220175738856.png" alt="image-20241220175738856"></p>
<ul>
<li>高 13 位是段表的 index；</li>
<li>TI(Table Index)为第 2 位，表示选择 GDT 还是 LDT，有专门的 GDTR、LDTR 寄存器保存段表基址 STBaseAddress。<img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220142058130-1734679404141-3.png" alt="image-20241220142058130"><ul>
<li><p>LDT 存放在 GPT 的 LDT 类型描述符中，LDT 本身是一个段，而 GDT 不是一个段</p>
</li>
<li><p>访问 LDT 需要使用段选择子，为了减少访问 LDT 时段转换的次数，LDT 的段选择符，段基址，界限都要放在 LDTR 寄存器之中。</p>
</li>
<li><p>GDT 本身不是一个段，而是线性地址空间的一个数据结构；GDT 的线性基地址和长度必须加载进 GDTR 之中。因为每个描述符长度是8，所以 GDT 的基地址最好进行8字节对齐。</p>
</li>
<li><p>段寄存器仍然有之前类似 TLB 的 <strong>缓存</strong> 机制，有可见和不可见两个部分：</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220180035716.png" alt="image-20241220180035716"></p>
</li>
</ul>
</li>
<li>0 - 1 为权限位(RPL) RPL 称为<strong>请求</strong>权限级别。<img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Booting%20&%20Operating%20Modes.assets/image-20241221224507677.png" alt="image-20241221224507677"><ul>
<li><strong>CPL</strong> 是当前<strong>正在执行的代码段</strong>的特权级（CS 寄存器的低 2 位）<ul>
<li>0 和 3 分别表示用户态和内核态.中间是驱动程序的优先界别</li>
<li>CPL只在代码段改变时改变，即跳转指令 JMP CALL</li>
</ul>
</li>
<li>RPL 是对于一个段的请求特权级别</li>
<li><code>max&#123;RPL,CPL&#125; &lt; DPL</code> 方可访问此段</li>
</ul>
</li>
</ul>
<h4 id="Address-Translation"><a href="#Address-Translation" class="headerlink" title="Address Translation"></a>Address Translation</h4><p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220180347195.png" alt="image-20241220180347195"></p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220141603315.png" alt="image-20241220141603315"></p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/Bootloader.assets/929457-20161229210613367-1902103210-1734526656105-28.png" alt="img"></p>
<p><code>STEntry Address = STBaseAddress + 8 * index</code>  DTEntry 的大小 = 每条目 8 字节</p>
<p>Descriptor(DTEntry) 中含有段基址 界限 DPL 等       物理地址 = 段基址 + 偏移 </p>
<p>CS:IP 组合称为逻辑地址，CS 唯一对应到段表的一个条目，应用程序内存不够用时，需要调用一些系统调用，让 DOS 分配一段内存，把这段内存的 base, limit 做成一个条目（Descriptor）加入到GDT或LDT中， 只有OS能更改CS，如果用户擅自更改CS，段表中找不到对应条目，会发生segmentation fault。逻辑地址一共有13+1=14位有效，偏移16位，因此虚拟内存 1 GB。但是地址线数量限制了物理内存大小最大 16 MB。</p>
<p>基于这种内存管理方式，用户应用程序可以实现动态链接。比如说一个程序分为代码段、数据段、零初始化段等，它依赖的库也是分段的，系统在加载程序时，只需为每个段分配一段内存，并为每个段设置一个描述符即可。 每个段的起始地址可以在加载时根据实际情况修改。</p>
<p>为了区分不同段的功能，可以在TYPE字段设置，比如代码段可读可执行，数据段可读可写等。</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220180319764.png" alt="image-20241220180319764"></p>
<h4 id="Workflow-Example"><a href="#Workflow-Example" class="headerlink" title="Workflow Example"></a>Workflow Example</h4><p>为了加深理解，用一个简单的指令执行流程来说明：</p>
<ol>
<li>取指：CPU 从 CS:IP 逻辑地址 获取指令的物理地址，取指令(16bit)，CS不变，IP+2；<ul>
<li>CS 此时就是一个选择子，只要代码段无变化，当前指令的执行权限就不变</li>
</ul>
</li>
<li>译码：翻译指令，指令被解析为 <code>MOV AX, [BX]</code> 操作数的逻辑地址 DS:BX 算出物理地址</li>
<li>执行：从物理地址取数，将 取来的数存到 AX 通用寄存器</li>
</ol>
<h3 id="IA-32-Protected-Mode-32-bit"><a href="#IA-32-Protected-Mode-32-bit" class="headerlink" title="IA-32 Protected Mode(32-bit)"></a>IA-32 Protected Mode(32-bit)</h3><h4 id="New-Features-of-80386"><a href="#New-Features-of-80386" class="headerlink" title="New Features of 80386"></a>New Features of <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/80386">80386</a></h4><ol>
<li><p>首次在 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/X86">x86</a> 处理器中实现了 32 位系统（<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/IA-32">IA-32</a>）；</p>
</li>
<li><p>可配合使用 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/w/index.php?title=80387&action=edit&redlink=1">80387</a> 数字<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%BC%94%E5%8A%A9%E8%99%95%E7%90%86%E5%99%A8">辅助处理器</a>增强<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%B5%AE%E7%82%B9">浮点</a>运算能力；</p>
</li>
<li><p>首次采用 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98">高速缓存</a>（外置）解决内存速度瓶颈问题；</p>
</li>
<li><p>在 IA-32 保护模式下，CPU 的 32 条地址线全部有效，可寻址高达 4 GB 的物理地址空间；</p>
<p>Descriptor 的变化，可以看到变成 32位 基地址：</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/929457-20161230154447711-2105143159-1734688534787-30.png" alt="img"></p>
</li>
<li><p>寄存器变化：</p>
<ol>
<li><p>在原来的四个段寄存器的基础上引入两个通用数据段寄存器 FS 和 GS；</p>
</li>
<li><p>除了段寄存器，其他寄存器全部升级到 32 位，名称加前缀 E，代表扩展；</p>
</li>
<li><p>将 80286 引入的 16 位 <strong>MSW</strong> 扩展为几个 32 位控制寄存器 <strong>CRx</strong> 用于控制机器特性。比如实模式、保护模式的切换以及分页机制的开启(CR0)页表的物理地址(CR3)，相对静态，初始化或特性切换时才改动，因此只有内核态可访问，以及还有用于调试的DRx寄存器；</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220175501376.png" alt="image-20241220175501376"></p>
</li>
<li><p>保护模式下的分段机制使用的寄存器 GDTR IDTR LDTR TR 有一些变化</p>
</li>
</ol>
</li>
</ol>
<h4 id="Flat-Memory-Model"><a href="#Flat-Memory-Model" class="headerlink" title="Flat Memory Model"></a>Flat Memory Model</h4><p><strong>最初的 Flat Model</strong>: </p>
<p>8086 以前，地址总线和数据寄存器只有 16 位，线性地址<strong>等于</strong>物理地址，最多支持64 KB的内存</p>
<p><strong>Real-Address Mode model</strong>: 实模式分段</p>
<p>1978 年的 8086 开始引入了内存<strong>分段</strong>，这使得 16 位 CPU 可以访问超过 64 KB (65,536字节)的内存，实际上 8086 CPU到内存的地址总线是 20 位，即可访问2^20^=1MB内存。</p>
<p>在 16 位模式，要让应用程序使用多个存储器分段（能够访问大于64K的内存）相当复杂。根源在于：数据总线位数少于地址总线，并且没有适当的地址算术指令适合做整个存储器范围的平面寻址，平面寻址方式也可以用像实模式那样的两个寄存器配合的乘法操作完成，但这会导致较慢的程序执行速度。并且 8086 只支持固定大小的段，这就引出了真正的分段机制</p>
<p><strong>Segmented Model</strong>: 保护模式分段</p>
<p>1982 年面世的 80286 不再将段寄存器左移 4 位作为段基址，而是索引到段表中获取段基址，这就是虚拟地址。</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220002439505-1734680053190-17.png" alt="image-20241220002439505"></p>
<p>分段机制有固有的问题：处理器的实模式与保护模式，以及 80386 推出的虚拟 86 模式，分段最大 64 KiB（使用 16 位索引寄存器）。在实模式下的分段架构的内存空间会有所重叠，这是一种不好的设计。</p>
<p><strong>32-bit Flat Memory Model</strong>: 32 位分页</p>
<p>1985 年面世的 80386 及其后续处理器的 32 位保护模式下，一个分段长度上限是2^20^个粒度单位，粒度可以是 1 字节或 4K 字节（一页），因此分段长度上限可以是 4 GB，与 32 位数据寄存器匹配。随着 32 位操作系统的推出，以及更舒适的 32-bit Flat Memory Model，到 1990 年末期几乎淘汰了使用分段寻址，转而使用分页寻址。</p>
<p>然而使用 32-bit Flat Memory Model 最多只能访问 4 GB 的线性地址空间，这种限制并没有远离日常。此时，分段机制可以支持更多根地址线，比如奔腾Pro, 2, 3在 IA-32 的架构下拥有 36 条地址线，最大64 GB的内存，就靠分段的支持，但这种最终回归到分段的尴尬，经常被引述为朝着 64 位处理器发展的动机。</p>
<p><strong>真正的 Flat Memory Model</strong>: 64 位分页</p>
<p>2003 年问世的 x86-64 架构下，强制实现了 Flat Memory Model 这种最简明有效的寻址模型，但保留了使用段寄存器 FS 或 GS 的 64 位下的分段寻址。</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220153250680.png" alt="image-20241220153250680"></p>
<h4 id="Paging"><a href="#Paging" class="headerlink" title="Paging"></a>Paging</h4><p><img src="C:/Users/Lenovo/Pictures/markdownfile/Bootloader.assets/2560px-080810-protected-386-paging.svg.png" alt="undefined"></p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/Bootloader.assets/image-20241219214149653.png" alt="image-20241219214149653"></p>
<p><strong>页表</strong>：采用二级页表，10+10+12 划分</p>
<p><strong>多进程</strong>：每个进程有一个页表，页表的物理地址存储在 CR3 寄存器</p>
<p>在Intel 80386及以后的版本中，保护模式保留了 80286 保护模式的分段机制，但增加了分页单元作为分段单元和物理总线之间的第二层地址转换。</p>
<ol>
<li>逻辑地址是 48 位，16 位属于段号，32 位偏移量，段表项中的段基址也是 32 位</li>
<li>应用程序寻址首先根据段号和段表基址定位到段表项，段的基地址加上偏移量算出线性地址</li>
<li>若关闭分页单元，段基址就是物理地址，直接送到地址总线上进行访存。</li>
<li>若启用分页单元，段表项存储的段基址是线性地址，而不是 80286 那样的物理地址。分页单元负责最终查询页表将这些线性地址转换为物理地址。</li>
</ol>
<p>80386 分页内存管理，比 80286 保护模式寻址具有更多的优点：</p>
<ul>
<li>操作系统可以控制与限制进程对页面的访问权限</li>
<li>为应用程序创造一个连续的、独立的、线性的虚拟内存空间</li>
<li>页面可以移出<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%B8%BB%E5%AD%98">主存</a>，存入更慢速的次级<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%A4%96%E5%AD%98%E5%82%A8%E5%99%A8">外存</a>如<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%A1%AC%E7%9B%98">硬盘</a>。这使得操作系统可以使用比物理内存更大的存储空间。</li>
</ul>
<h4 id="CR0-Enabling-Features"><a href="#CR0-Enabling-Features" class="headerlink" title="CR0: Enabling Features"></a>CR0: Enabling Features</h4><ol>
<li>通过清除 CR0 控制寄存器中的最低位，可以返回实模式，但这是一项特权操作，以增强安全性和鲁棒性。相比之下，80286 只能通过强制处理器重置来返回实模式，例如由三重故障或使用外部硬件。</li>
<li>控制寄存器 CR0 中的位 0 用 PE 标记，控制分段管理机制的操作，所以把它们称为保护控制位。 PE 控制分段管理机制。 PE=0，处理器运行于实模式； PE=1，处理器运行于保护方式。</li>
<li>是否启用分页由 CR0 的位 31 标记</li>
</ol>
<h4 id="Enabling-Protected-Mode"><a href="#Enabling-Protected-Mode" class="headerlink" title="Enabling Protected Mode"></a>Enabling Protected Mode</h4><p>进入保护模式前，必须初始化 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%85%A8%E5%B1%80%E6%8F%8F%E8%BF%B0%E7%AC%A6%E8%A1%A8">GDT</a>，并最少包含三个描述符：空描述符、CS 描述符以及 DS 描述符。并把（全局描述符表的所占用的字节数-1）和 GDT 的物理地址保存到 GDTR 寄存器中。如果是IBM兼容的机器，则还需要打开 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/A20%E6%80%BB%E7%BA%BF">A20总线</a> </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">; 设置CR0寄存器的PE位</span><br><span class="line">mov eax, cr0       ; 必须通过其他寄存器来修改CR0寄存器</span><br><span class="line">or eax, 1</span><br><span class="line">mov cr0, eax</span><br><span class="line"></span><br><span class="line">; 远转移 (cs = 代码段描述符)</span><br><span class="line">jmp cs:@pmode</span><br><span class="line"></span><br><span class="line">[bits 32]</span><br><span class="line">@pmode:</span><br><span class="line">; 现在已经进入了保护模式</span><br></pre></td></tr></table></figure>

<h3 id="Virtual-8086-Mode"><a href="#Virtual-8086-Mode" class="headerlink" title="Virtual 8086 Mode"></a>Virtual 8086 Mode</h3><p>80286 开始的保护模式支持<strong>更大的寻址空间</strong>和<strong>一定程度的保护措施</strong>，但是为了<strong>向下兼容</strong>运行在实模式下的软件，仍然保留了实模式（BIOS 工作在实模式，因此在正式启动操作系统之前必须运行在实模式，开始启动的<strong>第一步就是将实模式转换为保护模式</strong>）启动系统之后，80286 的 16 位保护模式，受硬件的限制，不支持分页，多任务支持也有限，因此不能向下兼容实模式的软件，<strong>必须遵循一定的标准将实模式代码重新编译、汇编才能在 16 位的保护模式运行</strong>，这就造成了诸多不便。</p>
<p>80386 开始的 IA-32 架构中，寄存器扩展至 32 位，随之而来的 32 位保护模式较完整，因此可以<strong>在 32 位保护模式直接运行 16 位实模式程序</strong>，也就是虚拟 8086 模式。</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/Bootloader.assets/image-20241219214209871.png" alt="image-20241219214209871"></p>
<ul>
<li>利用健全的多任务机制，多个虚拟 86 程序可以和 32 位程序并发执行，提升效率</li>
<li>利用分页机制，模拟出和 8086 一样的寻址方式，段基址 &lt;&lt; 4 + 段内的偏移地址，寻址空间为1 MB，将不同虚拟 86 程序的地址空间映射到不同的物理地址上，这样每个虚拟86任务看起来都认为自己在 0 ~ 1 MB 的地址空间。</li>
</ul>
<h4 id="Real-mode-Virtual-8086-8086"><a href="#Real-mode-Virtual-8086-8086" class="headerlink" title="Real mode/Virtual 8086/8086"></a>Real mode/Virtual 8086/8086</h4><p>下表可以看出 实模式、8086、虚拟 86 的中断向量表是不完全一致的</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220173857308.png" alt="image-20241220173857308"></p>
<ul>
<li>和实模式、8086相比：</li>
</ul>
<ol>
<li>段描述符加载之后会缓存，加快之后的访存速度</li>
<li>虚拟 8086 模式并不是完美兼容的，因为在 16 位架构里没有保护概念，CPU 也没有特权指令这一说，所以改变段寄存器、直接访问硬件等操作会陷入 OS 或者抛出异常，这就导致这些指令无法正常运行，但也没有办法，为了适应现代操作系统，只能放弃对这些应用的支持。</li>
</ol>
<h3 id="IA-32-Address-Translation"><a href="#IA-32-Address-Translation" class="headerlink" title="IA-32 Address Translation"></a>IA-32 Address Translation</h3><p>在 x86-64 架构下，长模式以外的三种模式也叫做 Legacy Mode </p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/Bootloader.assets/image-20241219214044009-1734615684145-17.png" alt="image-20241219214044009"></p>
<h2 id="Long-Mode-IA-32e-Mode"><a href="#Long-Mode-IA-32e-Mode" class="headerlink" title="Long Mode(IA-32e Mode)"></a>Long Mode(IA-32e Mode)</h2><p>在x86-64 等现代新架构中，长模式是64位操作系统可以访问64位指令和寄存器的模式，有两个子模式。 </p>
<p>64位程序在称为 64-bit Mode 的子模式下运行，32 位和 16 位保护模式程序在称为 Compatibility Mode 的子模式下执行，其允许 64 位操作系统运行现有的 16 位和 32 位 x86 应用程序。 在兼容模式下运行的应用程序使用 32 位或 16 位寻址，并且可以访问前 4 GB 虚拟地址空间。传统 x86 指令前缀在 16 位和 32 位地址和操作数大小之间切换。 与 64 位模式一样，兼容性模式由操作系统在单个代码段的基础上启用。</p>
<p>然而，与 64-bit Mode 不同的是，x86 分段功能与传统 x86 架构中相同，使用 16 位或 32 位保护模式语义。从应用程序的角度来看，兼容模式看起来就像传统的 x86 保护模式环境。然而，从操作系统的角度来看，地址转换、中断和异常处理以及系统数据结构都使用 64 位长模式机制。</p>
<p>删除了 HW Task Switch, TSS 变成一个堆栈表, 不再存储段相关的信息</p>
<h3 id="x86-64-Registers"><a href="#x86-64-Registers" class="headerlink" title="x86-64 Registers"></a>x86-64 Registers</h3><p>x86-64 架构在长模式（64 位模式）下，大部分寄存器位数增加为 64 位，前缀位为 R</p>
<ul>
<li>分段的概念被无限弱化：其中四个段寄存器 CS、SS、DS 和 ES 被强制设置为基地址 0，并且限制为 2^64^ ，形式上还有内存分段，但实际上所有内存都在唯一的一个分段中。</li>
<li>段寄存器 FS 和 GS 仍然可以具有非零基地址，这允许操作系统将这些段用于特殊目的。与传统模式使用的 GDT 机制不同，这些段的基地址存储在特定于模型的寄存器中。 x86-64架构还提供了特殊的 SWAPGS 指令，该指令允许交换内核模式和用户模式基地址。例如，x86-64 上的 Microsoft Windows 使用 FS 段指向线程环境块(TEB)，这是每个线程的一个小型数据结构，其中包含有关异常处理、线程局部变量和其他每线程状态的信息。同样，Linux 内核使用 GS 段来进行类似的线程本地存储(TLS)</li>
</ul>
<p><strong>应用程序编程</strong>使用如下寄存器：</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220183652263.png" alt="image-20241220183652263"></p>
<p>系统编程使用如下寄存器：    </p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220183817147.png" alt="image-20241220183817147"></p>
<h3 id="Address-Translation-1"><a href="#Address-Translation-1" class="headerlink" title="Address Translation"></a>Address Translation</h3><p><img src="C:/Users/Lenovo/Pictures/markdownfile/Bootloader.assets/image-20241219213948185.png" alt="image-20241219213948185"></p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220183850040.png" alt="image-20241220183850040"></p>
<h3 id="Legacy-Mode"><a href="#Legacy-Mode" class="headerlink" title="Legacy Mode"></a>Legacy Mode</h3><p>以前的模式统称 Legacy Mode</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220184344031.png" alt="image-20241220184344031"></p>
<h1 id="Interrupt-and-Exception-Handling"><a href="#Interrupt-and-Exception-Handling" class="headerlink" title="Interrupt and Exception Handling"></a>Interrupt and Exception Handling</h1><h2 id="Concepts"><a href="#Concepts" class="headerlink" title="Concepts"></a>Concepts</h2><p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/computer-interrupt1-l.jpg" alt="PPT - BIOS and DOS Interrupts PowerPoint Presentation, free download ..."></p>
<h3 id="Interrupt"><a href="#Interrupt" class="headerlink" title="Interrupt"></a>Interrupt</h3><p>中断可以分为硬件和软件引起的中断</p>
<ul>
<li>硬件中断(Hardware) 通常是 CPU 执行指令过程中收到外部硬件的中断信号，属于外部中断<img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/273421-20210821212504824-517540124.png" alt="img"><ul>
<li>可屏蔽中断：<strong>INTR</strong> 引脚传入，可以通过 <code>IF</code> 标志位屏蔽</li>
<li>不可屏蔽中断：<strong>NMI</strong> 引脚传入(Non-maskable Interrupt)，电源掉电、内存读写错误、总线奇偶校验错误等灾难性的错误，不可屏蔽，CPU 必须立刻处理。有一个专用的中断向量号，一般是不可屏蔽的，这样可以防止嵌套执行，直到 <code>IRET</code> 从中断返回</li>
<li>通过中断控制器从总线读取中断向量，高级可编程中断控制器 <strong>APIC</strong> 可以通过 LINT 引脚接收中断，可以处理 INTR 和 NMI，如果 APIC 禁用则会使用 INTR 和 NMI</li>
<li>CPU 收到硬中断以后需要保存执行现场，转去执行中断服务程序（ISR, Interrupt Service Routine）硬中断是异步、随机、无法预知的。</li>
</ul>
</li>
<li>软件中断(Software) 通常显式调用中断指令触发的中断，属于内部中断<ul>
<li>基础的汇编指令，由指令提供中断向量号 <code>INT n</code> </li>
</ul>
</li>
<li>中断服务程序的最后一条一定是 <code>IRET</code> 指令，恢复原先程序的执行</li>
</ul>
<h3 id="Exception-Processor"><a href="#Exception-Processor" class="headerlink" title="Exception(Processor)"></a>Exception(Processor)</h3><p>异常主要是 CPU 执行指令过程中发现的，属于内部中断,从源头来看，大体分为三类：</p>
<ol>
<li>处理器在执行指令的过程中检测到的程序错误(program error)，比如 <code>zero division</code> </li>
<li>软件生成的异常：<code>INTO, INT1, INT2, INT3, BOUND</code> 指令。有一些异常提供错误码，发生异常需要将错误码压栈，以便正确处理。如果使用 <code>INT n</code> 模拟异常，不会提供错误码，会将 EIP 指令指针错误提供，可能会出现错误。<ul>
<li><code>INTO</code>: Overflow</li>
<li><code>INT3</code>: Breakpoint, debugging</li>
<li><code>BOUND</code>: Bound Range Exceeded</li>
<li><code>UD</code>: Invalid Opcode</li>
</ul>
</li>
<li>还有一些异常源是机器检查（Machine-check）提供的</li>
</ol>
<h2 id="Restart"><a href="#Restart" class="headerlink" title="Restart"></a>Restart</h2><p>下文的 中断/异常处理程序 泛指 处理中断或异常的程序</p>
<ol>
<li><code>Fault</code>: (<strong>RETRY</strong>) 异常处理程序 返回指向 <strong>异常源指令</strong> 的指针，因此将会<strong>重新执行</strong>这条指令。一般是在无法正常通过地址访问到操作数就会触发这种异常，最典型的比如 Page Fault，为了能正确恢复需要 CPU 保存必要的寄存器（上下文）。</li>
<li><code>Trap</code>: (<strong>CONTINUE</strong>) 异常处理程序 返回指向 <strong>异常源的后一条指令</strong> 的指针，因此将会从下一条指令开始，最大特点就是不会影响程序执行的连贯性。比如 INTO 溢出异常，不过这里的下一条指的是逻辑上的下一条，他不一定和异常源相邻。比如执行 JMP 指令，返回的是指向 JMP 目的地的指针。</li>
<li><code>Abort</code>: (<strong>EXIT</strong>) 会影响程序的执行的连贯性，具体来说就是 异常处理程序 不能保证可靠的返回，旨在发生abort异常时收集有关处理器状态的诊断信息，然后尽可能优雅地关闭应用程序和系统。</li>
<li><code>Interrupt</code>: 中断严格支持程序的正确返回，不会影响可靠性与程序执行的连贯性，除非是掉电或者是硬件错误。中断虽然不可预知，但是 CPU 有完善的应对策略：首先，CPU 在每个指令周期都会检查是否有中断，一般是在最后阶段。第二，在开始执行 中断处理程序 之前，一定会保存当时指令执行的现场以便恢复执行，比如 I/O 操作，恢复时执行的指令就是中断前执行的最后一条指令的下一条</li>
</ol>
<h2 id="IDT"><a href="#IDT" class="headerlink" title="IDT"></a>IDT</h2><h3 id="Interrupt-Descriptor-Table"><a href="#Interrupt-Descriptor-Table" class="headerlink" title="Interrupt Descriptor Table"></a>Interrupt Descriptor Table</h3><p><img src="C:/Users/Lenovo/Pictures/markdownfile/Bootloader.assets/image-20241219181455217.png" alt="image-20241219181455217"></p>
<p>中断描述符表是一张用于存储<strong>中断处理程序入口</strong>的表格，每个表项（Entry）是一个中断描述符（Gate Descriptor），用于指明当某个中断或异常发生时，中断/异常处理程序 的入口地址、权限等信息。为了帮助处理异常和中断，需要处理器进行特殊处理的每个体系结构定义的异常和每个中断条件都被分配了一个唯一的标识号，称为中断向量号。处理器使用分配给异常或中断的向量号作为中断描述符表 (IDT) 的索引。该表提供了异常或中断 中断/异常处理程序 的入口点。中断表的索引范围是 0 到 255。</p>
<ul>
<li><p><code>0</code> 到 <code>31</code> 范围内的向量编号由 Intel 64 和 IA-32 体系结构保留，用于体系结构定义的异常和中断。并非所有中断都有相应的处理函数。该范围内未分配的向量编号被保留，不能使用。 </p>
</li>
<li><p><code>32</code> 到 <code>255</code> 范围内的向量编号被指定为用户定义的中断，并且不被 Intel 64 和 IA-32 体系结构保留，这些中断通常分配给外部 I/O 设备，以使这些设备能够通过外部硬件中断机制之一向处理器发送中断。</p>
</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th><strong>Trap Table</strong></th>
<th><strong>IDT</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>适用范围</strong></td>
<td>较简单的操作系统或教学架构中使用</td>
<td>主要用于 x86 架构的保护模式</td>
</tr>
<tr>
<td><strong>数据结构</strong></td>
<td>简单的映射表</td>
<td>复杂的描述符表，包含地址和其他元信息</td>
</tr>
<tr>
<td><strong>功能</strong></td>
<td>仅存储中断处理程序地址</td>
<td>支持权限管理、段选择、复杂异常和硬件中断处理</td>
</tr>
<tr>
<td><strong>实现机制</strong></td>
<td>直接使用固定大小的数组存储入口地址</td>
<td>通过描述符表实现，包含段选择子和偏移地址的组合</td>
</tr>
</tbody></table>
<p><strong>CPU 上电后（Real Mode阶段）：</strong> </p>
<ul>
<li>在实模式下，CPU 使用一个简单的中断向量表（Interrupt Vector Table, IVT），这是一个固定位置的内存表，系统刚引导时，内存0x00000到0x0003FF共1KB的空间用于存放中断向量表。每个中断向量占用4个字节，共可存储 256 个中断向量，中断向量表中存储的是异常处理程序的起始地址。</li>
<li>这个 IVT 是 16 位架构的中断处理机制，和 IDT 不同。</li>
</ul>
<p><strong>进入保护模式（Protected Mode）时：</strong> </p>
<ul>
<li>当系统进入保护模式后，操作系统需要配置自己的 IDT，因为保护模式支持更复杂的中断和异常处理。</li>
<li>操作系统初始化过程中会：<ol>
<li>分配一块内存用于存储 IDT。</li>
<li>填充 IDT 条目（包括中断号、处理程序地址、权限等）。</li>
<li>使用 <code>lidt</code> 指令加载 IDT 的基址和限制到 CPU 的 IDTR 寄存器。</li>
</ol>
</li>
</ul>
<p><strong>进入长模式（Long Mode）时：</strong></p>
<ul>
<li>在 64 位模式（长模式）下，IDT 同样需要重新设置，因为长模式支持更复杂的地址模式和更大的描述符。</li>
<li>通常操作系统会重新配置或直接复用保护模式下的 IDT。</li>
</ul>
<p>不过，本质都是中断向量表，本质存储的都是Handler入口</p>
<h3 id="Workflow"><a href="#Workflow" class="headerlink" title="Workflow"></a>Workflow</h3><p><img src="C:/Users/Lenovo/Pictures/markdownfile/Bootloader.assets/image-20241219204336594.png" alt="image-20241219204336594"></p>
<ol>
<li><p><strong>中断或异常发生</strong>：</p>
<ul>
<li>CPU 收到一个中断或异常信号。</li>
<li>信号对应一个中断号（Interrupt Vector），范围是 <code>0-255</code>。</li>
</ul>
</li>
<li><p><strong>查找 IDT</strong>（interrupt Descriptor Table）</p>
<ul>
<li>CPU 从 <strong>IDTR 寄存器</strong> 中读取 IDT 的基地址（起始地址）。</li>
</ul>
</li>
</ol>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220095504456.png" alt="image-20241220095504456"></p>
<ol start="3">
<li><p><strong>跳转到处理程序</strong>：</p>
<ul>
<li><p>根据中断向量在 IDT 中找到对应的 Descriptor (比如中断门和陷阱门)</p>
</li>
<li><p>Descriptor 中存储了 段选择器（Selector）和偏移量用来定位 中断/异常处理程序 的位置、特权级、类型（中断门、陷阱门、任务门等）</p>
</li>
<li><p>CPU 跳转到 中断/异常处理程序 并开始执行中断或异常的处理。</p>
</li>
</ul>
</li>
</ol>
<h3 id="Gate-Descriptors"><a href="#Gate-Descriptors" class="headerlink" title="Gate Descriptors"></a>Gate Descriptors</h3><h4 id="Interrupt-Trap-Gate"><a href="#Interrupt-Trap-Gate" class="headerlink" title="Interrupt/Trap Gate"></a>Interrupt/Trap Gate</h4><p><img src="C:/Users/Lenovo/Pictures/markdownfile/Bootloader.assets/image-20241219204408842.png" alt="image-20241219204408842"></p>
<table>
<thead>
<tr>
<th>特性</th>
<th>中断门(Interrupt Gate)</th>
<th>陷阱门(Trap Gate)</th>
<th align="left">任务门(Task Gate)</th>
</tr>
</thead>
<tbody><tr>
<td>触发来源</td>
<td>硬件中断/软件中断</td>
<td>异常/软件触发</td>
<td align="left">任务切换</td>
</tr>
<tr>
<td>IF 标志位</td>
<td><code>IF</code> 自动清零（关中断）</td>
<td><code>IF</code> 不变（不屏蔽中断）</td>
<td align="left">与任务无关</td>
</tr>
<tr>
<td>跳转目标</td>
<td>中断服务例程</td>
<td>异常或调试服务例程</td>
<td align="left">任务状态段（TSS）</td>
</tr>
<tr>
<td>返回方式</td>
<td><code>IRET</code> 指令</td>
<td><code>IRET</code> 指令</td>
<td align="left">任务切换完成后返回</td>
</tr>
<tr>
<td>典型用途</td>
<td>硬件中断处理</td>
<td>调试、异常处理</td>
<td align="left">多任务</td>
</tr>
</tbody></table>
<h4 id="Call-Gate"><a href="#Call-Gate" class="headerlink" title="Call Gate"></a>Call Gate</h4><p><strong>调用门</strong>(Call Gate)：调用门可以通过 <code>CALL</code> <code>JMP</code> 调用，从一个低特权级代码段跳转到另外一个高特权级的代码段，存在 GDT 和 LDT 中，但从未被实际使用过。对于系统调用的实现来说，这是不方便的并且不是最佳实现。大多数操作系统使用<strong>陷阱门</strong>（Linux 中的 <code>INT 0x80</code> 和 Windows 中的 <code>INT 0x2E</code>）或更强大的 <code>SYSENTER/SYSEXIT</code> 指令来代替调用门</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">; CALL 指令与 JMP 指令示例</span><br><span class="line">section .text</span><br><span class="line">global _start</span><br><span class="line"></span><br><span class="line">_start:</span><br><span class="line">    call 0x10:0x0000      ; 调用子程序 需要返回(my_function)</span><br><span class="line">    jmp  0x18:0x0000      ; 无条件跳转 不需要返回(end_program)</span><br><span class="line"></span><br><span class="line">0x10:0x0000:</span><br><span class="line">    ; 子程序代码</span><br><span class="line">    ret                   ; 返回主程序</span><br><span class="line"></span><br><span class="line">0x18:0x0000:</span><br><span class="line">    ; 程序结束</span><br><span class="line">    mov eax, 1            ; 系统调用号（exit）</span><br><span class="line">    xor ebx, ebx          ; 返回值（0）</span><br><span class="line">    int 0x80              ; TRAP into kernel</span><br></pre></td></tr></table></figure>

<h4 id="Task-Gate"><a href="#Task-Gate" class="headerlink" title="Task Gate"></a>Task Gate</h4><p>详见下文的硬件任务切换</p>
<h2 id="HW-Task-Switch"><a href="#HW-Task-Switch" class="headerlink" title="HW Task Switch"></a>HW Task Switch</h2><h3 id="Task-Gate-1"><a href="#Task-Gate-1" class="headerlink" title="Task Gate"></a>Task Gate</h3><p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220170638814-1734685697132-27.png" alt="image-20241220170638814"></p>
<p>在中断处理过程(IDT)或者在GDT LDT里索引到任务门，会开启硬件任务切换，影响着。</p>
<p><strong>任务门</strong>(Task Gate)：为多任务处理提供<strong>硬件</strong>支持，跳转到 TSS，目前不被使用。</p>
<p><strong>任务状态段</strong>(TSS, Task Status Segment): 保存了任务的执行上下文环境</p>
<h3 id="Task-Status-Segment"><a href="#Task-Status-Segment" class="headerlink" title="Task Status Segment"></a>Task Status Segment</h3><p><strong>TSS Descriptor 的结构，位于 GDT 中：</strong></p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220094926788-1734660034533-1.png" alt="image-20241220094926788"></p>
<p>一般 TSS 的 DPL 是小于3的，因为只有操作系统内核才有权调度任务</p>
<hr>
<p><strong>IA-32 TSS 内部的结构</strong>：</p>
<ul>
<li><p>I/O map的基地址， bitmap 本体通常映射到 TSS，通过 bitmap 限制进程对 IO 端口的访问</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220180936358.png" alt="image-20241220180936358"></p>
</li>
<li><p>本进程对应的 LDT Selector</p>
</li>
<li><p>所有的x86普通寄存器：6 个段，8个通用，1 个指令指针，1 个程序状态字</p>
</li>
<li><p>CR3 页表地址</p>
</li>
<li><p>其他特权级别的栈段和栈指针 SS2<del>0 ESP2</del>0 (内核栈)</p>
</li>
<li><p>用于嵌套任务的 link，也就是上一个 父任务的 TSS Selector</p>
</li>
</ul>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220001641685.png" alt="image-20241220001641685"></p>
<p><strong>TSS 寻址：</strong></p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220001517922-1734684881103-23.png" alt="image-20241220001517922"></p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220094649039.png" alt="image-20241220094649039"></p>
<hr>
<h3 id="Workflow-1"><a href="#Workflow-1" class="headerlink" title="Workflow"></a>Workflow</h3><p>处理器能够<strong>自动</strong>保存执行上下文，响应来自硬件或软件的请求，恢复另一任务的上下文：</p>
<ol>
<li>显式切换：<code>CALL/JMP tss_selector</code> <code>CALL/JMP task_gate_selector</code></li>
<li>隐式切换：中断/错误处理程序触发</li>
<li>可以通过控制特定的中断向量陷入 IDT 中的特定 Task Gate 来完成跳转，比如<code>INT n</code></li>
<li>嵌套任务的 <code>IRET</code>，EFLAGS 的 <code>NT</code> 标志位(Nested Tasks) 置位用于嵌套任务的跳转。</li>
</ol>
<p>下面为通过 IDT 的 Task Gate 进行任务切换的例子：</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220100119251.png" alt="image-20241220100119251"></p>
<ul>
<li><p>TR 寄存器结构如下：</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220001552753-1734684981103-25.png" alt="image-20241220001552753"></p>
</li>
<li><p>当 依赖 TSS 进行任务切换的时候，CPU 做了以下几件事情：</p>
</li>
</ul>
<ol>
<li><strong>保存现场</strong>：当前 TSS 中所有寄存器值填写到当前的 <strong>TR</strong> 寄存器（task register）指向的 TSS 中</li>
<li><strong>加载新现场</strong>：把新 TSS Selector 载入 <strong>TR</strong> ，<strong>按照一定的检验流程</strong>把新的 TSS 覆盖到寄存器。</li>
<li><strong>开始执行新代码</strong>：新设置的 EIP 指向将要执行的新代码</li>
</ol>
<ul>
<li><strong>缺点</strong>： 受硬件限制较大，且流程繁杂，不灵活也不便于调试</li>
</ul>
<ol>
<li>TSS 只能存在 GDT （最大长度只有 8,192）(TSS+LDT)*2+12=8192,最多 4090 个进程    </li>
<li>算上检验流程要消耗 200 多个时钟周期，全部串行，中间出现一个差错就无法切换成功。</li>
<li>硬件的切换过于重量级，保存完整的上下文，实际上任务切换不一定需要那么多寄存器</li>
</ol>
<p>ex. <strong>嵌套任务切换</strong></p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220172753514.png" alt="image-20241220172753514"></p>
<h3 id="SW-Task-Switch"><a href="#SW-Task-Switch" class="headerlink" title="SW Task Switch"></a>SW Task Switch</h3><p><strong>操作系统</strong> 将关键的上下文内容存到类似 PCB 等自由可控的轻量环境中，可以完全控制任务切换逻辑，能够支持指令流水的并行优化技术，更加适合复杂的多任务调度算法，提升性能。</p>
<p>Linux 2.4之前的内核有进程最大数的限制，受限制的原因是，每一个进程都有自已的 TSS 和 LDT。Linux 2.4以后，在同一个CPU上的进程使用同一个 TSS，有效内容只剩下 <code>ESP0</code> 和<code>IO MAP Address</code> </p>
<ul>
<li><code>ESP0</code>: 内核堆栈指针，因为linux完全使用分页，所以SS段没有用处</li>
<li><code>IO bitmap</code>: 控制进程的 I/O 许可</li>
</ul>
<h2 id="Stack-Usage-by-Handler"><a href="#Stack-Usage-by-Handler" class="headerlink" title="Stack Usage by Handler"></a>Stack Usage by Handler</h2><p><strong>有特权级别的转换</strong>（为防止恶意程序,一般会切换，比如系统调用、异常 陷入 OS 的内核模式）:</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220162644295.png" alt="image-20241220162644295"></p>
<p>因为有特权级别切换，因此要根据 TSS 里的内核栈段 SS0 和 ESP0 切换到处理程序自己的栈上，保存好被中断程序原先的 SS 和 ESP，将他的 CS, EIP, EFLAGS 也搬过去，最后将错误码压栈。</p>
<hr>
<p>如果没有特权级别转换，就不会切换执行堆栈，内核中发生了中断或者异常：</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220165159628.png" alt="image-20241220165159628"></p>
<h2 id="Concurrency"><a href="#Concurrency" class="headerlink" title="Concurrency"></a>Concurrency</h2><p><img src="C:/Users/Lenovo/Pictures/markdownfile/Bootloader.assets/image-20241219194949413.png" alt="image-20241219194949413"><img src="C:/Users/Lenovo/Pictures/markdownfile/Bootloader.assets/image-20241219204058993.png" alt="image-20241219204058993"></p>
<h3 id="INTR"><a href="#INTR" class="headerlink" title="INTR"></a>INTR</h3><p>从 0 到 32 的任何向量的中断都可以通过 INTR 引脚传递到处理器，并且从 16 到 32 的任何向量都可以通过本地 APIC 传递。当通过 INTR 引脚模拟异常向量中断(比如 Page Fault)，处理器不会将错误码压栈，因此异常处理程序可能无法正确运行。（和 <code>INT n</code> 的问题一样） </p>
<h4 id="EFLAGS-PSW"><a href="#EFLAGS-PSW" class="headerlink" title="EFLAGS(PSW)"></a>EFLAGS(PSW)</h4><p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220002704824.png" alt="image-20241220002704824"></p>
<h4 id="Masking-maskable-interrupts"><a href="#Masking-maskable-interrupts" class="headerlink" title="Masking maskable interrupts"></a>Masking maskable interrupts</h4><p><img src="C:/Users/Lenovo/Pictures/markdownfile/Bootloader.assets/2f761a5d7cb13f08919db2447c92f0aa.png" alt="在这里插入图片描述"></p>
<ol>
<li><code>STI</code><del>SET</del>, <code>CLI</code><del>CLEAR</del>这两个特权指令可以改变 <code>IF</code> 标志位（位于程序状态字 PSW, aka EFLAGS）控制 CPU 是否能够响应外部中断请求，是多重中断的基本条件，<code>IRET</code>也可以改变</li>
<li><strong>关中断</strong>：将 <code>IF</code> 中断标志位置零，用于保护现场、恢复现场和跳转到 ISR。</li>
<li>在执行 ISR 之前可以<strong>开中断</strong>，执行 ISR 的过程可以被其他中断打断，如果使用中断屏蔽技术(MASK)，就可以实现多重中断，高优先级有权打断低优先级，反之则不行。</li>
<li><strong>中断屏蔽技术</strong>：每个中断可以设置其他中断源的 <code>mask</code> ，被设置为0则被停止执行</li>
</ol>
<h1 id="OS-Booting"><a href="#OS-Booting" class="headerlink" title="OS Booting"></a>OS Booting</h1><p>一些早期的计算机系统，在接收到来自操作人员或外围设备的启动信号后，可以将极少量的固定指令加载到存储器的特定位置，初始化至少一个CPU，然后将CPU指向这些指令并执行指令这些指令通常从一些外围设备（可以由操作员通过开关选择）启动输入操作。其他系统可能会直接向外围设备或 I/O 控制器发送硬件命令，从而执行极其简单的输入操作（例如“将系统设备的扇区 0 读取到从位置 1000 开始的内存中”），从而有效地加载一个小文件。然后开始==链式引导系统启动==。</p>
<p>对于现代操作系统，当计算机关闭时，其软件（包括操作系统、应用程序代码和数据）仍存储在非易失性存储器中。当计算机开机时，它的 RAM 中通常没有操作系统或其加载程序。计算机首先执行存储在 ROM（后来的EEPROM，NOR Flash）中的相对较小的程序（也就是 ==BIOS== 与 ==UEFI==）。该程序支持就地执行，初始化 CPU 和主板，初始化 DRAM（特别是在x86系统上），访问非易失性存储器设备（通常是块寻址设备，例如 NAND Flash、SSD、HDD）或其他可以将操作系统程序和数据加载到 RAM 中的设备（U盘、CD-ROM、甚至是网络设备）此外，该程序还可以初始化显示设备（例如GPU）、文本输入设备（例如键盘）和指针输入设备（例如鼠标）加载到 RAM 中的第一个程序可能不足以加载操作系统，而必须加载另一个更大的程序，它加载的程序称为第二阶段引导加载程序（狭义上的 ==Bootloader==）</p>
<h2 id="BIOS"><a href="#BIOS" class="headerlink" title="BIOS"></a>BIOS</h2><p><strong>B</strong>asic <strong>I</strong>nput/<strong>O</strong>utput <strong>S</strong>ystem，基本输入输出系统，主要负责硬件层面的初始化和基本 I/O 管理，目标是找到设备上的 Bootloader，从Bootloader启动操作系统。</p>
<p>早年，BIOS 存储于<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/ROM">ROM</a>芯片上；现在的 BIOS 多存储于<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%BF%AB%E9%96%83%E8%A8%98%E6%86%B6%E9%AB%94">闪存</a>芯片上，这方便了 BIOS 的更新。BIOS 也可从<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%B6%B2%E5%8D%A1">网卡</a>等设备启动。</p>
<p>当电脑通电，BIOS 就会从存储器上加载，执行<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%8A%A0%E9%9B%BB%E8%87%AA%E6%AA%A2">加电自检</a>（POST），测试和初始化 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/CPU">CPU</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%9A%8F%E6%9C%BA%E5%AD%98%E5%8F%96%E5%AD%98%E5%82%A8%E5%99%A8">RAM</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%9B%B4%E6%8E%A5%E8%A8%98%E6%86%B6%E9%AB%94%E5%AD%98%E5%8F%96">DMA</a>控制器、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%99%B6%E7%89%87%E7%B5%84">芯片组</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%8D%B5%E7%9B%A4">键盘</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%BB%9F%E7%A2%9F">软盘</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%A1%AC%E7%A2%9F">硬盘</a>等设备。</p>
<p>所有的 Option ROM（扩展 BIOS 程序）被加载后，BIOS 就试图从启动设备（如<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%A1%AC%E7%A2%9F">硬盘</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%BB%9F%E7%A2%9F">软盘</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%85%89%E7%A2%9F">光盘</a>）加载 Bootloader，由 Bootloader 加载<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%BD%9C%E6%A5%AD%E7%B3%BB%E7%B5%B1">操作系统</a>。BIOS 以 16 位<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%9C%9F%E5%AF%A6%E6%A8%A1%E5%BC%8F">实模式</a>执行。现代操作系统以<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%BF%9D%E8%AD%B7%E6%A8%A1%E5%BC%8F">保护模式</a>或<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%95%BF%E6%A8%A1%E5%BC%8F">长模式</a>执行。</p>
<h3 id="BIOS-Filmware"><a href="#BIOS-Filmware" class="headerlink" title="BIOS Filmware"></a>BIOS Filmware</h3><p>BIOS 本身是汇编语言代码，是在 16 位实模式下执行的，由于 x86-64 是一个高度兼容的<a target="_blank" rel="noopener" href="https://zhida.zhihu.com/search?content_id=100152930&content_type=Article&match_order=1&q=%E6%8C%87%E4%BB%A4%E9%9B%86&zhida_source=entity">指令集</a>，也为了迁就 BIOS 的 16 位实模式的运行环境，所以即使现在的 CPU 都已是 64 位，如果还是在 BIOS 启动（基本见于 09 年以前的主板），在开机时仍然都是在 16 位实模式下执行的。16 位实模式直接能访问的内存只有 1 MB，就算你安了 4G、8G 或者 16 G 还是 32 G 内存，到了 BIOS 上一律只先认前 1 MB。在这 1 M内存中，前 640 K 称为基本内存，后面 384 K 内存留给开机必要硬件和各类 BIOS 本身使用。</p>
<h3 id="BIOS-Setup"><a href="#BIOS-Setup" class="headerlink" title="BIOS Setup"></a>BIOS Setup</h3><p>大约从<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/80386">80386</a> PC开始，个人电脑的 BIOS ROM 集成了设置程序（Setup）。主板的 CMOS 芯片用于存储 BIOS 设置值及硬件侦测值。</p>
<p>现代的 BIOS 可以让用户选择由哪个启动设备启动电脑，如<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%85%89%E7%A2%9F%E6%A9%9F">光盘驱动器</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%A1%AC%E7%A2%9F">硬盘</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%BB%9F%E7%A2%9F">软盘</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%9A%A8%E8%BA%AB%E7%A2%9F">U盘</a>等等。现代大多数 BIOS 支持图形化交互界面，有一些是厂商制作的，用户可以用鼠标键盘完成操作。</p>
<h4 id="CMOS"><a href="#CMOS" class="headerlink" title="CMOS"></a>CMOS</h4><p>CMOS 是计算机上另一个重要的存储器。之所以提到它，是因为 BIOS 程序的设置值、硬件参数侦测值就保存在 CMOS 中。而且，在 BIOS 程序启动计算机时，需要加载 CMOS 中的设置值。CMOS 通常被集成在南桥芯片组中。UEFI 系统则多用 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/NVRAM">NVRAM</a> 存储设置。</p>
<ul>
<li>BIOS 芯片属于 ROM ，不需要供电保存信息，其中存储的是固件（filmware，程序代码）</li>
<li>CMOS 芯片属于 RAM，内容在断电会消失，存储的是普通信息。主板上的钮扣电池用于让 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/CMOS">CMOS </a>存储 BIOS 设置值，以及电脑在断电时依然可以让系统时钟运作。把<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%B8%BB%E6%A9%9F%E6%9D%BF">主板</a>的电池拆出，便可重置其内容，拆出电池也会重置系统时钟。</li>
</ul>
<h3 id="Pre-booting"><a href="#Pre-booting" class="headerlink" title="Pre-booting"></a>Pre-booting</h3><h4 id="POST"><a href="#POST" class="headerlink" title="POST"></a>POST</h4><p>先进行 CPU 初始化：当按下电源开关时，电源就开始向主板和其他设备供电，这时电压还不稳定，在早期的南北桥主板上，由主板北桥向CPU发复位信号，对CPU初始化；稳定电压后复位信号便撤掉。而对于现在的单南桥主板，则由CPU自身调整稳定电压达到初始化的目的，当电压稳定后，CPU 便在系统BIOS保留的内存地址处执行跳转 BIOS 起始处指令，开始执行 POST 自检。</p>
<p><strong>加电自检</strong>(POST, Power-On Self Test)是计算机 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/BIOS">BIOS</a> 的一个重要功能，主要用于在 BIOS 加载操作系统之前检查计算机设备硬件是否存在问题，进而保证计算机的正常运行。在设备启动的过程中，自检程序主要检查<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/CPU">CPU</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%9A%8F%E6%9C%BA%E5%AD%98%E5%82%A8%E5%99%A8">内存</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/I/O">I/O设备</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%B8%BB%E6%9D%BF">主板</a>等对计算机正常运行会产生影响的设备硬件。</p>
<p>在POST自检中，BIOS 只检查系统的必要核心硬件是否有问题，主要是 CPU、640K基本内存、显卡是否正常，PS/2 键盘控制器、系统时钟是否有错误等等。由于 POST 检查在显卡初始化以前，因此在这个阶段如发生错误，是无法在屏幕上显示的，不过主板上还有个报警扬声器，而且如果主板的 8255 外围可编程接口芯片没有损坏的话，POST报警声音一定是会出来的。可以根据报警声的不同大致判断错误所在，一般情况下，一声短“嘀”声基本代表正常启动，不同的错误则是不同的短“嘀”声和长“嘀”声组合。POST 自检结束后，BIOS 开始调用中断完成各种硬件初始化工作。</p>
<h4 id="BIOS-Interrupt-Call"><a href="#BIOS-Interrupt-Call" class="headerlink" title="BIOS Interrupt Call"></a>BIOS Interrupt Call</h4><p><img src="C:/Users/Lenovo/Pictures/markdownfile/OS%20Extra.assets/image-20241220173802326.png" alt="image-20241220173802326"></p>
<p>与中断相对的是轮询（polling）<a target="_blank" rel="noopener" href="https://www.cnblogs.com/jadeshu/p/10663505.html">中断向量表 - jadeshu - 博客园</a> </p>
<p><strong>CPU 上电后（实模式阶段）：</strong> </p>
<ul>
<li>在实模式下，CPU 使用一个简单的中断向量表（Interrupt Vector Table, IVT），这是一个固定位置的内存表，系统刚引导时，内存0x00000到0x0003FF共1KB的空间用于存放中断向量表。每个中断向量占用4个字节，共可存储256个中断向量，中断向量表中存储的是异常处理程序的起始地址。这个 IVT 是 16 位架构的中断处理机制，和 IDT 不同。</li>
</ul>
<p><strong>进入保护模式（Protected Mode）或长模式（Long Mode）时：</strong> </p>
<ul>
<li>当系统进入保护模式后，操作系统需要配置自己的 IDT，因为保护模式支持更复杂的中断和异常处理。</li>
<li>操作系统初始化过程中会：<ol>
<li>分配一块内存用于存储 IDT。</li>
<li>填充 IDT 条目（包括中断号、处理程序地址、权限等）。</li>
<li>使用 <code>lidt</code> 指令加载 IDT 的基址和限制到 CPU。</li>
</ol>
</li>
</ul>
<p>BIOS 可通过 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/BIOS%E4%B8%AD%E6%96%B7%E5%91%BC%E5%8F%AB">BIOS 中断调用</a>为 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/MS-DOS">MS-DOS</a> 操作系统及 MS-DOS 程序提供磁盘、键盘、显示等标准服务。通过 BIOS 中断调用访问视频硬件非常缓慢。许多现代操作系统（如<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/Windows">Windows</a>、<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/Linux">Linux</a>）的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%95%9F%E5%8B%95%E7%A8%8B%E5%BC%8F">启动程序</a>(Bootloader)会使用 BIOS 中断调用加载内核，然后由<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%86%85%E6%A0%B8">内核</a>将处理器从16位<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E7%9C%9F%E5%AF%A6%E6%A8%A1%E5%BC%8F">实模式</a>转换到32位<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%BF%9D%E8%AD%B7%E6%A8%A1%E5%BC%8F">保护模式</a>（或64位<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%95%BF%E6%A8%A1%E5%BC%8F">长模式</a>）</p>
<p>在INTEL后续的32位CPU中，使用中断描述符表 IDT 来代替中断向量表 IVT。中断描述符表的起始地址由中断描述符表寄存器（IDTR）来定位，因此不再限于底部1K位置。另一方面，中断描述符表的每一个项目——称作门描述符——除了含有中断处理程序地址信息外，还包括许多属性／类型位。门描述符分为三类：任务门、中断门和自陷门。CPU对不同的门有不同的调用（处理）方式。</p>
<h4 id="HW-Initialization"><a href="#HW-Initialization" class="headerlink" title="HW Initialization"></a>HW Initialization</h4><p>硬件初始化工作是通过 BIOS 中断调用实现的，经过POST检测后，电脑终于出现了开机启动画面，这就是已经检测到了显卡并完成了初始化。但是请注意，由于BIOS是在16位实模式运行，因此该画面是以VGA分辨率（640*480，纵横比 4:3）显示的，因为实模式最高支持的就是 VGA。以前的小 14-17 寸CRT显示器由于都是 4:3 比例，最高分辨率也比较低，因此这个开机启动画面没有什么违和感，但现在的液晶显示器基本上都是宽屏 16:9 的，分辨率也较高，因此在这样的显示屏下，启动画面上的一切东西显示都可以说“惨不忍睹”——图形被拉长，字体很大很模糊，可以很明显看到显示字体的锯齿。</p>
<h3 id="Bootloader-Location"><a href="#Bootloader-Location" class="headerlink" title="Bootloader Location"></a>Bootloader Location</h3><p>引导启动的过程也是使用 BIOS 中断调用，因为 BIOS 处在实模式，Bootloader 才能切换模式</p>
<p>BIOS 根据 Setup 中用户指定的硬件启动顺序，如果将启动顺序设为“第一：DVD 驱动器；第二：硬盘驱动器”，固件会先尝试从 DVD 驱动器启动，再尝试从本地的硬盘驱动器启动。BIOS 负责硬件和软件间的相互通信。如果发现所有硬件都没有能引导操作系统的记录，则会在屏幕上显示相应错误信息（NO ROM BASIC）将电脑维持在 16 位实模式。BIOS 只识别到由主引导记录（MBR）初始化的硬盘。</p>
<h4 id="MBR"><a href="#MBR" class="headerlink" title="MBR"></a>MBR</h4><p>主引导扇区，Master Boot Record，BIOS 检查时会把硬盘最初一个扇区(MBR)加载到内存中。</p>
<p>它在硬盘上的三维地址(CHS 地址)为（柱面，磁头，扇区）＝（0，0，1）</p>
<p>MBR 位于磁盘的第一个扇区（LBA 0），其大小为 <strong>512 字节</strong>，划分如下：</p>
<ul>
<li><strong>前 446 字节</strong>: 引导代码（Bootloader Code）</li>
<li><strong>接下来的 64 字节</strong>: 分区表（DPT, Disk Partition Table），记录最多 4 个主分区的信息</li>
<li><strong>最后的 2 字节</strong>: 魔数（Signature, 0x55AA），表示这是一个有效的 MBR。</li>
</ul>
<p>BIOS 硬件检查方式：这个存储设备的前 512 字节是不是以0x55 0xAA(10101010,01010101)结尾？如果不是就按照顺序检查下一个，如果是就加载这 512 字节内部的引导代码，然后执行它。</p>
<p>MBR 最开头是第一阶段引导代码。主要作用是在检查分区表是否正确和在系统硬件完成自检以后，在活跃分区的 PBR 找到并执行 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%BC%95%E5%AF%BC%E7%A8%8B%E5%BA%8F">Bootloader</a> 主程序（如 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/GNU_GRUB">GNU GRUB</a>），不依赖任何操作系统，而且启动代码也是可以改变的，从而能够实现<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/w/index.php?title=%E5%A4%9A%E7%B3%BB%E7%BB%9F%E5%BC%95%E5%AF%BC&action=edit&redlink=1">多系统引导</a>  </p>
<p>MBR 还记录着硬盘本身的相关信息以及硬盘各个分区的大小及位置信息（分区表），是数据信息的重要入口。如果它受到破坏，硬盘上的基本数据结构信息将会丢失，需要用繁琐的方式试探性的重建数据结构信息后才可能重新访问原先的数据。因为 512B 的限制，分区表也有限制，MBR 支持最大卷为2 TB（<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/Terabyte">Terabyte</a>s）并且每个磁盘最多有4个主分区（或3个主分区，1个扩展分区和无限制的逻辑驱动器）</p>
<h4 id="Sector-amp-LBA"><a href="#Sector-amp-LBA" class="headerlink" title="Sector &amp; LBA"></a>Sector &amp; LBA</h4><p>在 GPT 分区中，每一个数据读写单元成为 LBA（逻辑块地址），一个“逻辑块”相当于传统 MBR 分区中的一个“扇区”，之所以会有区别，是因为GPT除了要支持传统硬盘，还需要支持以 NAND FLASH 为材料的 SSD 硬盘。</p>
<p>不像磁盘那样有磁片，而磁片又划分磁道和扇区来保存数据，因此，闪存材料需要采用模拟扇区来保持统一性。这些硬盘的一个读写单元是 2KB 或 4KB，所以，GPT 分区中干脆用 LBA 来表示一个基础读写块，当 GPT 分区用在传统硬盘上时，通常，LBA 就等于扇区号，有些物理硬盘支持 2KB 或 4KB 对齐，此时，LBA 所表示的一个逻辑块就是 2KB的空间，为了方便，我们后面仍然将逻辑块称为扇区。</p>
<p>以 CHS 寻址的硬盘， 最高容量是 512×63×256×1024=8064 MiB，BIOS 使用的是 LBA 寻址</p>
<h2 id="UEFI"><a href="#UEFI" class="headerlink" title="UEFI"></a>UEFI</h2><p>作为 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/BIOS">BIOS </a>的替代方案，可扩展固件接口 UEFI 负责 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%8A%A0%E9%9B%BB%E8%87%AA%E6%AA%A2">加电自检</a>（POST）、联系操作系统以及提供连接操作系统与硬件的接口。前身是 EFI</p>
<h3 id="EFI"><a href="#EFI" class="headerlink" title="EFI"></a>EFI</h3><p>虽然 BIOS 作为电脑加电启动所必不可少的部分，但是从其于 1975 年诞生之日起近 30 余年，16 位汇编语言代码，1 M 内存寻址，调用中断一条条执行的理念和方式竟然一点都没有改变，虽然经各大主板商不懈努力，BIOS 也有了 ACPI、USB 设备支持，PnP 即插即用支持等新东西，但是这在根本上没有改变 BIOS 的本质，而英特尔为了迁就这些旧技术，不得不在一代又一代处理器中保留着 16 位实模式，否则根本无法开机。英特尔推出了可扩展固件接口(EFI, Extensible Filmware Interface) 和后继的 UEFI(Unified EFI) ，是现在电脑的主要预启动环境。</p>
<h4 id="Features"><a href="#Features" class="headerlink" title="Features"></a>Features</h4><ol>
<li>摒弃 16 位实模式，完全是 32 位或 64 位模式，在 EFI 中可以实现处理器的最大寻址，因此可以在任何内存地址存放任何信息</li>
<li>模块化，C 语言风格的参数堆栈传递方式，动态链接的形式构建的系统，通用性和兼容性较好，在 EFI 驱动环境(DXE)中解释执行 EFI 字节码（虚拟机器指令）写成的 EFI 驱动，识别系统硬件并完成硬件初始化。EFI 的驱动开发非常简单，基于 EFI 的驱动模型原则上可以使 EFI 接触到所有硬件功能</li>
<li>和 OS 相比，EFI 没有中断访问机制，只能轮询</li>
<li>只有简单的存储器管理机制，在段保护模式下只将存储器分段，所有程序都可以存取任何一段位置，不提供真实的保护服务。</li>
<li>支持 GPT 分区模式</li>
<li>区分不同的开机模式，向前兼容模式(Legacy) 可以启动 16 和 32 位的操作系统，采用64位UEFI固件的PC，在UEFI 开机模式下只能执行64位操作系统启动程序</li>
</ol>
<h4 id="GPT"><a href="#GPT" class="headerlink" title="GPT"></a>GPT</h4><p><strong>全局唯一标识分区表</strong> GUID Partition Table，使用通用唯一标识符(也称为全局唯一标识符(GUID))对物理计算机存储设备(例如硬盘驱动器或固态驱动器)的分区表进行布局</p>
<p>在MBR硬盘中，分区信息直接存储于主引导扇区中（其中还存储着引导 Bootloader 的引导代码）但在GPT硬盘中，分区表的位置信息储存在GPT头中。出于兼容性考虑，硬盘的第一个扇区仍然用作 MBR，之后才是 GPT 头。为了减少分区表损坏的风险，GPT在硬盘最后保存了一份分区表的副本。其中的 EFI 系统分区可以被 EFI 存取，用来存取部分驱动和应用程序。</p>
<img src="C:/Users/Lenovo/Pictures/markdownfile/Read.assets/1024px-GUID_Partition_Table_Scheme.svg.png" alt="undefined" style="zoom: 33%;" />

<p>GPT分区表的结构。此例中，每个逻辑块（LBA）为512字节，每个分区的记录为128字节。负数的LBA地址表示从最后的块开始倒数，−1表示最后一个块。</p>
<p><strong>保护性 MBR（Protective MBR）</strong></p>
<ul>
<li><strong>位置</strong>: 分区表的第一个扇区（LBA 0）。</li>
<li><strong>作用</strong>: 这是兼容性区域，用于保护 GPT 磁盘免受旧式 MBR 工具的意外覆盖。保护性 MBR 声明整个磁盘为一个分区，以阻止不支持 GPT 的软件误将磁盘视为未分区。</li>
</ul>
<p><strong>GPT 标头（GPT Header）</strong> </p>
<ul>
<li><strong>位置</strong>: 磁盘的第一个逻辑块地址（LBA 1）。</li>
<li><strong>作用</strong>: 包含 GPT 的全局信息，包括分区表的起始位置、大小和校验和。</li>
</ul>
<p><strong>分区条目表（Partition Entries）</strong></p>
<ul>
<li><strong>位置</strong>: 通常从 LBA 2 开始，连续占用一定数量的扇区。</li>
<li><strong>作用</strong>: 存储每个分区的详细信息，包括分区类型、GUID、起始和结束地址。</li>
</ul>
<p><strong>引导分区（EFI System Partition, ESP）</strong></p>
<ul>
<li><strong>位置</strong>: 通常是 GPT 分区中专门指定的一部分（由 EFI 分区条目指定）</li>
<li><strong>作用</strong>: 用于存储 Bootloader EFI 文件、操作系统引导管理器，以及其他必要的启动文件。EFI 系统分区可以位于任何地方，只要分区条目中有正确的指向即可。实际上是一个FAT32文件系统</li>
<li><strong>固定 GUID</strong>: <code>C12A-7328-F81F-11D2-BA4B-00A0-C93E-C93B</code></li>
</ul>
<p><strong>备份 GPT 数据</strong></p>
<ul>
<li><strong>位置</strong>: 通常在磁盘的最后几个逻辑块地址（倒数第一个扇区存储备份 GPT Header，倒数第二个扇区起存储备份分区条目）。</li>
<li><strong>作用</strong>: 用于恢复主 GPT 数据结构。</li>
</ul>
<h4 id="UEFI-Optimization"><a href="#UEFI-Optimization" class="headerlink" title="UEFI Optimization"></a>UEFI Optimization</h4><ol>
<li>拥有完整的图形驱动。EFI多数还是一种类DOS界面（仍然是640*480VGA分辨率），只支持PS/2键盘操作（极少数支持鼠标操作）。无论是PS/2还是USB键盘和鼠标，UEFI一律是支持的，而且UEFI在显卡也支持GOP VBIOS的时候，显示的设置界面是显卡高分辨率按640*480或1024*768显示</li>
<li>安全启动。固件验证：根据硬件签名对各硬件判断，只有符合认证的硬件驱动才会被加载</li>
</ol>
<h3 id="Pre-booting-1"><a href="#Pre-booting-1" class="headerlink" title="Pre-booting"></a>Pre-booting</h3><img src="C:/Users/Lenovo/Pictures/markdownfile/Read.assets/Efi_flowchart_extended.jpg" alt="undefined" style="zoom: 67%;" />

<h4 id="POST-1"><a href="#POST-1" class="headerlink" title="POST"></a>POST</h4><p>当打开电源开关时，电脑的主要部件都开始有了供电，与 BIOS 不同的是，UEFI 预加载(Pre-EFI)环境首先开始执行，负责 CPU 和内存（是全部容量）的初始化工作，这里如出现重要问题，电脑即使有报警喇叭也不会响，因为 UEFI 没有去驱动 8255 发声，不过预加载环境只检查 CPU 和内存，如果这两个主要硬件出问题，屏幕没显示可以立即确定，另外一些主板会有提供LED提示，可根据CPU或内存亮灯大致判断故障。</p>
<h4 id="HW-Initialization-1"><a href="#HW-Initialization-1" class="headerlink" title="HW Initialization"></a>HW Initialization</h4><p>CPU 和内存初始化成功后，驱动执行环境（DXE）载入，当 DXE 载入后，UEFI 就具有了逐个加载UEFI 驱动的能力，在此阶段，UEFI 会迭代搜索各个硬件的 UEFI 驱动并相继加载，加载各种总线（包括PCI、SATA、USB、ISA）及硬件的 UEFI 驱动程序，完成硬件初始化工作，这相比 BIOS 的中断速度会快的多，同样如加载显卡的 UEFI 驱动成功，电脑也会出现启动画面，硬件驱动全部加载完毕后，最后同 BIOS 一样，去寻找硬盘上的操作系统的引导启动程序。</p>
<p>UEFI 应用程序（UEFI Application）和 UEFI 驱动程序（UEFI driver）是 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%8F%AF%E7%A7%BB%E6%A4%8D%E5%8F%AF%E6%89%A7%E8%A1%8C">PE格式</a> 的<code>.efi</code>文件，可用C语言编写。</p>
<h3 id="Bootloader-Location-1"><a href="#Bootloader-Location-1" class="headerlink" title="Bootloader Location"></a>Bootloader Location</h3><p>UEFI 引导管理程序可以直接从支持的文件系统（如FAT32）中读取启动文件，而不依赖硬件中断和传统的16位服务调用，UEFI 整体就处在保护模式或者长模式下。</p>
<p>在启动操作系统的阶段，同样是根据启动记录的启动顺序，转到相应设备（GPT）引导记录，引导操作系统并进入，在 UEFI 开机模式下，Bootloader 本身也是 UEFI 应用程序，其 EFI 文件存储在 EFI 系统分区（ESP）</p>
<p>这里需要注意的是，UEFI 在检测到无任何操作系统启动设备时，会直接进入 UEFI 设置页面，而不是像 BIOS 那样黑屏显示相关信息。</p>
<p>如果启动传统 MBR 设备，则需要打开 CSM 支持。</p>
<h2 id="Legacy-MBR"><a href="#Legacy-MBR" class="headerlink" title="Legacy + MBR"></a>Legacy + MBR</h2><p><strong>MBR+Legacy</strong> 是通过引导代码指向 <strong>Bootloader</strong> 文件.</p>
<ul>
<li><p><strong>Windows</strong>: </p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/Read.assets/1460000020850912-1734487610917-44.png" alt="image"></p>
<ul>
<li><p>Windows 中根据 MBR 分区表指向活跃分区记录 PBR，这里启动系统用的分区和真正装系统的分区不一定在一起，Windows 的 PBR 可以识别 FAT32 和 NTFS 两种分区，找到分区根目录的 bootmgr 文件，并加载、执行 bootmgr。</p>
</li>
<li><p>bootmgr 没有 MBR 和 PBR 的大小限制，可以做更多的事，它会加载并分析BCD启动项存储，而且 bootmgr 可以跨越磁盘读取文件。所以无论我们有几个磁盘，在多少块磁盘上装了 Windows，一个电脑只需要一个 bootmgr 就行了。bootmgr 会去加载某磁盘某 NTFS 分区的 <code>\Windows\System32\WinLoad.exe</code>，然后，由 <code>WinLoad.exe</code> 启动 Windows (<code>ntoskrnl.exe</code>) 系统分区和启动分区可能不是位于同一分区。</p>
</li>
</ul>
</li>
<li><p>Linux:</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/Read.assets/v2-709d9b2f76d718894bcc04c706986fcf_1440w-1734485433191-9-1734487325852-39-1734487632482-49.jpg" alt="img"></p>
<ul>
<li><p>写入 0 号扇区的 446 字节是第一阶段，其作用就是用来找到和加载真正的Grub bootloader主程序，也就是位于操作系统启动分区的Grub2第二阶段的程序。而且受限于446字节的大小，这个阶段的stage1 binary是不包含文件系统功能 对应 boot.img</p>
</li>
<li><p>被加载Stage1加载后，解析/boot/grub2/grub.cfg配置文件，跟据该配置文件的定义，显示多系统的启动选择界面，或者直接加载Linux kernel和文件系统，然后就由Kernel来启动后续的过程。Grub2 Stage2的镜像对应于core.img，位置为/boot/grub2/i386-pc目录下。</p>
</li>
</ul>
</li>
</ul>
<h2 id="UEFI-GPT"><a href="#UEFI-GPT" class="headerlink" title="UEFI + GPT"></a>UEFI + GPT</h2><p>**GPT+UEFI **没有明显的引导代码指向 Bootloader EFI 文件</p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/Read.assets/1460000020850915.png" alt="image"></p>
<p><img src="C:/Users/Lenovo/Pictures/markdownfile/Read.assets/1460000020850916-1734486587950-27.png" alt="image"></p>
<p>GPT 直接把 Bootloader 存到 EFI 分区</p>
<table>
<thead>
<tr>
<th>特性</th>
<th>MBR + Legacy</th>
<th>GPT + UEFI</th>
</tr>
</thead>
<tbody><tr>
<td>代码位置</td>
<td>磁盘第一个扇区 (LBA 0)</td>
<td>EFI 分区</td>
</tr>
<tr>
<td>引导文件</td>
<td>BIOS 引导代码</td>
<td>支持 EFI 格式文件 (.efi)</td>
</tr>
<tr>
<td>机制</td>
<td>根据引导代码启动 Bootloader</td>
<td>UEFI 直接去读取并运行 Bootloader</td>
</tr>
<tr>
<td>代码大小</td>
<td>446 字节 非 Bootloader 本身</td>
<td>Bootloader，上限取决于 EFI 分区大小</td>
</tr>
<tr>
<td>Bootloader</td>
<td>MBR 同时存储分区表和引导代码，Bootloader 在其他位置</td>
<td>GPT 分区表 存储分区信息，ESP 分区直接存储 Bootloader</td>
</tr>
</tbody></table>
<p>Legacy 无法识别 GPT 分区表格式，所以也就没有 Legacy + GPT 组合方式。</p>
<p>UEFI 可同时识别 MBR 分区(开启 CSM 模式)和 GPT 分区，所以在 UEFI 下，MBR 和 GPT 磁盘都可用于启动操作系统。不过由于微软限制，UEFI 下使用 Windows 安装程序安装操作系统是只能将系统安装在 GPT 磁盘中。</p>
<h2 id="Bootloader"><a href="#Bootloader" class="headerlink" title="Bootloader"></a>Bootloader</h2><p>加载到 RAM 中的第一个程序可能不足以加载操作系统，而必须加载另一个更大的程序。第一个加载到 RAM 中的程序称为第一阶段引导加载程序（BIOS、UEFI），它加载的程序称为第二阶段引导加载程序（狭义上的 Bootloader）</p>
<p>Bootloader 有 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/GNU_GRUB">GNU GRUB</a>、<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/REFInd">rEFInd</a>、<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/SYSLINUX">Syslinux</a>、Windows 的 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/BOOTMGR">BOOTMGR</a>、 和 Windows NT/2000/XP 的 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/NTLDR">NTLDR</a> 等，它们本身不是操作系统，但能够正确加载操作系统并将 CPU 控制权转移到它;操作系统随后会自行初始化并可能加载额外的设备驱动程序。</p>
<p>Bootloader 不需要驱动程序来进行自身操作，可以使用系统固件（例如 BIOS、UEFI 或开放固件）提供的通用存储访问方法，但通常硬件功能有限且性能较低。</p>
<p>许多 Bootloader 可以配置为给用户提供多种引导选择。这些选择可以包括不同的操作系统（用于从不同分区或驱动器进行双重或多重引导）、同一操作系统的不同版本（以防新版本出现意外问题）、不同的操作系统加载选项（例如，引导至不同的操作系统）、安全模式），以及一些无需操作系统即可运行的独立程序，例如内存测试程序（例如 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Memtest86%2B">memtest86+</a>）、基本 shell（如 GNU GRUB 中），甚至游戏。</p>
<p>一些 Bootloader 可以加载其他 Bootloader，例如，GRUB 可以加载 BOOTMGR 而不是直接加载 Windows。通常，默认选择是预先选择的，并有一定的时间延迟，在此期间用户可以按某个键来更改选择；在此延迟之后，默认选择将自动运行，因此无需交互即可正常启动。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/default/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/default/page/6/">6</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/default/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2023 – 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">碎梦</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/scatteredream" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
