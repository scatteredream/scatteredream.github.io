<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 5.4.2">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&family=Arvo:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&family=JetBrains+Mono:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"scatteredream.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":true,"version":"8.23.0","exturl":false,"sidebar":{"position":"right","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"flat"},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":false,"async":false},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="分布式缓存– 基于Redis集群解决单机Redis存在的问题 单机的Redis存在四大问题：  持久化Redis有两种持久化方案：  RDB持久化 AOF持久化  RDB 持久化RDB全称Redis Database Backup file（Redis数据备份文件），也被叫做Redis数据快照（SNAPSHOT）。简单来说就是把内存中的所有数据都记录到磁盘中。当Redis实例故障重启后，从磁盘读取">
<meta property="og:type" content="article">
<meta property="og:title" content="Redis 分布式应用">
<meta property="og:url" content="http://scatteredream.github.io/2024/08/14/redis-cluster-canal/index.html">
<meta property="og:site_name" content="scatteredream&#39;s blog">
<meta property="og:description" content="分布式缓存– 基于Redis集群解决单机Redis存在的问题 单机的Redis存在四大问题：  持久化Redis有两种持久化方案：  RDB持久化 AOF持久化  RDB 持久化RDB全称Redis Database Backup file（Redis数据备份文件），也被叫做Redis数据快照（SNAPSHOT）。简单来说就是把内存中的所有数据都记录到磁盘中。当Redis实例故障重启后，从磁盘读取">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725144240631.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725144536958.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725144725943.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725151319695.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725151543640.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725151654046.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241117220311689.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/aof-work-process.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725151729118.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725151940515.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725152037611.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725152222497.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725152700914.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725153201086.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725153359022.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725153524190.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725153715910.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725153937031.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725154155984.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725154216392.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725154405899.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725154528072.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725154632354.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725154816841.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241119171035000.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241119171850683.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241119172740595.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241119172833310.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241119184050478.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241119184124945.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725155747294.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241119193312708.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241119201022033.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241119203336515.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725155820320.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241119201236259.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725160138290.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725160448139.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725160448139.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725161007099.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725161241793.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725161401925.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725161506241.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725161540841.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725161637152.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725161731738.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725161817642.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725162030478.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725162101228.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725162145497.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725162224058.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/%E6%97%A0%E6%A0%87%E9%A2%98.jpg">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210727161152065.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725162319490.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725162408979.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210727160803386.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725162441407.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210727160037766.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210727161152065.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241119212106075.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210821075259137.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210821075558137.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210821080511581.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210821080954947.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210821081826399.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210821115552327.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210821115719363.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210821115914748.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210821115948395.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210821120049024.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20220521120213631.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20220521122320482.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20220521124650117.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20220521133359507.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20220521133703245.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20220521140415785.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20220521140621204.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20220521142943350.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20220521143458010.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20220521144339377.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20220521151459880.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20220521151524621.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20220521151902080.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/1653126446641.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/1653129590210.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/1653130457771.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/1653130475979.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/1653130858066.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/1653132073570.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/1653132098823.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/1653132410073.png">
<meta property="og:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/1653132740637.png">
<meta property="article:published_time" content="2024-08-13T16:00:00.000Z">
<meta property="article:modified_time" content="2025-05-22T12:02:32.219Z">
<meta property="article:author" content="碎梦">
<meta property="article:tag" content="缓存">
<meta property="article:tag" content="redis">
<meta property="article:tag" content="哈希插槽">
<meta property="article:tag" content="集群">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725144240631.png">


<link rel="canonical" href="http://scatteredream.github.io/2024/08/14/redis-cluster-canal/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://scatteredream.github.io/2024/08/14/redis-cluster-canal/","path":"2024/08/14/redis-cluster-canal/","title":"Redis 分布式应用"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Redis 分布式应用 | scatteredream's blog</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous" defer></script>
<script src="/js/third-party/search/local-search.js" defer></script>







  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">scatteredream's blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98"><span class="nav-number">1.</span> <span class="nav-text">分布式缓存</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8C%81%E4%B9%85%E5%8C%96"><span class="nav-number">1.1.</span> <span class="nav-text">持久化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#RDB-%E6%8C%81%E4%B9%85%E5%8C%96"><span class="nav-number">1.1.1.</span> <span class="nav-text">RDB 持久化</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#RDB-%E5%8E%9F%E7%90%86"><span class="nav-number">1.1.1.1.</span> <span class="nav-text">RDB 原理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B0%8F%E7%BB%93"><span class="nav-number">1.1.1.2.</span> <span class="nav-text">小结</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#RDB%E6%96%B9%E5%BC%8Fbgsave%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B%EF%BC%9F"><span class="nav-number">1.1.1.2.1.</span> <span class="nav-text">RDB方式bgsave的基本流程？</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#RDB%E4%BC%9A%E5%9C%A8%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E6%89%A7%E8%A1%8C%EF%BC%9Fsave-60-1000%E4%BB%A3%E8%A1%A8%E4%BB%80%E4%B9%88%E5%90%AB%E4%B9%89%EF%BC%9F"><span class="nav-number">1.1.1.2.2.</span> <span class="nav-text">RDB会在什么时候执行？save 60 1000代表什么含义？</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#RDB%E7%9A%84%E7%BC%BA%E7%82%B9%EF%BC%9F"><span class="nav-number">1.1.1.2.3.</span> <span class="nav-text">RDB的缺点？</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#AOF%E6%8C%81%E4%B9%85%E5%8C%96"><span class="nav-number">1.1.2.</span> <span class="nav-text">AOF持久化</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#AOF-%E5%8E%9F%E7%90%86"><span class="nav-number">1.1.2.1.</span> <span class="nav-text">AOF 原理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#AOF-%E9%85%8D%E7%BD%AE"><span class="nav-number">1.1.2.2.</span> <span class="nav-text">AOF 配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#AOF-%E6%AD%A5%E9%AA%A4"><span class="nav-number">1.1.2.3.</span> <span class="nav-text">AOF 步骤</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#AOF-%E6%96%87%E4%BB%B6%E9%87%8D%E5%86%99"><span class="nav-number">1.1.2.4.</span> <span class="nav-text">AOF 文件重写</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#AOF-%E6%A0%A1%E9%AA%8C%E6%9C%BA%E5%88%B6%E4%BA%86%E8%A7%A3%E5%90%97%EF%BC%9F"><span class="nav-number">1.1.2.5.</span> <span class="nav-text">AOF 校验机制了解吗？</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RDB%E4%B8%8EAOF%E5%AF%B9%E6%AF%94"><span class="nav-number">1.1.3.</span> <span class="nav-text">RDB与AOF对比</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Master-Slave-%E9%9B%86%E7%BE%A4%EF%BC%9A%E9%AB%98%E5%B9%B6%E5%8F%91%E8%AF%BB"><span class="nav-number">1.2.</span> <span class="nav-text">Master&#x2F;Slave 集群：高并发读</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%90%AD%E5%BB%BA%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84"><span class="nav-number">1.2.1.</span> <span class="nav-text">搭建主从架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E5%8E%9F%E7%90%86"><span class="nav-number">1.2.2.</span> <span class="nav-text">主从同步原理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%A8%E9%87%8F%E5%90%8C%E6%AD%A5"><span class="nav-number">1.2.2.1.</span> <span class="nav-text">全量同步</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A2%9E%E9%87%8F%E5%90%8C%E6%AD%A5"><span class="nav-number">1.2.2.2.</span> <span class="nav-text">增量同步</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#repl-backlog%E5%8E%9F%E7%90%86"><span class="nav-number">1.2.2.3.</span> <span class="nav-text">repl_backlog原理</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E4%BC%98%E5%8C%96"><span class="nav-number">1.2.3.</span> <span class="nav-text">主从同步优化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B0%8F%E7%BB%93-1"><span class="nav-number">1.2.4.</span> <span class="nav-text">小结</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%AE%80%E8%BF%B0%E5%85%A8%E9%87%8F%E5%90%8C%E6%AD%A5%E5%92%8C%E5%A2%9E%E9%87%8F%E5%90%8C%E6%AD%A5%E5%8C%BA%E5%88%AB%EF%BC%9F"><span class="nav-number">1.2.4.1.</span> <span class="nav-text">简述全量同步和增量同步区别？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E6%89%A7%E8%A1%8C%E5%85%A8%E9%87%8F%E5%90%8C%E6%AD%A5%EF%BC%9F"><span class="nav-number">1.2.4.2.</span> <span class="nav-text">什么时候执行全量同步？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E6%89%A7%E8%A1%8C%E5%A2%9E%E9%87%8F%E5%90%8C%E6%AD%A5%EF%BC%9F"><span class="nav-number">1.2.4.3.</span> <span class="nav-text">什么时候执行增量同步？</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Sentinel-%E9%9B%86%E7%BE%A4%EF%BC%9A%E4%BF%9D%E8%AF%81M-S%E9%AB%98%E5%8F%AF%E7%94%A8"><span class="nav-number">1.3.</span> <span class="nav-text">Sentinel 集群：保证M&#x2F;S高可用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%93%A8%E5%85%B5%E5%8E%9F%E7%90%86"><span class="nav-number">1.3.1.</span> <span class="nav-text">哨兵原理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E7%BB%93%E6%9E%84%E5%92%8C%E4%BD%9C%E7%94%A8"><span class="nav-number">1.3.1.1.</span> <span class="nav-text">集群结构和作用</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E7%9B%91%E6%8E%A7%E7%8A%B6%E6%80%81%E5%8E%9F%E7%90%86%EF%BC%9A%E5%BF%83%E8%B7%B3%E6%9C%BA%E5%88%B6"><span class="nav-number">1.3.1.2.</span> <span class="nav-text">集群监控状态原理：心跳机制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D%E5%8E%9F%E7%90%86%EF%BC%9A%E9%80%89%E4%B8%BE%E6%9C%BA%E5%88%B6"><span class="nav-number">1.3.1.3.</span> <span class="nav-text">集群故障恢复原理：选举机制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B0%8F%E7%BB%93-2"><span class="nav-number">1.3.1.4.</span> <span class="nav-text">小结</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Sentinel%E7%9A%84%E4%B8%89%E4%B8%AA%E4%BD%9C%E7%94%A8%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="nav-number">1.3.1.4.1.</span> <span class="nav-text">Sentinel的三个作用是什么？</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Sentinel%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E4%B8%80%E4%B8%AAredis%E5%AE%9E%E4%BE%8B%E6%98%AF%E5%90%A6%E5%81%A5%E5%BA%B7%EF%BC%9F"><span class="nav-number">1.3.1.4.2.</span> <span class="nav-text">Sentinel如何判断一个redis实例是否健康？</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB%E6%AD%A5%E9%AA%A4%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F"><span class="nav-number">1.3.1.4.3.</span> <span class="nav-text">故障转移步骤有哪些？</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%A2%E6%88%B7%E7%AB%AF%E9%85%8D%E7%BD%AE"><span class="nav-number">1.3.2.</span> <span class="nav-text">客户端配置</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BC%95%E5%85%A5%E4%BE%9D%E8%B5%96"><span class="nav-number">1.3.2.1.</span> <span class="nav-text">引入依赖</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%85%8D%E7%BD%AERedis%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4%E5%9C%B0%E5%9D%80"><span class="nav-number">1.3.2.2.</span> <span class="nav-text">配置Redis哨兵集群地址</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB"><span class="nav-number">1.3.2.3.</span> <span class="nav-text">配置读写分离</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Cluster-%E9%9B%86%E7%BE%A4%EF%BC%9A%E9%AB%98%E5%B9%B6%E5%8F%91%E5%86%99%E4%B8%8E%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8"><span class="nav-number">1.4.</span> <span class="nav-text">Cluster 集群：高并发写与海量数据存储</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BA%B5%E5%90%91-%E6%A8%AA%E5%90%91%E6%89%A9%E5%B1%95"><span class="nav-number">1.4.1.</span> <span class="nav-text">纵向&#x2F;横向扩展</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%90%AD%E5%BB%BA%E5%88%86%E7%89%87%E9%9B%86%E7%BE%A4"><span class="nav-number">1.4.2.</span> <span class="nav-text">搭建分片集群</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%A3%E5%88%97%E6%8F%92%E6%A7%BD%EF%BC%88Hashslot%EF%BC%89"><span class="nav-number">1.4.3.</span> <span class="nav-text">散列插槽（Hashslot）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#slot%E5%8E%9F%E7%90%86"><span class="nav-number">1.4.3.1.</span> <span class="nav-text">slot原理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%93%88%E5%B8%8C%E6%A7%BD%E6%95%B0%E7%9B%AE%E4%B8%BA%E4%BB%80%E4%B9%88%E9%80%89%E6%8B%A9-16384%EF%BC%9F"><span class="nav-number">1.4.3.2.</span> <span class="nav-text">哈希槽数目为什么选择 16384？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E9%87%87%E7%94%A8%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%EF%BC%9F"><span class="nav-number">1.4.3.3.</span> <span class="nav-text">为什么不采用一致性哈希？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E6%9F%90%E4%B8%AAkey%E5%BA%94%E8%AF%A5%E5%9C%A8%E5%93%AA%E4%B8%AA%E5%AE%9E%E4%BE%8B%EF%BC%9F"><span class="nav-number">1.4.3.4.</span> <span class="nav-text">如何判断某个key应该在哪个实例？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E5%B0%86%E5%90%8C%E4%B8%80%E7%B1%BB%E6%95%B0%E6%8D%AE%E5%9B%BA%E5%AE%9A%E7%9A%84%E4%BF%9D%E5%AD%98%E5%9C%A8%E5%90%8C%E4%B8%80%E4%B8%AA%E5%AE%9E%E4%BE%8B%EF%BC%9F"><span class="nav-number">1.4.3.5.</span> <span class="nav-text">如何将同一类数据固定的保存在同一个实例？</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E4%BC%B8%E7%BC%A9%EF%BC%9A%E6%8F%92%E6%A7%BD%E8%BF%81%E7%A7%BB"><span class="nav-number">1.4.4.</span> <span class="nav-text">集群伸缩：插槽迁移</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%81%E7%A7%BB%E6%B5%81%E7%A8%8B%EF%BC%9A%E9%9B%86%E7%BE%A4%E8%8A%82%E7%82%B9%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><span class="nav-number">1.4.4.1.</span> <span class="nav-text">迁移流程：集群节点的数据结构</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB%EF%BC%9A%E5%85%A8%E5%91%98%E5%93%A8%E5%85%B5"><span class="nav-number">1.4.5.</span> <span class="nav-text">故障转移：全员哨兵</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%87%AA%E5%8A%A8%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB"><span class="nav-number">1.4.5.1.</span> <span class="nav-text">自动故障转移</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%89%8B%E5%8A%A8%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB"><span class="nav-number">1.4.5.2.</span> <span class="nav-text">手动故障转移</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%AE%BF%E9%97%AE%E5%88%86%E7%89%87%E9%9B%86%E7%BE%A4"><span class="nav-number">1.4.6.</span> <span class="nav-text">客户端访问分片集群</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%AE%BF%E9%97%AE%E6%97%B6%E9%9B%86%E7%BE%A4%E6%AD%A3%E5%9C%A8%E8%BF%81%E7%A7%BB%E6%95%B0%E6%8D%AE%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F"><span class="nav-number">1.4.6.1.</span> <span class="nav-text">客户端访问时集群正在迁移数据怎么办？</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#ASK"><span class="nav-number">1.4.6.1.1.</span> <span class="nav-text">ASK</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#MOVED"><span class="nav-number">1.4.6.1.2.</span> <span class="nav-text">MOVED</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%BC%93%E5%AD%98%E6%8F%92%E6%A7%BD%E4%B8%8E%E8%8A%82%E7%82%B9%E6%98%A0%E5%B0%84%E8%A1%A8"><span class="nav-number">1.4.6.1.3.</span> <span class="nav-text">客户端缓存插槽与节点映射表</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Sentinel-vs-Cluster"><span class="nav-number">1.5.</span> <span class="nav-text">Sentinel vs Cluster</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%A4%9A%E7%BA%A7%E7%BC%93%E5%AD%98"><span class="nav-number">2.</span> <span class="nav-text">多级缓存</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#JVM%E8%BF%9B%E7%A8%8B%E7%BC%93%E5%AD%98%EF%BC%9ACaffeine"><span class="nav-number">2.1.</span> <span class="nav-text">JVM进程缓存：Caffeine</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%9D%E8%AF%86Caffeine"><span class="nav-number">2.1.1.</span> <span class="nav-text">初识Caffeine</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0JVM%E8%BF%9B%E7%A8%8B%E7%BC%93%E5%AD%98"><span class="nav-number">2.1.2.</span> <span class="nav-text">实现JVM进程缓存</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%BC%93%E5%AD%98%E5%90%8C%E6%AD%A5%EF%BC%9ACanal"><span class="nav-number">3.</span> <span class="nav-text">缓存同步：Canal</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E7%AD%96%E7%95%A5"><span class="nav-number">3.1.</span> <span class="nav-text">数据同步策略</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Canal"><span class="nav-number">3.2.</span> <span class="nav-text">Canal</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9B%91%E5%90%AC-Canal"><span class="nav-number">3.3.</span> <span class="nav-text">监听 Canal</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BC%96%E5%86%99%E7%9B%91%E5%90%AC%E5%99%A8"><span class="nav-number">3.3.1.</span> <span class="nav-text">编写监听器</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5"><span class="nav-number">4.</span> <span class="nav-text">最佳实践</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Redis%E9%94%AE%E5%80%BC%E8%AE%BE%E8%AE%A1"><span class="nav-number">4.1.</span> <span class="nav-text">Redis键值设计</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BC%98%E9%9B%85%E7%9A%84key%E7%BB%93%E6%9E%84"><span class="nav-number">4.1.1.</span> <span class="nav-text">优雅的key结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8B%92%E7%BB%9D%E5%A4%A7key"><span class="nav-number">4.1.2.</span> <span class="nav-text">拒绝大key</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A4%A7Key%E7%9A%84%E5%8D%B1%E5%AE%B3"><span class="nav-number">4.1.2.1.</span> <span class="nav-text">大Key的危害</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E5%8F%91%E7%8E%B0%E5%A4%A7Key"><span class="nav-number">4.1.2.2.</span> <span class="nav-text">如何发现大Key</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E5%88%A0%E9%99%A4BigKey"><span class="nav-number">4.1.2.3.</span> <span class="nav-text">如何删除BigKey</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%81%B0%E5%BD%93%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="nav-number">4.1.3.</span> <span class="nav-text">恰当的数据类型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AD%98%E5%82%A8%E4%B8%80%E4%B8%AAUser%E5%AF%B9%E8%B1%A1%EF%BC%8C%E6%88%91%E4%BB%AC%E6%9C%89%E4%B8%89%E7%A7%8D%E5%AD%98%E5%82%A8%E6%96%B9%E5%BC%8F%EF%BC%9A"><span class="nav-number">4.1.3.1.</span> <span class="nav-text">存储一个User对象，我们有三种存储方式：</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#json%E5%AD%97%E7%AC%A6%E4%B8%B2"><span class="nav-number">4.1.3.1.1.</span> <span class="nav-text">json字符串</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AD%97%E6%AE%B5%E6%89%93%E6%95%A3"><span class="nav-number">4.1.3.1.2.</span> <span class="nav-text">字段打散</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#hash%EF%BC%88%E6%8E%A8%E8%8D%90%EF%BC%89"><span class="nav-number">4.1.3.1.3.</span> <span class="nav-text">hash（推荐）</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%81%87%E5%A6%82%E6%9C%89hash%E7%B1%BB%E5%9E%8B%E7%9A%84key%EF%BC%8C%E5%85%B6%E4%B8%AD%E6%9C%89100%E4%B8%87%E5%AF%B9field%E5%92%8Cvalue%EF%BC%8Cfield%E6%98%AF%E8%87%AA%E5%A2%9Eid%EF%BC%8C%E8%BF%99%E4%B8%AAkey%E5%AD%98%E5%9C%A8%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96%EF%BC%9F"><span class="nav-number">4.1.3.2.</span> <span class="nav-text">假如有hash类型的key，其中有100万对field和value，field是自增id，这个key存在什么问题？如何优化？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%B9%E6%A1%88%E4%B8%80%EF%BC%9A%E6%8B%86%E5%88%86%E4%B8%BAstring"><span class="nav-number">4.1.3.3.</span> <span class="nav-text">方案一：拆分为string</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%96%B9%E6%A1%88%E4%BA%8C%EF%BC%9A%E6%8B%86%E5%88%86%E4%B8%BA%E5%B0%8Fhash"><span class="nav-number">4.1.3.4.</span> <span class="nav-text">方案二：拆分为小hash</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">4.1.4.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%89%B9%E5%A4%84%E7%90%86%E4%BC%98%E5%8C%96"><span class="nav-number">4.2.</span> <span class="nav-text">批处理优化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Pipeline"><span class="nav-number">4.2.1.</span> <span class="nav-text">Pipeline</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%88%91%E4%BB%AC%E7%9A%84%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8Eredis%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%98%AF%E8%BF%99%E6%A0%B7%E4%BA%A4%E4%BA%92%E7%9A%84"><span class="nav-number">4.2.1.1.</span> <span class="nav-text">我们的客户端与redis服务器是这样交互的</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MSet"><span class="nav-number">4.2.1.2.</span> <span class="nav-text">MSet</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Pipeline-1"><span class="nav-number">4.2.1.3.</span> <span class="nav-text">Pipeline</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E4%B8%8B%E7%9A%84%E6%89%B9%E5%A4%84%E7%90%86"><span class="nav-number">4.2.2.</span> <span class="nav-text">集群下的批处理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%B2%E8%A1%8C%E5%8C%96%E6%89%A7%E8%A1%8C%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5"><span class="nav-number">4.2.2.1.</span> <span class="nav-text">串行化执行代码实践</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Spring%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E4%B8%8B%E6%89%B9%E5%A4%84%E7%90%86%E4%BB%A3%E7%A0%81"><span class="nav-number">4.2.2.2.</span> <span class="nav-text">Spring集群环境下批处理代码</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AB%AF%E4%BC%98%E5%8C%96"><span class="nav-number">4.3.</span> <span class="nav-text">服务器端优化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8C%81%E4%B9%85%E5%8C%96%E9%85%8D%E7%BD%AE"><span class="nav-number">4.3.1.</span> <span class="nav-text">持久化配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%85%A2%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96"><span class="nav-number">4.3.2.</span> <span class="nav-text">慢查询优化</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%85%A2%E6%9F%A5%E8%AF%A2"><span class="nav-number">4.3.2.1.</span> <span class="nav-text">什么是慢查询</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8B%E6%85%A2%E6%9F%A5%E8%AF%A2"><span class="nav-number">4.3.2.2.</span> <span class="nav-text">如何查看慢查询</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%91%BD%E4%BB%A4%E5%8F%8A%E5%AE%89%E5%85%A8%E9%85%8D%E7%BD%AE"><span class="nav-number">4.3.3.</span> <span class="nav-text">命令及安全配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Redis%E5%86%85%E5%AD%98%E5%88%92%E5%88%86%E5%92%8C%E5%86%85%E5%AD%98%E9%85%8D%E7%BD%AE"><span class="nav-number">4.3.4.</span> <span class="nav-text">Redis内存划分和内存配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9B%86%E7%BE%A4%E4%BC%98%E5%8C%96-%E9%9B%86%E7%BE%A4-or-%E4%B8%BB%E4%BB%8E"><span class="nav-number">4.3.5.</span> <span class="nav-text">集群优化 集群 or 主从</span></a></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="碎梦"
      src="https://avatars.githubusercontent.com/u/62317679?s=400&v=4">
  <p class="site-author-name" itemprop="name">碎梦</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">83</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">126</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://scatteredream.github.io/2024/08/14/redis-cluster-canal/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars.githubusercontent.com/u/62317679?s=400&v=4">
      <meta itemprop="name" content="碎梦">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="scatteredream's blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Redis 分布式应用 | scatteredream's blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Redis 分布式应用
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-08-14 00:00:00" itemprop="dateCreated datePublished" datetime="2024-08-14T00:00:00+08:00">2024-08-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-05-22 20:02:32" itemprop="dateModified" datetime="2025-05-22T20:02:32+08:00">2025-05-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/redis/" itemprop="url" rel="index"><span itemprop="name">redis</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h1 id="分布式缓存"><a href="#分布式缓存" class="headerlink" title="分布式缓存"></a>分布式缓存</h1><p>– 基于Redis集群解决单机Redis存在的问题</p>
<p>单机的Redis存在四大问题：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725144240631.png" alt="image-20210725144240631"></p>
<h2 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h2><p>Redis有两种持久化方案：</p>
<ul>
<li>RDB持久化</li>
<li>AOF持久化</li>
</ul>
<h3 id="RDB-持久化"><a href="#RDB-持久化" class="headerlink" title="RDB 持久化"></a>RDB 持久化</h3><p>RDB全称Redis Database Backup file（Redis数据备份文件），也被叫做Redis数据快照（<mark>SNAPSHOT<mark>）。简单来说就是把内存中的所有数据都记录到磁盘中。当Redis实例故障重启后，从磁盘读取快照文件，恢复数据。快照文件称为RDB文件，默认是保存在当前运行目录。</p>
<p>执行时机</p>
<p>RDB持久化在四种情况下会执行：</p>
<ul>
<li>执行save命令</li>
<li>执行bgsave命令</li>
<li>Redis停机时</li>
<li>触发RDB条件时</li>
</ul>
<p><strong>1）save命令</strong></p>
<p>执行下面的命令，可以立即执行一次RDB：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725144536958.png" alt="image-20210725144536958"></p>
<p>save命令会导致主进程执行RDB，这个过程中其它所有命令都会被阻塞。只有在数据迁移时可能用到。</p>
<p><strong>2）bgsave命令</strong></p>
<p>下面的命令可以异步执行RDB：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725144725943.png" alt="image-20210725144725943"></p>
<p>这个命令执行后会开启独立进程完成RDB，主进程可以持续处理用户请求，不受影响。</p>
<p><strong>3）停机时</strong></p>
<p>Redis停机时会执行一次save命令，实现RDB持久化。</p>
<p><strong>4）触发RDB条件</strong></p>
<p>Redis内部有触发RDB的机制，可以在redis.conf文件中找到，格式如下：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 900秒内，如果至少有1个key发生变化，则自动执行bgsave ， 如果是save &quot;&quot; 则表示:禁用RDB</span></span><br><span class="line"><span class="attr">save</span> <span class="string">900 1  </span></span><br><span class="line"><span class="attr">save</span> <span class="string">300 10  </span></span><br><span class="line"><span class="attr">save</span> <span class="string">60 10000 </span></span><br></pre></td></tr></table></figure>

<p>RDB的其它配置也可以在redis.conf文件中设置：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 是否压缩 ,建议不开启，压缩也会消耗cpu，磁盘不值钱</span></span><br><span class="line"><span class="attr">rdbcompression</span> <span class="string">yes</span></span><br><span class="line"><span class="comment"># RDB文件名称</span></span><br><span class="line"><span class="attr">dbfilename</span> <span class="string">dump.rdb  </span></span><br><span class="line"><span class="comment"># 文件保存的路径目录</span></span><br><span class="line"><span class="attr">dir</span> <span class="string">./ </span></span><br></pre></td></tr></table></figure>

<h4 id="RDB-原理"><a href="#RDB-原理" class="headerlink" title="RDB 原理"></a>RDB 原理</h4><p>bgsave开始时会 <strong>fork</strong> 主进程得到子进程，子进程共享主进程的内存数据。完成fork后读取内存数据并写入 RDB 文件。</p>
<p>fork采用的是copy-on-write技术：写入时复制</p>
<ul>
<li>当主进程执行读操作时，访问共享内存；</li>
<li>当主进程执行写操作时，则会拷贝一份数据，执行写操作。</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725151319695.png" alt="image-20210725151319695"></p>
<p>如果在RDB过程中，修改了所有的数据，那么redis占用内存将直接<mark>翻倍<mark></p>
<h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><h5 id="RDB方式bgsave的基本流程？"><a href="#RDB方式bgsave的基本流程？" class="headerlink" title="RDB方式bgsave的基本流程？"></a>RDB方式bgsave的基本流程？</h5><ul>
<li>fork主进程得到一个子进程，共享内存空间</li>
<li>子进程读取内存数据并写入新的RDB文件</li>
<li>用新RDB文件替换旧的RDB文件</li>
</ul>
<h5 id="RDB会在什么时候执行？save-60-1000代表什么含义？"><a href="#RDB会在什么时候执行？save-60-1000代表什么含义？" class="headerlink" title="RDB会在什么时候执行？save 60 1000代表什么含义？"></a>RDB会在什么时候执行？save 60 1000代表什么含义？</h5><ul>
<li>默认是服务停止时</li>
<li>代表60秒内至少执行1000次修改则触发RDB</li>
</ul>
<h5 id="RDB的缺点？"><a href="#RDB的缺点？" class="headerlink" title="RDB的缺点？"></a>RDB的缺点？</h5><ul>
<li>RDB执行间隔时间长，两次RDB之间写入数据有丢失的风险</li>
<li>fork子进程、压缩、写出RDB文件都比较耗时，仅仅修改save命令的第一个参数不会提高RDB执行的效率</li>
</ul>
<h3 id="AOF持久化"><a href="#AOF持久化" class="headerlink" title="AOF持久化"></a>AOF持久化</h3><h4 id="AOF-原理"><a href="#AOF-原理" class="headerlink" title="AOF 原理"></a>AOF 原理</h4><p>AOF全称为<mark>Append Only File<mark>（追加文件）。Redis处理的<mark>每一个写命令<mark>都会记录在AOF文件，可以看做是命令日志文件。(binlog in MySQL)。AOF是执行命令之后写入，binlog是执行之前写入</p>
<ul>
<li>避免额外的检查开销，AOF 记录日志不会对命令进行语法检查；</li>
<li>在命令执行完之后再记录，不会阻塞当前的命令执行。</li>
<li>如果刚执行完命令 Redis 就宕机会导致对应的修改丢失；</li>
<li>可能会阻塞后续其他命令的执行（AOF 记录日志是在 Redis 主线程中进行的）。</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725151543640.png" alt="image-20210725151543640"></p>
<h4 id="AOF-配置"><a href="#AOF-配置" class="headerlink" title="AOF 配置"></a>AOF 配置</h4><p>AOF默认是关闭的，需要修改redis.conf配置文件来开启AOF：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 是否开启AOF功能，默认是no</span></span><br><span class="line"><span class="attr">appendonly</span> <span class="string">yes</span></span><br><span class="line"><span class="comment"># AOF文件的名称</span></span><br><span class="line"><span class="attr">appendfilename</span> <span class="string">&quot;appendonly.aof&quot;</span></span><br></pre></td></tr></table></figure>

<p>AOF的命令记录的频率也可以通过redis.conf文件来配：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 表示每执行一次写命令，立即记录到AOF文件</span></span><br><span class="line"><span class="attr">appendfsync</span> <span class="string">always </span></span><br><span class="line"><span class="comment"># 写命令执行完先放入AOF缓冲区，然后表示每隔1秒将缓冲区数据写到AOF文件，是默认方案</span></span><br><span class="line"><span class="attr">appendfsync</span> <span class="string">everysec </span></span><br><span class="line"><span class="comment"># 写命令执行完先放入AOF缓冲区，由操作系统决定何时将缓冲区内容写回磁盘</span></span><br><span class="line"><span class="attr">appendfsync</span> <span class="string">no</span></span><br></pre></td></tr></table></figure>

<p>三种策略对比：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725151654046.png" alt="image-20210725151654046"></p>
<img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241117220311689.png" alt="image-20241117220311689" style="zoom: 50%;" />

<h4 id="AOF-步骤"><a href="#AOF-步骤" class="headerlink" title="AOF 步骤"></a>AOF 步骤</h4><p><strong>命令追加（append）</strong>：所有的写命令会追加到 AOF 缓冲区中。</p>
<p><strong>文件写入（write）</strong>：将 AOF 缓冲区的数据写入到 AOF 文件中。这一步需要调用<code>write</code>函数（系统调用），<code>write</code>将数据写入到了系统内核缓冲区之后直接返回了（延迟写）。注意！！！此时并没有同步到磁盘。写入系统内核缓冲区之后直接返回（仅仅是写到缓冲区），不会立即同步到硬盘。虽然提高了效率，但也带来了数据丢失的风险。同步硬盘操作通常依赖于系统调度机制，Linux 内核通常为 30s 同步一次，具体值取决于写出的数据量和 I/O 缓冲区的状态。</p>
<p><strong>文件同步（fsync）</strong>：AOF 缓冲区根据对应的持久化方式（ <code>fsync</code> 策略）向硬盘做同步操作。这一步需要调用 <code>fsync</code> 函数（系统调用）， <code>fsync</code> 针对单个文件操作，对其进行强制硬盘同步，<code>fsync</code> 将阻塞直到写入磁盘完成后返回，保证了数据持久化。强制刷新系统内核缓冲区（同步到到磁盘），确保写磁盘操作结束才会返回。</p>
<p><strong>文件重写（rewrite）</strong>：随着 AOF 文件越来越大，需要定期对 AOF 文件进行重写，达到压缩的目的。</p>
<p><strong>重启加载（load）</strong>：当 Redis 重启时，可以加载 AOF 文件进行数据恢复。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/aof-work-process.png"></p>
<p>从 Redis 7 开始，Redis 使用了 <strong>Multi Part AOF</strong> 机制。顾名思义，Multi Part AOF 就是将原来的单个 AOF 文件拆分成多个 AOF 文件。在 Multi Part AOF 中，AOF 文件被分为三种类型，分别为：</p>
<ul>
<li>BASE：表示基础 AOF 文件，它一般由子进程通过重写产生，该文件最多只有一个。</li>
<li>INCR：表示增量 AOF 文件，它一般会在 AOFRW 开始执行时被创建，该文件可能存在多个。</li>
<li>HISTORY：表示历史 AOF 文件，它由 BASE 和 INCR AOF 变化而来，每次 AOFRW 成功完成时，本次 AOFRW 之前对应的 BASE 和 INCR AOF 都将变为 HISTORY，HISTORY 类型的 AOF 会被 Redis 自动删除。</li>
</ul>
<h4 id="AOF-文件重写"><a href="#AOF-文件重写" class="headerlink" title="AOF 文件重写"></a>AOF 文件重写</h4><p>因为是记录命令，AOF文件会比RDB文件大的多。而且AOF会记录对同一个key的多次写操作，但只有最后一次写操作才有意义。通过执行<code>bgrewriteaof</code>命令，可以让AOF文件执行重写功能，用最少的命令达到相同效果。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725151729118.png" alt="image-20210725151729118"></p>
<p>如图，AOF原本有三个命令，但是<code>set num 123 和 set num 666</code>都是对num的操作，第二次会覆盖第一次的值，因此第一个命令记录下来没有意义。</p>
<p>所以重写命令后，AOF文件内容就是：<code>mset name jack num 666</code></p>
<p>Redis也会在触发阈值时自动去重写AOF文件。阈值也可以在redis.conf中配置：</p>
<ol>
<li>增长百分比阈值</li>
<li>文件体积大小阈值</li>
</ol>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># AOF文件比上次文件 增长超过多少百分比则触发重写</span></span><br><span class="line"><span class="attr">auto-aof-rewrite-percentage</span> <span class="string">100</span></span><br><span class="line"><span class="comment"># AOF文件体积最小多大以上才触发重写 </span></span><br><span class="line"><span class="attr">auto-aof-rewrite-min-size</span> <span class="string">64mb </span></span><br></pre></td></tr></table></figure>

<h4 id="AOF-校验机制了解吗？"><a href="#AOF-校验机制了解吗？" class="headerlink" title="AOF 校验机制了解吗？"></a><a href="#aof-%E6%A0%A1%E9%AA%8C%E6%9C%BA%E5%88%B6%E4%BA%86%E8%A7%A3%E5%90%97">AOF 校验机制了解吗？</a></h4><p>AOF 校验机制是 Redis 在启动时对 AOF 文件进行检查，以判断文件是否完整，是否有损坏或者丢失的数据。这个机制的原理其实非常简单，就是通过使用一种叫做 <strong>校验和（checksum）</strong> 的数字来验证 AOF 文件。这个校验和是通过对整个 AOF 文件内容进行 CRC64 算法计算得出的数字。如果文件内容发生了变化，那么校验和也会随之改变。因此，Redis 在启动时会比较计算出的校验和与文件末尾保存的校验和（计算的时候会把最后一行保存校验和的内容给忽略点），从而判断 AOF 文件是否完整。如果发现文件有问题，Redis 就会拒绝启动并提供相应的错误信息。AOF 校验机制十分简单有效，可以提高 Redis 数据的可靠性。</p>
<hr>
<p>著作权归JavaGuide(javaguide.cn)所有 基于MIT协议 原文链接：<a target="_blank" rel="noopener" href="https://javaguide.cn/database/redis/redis-persistence.html">https://javaguide.cn/database/redis/redis-persistence.html</a></p>
<h3 id="RDB与AOF对比"><a href="#RDB与AOF对比" class="headerlink" title="RDB与AOF对比"></a>RDB与AOF对比</h3><p>RDB和AOF各有自己的优缺点，如果对数据安全性要求较高，在实际开发中往往会<strong>结合</strong>两者来使用。</p>
<ul>
<li>RDB 文件是以特定的二进制格式保存的，并且在 Redis 版本演进中有多个版本的 RDB，所以存在老版本的 Redis 服务不兼容新版本的 RDB 格式的问题。</li>
<li>AOF 以一种易于理解和解析的格式包含所有操作的日志。你可以轻松地导出 AOF 文件进行分析，你也可以直接操作 AOF 文件来解决一些问题。比如，如果执行<code>FLUSHALL</code>命令意外地刷新了所有内容后，只要 AOF 文件没有被重写，删除最新命令并重启即可恢复之前的状态。</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725151940515.png" alt="image-20210725151940515"></p>
<p>Redis 7.0 版本之前，如果在重写期间有写入命令，AOF 可能会使用大量内存，重写期间到达的所有写入命令都会写入磁盘两次。</p>
<p>Redis 7.0 版本之后，AOF 重写机制得到了优化改进。具体方法是采用 base（全量数据）+inc（增量数据）独立文件存储的方式，彻底解决内存和 IO 资源的浪费，同时也支持对历史 AOF 文件的保存管理，结合 AOF 文件中的时间信息还可以实现 PITR 按时间点恢复（阿里云企业版 Tair 已支持），这进一步增强了 Redis 的数据可靠性，满足用户数据回档等需求。</p>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/RnoPPL7jiFSKkx3G4p57Pg">从Redis7.0发布看Redis的过去与未来 (qq.com)</a> </p>
<h2 id="Master-Slave-集群：高并发读"><a href="#Master-Slave-集群：高并发读" class="headerlink" title="Master/Slave 集群：高并发读"></a>Master/Slave 集群：高并发读</h2><p>Redis 通过 Replica/Slave 从节点机制 完成主从复制与读写分离</p>
<h3 id="搭建主从架构"><a href="#搭建主从架构" class="headerlink" title="搭建主从架构"></a>搭建主从架构</h3><p>主从复制：单节点Redis的并发能力是有上限的，要进一步提高Redis的并发能力，就需要搭建主从集群，实现读写分离。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725152037611.png" alt="image-20210725152037611"></p>
<blockquote>
<p>步骤</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建三个文件夹，将redis.conf复制过去</span></span><br><span class="line"><span class="built_in">mkdir</span> 7001 7002 7003</span><br><span class="line"><span class="built_in">cp</span> redis-6.2.6/redis.conf 7001</span><br><span class="line"><span class="built_in">cp</span> redis-6.2.6/redis.conf 7002</span><br><span class="line"><span class="built_in">cp</span> redis-6.2.6/redis.conf 7003</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更改redis.conf中的port、dir</span></span><br><span class="line">sed -i -e <span class="string">&#x27;s/6379/7001/g&#x27;</span> -e <span class="string">&#x27;s/dir .\//dir \/root\/redissetup\/7001\//g&#x27;</span> 7001/redis.conf</span><br><span class="line">sed -i -e <span class="string">&#x27;s/6379/7002/g&#x27;</span> -e <span class="string">&#x27;s/dir .\//dir \/root\/redissetup\/7002\//g&#x27;</span> 7002/redis.conf</span><br><span class="line">sed -i -e <span class="string">&#x27;s/6379/7003/g&#x27;</span> -e <span class="string">&#x27;s/dir .\//dir \/root\/redissetup\/7003\//g&#x27;</span> 7003/redis.conf</span><br><span class="line"><span class="comment"># 添加主从配置ip</span></span><br><span class="line">sed -i <span class="string">&#x27;1a replica-announce-ip localhost&#x27;</span> 7001/redis.conf</span><br><span class="line">sed -i <span class="string">&#x27;1a replica-announce-ip localhost&#x27;</span> 7002/redis.conf</span><br><span class="line">sed -i <span class="string">&#x27;1a replica-announce-ip localhost&#x27;</span> 7003/redis.conf</span><br><span class="line"><span class="comment"># 添加主从配置端口号 和 主节点的密码</span></span><br><span class="line">sed -i <span class="string">&#x27;1i slaveof 127.0.0.1 7001&#x27;</span> 7002/redis.conf</span><br><span class="line">sed -i <span class="string">&#x27;2i masterauth 123321&#x27;</span> 7002/redis.conf</span><br><span class="line">sed -i <span class="string">&#x27;1i slaveof 127.0.0.1 7001&#x27;</span> 7003/redis.conf</span><br><span class="line">sed -i <span class="string">&#x27;2i masterauth 123321&#x27;</span> 7003/redis.conf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动redis-server</span></span><br><span class="line">redis-server -p 7001/redis.conf</span><br><span class="line">redis-server -p 7002/redis.conf</span><br><span class="line">redis-server -p 7003/redis.conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动命令行</span></span><br><span class="line">redis-cli -p 7001</span><br><span class="line">redis-cli -p 7002</span><br><span class="line">redis-cli -p 7003</span><br><span class="line"></span><br><span class="line">INFO replication <span class="comment">#显示主从信息</span></span><br></pre></td></tr></table></figure>



<h3 id="主从同步原理"><a href="#主从同步原理" class="headerlink" title="主从同步原理"></a>主从同步原理</h3><h4 id="全量同步"><a href="#全量同步" class="headerlink" title="全量同步"></a>全量同步</h4><p>主从第一次建立连接时，会执行<strong>全量同步</strong>，将master节点的所有数据都拷贝给slave节点，流程：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725152222497.png" alt="image-20210725152222497"></p>
<p>这里有一个问题，master如何得知slave是第一次来连接呢？？</p>
<p>有几个概念，可以作为判断依据：</p>
<ul>
<li><strong>Replication Id</strong>：简称replid，是数据集的标记，id一致则说明是同一数据集。每一个master都有唯一的replid，slave则会继承master节点的replid<mark>（表示主从关系）<mark> </li>
<li><strong>offset</strong>：偏移量，随着记录在repl_backlog中的数据增多而逐渐增大。slave完成同步时也会记录当前同步的offset。如果slave的offset小于master的offset，说明slave数据落后于master，需要更新。<mark>（表示数据版本）<mark></li>
</ul>
<p>因此slave做数据同步，必须向master声明自己的replication id 和offset，master才可以判断到底需要同步哪些数据。</p>
<p>因为slave原本也是一个master，有自己的replid和offset，当第一次变成slave，与master建立连接时，发送的replid和offset是自己的replid和offset。</p>
<p>master判断发现slave发送来的replid与自己的不一致，说明这是一个全新的slave，就知道要做全量同步了。</p>
<p>master会将自己的replid和offset都发送给这个slave，slave保存这些信息。以后slave的replid就与master一致了。</p>
<p>因此，<strong>master判断一个节点是否是第一次同步的依据，就是看replid是否一致</strong>。</p>
<p>如图：AOF + RDB</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725152700914.png" alt="image-20210725152700914"></p>
<p>完整流程描述：</p>
<ol>
<li><p>slave节点请求同步，发送replid + offset</p>
</li>
<li><p>master节点判断replid，发现不一致，则进行全量同步返回master的replid + offset</p>
<ul>
<li>master将完整内存数据生成RDB（bgsave）发送RDB到slave</li>
<li>slave清空本地数据，加载master的RDB</li>
<li>master将RDB期间的命令记录在repl_backlog，并持续将repl_backlog的命令发送给slave</li>
</ul>
</li>
<li><p>master节点判断replid，发现一致，并且offset较小</p>
<ul>
<li>去repl_backlog中取得offset之后的数据，将repl_backlog的命令发送给slave</li>
</ul>
</li>
<li><p>slave执行接收到的命令，保持与master之间的同步</p>
</li>
</ol>
<h4 id="增量同步"><a href="#增量同步" class="headerlink" title="增量同步"></a>增量同步</h4><p>全量同步需要先做RDB，然后将RDB文件通过网络传输给slave，成本太高了。因此除了第一次做全量同步，其它大多数时候slave与master都是做<strong>增量同步</strong></p>
<p>什么是增量同步？就是只更新slave与master存在差异的部分数据。如图：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725153201086.png" alt="image-20210725153201086"></p>
<p>那么master怎么知道slave与自己的数据差异在哪里呢?</p>
<h4 id="repl-backlog原理"><a href="#repl-backlog原理" class="headerlink" title="repl_backlog原理"></a>repl_backlog原理</h4><p>master怎么知道slave与自己的数据差异在哪里呢?</p>
<p>这就要说到全量同步时的repl_backlog文件了。</p>
<p>这个文件是一个固定大小的数组，只不过数组是环形，也就是说<strong>角标到达数组末尾后，会再次从0开始读写</strong>，这样数组头部的数据就会被覆盖。</p>
<p>repl_backlog中会记录Redis处理过的命令日志及offset，包括master当前的offset，和slave已经拷贝到的offset：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725153359022.png" alt="image-20210725153359022"> </p>
<p>slave与master的offset之间的差异，就是slave需要增量拷贝的数据了。</p>
<p>随着不断有数据写入，master的offset逐渐变大，slave也不断的拷贝，追赶master的offset：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725153524190.png" alt="image-20210725153524190"> </p>
<p>直到数组被填满：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725153715910.png" alt="image-20210725153715910"> </p>
<p>此时，如果有新的数据写入，就会覆盖数组中的旧数据。不过，旧的数据只要是绿色的，说明是已经被同步到slave的数据，即便被覆盖了也没什么影响。因为未同步的仅仅是红色部分。</p>
<p>但是，如果slave出现网络阻塞，导致master的offset远远超过了slave的offset：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725153937031.png" alt="image-20210725153937031"> </p>
<p>slave : 5 master 110(10) 10-100错过的数据还在，错过了105-110(5-10)的数据</p>
<p>如果master继续写入新数据，其offset就会覆盖旧的数据，直到将slave现在的offset也覆盖：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725154155984.png" alt="image-20210725154155984"> </p>
<p>棕色框中的红色部分，就是尚未同步，但是却已经被覆盖的数据。此时如果slave恢复，需要同步，却发现自己的offset都没有了，无法完成增量同步了。只能做全量同步。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725154216392.png" alt="image-20210725154216392"></p>
<h3 id="主从同步优化"><a href="#主从同步优化" class="headerlink" title="主从同步优化"></a>主从同步优化</h3><p>主从同步可以保证主从数据的一致性，非常重要。</p>
<p>可以从以下几个方面来优化Redis主从就集群：</p>
<ul>
<li><p>提高全量同步的性能</p>
<ul>
<li><p>在master中配置repl-diskless-sync yes启用无磁盘复制，避免全量同步时的磁盘IO。（磁盘慢，网络快）</p>
</li>
<li><p>Redis单节点上的内存占用不要太大，减少RDB导致的过多磁盘IO（RDB 小）</p>
</li>
</ul>
</li>
</ul>
<ul>
<li>适当提高repl_backlog的大小，发现slave宕机时尽快实现故障恢复，尽可能避免全量同步(OFFSET_MAX)</li>
<li>限制一个master上的slave节点数量，如果实在是太多slave，则可以采用主-从-从链式结构，减少master压力（减少压力）</li>
</ul>
<p>主从从架构图：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725154405899.png" alt="image-20210725154405899"></p>
<h3 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h3><h4 id="简述全量同步和增量同步区别？"><a href="#简述全量同步和增量同步区别？" class="headerlink" title="简述全量同步和增量同步区别？"></a>简述全量同步和增量同步区别？</h4><ul>
<li>全量同步：master将完整内存数据生成RDB，发送RDB到slave。后续命令则记录在repl_backlog，逐个发送给slave。</li>
<li>增量同步：slave提交自己的offset到master，master获取repl_backlog中从offset之后的命令给slave</li>
</ul>
<h4 id="什么时候执行全量同步？"><a href="#什么时候执行全量同步？" class="headerlink" title="什么时候执行全量同步？"></a>什么时候执行全量同步？</h4><ul>
<li>slave节点第一次连接master节点时</li>
<li>slave节点断开时间太久，repl_backlog中的offset已经被覆盖时</li>
</ul>
<h4 id="什么时候执行增量同步？"><a href="#什么时候执行增量同步？" class="headerlink" title="什么时候执行增量同步？"></a>什么时候执行增量同步？</h4><ul>
<li>slave节点断开又恢复，并且在repl_backlog中能找到offset时</li>
</ul>
<h2 id="Sentinel-集群：保证M-S高可用"><a href="#Sentinel-集群：保证M-S高可用" class="headerlink" title="Sentinel 集群：保证M/S高可用"></a>Sentinel 集群：保证M/S高可用</h2><p>Redis提供了哨兵（Sentinel）机制来实现主从集群的自动故障恢复。</p>
<h3 id="哨兵原理"><a href="#哨兵原理" class="headerlink" title="哨兵原理"></a>哨兵原理</h3><h4 id="集群结构和作用"><a href="#集群结构和作用" class="headerlink" title="集群结构和作用"></a>集群结构和作用</h4><p>哨兵的结构如图：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725154528072.png" alt="image-20210725154528072"></p>
<p>哨兵的作用如下：</p>
<ul>
<li><strong>监控</strong>：Sentinel 会不断检查您的master和slave是否按预期工作 </li>
<li><strong>自动故障恢复（转移）</strong>：如果master故障，Sentinel会<mark>将一个slave提升为master<mark>。当故障实例恢复后也以新的master为主</li>
<li><strong>通知</strong>：Sentinel充当Redis<mark>客户端的服务发现来源<mark>，当集群发生故障转移时，会将最新信息推送给Redis的客户端</li>
</ul>
<h4 id="集群监控状态原理：心跳机制"><a href="#集群监控状态原理：心跳机制" class="headerlink" title="集群监控状态原理：心跳机制"></a>集群监控状态原理：心跳机制</h4><p>Sentinel基于<mark>心跳机制<mark>监测服务状态，每隔<mark>1秒<mark>向集群的每个实例<mark>发送ping命令<mark>：</p>
<p>•主观下线：如果某sentinel节点发现某实例未在规定时间响应，则认为该实例<strong>主观下线</strong>。</p>
<p>•客观下线：若超过指定数量（quorum）的sentinel都认为该实例主观下线，则该实例<strong>客观下线</strong>。quorum值最好超过Sentinel实例数量的一半。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725154632354.png" alt="image-20210725154632354"></p>
<h4 id="集群故障恢复原理：选举机制"><a href="#集群故障恢复原理：选举机制" class="headerlink" title="集群故障恢复原理：选举机制"></a>集群故障恢复原理：选举机制</h4><p>一旦发现master故障，sentinel需要在slave中选择一个作为新的master，选择依据是这样的：</p>
<ul>
<li><strong>与master断开时间</strong>：首先会判断slave节点与master节点断开时间长短，如果超过指定值（down-after-milliseconds * 10）则会排除该slave节点</li>
<li><strong>优先级</strong>：然后判断slave节点的slave-priority值，越小优先级越高，如果是0则永不参与选举</li>
<li><strong>offset</strong>：如果slave-prority一样，则判断slave节点的offset值，越大说明数据越新，优先级越高</li>
<li><strong>运行id</strong>：最后是判断slave节点的运行id大小，越小优先级越高。每个 redis 节点启动时都有一个 40 字节随机字符串作为运行 id。</li>
</ul>
<p>当选出一个新的master后，该如何实现切换呢？</p>
<p>流程如下：</p>
<ul>
<li>sentinel给备选的slave1节点发送<code>slaveof no one</code>命令，让该节点成为master</li>
<li>sentinel给所有其它slave发送slaveof 127.0.0.1 7002(也就是slave1) 命令，让这些slave成为新master的从节点，开始从新的master上同步数据。</li>
<li>最后，sentinel将故障节点标记为slave，当故障节点恢复后会自动成为新的master的slave节点</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725154816841.png" alt="image-20210725154816841"></p>
<h4 id="小结-2"><a href="#小结-2" class="headerlink" title="小结"></a>小结</h4><h5 id="Sentinel的三个作用是什么？"><a href="#Sentinel的三个作用是什么？" class="headerlink" title="Sentinel的三个作用是什么？"></a>Sentinel的三个作用是什么？</h5><ul>
<li>监控</li>
<li>故障转移</li>
<li>通知</li>
</ul>
<h5 id="Sentinel如何判断一个redis实例是否健康？"><a href="#Sentinel如何判断一个redis实例是否健康？" class="headerlink" title="Sentinel如何判断一个redis实例是否健康？"></a>Sentinel如何判断一个redis实例是否健康？</h5><ul>
<li>每隔1秒发送一次ping命令，如果超过一定时间没有相向则认为是主观下线</li>
<li>如果大多数sentinel都认为实例主观下线，则判定服务下线</li>
</ul>
<h5 id="故障转移步骤有哪些？"><a href="#故障转移步骤有哪些？" class="headerlink" title="故障转移步骤有哪些？"></a>故障转移步骤有哪些？</h5><ul>
<li>首先选定一个slave作为新的master，执行slaveof no one</li>
<li>然后让所有节点(包括故障节点)都执行slaveof 新master</li>
<li>修改故障节点配置，添加slaveof 新master</li>
</ul>
<blockquote>
<p>搭建哨兵集群：master宕机案例</p>
</blockquote>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241119171035000.png" alt="image-20241119171035000"></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241119171850683.png" alt="image-20241119171850683"></p>
<p>从节点连不上主节点</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241119172740595.png" alt="image-20241119172740595"></p>
<p>哨兵选举一个slave作为新的master</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241119172833310.png" alt="image-20241119172833310"></p>
<p>被选中的slave变成master</p>
<h3 id="客户端配置"><a href="#客户端配置" class="headerlink" title="客户端配置"></a>客户端配置</h3><p>在Sentinel集群监管下的Redis主从集群，其节点会因为自动故障转移而发生变化，Redis的客户端必须感知这种变化，及时更新连接信息。Spring的RedisTemplate底层利用lettuce实现了节点的感知和自动切换。</p>
<p>下面，我们通过一个测试来实现RedisTemplate集成哨兵机制。</p>
<h4 id="引入依赖"><a href="#引入依赖" class="headerlink" title="引入依赖"></a>引入依赖</h4><p>在项目的pom文件中引入依赖：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-data-redis<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="配置Redis哨兵集群地址"><a href="#配置Redis哨兵集群地址" class="headerlink" title="配置Redis哨兵集群地址"></a>配置Redis哨兵集群地址</h4><p>然后在配置文件application.yml中指定redis的sentinel相关信息：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">spring:</span><br><span class="line">  redis:</span><br><span class="line">    sentinel:</span><br><span class="line">      master: mymaster</span><br><span class="line">      nodes:</span><br><span class="line">        - <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">27001</span><span class="comment">//哨兵一号</span></span><br><span class="line">        - <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">27002</span></span><br><span class="line">        - <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">27003</span></span><br></pre></td></tr></table></figure>

<p>哨兵的启动配置文件里已经有了主节点的一切信息，IP+PORT+quorum+name，只需要引入哨兵就能启用集群</p>
<h4 id="配置读写分离"><a href="#配置读写分离" class="headerlink" title="配置读写分离"></a>配置读写分离</h4><p>在项目的启动类中，添加一个新的bean：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="keyword">public</span> LettuceClientConfigurationBuilderCustomizer <span class="title function_">clientConfigurationBuilderCustomizer</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> clientConfigurationBuilder -&gt; clientConfigurationBuilder.readFrom(ReadFrom.REPLICA_PREFERRED);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>这个bean中配置的就是读写策略，包括四种：</p>
<ul>
<li>MASTER：从主节点读取</li>
<li>MASTER_PREFERRED：优先从master节点读取，master不可用才读取replica</li>
<li>REPLICA：从slave（replica）节点读取</li>
<li><mark>REPLICA _PREFERRED<mark>：优先从slave（replica）节点读取，所有的slave都不可用才读取master</li>
</ul>
<p>每个节点都会建立连接，读取时会按照读写分离的策略读。</p>
<h2 id="Cluster-集群：高并发写与海量数据存储"><a href="#Cluster-集群：高并发写与海量数据存储" class="headerlink" title="Cluster 集群：高并发写与海量数据存储"></a>Cluster 集群：高并发写与海量数据存储</h2><p>Redis Cluster 解决了哨兵机制的弊端：每个实例全量存储，木桶效应，提供动态的横向扩展，</p>
<h3 id="纵向-横向扩展"><a href="#纵向-横向扩展" class="headerlink" title="纵向/横向扩展"></a>纵向/横向扩展</h3><p>纵向也可以多节点，纵/横的标准是：是否所有节点的存储内容都一样</p>
<p>究竟选择scale-up（纵向）还是scale-out（横向）架构,主要考虑以下因素：</p>
<table>
<thead>
<tr>
<th align="center">成本</th>
<th align="left">Scale-up架构只有容量升级的成本，不会增加控制器或基础设施的开销。如果我们主要衡量每GB存储的单位价格，scale-up的扩展方式无疑更便宜一些</th>
</tr>
</thead>
<tbody><tr>
<td align="center">容量</td>
<td align="left">两种解决方案都可以满足容量需求，但scale-up架构也许会有些限制，主要取决于单个系统最大支持多少个磁盘数量和多大的容量</td>
</tr>
<tr>
<td align="center">性能</td>
<td align="left">Scale-out架构在性能上具有扩展潜力，在多个存储控制器下，IOPS处理能力和吞吐带宽都可以聚合。虽然节点之间的通信会引发延迟，但那是部署时的细节问题</td>
</tr>
<tr>
<td align="center">管理</td>
<td align="left">Scale-up架构本身就是以单一系统的方式来进行管理的。而Scale-out架构通常有聚合管理的能力，但每个厂商提供的产品可能会有所不同</td>
</tr>
<tr>
<td align="center">复杂性</td>
<td align="left">Scale-up架构的存储相对简单，而scale-out架构的系统会更复杂一些，毕竟每个节点都需要管理</td>
</tr>
<tr>
<td align="center">可用性</td>
<td align="left">多个节点可以提供更好的可用性，假使有一个部件故障或失效，系统也不至于整体宕机。这一点与具体的实施方案也有关系</td>
</tr>
</tbody></table>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241119184050478.png" alt="Scale-UP 纵向扩展"></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241119184124945.png" alt="Scale-OUT 横向扩展"></p>
<h3 id="搭建分片集群"><a href="#搭建分片集群" class="headerlink" title="搭建分片集群"></a>搭建分片集群</h3><p>主从和哨兵可以解决高可用、高并发读的问题。但是依然有两个问题没有解决：</p>
<ul>
<li><p><mark>海量数据存储问题<mark></p>
</li>
<li><p><mark>高并发写的问题<mark></p>
</li>
</ul>
<p>使用横向扩展分片集群可以解决上述问题，如图:</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725155747294.png" alt="分片集群"></p>
<p>分片集群特征：</p>
<ul>
<li><p>集群中有多个master，每个master保存不同数据</p>
</li>
<li><p>每个master都可以有多个slave节点（高可用）</p>
</li>
<li><p>slave 不对外提供读服务，主要用来保障 master 的高可用，做数据的热备份，当 master 出现故障的时候替代它。</p>
</li>
<li><p>master之间通过ping监测彼此健康状态（全员哨兵）</p>
</li>
<li><p>客户端请求可以访问集群任意节点，最终都会被自动路由转发到正确节点（自动路由）</p>
</li>
</ul>
<p>本质就是多个主从集群的互相监控，不需要另外sentinel的监控，不过此时的slave</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">port</span> <span class="string">6379</span></span><br><span class="line"><span class="comment"># 开启集群功能</span></span><br><span class="line"><span class="attr">cluster-enabled</span> <span class="string">yes</span></span><br><span class="line"><span class="comment"># 集群的配置文件名称，不需要我们创建，由redis自己维护</span></span><br><span class="line"><span class="attr">cluster-config-file</span> <span class="string">/root/redissetup/6379/nodes.conf</span></span><br><span class="line"><span class="comment"># 节点心跳失败的超时时间</span></span><br><span class="line"><span class="attr">cluster-node-timeout</span> <span class="string">5000</span></span><br><span class="line"><span class="comment"># 持久化</span></span><br><span class="line"><span class="attr">dir</span> <span class="string">/root/redissetup/6379</span></span><br><span class="line"></span><br><span class="line"><span class="attr">bind</span> <span class="string">0.0.0.0</span></span><br><span class="line"><span class="comment"># 后台运行</span></span><br><span class="line"><span class="attr">daemonize</span> <span class="string">yes</span></span><br><span class="line"><span class="comment"># 主从ip地址</span></span><br><span class="line"><span class="attr">replica-announce-ip</span> <span class="string">127.0.0.1</span></span><br><span class="line"><span class="comment"># 保护模式</span></span><br><span class="line"><span class="attr">protected-mode</span> <span class="string">no</span></span><br><span class="line"></span><br><span class="line"><span class="attr">databases</span> <span class="string">1</span></span><br><span class="line"><span class="comment"># 日志记录</span></span><br><span class="line"><span class="attr">logfile</span> <span class="string">/root/redissetup/6379/run.log</span></span><br></pre></td></tr></table></figure>



<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">printf</span> <span class="string">&#x27;%s\n&#x27;</span> 7001 7002 7003 8001 8002 8003 | xargs -I&#123;&#125; -t sed -i <span class="string">&#x27;s/6379/&#123;&#125;/g&#x27;</span> &#123;&#125;/redis.conf</span><br><span class="line"><span class="comment"># 编辑端口号</span></span><br><span class="line"><span class="built_in">printf</span> <span class="string">&#x27;%s\n&#x27;</span> 7001 7002 7003 8001 8002 8003 | xargs -I&#123;&#125; -t redis-server &#123;&#125;/redis.conf</span><br><span class="line"><span class="comment"># 开启服务器实例</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis-cli --cluster create --cluster-replicas 1 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:8001 127.0.0.1:8002 127.0.0.1:8003</span><br><span class="line"><span class="comment"># 开启分片集群功能</span></span><br></pre></td></tr></table></figure>

<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241119193312708.png" alt="image-20241119193312708"></p>
<p>6/(1+1) = 3</p>
<p>！！！！！！！！</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241119201022033.png" alt="image-20241119201022033"></p>
<p>启动一定加 -c</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241119203336515.png" alt="image-20241119203336515"></p>
<p>查看节点状况</p>
<h3 id="散列插槽（Hashslot）"><a href="#散列插槽（Hashslot）" class="headerlink" title="散列插槽（Hashslot）"></a>散列插槽（Hashslot）</h3><h4 id="slot原理"><a href="#slot原理" class="headerlink" title="slot原理"></a>slot原理</h4><p>Redis Cluster 并没有使用一致性哈希，采用的是 哈希槽分区 ，每一个键值对都属于一个 hash slot（哈希槽） 。</p>
<p>Redis会把每一个master节点映射到0~16383共16384个插槽（hash slot）上，查看集群信息时就能看到：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725155820320.png" alt="image-20210725155820320"></p>
<p>数据key不是与节点绑定，而是与插槽绑定。redis会根据key的有效部分计算插槽值，分两种情况：</p>
<ul>
<li><mark>key中包含”{}”，且“{}”中至少包含1个字符，“{}”中的部分是有效部分<mark> </li>
<li>key中不包含“{}”，整个key都是有效部分</li>
</ul>
<p>例如：key是num，那么就根据num计算，如果是{itcast}num，则根据itcast计算。计算方式是利用CRC16算法得到一个hash值，然后对16384取余，得到的结果就是slot值。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241119201236259.png" alt="image-20241119201236259"> </p>
<p>如图，在7001这个节点执行set a 1时，对a做hash运算，对16384取余，得到的结果是15495，因此要存储到7003节点。</p>
<p>到了7003后，执行<code>get num</code>时，对num做hash运算，对16384取余，得到的结果是2765，因此需要切换到7001节点</p>
<p>当客户端发送命令请求的时候，需要</p>
<ul>
<li>先根据 key 找到的对应的哈希槽，</li>
<li>然后再查询哈希槽和节点的映射关系，即可找到目标节点。 </li>
</ul>
<h4 id="哈希槽数目为什么选择-16384？"><a href="#哈希槽数目为什么选择-16384？" class="headerlink" title="哈希槽数目为什么选择 16384？"></a>哈希槽数目为什么选择 16384？</h4><p><code>CRC16</code>算法产生的hash值有16bit，该算法可以产生2^16-=65536个值。换句话说，值是分布在0~65535之间。那作者在做<code>mod</code>运算的时候，为什么不<code>mod</code>65536，而选择<code>mod</code>16384？</p>
<p>哈希槽的数量选择 16384 而不是 65536 的主要原因：</p>
<ul>
<li>哈希槽太大会导致心跳包（包括slots信息）太大，消耗太多带宽； </li>
<li>哈希槽总数越少，对存储哈希槽信息的 bitmap 压缩效果越好； </li>
<li>Redis Cluster 的主节点通常不会扩展太多，16384 个哈希槽已经足够用了。</li>
</ul>
<p>一致性哈希理论上可以有2^32^个节点，实际上不会有那么多，</p>
<p>正常的心跳包会携带一个节点的完整配置，它会以幂等的方式更新旧的配置，这意味着心跳包会附 带当前节点的负责的哈希槽的信息。假设哈希槽采用 16384 ,则占空间 2k(16384/8)。假设哈希槽 采用 65536， 则占空间 8k(65536/8)，这是令人难以接受的内存占用。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    <span class="comment">// 省略部分字段</span></span><br><span class="line">    <span class="comment">// ......</span></span><br><span class="line">    <span class="comment">// 本节点负责的哈希槽信息,16384/8 个 char 数组，一共为16384bit</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> myslots[CLUSTER_SLOTS/<span class="number">8</span>];</span><br><span class="line">    <span class="comment">// 集群的状态</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> state;</span><br><span class="line">    <span class="comment">// 消息的内容</span></span><br><span class="line">    <span class="class"><span class="keyword">union</span> <span class="title">clusterMsgData</span> <span class="title">data</span>;</span></span><br><span class="line">&#125; clusterMsg;</span><br></pre></td></tr></table></figure>

<p>可以看到哈希槽是使用槽位数/8 使用一个char数组来表示，这里实际就是通过 bitmap 这种数据结构维护的哈希槽信息，每一个 bit 代表一个哈希槽，每个 bit 只能 存储 0/1 。如果该位为 1，表示这个哈希槽是属于这个节点。</p>
<p>虽说 Redis Cluster 可以扩展到 1000 个节点，但强烈不推荐这样做，应尽量避免集群中的节点过多。这 是因为 Redis Cluster 中的各个节点基于 Gossip 协议 来进行通信共享信息，当节点过多时，<strong>Gossip</strong> 协议的效率会显著下降，通信成本剧增。请注意，在小簇中，位图将很难压缩，因为当 N 很小时，位图将具有插槽/N 位设置，这是位设置的很大百分比。</p>
<h4 id="为什么不采用一致性哈希？"><a href="#为什么不采用一致性哈希？" class="headerlink" title="为什么不采用一致性哈希？"></a>为什么不采用一致性哈希？</h4><p>一致性哈希：为了防止节点和数据绑定，将整个哈希结果构造为一个2^32的域，服务器名称也在域中，根据key的哈希结果和服务器的位置关系判断应该访问哪个服务器。（狭义上）</p>
<p>为啥redis cluster 不设置 2的32次方个槽位呢？主要是考虑节点数在1000的规模左右，而使用 <strong>Gossip</strong> 去中心一致性协议，数据包不能太大，16K 个二进制位 2K字节已经很大了。</p>
<p>Redis 选择哈希插槽，是因为其设计目标（强一致性、高可用性）与哈希插槽的特性高度契合，而一致性哈希更适合对扩展性要求更高、允许最终一致性的场景（如缓存系统）。</p>
<ul>
<li><p>一致性hash 哈希环顺时针映射 优先考虑的是： 如何实现 最少的节点数据发生数据迁移。</p>
<p>一致性hash 哈希环上面，只有被干掉的节点顺时针方向最近的那一个节点涉及到数据迁移；其他间隔较远的节点，不涉及到数据迁移。迁移范围仅限环上相邻节点间的键。</p>
</li>
<li><p>redis cluster 哈希槽静态映射 优先考虑的是： 如何 实现数据的均匀。</p>
<p>槽位是逻辑单位，节点是物理单位，二者通过配置文件或集群协议关联。<strong>映射关系由集群元数据控制</strong>（如 Redis Cluster 的 Gossip 协议同步），客户端需缓存槽位分布表。</p>
<p>redis cluster 各个节点都会参与数据迁移，优先保证各个redis节点承担同样的访问压力。</p>
</li>
<li><p>同时，redis cluster 哈希槽静态映射还有一个优点，<mark>手动迁移<mark>。</p>
<p>redis cluster 可以自动分配，也可以根据节点的性能（比如Memory大小） 手动的调整slot的分配。</p>
</li>
</ul>
<h4 id="如何判断某个key应该在哪个实例？"><a href="#如何判断某个key应该在哪个实例？" class="headerlink" title="如何判断某个key应该在哪个实例？"></a>如何判断某个key应该在哪个实例？</h4><ul>
<li>将16384个插槽分配到不同的实例</li>
<li>根据key的有效部分计算哈希值，对16384取余</li>
<li>余数作为插槽，寻找插槽所在实例即可</li>
</ul>
<h4 id="如何将同一类数据固定的保存在同一个实例？"><a href="#如何将同一类数据固定的保存在同一个实例？" class="headerlink" title="如何将同一类数据固定的保存在同一个实例？"></a>如何将同一类数据固定的保存在同一个实例？</h4><p>不同节点之间的切换比较耗时，所以同类的key尽量存在同一个节点上面</p>
<ul>
<li>这一类数据使用相同的有效部分，例如key都以{typeId}为前缀</li>
</ul>
<p><mark>要清楚的一点：<mark>数据不存在hash插槽上，因此也不存在哈希冲突这一说，key映射到某个哈希插槽仅仅说明它属于XX节点，将来相同key也会去找相同的节点，仅此而已。</p>
<h3 id="集群伸缩：插槽迁移"><a href="#集群伸缩：插槽迁移" class="headerlink" title="集群伸缩：插槽迁移"></a>集群伸缩：插槽迁移</h3><p>redis-cli –cluster提供了很多操作集群的命令，可以通过下面方式查看：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725160138290.png" alt="image-20210725160138290"></p>
<p>比如，添加节点的命令：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725160448139.png" alt="image-20210725160448139"></p>
<p>需求：向集群中添加一个新的master节点，并向其中存储 num = 10</p>
<ul>
<li>启动一个新的redis实例，端口为7004</li>
<li>添加7004到之前的集群，并作为一个master节点</li>
<li>给7004节点分配插槽，使得num这个key可以存储到7004实例</li>
</ul>
<p>这里需要两个新的功能：</p>
<ul>
<li>添加一个节点到集群中</li>
<li>将部分插槽分配到新插槽</li>
</ul>
<blockquote>
<p>步骤</p>
</blockquote>
<p><strong>创建新的redis实例</strong></p>
<p>创建一个文件夹：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> 7004</span><br></pre></td></tr></table></figure>

<p>拷贝配置文件：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> redis.conf /7004</span><br></pre></td></tr></table></figure>

<p>修改配置文件：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed /s/6379/7004/g 7004/redis.conf</span><br></pre></td></tr></table></figure>

<p>启动</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-server 7004/redis.conf</span><br></pre></td></tr></table></figure>



<p><strong>添加新节点到redis</strong></p>
<p>添加节点的语法如下：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725160448139.png" alt="image-20210725160448139"></p>
<p>执行命令：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli --cluster add-node  127.0.0.1:7004 127.0.0.1:7001</span><br></pre></td></tr></table></figure>



<p>通过命令查看集群状态：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -p 7001 cluster nodes</span><br></pre></td></tr></table></figure>



<p>如图，7004加入了集群，并且默认是一个master节点：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725161007099.png" alt="image-20210725161007099"></p>
<p>但是，可以看到7004节点的插槽数量为0，因此没有任何数据可以存储到7004上</p>
<p><strong>转移插槽</strong></p>
<p>每个数据都有对应的插槽编号，可以根据编号查出数据</p>
<p>我们要将num存储到7004节点，因此需要先看看num的插槽是多少：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725161241793.png" alt="image-20210725161241793"></p>
<p>如上图所示，num的插槽为2765.</p>
<p>我们可以将0~3000的插槽从7001转移到7004，命令格式如下：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725161401925.png" alt="image-20210725161401925"></p>
<p>具体命令如下：</p>
<p>建立连接：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725161506241.png" alt="image-20210725161506241"></p>
<p>得到下面的反馈：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725161540841.png" alt="image-20210725161540841"></p>
<p>询问要移动多少个插槽，我们计划是3000个：新的问题来了：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725161637152.png" alt="image-20210725161637152"></p>
<p>那个node来接收这些插槽？？显然是7004，那么7004节点的id是多少呢？</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725161731738.png" alt="image-20210725161731738"></p>
<p>复制这个id，然后拷贝到刚才的控制台后：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725161817642.png" alt="image-20210725161817642"></p>
<p>这里询问，你的插槽是从哪里移动过来的？</p>
<ul>
<li>all：代表全部，也就是三个节点各转移一部分</li>
<li>具体的id：目标节点的id</li>
<li>done：没有了</li>
</ul>
<p>这里我们要从7001获取，因此填写7001的id：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725162030478.png" alt="image-20210725162030478"></p>
<p>填完后，点击done，这样插槽转移就准备好了：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725162101228.png" alt="image-20210725162101228"></p>
<p>确认要转移吗？输入yes：然后，通过命令查看结果：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725162145497.png" alt="image-20210725162145497"> </p>
<p>可以看到： </p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725162224058.png" alt="image-20210725162224058"></p>
<p>目的达成。</p>
<h4 id="迁移流程：集群节点的数据结构"><a href="#迁移流程：集群节点的数据结构" class="headerlink" title="迁移流程：集群节点的数据结构"></a>迁移流程：集群节点的数据结构</h4><p>每个节点都有一个对应的clusterNode clusterState结构</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/%E6%97%A0%E6%A0%87%E9%A2%98.jpg"></p>
<p>存储的时候，会根据key计算哈希，这是key到哈希槽位的映射，</p>
<p>迁移的时候，如果遍历整个数据库，分别计算哈希，效率低下，因此节点自身用一个跳表slots_to_key维护槽位到key的映射，score是槽位号，member是key值    </p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/sulishihupan/p/14538864.html">Redis–集群Cluster（槽指派、重新分片） - 苏黎世湖畔 - 博客园 (cnblogs.com)</a> </p>
<p>假设将 <code>0-3000</code> 插槽从节点 A 迁移至节点 B：</p>
<ol>
<li>节点 A 标记为 <code>MIGRATING</code>，表示它即将释放这些插槽。节点 B 标记为 <code>IMPORTING</code>，表示它即将接管这些插槽。</li>
<li>通知所有节点，让客户端感知到这些插槽的迁移状态，确保客户端请求能够动态路由到正确的节点。</li>
</ol>
<h3 id="故障转移：全员哨兵"><a href="#故障转移：全员哨兵" class="headerlink" title="故障转移：全员哨兵"></a>故障转移：全员哨兵</h3><p>clusterState结构中，有一个nodes，指向其他节点，因此能够实现全员哨兵</p>
<p>有了 Redis Cluster 之后，不需要专门部署 Sentinel 集群服务了。Redis Cluster 相当于是内置了 Sentinel 机制，Redis Cluster 内部的各个 Redis 节点通过 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/463455831">Gossip 协议</a>互相探测健康状态，在故障时可 以自动切换。</p>
<p>集群初始状态是这样的：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210727161152065.png" alt="image-20210727161152065"></p>
<p>其中7001、7002、7003都是master，我们计划让7002宕机。</p>
<h4 id="自动故障转移"><a href="#自动故障转移" class="headerlink" title="自动故障转移"></a>自动故障转移</h4><p>当集群中有一个master宕机会发生什么呢？</p>
<p>直接停止一个redis实例，例如7002：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -p 7002 shutdown</span><br></pre></td></tr></table></figure>

<p>1）首先是该实例与其它实例失去连接</p>
<p>2）然后是疑似宕机：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725162319490.png" alt="image-20210725162319490"></p>
<p>3）最后是确定下线，自动提升一个slave为新的master：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725162408979.png" alt="image-20210725162408979"></p>
<p>4）当7002再次启动，就会变为一个slave节点了：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210727160803386.png" alt="image-20210727160803386"></p>
<h4 id="手动故障转移"><a href="#手动故障转移" class="headerlink" title="手动故障转移"></a>手动故障转移</h4><p>利用cluster failover命令可以手动让集群中的某个master宕机，切换到执行cluster failover命令的这个slave节点，实现无感知的数据迁移。其流程如下：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210725162441407.png" alt="image-20210725162441407"></p>
<p>这种failover命令可以指定三种模式：</p>
<ul>
<li>缺省：默认的流程，如图1~6歩</li>
<li>force：省略了对offset的一致性校验</li>
<li>takeover：直接执行第5歩，忽略数据一致性、忽略master状态和其它master的意见</li>
</ul>
<p><strong>案例需求</strong>：在7002这个slave节点执行手动故障转移，重新夺回master地位</p>
<p>步骤如下：</p>
<p>1）利用redis-cli连接7002这个节点</p>
<p>2）执行cluster failover命令</p>
<p>如图：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210727160037766.png" alt="image-20210727160037766"></p>
<p>效果：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210727161152065.png" alt="image-20210727161152065"></p>
<h3 id="客户端访问分片集群"><a href="#客户端访问分片集群" class="headerlink" title="客户端访问分片集群"></a>客户端访问分片集群</h3><p>RedisTemplate底层同样基于lettuce实现了分片集群的支持，而使用的步骤与哨兵模式基本一致：</p>
<p>1）引入redis的starter依赖</p>
<p>2）配置分片集群地址</p>
<p>3）配置读写分离</p>
<p>与哨兵模式相比，其中只有分片集群的配置方式略有差异，如下：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">redis:</span></span><br><span class="line">    <span class="attr">cluster:</span></span><br><span class="line">      <span class="attr">nodes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:7001</span></span><br><span class="line">        <span class="bullet">-</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:7002</span></span><br><span class="line">        <span class="bullet">-</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:7003</span></span><br><span class="line">        <span class="bullet">-</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:8001</span></span><br><span class="line">        <span class="bullet">-</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:8002</span></span><br><span class="line">        <span class="bullet">-</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:8003</span></span><br></pre></td></tr></table></figure>

<h4 id="客户端访问时集群正在迁移数据怎么办？"><a href="#客户端访问时集群正在迁移数据怎么办？" class="headerlink" title="客户端访问时集群正在迁移数据怎么办？"></a>客户端访问时集群正在迁移数据怎么办？</h4><p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20241119212106075.png" alt="image-20241119212106075"></p>
<h5 id="ASK"><a href="#ASK" class="headerlink" title="ASK"></a>ASK</h5><ol>
<li>客户端发送请求命令，如果请求的 key 对应的哈希槽还在当前节点，就直接响应客户端的请求。如果客户端请求的 key 对应的哈希槽当前正在迁移至新的节点，就会返回<code>-ASK</code> 重定向错误，告知客户端要将请求发送到哈希槽被迁移到的目标节点。</li>
<li>客户端收到<code>-ASK</code>重定向错误后，将会临时（一次性）重定向，自动向目标节点发送一条 ASKING 命令。也就是说，接收到 ASKING 命令的节点会强制执行一次请求，下次再来需要重新提前发送 ASKING 命令。</li>
<li>ASK 重定向并不会同步更新客户端缓存的哈希槽分配信息，也就是说，客户端对正在迁移的相同哈希槽的请求依然会发送到原节点而不是目标节点。</li>
</ol>
<h5 id="MOVED"><a href="#MOVED" class="headerlink" title="MOVED"></a>MOVED</h5><ol>
<li>当客户端请求的 key 对应的哈希槽迁移完成，就会返回 -MOVED 重定向错误，告知客户端当前哈希槽是由哪个节点负责，客户端向目标节点发送请求并更新缓存的哈希槽分配信息。</li>
</ol>
<h5 id="客户端缓存插槽与节点映射表"><a href="#客户端缓存插槽与节点映射表" class="headerlink" title="客户端缓存插槽与节点映射表"></a>客户端缓存插槽与节点映射表</h5><p>当 Redis 客户端连接到集群时，会通过 <code>CLUSTER SLOTS</code> 命令从 Redis 获取插槽与节点的对应关系。客户端将这张表缓存起来，用于后续操作中快速定位目标节点，而无需每次操作都向服务器查询。减少了每次请求都需要额外的网络交互来查询插槽分布，增加延迟。</p>
<p>缓存后，客户端可以直接根据键快速定位目标节点并发送请求。</p>
<h2 id="Sentinel-vs-Cluster"><a href="#Sentinel-vs-Cluster" class="headerlink" title="Sentinel vs Cluster"></a>Sentinel vs Cluster</h2><p>用 Redis 作为缓存或会话存储，数据量不大，Spring Boot 项目 + Jedis/Lettuce → 推荐用 <strong>Sentinel</strong></p>
<p>如果是大型在线教育平台，Redis 承载排行榜、点赞数、搜索缓存等，数据量大、读写频繁 → 推荐用 <strong>Cluster</strong></p>
<table>
<thead>
<tr>
<th>特性/维度</th>
<th>Sentinel（哨兵）</th>
<th>Cluster（分片集群）</th>
</tr>
</thead>
<tbody><tr>
<td><strong>高可用（故障转移）</strong></td>
<td>✅ 支持自动故障转移</td>
<td>✅ 支持自动故障转移（主从切换）</td>
</tr>
<tr>
<td><strong>水平扩展能力</strong></td>
<td>❌ 不支持，单实例容量受限</td>
<td>✅ 原生支持分片，数据分散存储，可横向扩容</td>
</tr>
<tr>
<td><strong>部署复杂度</strong></td>
<td>✅ 相对简单</td>
<td>❌ 更复杂（至少需要 6 个节点：3主3从）</td>
</tr>
<tr>
<td><strong>客户端支持</strong></td>
<td>✅ 普通客户端即可</td>
<td>❌ 客户端需支持 Cluster 协议（JedisCluster、Lettuce等）</td>
</tr>
<tr>
<td><strong>一致性控制</strong></td>
<td>✅ 使用主从结构，数据一致性较强（但仍为最终一致）</td>
<td>❌ 存在异步复制，主从间可能数据丢失</td>
</tr>
<tr>
<td><strong>读写方式</strong></td>
<td>主写从读</td>
<td>自动分片读写</td>
</tr>
<tr>
<td><strong>适用场景</strong></td>
<td>单机数据量不大、业务不复杂</td>
<td>高并发、大数据量、分布式场景</td>
</tr>
</tbody></table>
<h1 id="多级缓存"><a href="#多级缓存" class="headerlink" title="多级缓存"></a>多级缓存</h1><p>传统的缓存策略一般是请求到达Tomcat后，先查询Redis，如果未命中则查询数据库，如图：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210821075259137.png" alt="image-20210821075259137"></p>
<p>存在下面的问题：</p>
<p>•请求要经过Tomcat处理，Tomcat的性能成为整个系统的瓶颈</p>
<p>•Redis缓存失效时，会对数据库产生冲击</p>
<p>多级缓存就是充分利用请求处理的每个环节，分别添加缓存，减轻Tomcat压力，提升服务性能：</p>
<ul>
<li>浏览器访问静态资源时，优先读取浏览器本地缓存</li>
<li>访问非静态资源（ajax查询数据）时，访问服务端</li>
<li>请求到达Nginx后，优先读取Nginx本地缓存</li>
<li>如果Nginx本地缓存未命中，则去直接查询Redis（不经过Tomcat）</li>
<li>如果Redis查询未命中，则查询Tomcat</li>
<li>请求进入Tomcat后，优先查询JVM进程缓存</li>
<li>如果JVM进程缓存未命中，则查询数据库</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210821075558137.png" alt="image-20210821075558137"></p>
<p>在多级缓存架构中，Nginx内部需要编写本地缓存查询、Redis查询、Tomcat查询的业务逻辑，因此这样的nginx服务不再是一个<strong>反向代理服务器</strong>，而是一个编写<strong>业务的Web服务器了</strong>。</p>
<p>因此这样的业务Nginx服务也需要搭建集群来提高并发，再有专门的nginx服务来做反向代理，如图：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210821080511581.png" alt="image-20210821080511581"></p>
<p>另外，我们的Tomcat服务将来也会部署为集群模式：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210821080954947.png" alt="image-20210821080954947"></p>
<p>可见，多级缓存的关键有两个：</p>
<ul>
<li><p>一个是在nginx中编写业务，实现nginx本地缓存、Redis、Tomcat的查询</p>
</li>
<li><p>另一个就是在Tomcat中实现JVM进程缓存</p>
</li>
</ul>
<p>其中Nginx编程则会用到OpenResty框架结合Lua这样的语言。</p>
<h2 id="JVM进程缓存：Caffeine"><a href="#JVM进程缓存：Caffeine" class="headerlink" title="JVM进程缓存：Caffeine"></a>JVM进程缓存：Caffeine</h2><p>Guava/Caffeine</p>
<p>为了演示多级缓存的案例，我们先准备一个商品查询的业务。</p>
<h3 id="初识Caffeine"><a href="#初识Caffeine" class="headerlink" title="初识Caffeine"></a>初识Caffeine</h3><p>缓存在日常开发中启动至关重要的作用，由于是存储在内存中，数据的读取速度是非常快的，能大量减少对数据库的访问，减少数据库的压力。我们把缓存分为两类：</p>
<ul>
<li>分布式缓存，例如Redis：<ul>
<li>优点：存储容量更大、可靠性更好、可以在集群间共享</li>
<li>缺点：访问缓存有网络开销</li>
<li>场景：缓存数据量较大、可靠性要求较高、需要在集群间共享</li>
</ul>
</li>
<li>进程本地缓存，例如HashMap、GuavaCache：<ul>
<li>优点：读取本地内存，没有网络开销，速度更快</li>
<li>缺点：存储容量有限、可靠性较低、无法共享</li>
<li>场景：性能要求较高，缓存数据量较小</li>
</ul>
</li>
</ul>
<p>我们今天会利用Caffeine框架来实现JVM进程缓存。</p>
<p><strong>Caffeine</strong>是一个基于Java8开发的，提供了近乎最佳命中率的高性能的本地缓存库。目前Spring内部的缓存使用的就是Caffeine。GitHub地址：<a target="_blank" rel="noopener" href="https://github.com/ben-manes/caffeine">https://github.com/ben-manes/caffeine</a></p>
<p>Caffeine的性能非常好，下图是官方给出的性能对比：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210821081826399.png" alt="image-20210821081826399"></p>
<p>可以看到Caffeine的性能遥遥领先！</p>
<p>缓存使用的基本API：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">testBasicOps</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">// 构建cache对象</span></span><br><span class="line">    Cache&lt;String, String&gt; cache = Caffeine.newBuilder().build();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 存数据</span></span><br><span class="line">    cache.put(<span class="string">&quot;gf&quot;</span>, <span class="string">&quot;迪丽热巴&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 取数据</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">gf</span> <span class="operator">=</span> cache.getIfPresent(<span class="string">&quot;gf&quot;</span>);</span><br><span class="line">    System.out.println(<span class="string">&quot;gf = &quot;</span> + gf);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 取数据，包含两个参数：</span></span><br><span class="line">    <span class="comment">// 参数一：缓存的key</span></span><br><span class="line">    <span class="comment">// 参数二：Lambda表达式，表达式参数就是缓存的key，方法体是查询数据库的逻辑</span></span><br><span class="line">    <span class="comment">// 优先根据key查询JVM缓存，如果未命中，则执行参数二的Lambda表达式</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">defaultGF</span> <span class="operator">=</span> cache.get(<span class="string">&quot;defaultGF&quot;</span>, key -&gt; &#123;</span><br><span class="line">        <span class="comment">// 根据key去数据库查询数据</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;柳岩&quot;</span>;</span><br><span class="line">    &#125;);</span><br><span class="line">    System.out.println(<span class="string">&quot;defaultGF = &quot;</span> + defaultGF);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<p>Caffeine既然是缓存的一种，肯定需要有缓存的清除策略，不然的话内存总会有耗尽的时候。</p>
<p>Caffeine提供了三种缓存驱逐策略：</p>
<ul>
<li><p><strong>基于容量</strong>：设置缓存的数量上限</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建缓存对象</span></span><br><span class="line">Cache&lt;String, String&gt; cache = Caffeine.newBuilder()</span><br><span class="line">    .maximumSize(<span class="number">1</span>) <span class="comment">// 设置缓存大小上限为 1</span></span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure></li>
<li><p><strong>基于时间</strong>：设置缓存的有效时间</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建缓存对象</span></span><br><span class="line">Cache&lt;String, String&gt; cache = Caffeine.newBuilder()</span><br><span class="line">    <span class="comment">// 设置缓存有效期为 10 秒，从最后一次写入开始计时 </span></span><br><span class="line">    .expireAfterWrite(Duration.ofSeconds(<span class="number">10</span>)) </span><br><span class="line">    .build();</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p><strong>基于引用</strong>：设置缓存为软引用或弱引用，利用GC来回收缓存数据。性能较差，不建议使用。</p>
</li>
</ul>
<blockquote>
<p><strong>注意</strong>：在默认情况下，当一个缓存元素过期的时候，Caffeine不会自动立即将其清理和驱逐。而是在一次读或写操作后，或者在空闲时间完成对失效数据的驱逐。</p>
</blockquote>
<h3 id="实现JVM进程缓存"><a href="#实现JVM进程缓存" class="headerlink" title="实现JVM进程缓存"></a>实现JVM进程缓存</h3><p>利用Caffeine实现下列需求：</p>
<ul>
<li>给根据id查询商品的业务添加缓存，缓存未命中时查询数据库</li>
<li>给根据id查询商品库存的业务添加缓存，缓存未命中时查询数据库</li>
<li>缓存初始大小为100</li>
<li>缓存上限为10000</li>
</ul>
<p>首先，我们需要定义两个Caffeine的缓存对象，分别保存商品、库存的缓存数据。</p>
<p>在item-service的<code>com.heima.item.config</code>包下定义<code>CaffeineConfig</code>类：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.heima.item.config;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.github.benmanes.caffeine.cache.Cache;</span><br><span class="line"><span class="keyword">import</span> com.github.benmanes.caffeine.cache.Caffeine;</span><br><span class="line"><span class="keyword">import</span> com.heima.item.pojo.Item;</span><br><span class="line"><span class="keyword">import</span> com.heima.item.pojo.ItemStock;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Bean;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Configuration;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CaffeineConfig</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> Cache&lt;Long, Item&gt; <span class="title function_">itemCache</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> Caffeine.newBuilder()</span><br><span class="line">                .initialCapacity(<span class="number">100</span>)</span><br><span class="line">                .maximumSize(<span class="number">10_000</span>)</span><br><span class="line">                .build();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> Cache&lt;Long, ItemStock&gt; <span class="title function_">stockCache</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> Caffeine.newBuilder()</span><br><span class="line">                .initialCapacity(<span class="number">100</span>)</span><br><span class="line">                .maximumSize(<span class="number">10_000</span>)</span><br><span class="line">                .build();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>然后，修改item-service中的<code>com.heima.item.web</code>包下的ItemController类，添加缓存逻辑：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="meta">@RequestMapping(&quot;item&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ItemController</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> IItemService itemService;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> IItemStockService stockService;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> Cache&lt;Long, Item&gt; itemCache;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> Cache&lt;Long, ItemStock&gt; stockCache;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// ...其它略</span></span><br><span class="line">    </span><br><span class="line">    <span class="meta">@GetMapping(&quot;/&#123;id&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> Item <span class="title function_">findById</span><span class="params">(<span class="meta">@PathVariable(&quot;id&quot;)</span> Long id)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> itemCache.get(id, key -&gt; itemService.query()</span><br><span class="line">                .ne(<span class="string">&quot;status&quot;</span>, <span class="number">3</span>).eq(<span class="string">&quot;id&quot;</span>, key)</span><br><span class="line">                .one()</span><br><span class="line">        );</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/stock/&#123;id&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> ItemStock <span class="title function_">findStockById</span><span class="params">(<span class="meta">@PathVariable(&quot;id&quot;)</span> Long id)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> stockCache.get(id, key -&gt; stockService.getById(key));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>







<h1 id="缓存同步：Canal"><a href="#缓存同步：Canal" class="headerlink" title="缓存同步：Canal"></a>缓存同步：Canal</h1><p>大多数情况下，浏览器查询到的都是缓存数据，如果缓存数据与数据库数据存在较大差异，可能会产生比较严重的后果。</p>
<p>所以我们必须保证数据库数据、缓存数据的一致性，这就是缓存与数据库的同步。</p>
<h2 id="数据同步策略"><a href="#数据同步策略" class="headerlink" title="数据同步策略"></a>数据同步策略</h2><p>缓存数据同步的常见方式有三种：</p>
<p><strong>设置有效期</strong>：给缓存设置有效期，到期后自动删除。再次查询时更新</p>
<ul>
<li>优势：简单、方便</li>
<li>缺点：时效性差，缓存过期之前可能不一致</li>
<li>场景：更新频率较低，时效性要求低的业务</li>
</ul>
<p><strong>同步双写</strong>：在修改数据库的同时，直接修改缓存</p>
<ul>
<li>优势：时效性强，缓存与数据库强一致</li>
<li>缺点：有代码侵入，耦合度高；</li>
<li>场景：对一致性、时效性要求较高的缓存数据</li>
</ul>
<p><strong>异步通知：</strong>修改数据库时发送事件通知，相关服务监听到通知后修改缓存数据</p>
<ul>
<li>优势：低耦合，可以同时通知多个缓存服务</li>
<li>缺点：时效性一般，可能存在中间不一致状态</li>
<li>场景：时效性要求一般，有多个服务需要同步</li>
</ul>
<p>而异步实现又可以基于MQ或者Canal来实现：</p>
<p>1）基于MQ的异步通知：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210821115552327.png" alt="image-20210821115552327"></p>
<p>解读：</p>
<ul>
<li>商品服务完成对数据的修改后，只需要发送一条消息到MQ中。</li>
<li>缓存服务监听MQ消息，然后完成对缓存的更新</li>
</ul>
<p>依然有少量的代码侵入。</p>
<p>2）基于Canal的通知</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210821115719363.png" alt="image-20210821115719363"></p>
<p>解读：</p>
<ul>
<li>商品服务完成商品修改后，业务直接结束，没有任何代码侵入</li>
<li>Canal监听MySQL变化，当发现变化后，立即通知缓存服务</li>
<li>缓存服务接收到canal通知，更新缓存</li>
</ul>
<p>代码零侵入</p>
<h2 id="Canal"><a href="#Canal" class="headerlink" title="Canal"></a>Canal</h2><p>**Canal [kə’næl]**，译意为水道/管道/沟渠，canal是阿里巴巴旗下的一款开源项目，基于Java开发。基于数据库增量日志解析，提供增量数据订阅&amp;消费。GitHub的地址：<a target="_blank" rel="noopener" href="https://github.com/alibaba/canal">https://github.com/alibaba/canal</a></p>
<p>Canal是基于mysql的主从同步来实现的，MySQL主从同步的原理如下：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210821115914748.png" alt="image-20210821115914748"></p>
<ul>
<li>1）MySQL master 将数据变更写入二进制日志( binary log），其中记录的数据叫做binary log events</li>
<li>2）MySQL slave 将 master 的 binary log events拷贝到它的中继日志(relay log)</li>
<li>3）MySQL slave 重放 relay log 中事件，将数据变更反映它自己的数据</li>
</ul>
<p>而Canal就是把自己伪装成MySQL的一个slave节点，从而监听master的binary log变化。再把得到的变化信息通知给Canal的客户端，进而完成对其它数据库的同步。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210821115948395.png" alt="image-20210821115948395"></p>
<h2 id="监听-Canal"><a href="#监听-Canal" class="headerlink" title="监听 Canal"></a>监听 Canal</h2><p>Canal提供了各种语言的客户端，当Canal监听到binlog变化时，会通知Canal的客户端。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20210821120049024.png" alt="image-20210821120049024"></p>
<p>我们可以利用Canal提供的Java客户端，监听Canal通知消息。当收到变化的消息时，完成对缓存的更新。</p>
<p>不过这里我们会使用GitHub上的第三方开源的canal-starter客户端。地址：<a target="_blank" rel="noopener" href="https://github.com/NormanGyllenhaal/canal-client">https://github.com/NormanGyllenhaal/canal-client</a></p>
<p>与SpringBoot完美整合，自动装配，比官方客户端要简单好用很多。</p>
<blockquote>
<p>引入依赖</p>
</blockquote>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>top.javatool<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>canal-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.1-RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>编写配置</p>
</blockquote>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">canal:</span></span><br><span class="line">  <span class="attr">destination:</span> <span class="string">heima</span> <span class="comment"># canal的集群名字，要与安装canal时设置的名称一致</span></span><br><span class="line">  <span class="attr">server:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:11111</span> <span class="comment"># canal服务地址</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>修改Item实体类</p>
</blockquote>
<p>通过@Id、@Column、等注解完成Item与数据库表字段的映射：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.heima.item.pojo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.baomidou.mybatisplus.annotation.IdType;</span><br><span class="line"><span class="keyword">import</span> com.baomidou.mybatisplus.annotation.TableField;</span><br><span class="line"><span class="keyword">import</span> com.baomidou.mybatisplus.annotation.TableId;</span><br><span class="line"><span class="keyword">import</span> com.baomidou.mybatisplus.annotation.TableName;</span><br><span class="line"><span class="keyword">import</span> lombok.Data;</span><br><span class="line"><span class="keyword">import</span> org.springframework.data.annotation.Id;</span><br><span class="line"><span class="keyword">import</span> org.springframework.data.annotation.Transient;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.persistence.Column;</span><br><span class="line"><span class="keyword">import</span> java.util.Date;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@TableName(&quot;tb_item&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Item</span> &#123;</span><br><span class="line">    <span class="meta">@TableId(type = IdType.AUTO)</span></span><br><span class="line">    <span class="meta">@Id</span></span><br><span class="line">    <span class="keyword">private</span> Long id;<span class="comment">//商品id</span></span><br><span class="line">    <span class="meta">@Column(name = &quot;name&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String name;<span class="comment">//商品名称</span></span><br><span class="line">    <span class="keyword">private</span> String title;<span class="comment">//商品标题</span></span><br><span class="line">    <span class="keyword">private</span> Long price;<span class="comment">//价格（分）</span></span><br><span class="line">    <span class="keyword">private</span> String image;<span class="comment">//商品图片</span></span><br><span class="line">    <span class="keyword">private</span> String category;<span class="comment">//分类名称</span></span><br><span class="line">    <span class="keyword">private</span> String brand;<span class="comment">//品牌名称</span></span><br><span class="line">    <span class="keyword">private</span> String spec;<span class="comment">//规格</span></span><br><span class="line">    <span class="keyword">private</span> Integer status;<span class="comment">//商品状态 1-正常，2-下架</span></span><br><span class="line">    <span class="keyword">private</span> Date createTime;<span class="comment">//创建时间</span></span><br><span class="line">    <span class="keyword">private</span> Date updateTime;<span class="comment">//更新时间</span></span><br><span class="line">    <span class="meta">@TableField(exist = false)</span></span><br><span class="line">    <span class="meta">@Transient</span></span><br><span class="line">    <span class="keyword">private</span> Integer stock;</span><br><span class="line">    <span class="meta">@TableField(exist = false)</span></span><br><span class="line">    <span class="meta">@Transient</span></span><br><span class="line">    <span class="keyword">private</span> Integer sold;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="编写监听器"><a href="#编写监听器" class="headerlink" title="编写监听器"></a>编写监听器</h3><p>通过实现<code>EntryHandler&lt;T&gt;</code>接口编写监听器，监听Canal消息。注意两点：</p>
<ul>
<li>实现类通过<code>@CanalTable(&quot;tb_item&quot;)</code>指定监听的表信息</li>
<li>EntryHandler的泛型是与表对应的实体类</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.heima.item.canal;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.github.benmanes.caffeine.cache.Cache;</span><br><span class="line"><span class="keyword">import</span> com.heima.item.config.RedisHandler;</span><br><span class="line"><span class="keyword">import</span> com.heima.item.pojo.Item;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"><span class="keyword">import</span> top.javatool.canal.client.annotation.CanalTable;</span><br><span class="line"><span class="keyword">import</span> top.javatool.canal.client.handler.EntryHandler;</span><br><span class="line"></span><br><span class="line"><span class="meta">@CanalTable(&quot;tb_item&quot;)</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ItemHandler</span> <span class="keyword">implements</span> <span class="title class_">EntryHandler</span>&lt;Item&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> RedisHandler redisHandler;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> Cache&lt;Long, Item&gt; itemCache;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">insert</span><span class="params">(Item item)</span> &#123;</span><br><span class="line">        <span class="comment">// 写数据到JVM进程缓存</span></span><br><span class="line">        itemCache.put(item.getId(), item);</span><br><span class="line">        <span class="comment">// 写数据到redis</span></span><br><span class="line">        redisHandler.saveItem(item);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">update</span><span class="params">(Item before, Item after)</span> &#123;</span><br><span class="line">        <span class="comment">// 写数据到JVM进程缓存</span></span><br><span class="line">        itemCache.put(after.getId(), after);</span><br><span class="line">        <span class="comment">// 写数据到redis</span></span><br><span class="line">        redisHandler.saveItem(after);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">delete</span><span class="params">(Item item)</span> &#123;</span><br><span class="line">        <span class="comment">// 删除数据到JVM进程缓存</span></span><br><span class="line">        itemCache.invalidate(item.getId());</span><br><span class="line">        <span class="comment">// 删除数据到redis</span></span><br><span class="line">        redisHandler.deleteItemById(item.getId());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>在这里对Redis的操作都封装到了RedisHandler这个对象中，是我们之前做缓存预热时编写的一个类，内容如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.heima.item.config;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.fasterxml.jackson.core.JsonProcessingException;</span><br><span class="line"><span class="keyword">import</span> com.fasterxml.jackson.databind.ObjectMapper;</span><br><span class="line"><span class="keyword">import</span> com.heima.item.pojo.Item;</span><br><span class="line"><span class="keyword">import</span> com.heima.item.pojo.ItemStock;</span><br><span class="line"><span class="keyword">import</span> com.heima.item.service.IItemService;</span><br><span class="line"><span class="keyword">import</span> com.heima.item.service.IItemStockService;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.InitializingBean;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.data.redis.core.StringRedisTemplate;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RedisHandler</span> <span class="keyword">implements</span> <span class="title class_">InitializingBean</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> StringRedisTemplate redisTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> IItemService itemService;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> IItemStockService stockService;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">ObjectMapper</span> <span class="variable">MAPPER</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ObjectMapper</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">afterPropertiesSet</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">// 初始化缓存</span></span><br><span class="line">        <span class="comment">// 1.查询商品信息</span></span><br><span class="line">        List&lt;Item&gt; itemList = itemService.list();</span><br><span class="line">        <span class="comment">// 2.放入缓存</span></span><br><span class="line">        <span class="keyword">for</span> (Item item : itemList) &#123;</span><br><span class="line">            <span class="comment">// 2.1.item序列化为JSON</span></span><br><span class="line">            <span class="type">String</span> <span class="variable">json</span> <span class="operator">=</span> MAPPER.writeValueAsString(item);</span><br><span class="line">            <span class="comment">// 2.2.存入redis</span></span><br><span class="line">            redisTemplate.opsForValue().set(<span class="string">&quot;item:id:&quot;</span> + item.getId(), json);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3.查询商品库存信息</span></span><br><span class="line">        List&lt;ItemStock&gt; stockList = stockService.list();</span><br><span class="line">        <span class="comment">// 4.放入缓存</span></span><br><span class="line">        <span class="keyword">for</span> (ItemStock stock : stockList) &#123;</span><br><span class="line">            <span class="comment">// 2.1.item序列化为JSON</span></span><br><span class="line">            <span class="type">String</span> <span class="variable">json</span> <span class="operator">=</span> MAPPER.writeValueAsString(stock);</span><br><span class="line">            <span class="comment">// 2.2.存入redis</span></span><br><span class="line">            redisTemplate.opsForValue().set(<span class="string">&quot;item:stock:id:&quot;</span> + stock.getId(), json);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">saveItem</span><span class="params">(Item item)</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">json</span> <span class="operator">=</span> MAPPER.writeValueAsString(item);</span><br><span class="line">            redisTemplate.opsForValue().set(<span class="string">&quot;item:id:&quot;</span> + item.getId(), json);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (JsonProcessingException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">deleteItemById</span><span class="params">(Long id)</span> &#123;</span><br><span class="line">        redisTemplate.delete(<span class="string">&quot;item:id:&quot;</span> + id);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h1><p><strong>今日内容</strong></p>
<blockquote>
<ul>
<li>Redis键值设计</li>
<li>批处理优化</li>
<li>服务端优化</li>
<li>集群最佳实践</li>
</ul>
</blockquote>
<h2 id="Redis键值设计"><a href="#Redis键值设计" class="headerlink" title="Redis键值设计"></a>Redis键值设计</h2><h3 id="优雅的key结构"><a href="#优雅的key结构" class="headerlink" title="优雅的key结构"></a>优雅的key结构</h3><p>Redis的Key虽然可以自定义，但最好遵循下面的几个最佳实践约定：</p>
<ul>
<li>遵循基本格式：[业务名称]:[数据名]:[id]</li>
<li>长度不超过44字节</li>
<li>不包含特殊字符</li>
</ul>
<p>例如：我们的登录业务，保存用户信息，其key可以设计成如下格式：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20220521120213631.png" alt="image-20220521120213631"></p>
<p>这样设计的好处：</p>
<ul>
<li>可读性强</li>
<li>避免key冲突</li>
<li>方便管理</li>
<li>更节省内存： key是string类型，底层编码包含int、embstr和raw三种。embstr在小于44字节使用，采用连续内存空间，内存占用更小。当字节数大于44字节时，会转为raw模式存储，在raw模式下，内存空间不是连续的，而是采用一个指针指向了另外一段内存空间，在这段空间里存储SDS内容，这样空间不连续，访问的时候性能也就会收到影响，还有可能产生内存碎片</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20220521122320482.png" alt="image-20220521122320482"></p>
<h3 id="拒绝大key"><a href="#拒绝大key" class="headerlink" title="拒绝大key"></a>拒绝大key</h3><p>BigKey通常以Key的大小和Key中成员的数量来综合判定，例如：</p>
<ul>
<li>Key本身的数据量过大：一个String类型的Key，它的值为5 MB</li>
<li>Key中的成员数过多：一个ZSET类型的Key，它的成员数量为10,000个</li>
<li>Key中成员的数据量过大：一个Hash类型的Key，它的成员数量虽然只有1,000个但这些成员的Value（值）总大小为100 MB</li>
</ul>
<p>那么如何判断元素的大小呢？redis也给我们提供了命令</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20220521124650117.png" alt="image-20220521124650117"></p>
<p>推荐值：</p>
<ul>
<li>单个key的value小于10KB</li>
<li>对于集合类型的key，建议元素数量小于1000</li>
</ul>
<h4 id="大Key的危害"><a href="#大Key的危害" class="headerlink" title="大Key的危害"></a>大Key的危害</h4><ul>
<li>网络阻塞<ul>
<li>对BigKey执行读请求时，少量的QPS就可能导致带宽使用率被占满，导致Redis实例，乃至所在物理机变慢</li>
</ul>
</li>
<li>数据倾斜<ul>
<li>BigKey所在的Redis实例内存使用率远超其他实例，无法使数据分片的内存资源达到均衡</li>
</ul>
</li>
<li>Redis阻塞<ul>
<li>对元素较多的hash、list、zset等做运算会耗时较旧，使主线程被阻塞</li>
</ul>
</li>
<li>CPU压力<ul>
<li>对BigKey的数据序列化和反序列化会导致CPU的使用率飙升，影响Redis实例和本机其它应用</li>
</ul>
</li>
</ul>
<h4 id="如何发现大Key"><a href="#如何发现大Key" class="headerlink" title="如何发现大Key"></a>如何发现大Key</h4><blockquote>
<p><strong>redis-cli –bigkeys</strong></p>
</blockquote>
<p>利用redis-cli提供的–bigkeys参数，可以遍历分析所有key，并返回Key的整体统计信息与每个数据的Top1的big key</p>
<p>命令：<code>redis-cli -a 密码 --bigkeys</code></p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20220521133359507.png" alt="image-20220521133359507"></p>
<blockquote>
<p>scan扫描</p>
</blockquote>
<p>自己编程，利用scan扫描Redis中的所有key，利用strlen、hlen等命令判断key的长度（此处不建议使用MEMORY USAGE）</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20220521133703245.png" alt="image-20220521133703245"></p>
<p>scan 命令调用完后每次会返回2个元素，第一个是下一次迭代的光标，第一次光标会设置为0，当最后一次scan 返回的光标等于0时，表示整个scan遍历结束了，第二个返回的是List，一个匹配的key的数组</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.heima.jedis.util.JedisConnectionFactory;</span><br><span class="line"><span class="keyword">import</span> org.junit.jupiter.api.AfterEach;</span><br><span class="line"><span class="keyword">import</span> org.junit.jupiter.api.BeforeEach;</span><br><span class="line"><span class="keyword">import</span> org.junit.jupiter.api.Test;</span><br><span class="line"><span class="keyword">import</span> redis.clients.jedis.Jedis;</span><br><span class="line"><span class="keyword">import</span> redis.clients.jedis.ScanResult;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">JedisTest</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> Jedis jedis;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@BeforeEach</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">setUp</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 1.建立连接</span></span><br><span class="line">        <span class="comment">// jedis = new Jedis(&quot;127.0.0.1&quot;, 6379);</span></span><br><span class="line">        jedis = JedisConnectionFactory.getJedis();</span><br><span class="line">        <span class="comment">// 2.设置密码</span></span><br><span class="line">        jedis.auth(<span class="string">&quot;123321&quot;</span>);</span><br><span class="line">        <span class="comment">// 3.选择库</span></span><br><span class="line">        jedis.select(<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">static</span> <span class="type">int</span> <span class="variable">STR_MAX_LEN</span> <span class="operator">=</span> <span class="number">10</span> * <span class="number">1024</span>;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">static</span> <span class="type">int</span> <span class="variable">HASH_MAX_LEN</span> <span class="operator">=</span> <span class="number">500</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">testScan</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">maxLen</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="type">long</span> <span class="variable">len</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">cursor</span> <span class="operator">=</span> <span class="string">&quot;0&quot;</span>;</span><br><span class="line">        <span class="keyword">do</span> &#123;</span><br><span class="line">            <span class="comment">// 扫描并获取一部分key</span></span><br><span class="line">            ScanResult&lt;String&gt; result = jedis.scan(cursor);</span><br><span class="line">            <span class="comment">// 记录cursor</span></span><br><span class="line">            cursor = result.getCursor();</span><br><span class="line">            List&lt;String&gt; list = result.getResult();</span><br><span class="line">            <span class="keyword">if</span> (list == <span class="literal">null</span> || list.isEmpty()) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 遍历</span></span><br><span class="line">            <span class="keyword">for</span> (String key : list) &#123;</span><br><span class="line">                <span class="comment">// 判断key的类型</span></span><br><span class="line">                <span class="type">String</span> <span class="variable">type</span> <span class="operator">=</span> jedis.type(key);</span><br><span class="line">                <span class="keyword">switch</span> (type) &#123;</span><br><span class="line">                    <span class="keyword">case</span> <span class="string">&quot;string&quot;</span>:</span><br><span class="line">                        len = jedis.strlen(key);</span><br><span class="line">                        maxLen = STR_MAX_LEN;</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    <span class="keyword">case</span> <span class="string">&quot;hash&quot;</span>:</span><br><span class="line">                        len = jedis.hlen(key);</span><br><span class="line">                        maxLen = HASH_MAX_LEN;</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    <span class="keyword">case</span> <span class="string">&quot;list&quot;</span>:</span><br><span class="line">                        len = jedis.llen(key);</span><br><span class="line">                        maxLen = HASH_MAX_LEN;</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    <span class="keyword">case</span> <span class="string">&quot;set&quot;</span>:</span><br><span class="line">                        len = jedis.scard(key);</span><br><span class="line">                        maxLen = HASH_MAX_LEN;</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    <span class="keyword">case</span> <span class="string">&quot;zset&quot;</span>:</span><br><span class="line">                        len = jedis.zcard(key);</span><br><span class="line">                        maxLen = HASH_MAX_LEN;</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    <span class="keyword">default</span>:</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (len &gt;= maxLen) &#123;</span><br><span class="line">                    System.out.printf(<span class="string">&quot;Found big key : %s, type: %s, length or size: %d %n&quot;</span>, key, type, len);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">while</span> (!cursor.equals(<span class="string">&quot;0&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@AfterEach</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">tearDown</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (jedis != <span class="literal">null</span>) &#123;</span><br><span class="line">            jedis.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>第三方工具</p>
</blockquote>
<ul>
<li>利用第三方工具，如 Redis-Rdb-Tools 分析RDB快照文件，全面分析内存使用情况</li>
<li><a target="_blank" rel="noopener" href="https://github.com/sripathikrishnan/redis-rdb-tools">https://github.com/sripathikrishnan/redis-rdb-tools</a></li>
</ul>
<blockquote>
<p>网络监控</p>
</blockquote>
<ul>
<li>自定义工具，监控进出Redis的网络数据，超出预警值时主动告警</li>
<li>一般阿里云搭建的云服务器就有相关监控页面</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20220521140415785.png" alt="image-20220521140415785"></p>
<h4 id="如何删除BigKey"><a href="#如何删除BigKey" class="headerlink" title="如何删除BigKey"></a>如何删除BigKey</h4><p>BigKey内存占用较多，即便时删除这样的key也需要耗费很长时间，导致Redis主线程阻塞，引发一系列问题。</p>
<ul>
<li>redis 3.0 及以下版本<ul>
<li>如果是集合类型，则遍历BigKey的元素，先逐个删除子元素，最后删除BigKey</li>
</ul>
</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20220521140621204.png" alt="image-20220521140621204"></p>
<ul>
<li>Redis 4.0以后<ul>
<li>Redis在4.0后提供了异步删除的命令：unlink</li>
</ul>
</li>
</ul>
<h3 id="恰当的数据类型"><a href="#恰当的数据类型" class="headerlink" title="恰当的数据类型"></a>恰当的数据类型</h3><h4 id="存储一个User对象，我们有三种存储方式："><a href="#存储一个User对象，我们有三种存储方式：" class="headerlink" title="存储一个User对象，我们有三种存储方式："></a>存储一个User对象，我们有三种存储方式：</h4><h5 id="json字符串"><a href="#json字符串" class="headerlink" title="json字符串"></a>json字符串</h5><table>
<thead>
<tr>
<th align="center">user:1</th>
<th align="center">{“name”: “Jack”, “age”: 21}</th>
</tr>
</thead>
</table>
<p>优点：实现简单粗暴</p>
<p>缺点：数据耦合，不够灵活</p>
<h5 id="字段打散"><a href="#字段打散" class="headerlink" title="字段打散"></a>字段打散</h5><table>
<thead>
<tr>
<th align="center">user:1:name</th>
<th align="center">Jack</th>
</tr>
</thead>
<tbody><tr>
<td align="center">user:1:age</td>
<td align="center">21</td>
</tr>
</tbody></table>
<p>优点：可以灵活访问对象任意字段</p>
<p>缺点：占用空间大、没办法做统一控制</p>
<h5 id="hash（推荐）"><a href="#hash（推荐）" class="headerlink" title="hash（推荐）"></a>hash（推荐）</h5><table>
    <tr>
        <td rowspan="2">user:1</td>
        <td>name</td>
        <td>jack</td>
    </tr>
    <tr>
        <td>age</td>
        <td>21</td>
    </tr>
</table>



<p>优点：底层使用ziplist，空间占用小，可以灵活访问对象的任意字段</p>
<p>缺点：代码相对复杂</p>
<h4 id="假如有hash类型的key，其中有100万对field和value，field是自增id，这个key存在什么问题？如何优化？"><a href="#假如有hash类型的key，其中有100万对field和value，field是自增id，这个key存在什么问题？如何优化？" class="headerlink" title="假如有hash类型的key，其中有100万对field和value，field是自增id，这个key存在什么问题？如何优化？"></a>假如有hash类型的key，其中有100万对field和value，field是自增id，这个key存在什么问题？如何优化？</h4><table>
    <tr style="color:red">
        <td>key</td>
        <td>field</td>
        <td>value</td>
    </tr>
    <tr>
        <td rowspan="3">someKey</td>
        <td>id:0</td>
        <td>value0</td>
    </tr>
    <tr>
        <td>.....</td>
        <td>.....</td>
    </tr>
    <tr>
        <td>id:999999</td>
        <td>value999999</td>
    </tr>
</table>



<p>存在的问题：</p>
<ul>
<li>hash的entry数量超过500时，会使用哈希表而不是ZipList，内存占用较多<ul>
<li><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20220521142943350.png" alt="image-20220521142943350"></li>
</ul>
</li>
<li>可以通过hash-max-ziplist-entries配置entry上限。但是如果entry过多就会导致BigKey问题</li>
</ul>
<h4 id="方案一：拆分为string"><a href="#方案一：拆分为string" class="headerlink" title="方案一：拆分为string"></a>方案一：拆分为string</h4><p>拆分为string类型</p>
<table>
    <tr style="color:red">
        <td>key</td>
        <td>value</td>
    </tr>
    <tr>
        <td>id:0</td>
        <td>value0</td>
    </tr>
    <tr>
        <td>.....</td>
        <td>.....</td>
    </tr>
    <tr>
        <td>id:999999</td>
        <td>value999999</td>
    </tr>
</table>

<p>存在的问题：</p>
<ul>
<li>string结构底层没有太多内存优化，内存占用较多</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20220521143458010.png" alt="image-20220521143458010"></p>
<ul>
<li>想要批量获取这些数据比较麻烦</li>
</ul>
<h4 id="方案二：拆分为小hash"><a href="#方案二：拆分为小hash" class="headerlink" title="方案二：拆分为小hash"></a>方案二：拆分为小hash</h4><p>拆分为小的hash，将 id / 100 作为key， 将id % 100 作为field，这样每100个元素为一个Hash</p>
<table>
    <tr style="color:red">
        <td>key</td>
        <td>field</td>
        <td>value</td>
    </tr>
    <tr>
        <td rowspan="3">key:0</td>
        <td>id:00</td>
        <td>value0</td>
    </tr>
    <tr>
        <td>.....</td>
        <td>.....</td>
    </tr>
    <tr>
        <td>id:99</td>
        <td>value99</td>
    </tr>
    <tr>
        <td rowspan="3">key:1</td>
        <td>id:00</td>
        <td>value100</td>
    </tr>
    <tr>
        <td>.....</td>
        <td>.....</td>
    </tr>
    <tr>
        <td>id:99</td>
        <td>value199</td>
    </tr>
    <tr>
        <td colspan="3">....</td>
    </tr>
    <tr>
        <td rowspan="3">key:9999</td>
        <td>id:00</td>
        <td>value999900</td>
    </tr>
    <tr>
        <td>.....</td>
        <td>.....</td>
    </tr>
    <tr>
        <td>id:99</td>
        <td>value999999</td>
    </tr>
</table>



<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20220521144339377.png" alt="image-20220521144339377"></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.heima.test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.heima.jedis.util.JedisConnectionFactory;</span><br><span class="line"><span class="keyword">import</span> org.junit.jupiter.api.AfterEach;</span><br><span class="line"><span class="keyword">import</span> org.junit.jupiter.api.BeforeEach;</span><br><span class="line"><span class="keyword">import</span> org.junit.jupiter.api.Test;</span><br><span class="line"><span class="keyword">import</span> redis.clients.jedis.Jedis;</span><br><span class="line"><span class="keyword">import</span> redis.clients.jedis.Pipeline;</span><br><span class="line"><span class="keyword">import</span> redis.clients.jedis.ScanResult;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">JedisTest</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> Jedis jedis;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@BeforeEach</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">setUp</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 1.建立连接</span></span><br><span class="line">        <span class="comment">// jedis = new Jedis(&quot;127.0.0.1&quot;, 6379);</span></span><br><span class="line">        jedis = JedisConnectionFactory.getJedis();</span><br><span class="line">        <span class="comment">// 2.设置密码</span></span><br><span class="line">        jedis.auth(<span class="string">&quot;123321&quot;</span>);</span><br><span class="line">        <span class="comment">// 3.选择库</span></span><br><span class="line">        jedis.select(<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">testSetBigKey</span><span class="params">()</span> &#123;</span><br><span class="line">        Map&lt;String, String&gt; map = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span>; i &lt;= <span class="number">650</span>; i++) &#123;</span><br><span class="line">            map.put(<span class="string">&quot;hello_&quot;</span> + i, <span class="string">&quot;world!&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        jedis.hmset(<span class="string">&quot;m2&quot;</span>, map);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">testBigHash</span><span class="params">()</span> &#123;</span><br><span class="line">        Map&lt;String, String&gt; map = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span>; i &lt;= <span class="number">100000</span>; i++) &#123;</span><br><span class="line">            map.put(<span class="string">&quot;key_&quot;</span> + i, <span class="string">&quot;value_&quot;</span> + i);</span><br><span class="line">        &#125;</span><br><span class="line">        jedis.hmset(<span class="string">&quot;test:big:hash&quot;</span>, map);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">testBigString</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span>; i &lt;= <span class="number">100000</span>; i++) &#123;</span><br><span class="line">            jedis.set(<span class="string">&quot;test:str:key_&quot;</span> + i, <span class="string">&quot;value_&quot;</span> + i);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">testSmallHash</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">hashSize</span> <span class="operator">=</span> <span class="number">100</span>;</span><br><span class="line">        Map&lt;String, String&gt; map = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;(hashSize);</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span>; i &lt;= <span class="number">100000</span>; i++) &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">k</span> <span class="operator">=</span> (i - <span class="number">1</span>) / hashSize;</span><br><span class="line">            <span class="type">int</span> <span class="variable">v</span> <span class="operator">=</span> i % hashSize;</span><br><span class="line">            map.put(<span class="string">&quot;key_&quot;</span> + v, <span class="string">&quot;value_&quot;</span> + v);</span><br><span class="line">            <span class="keyword">if</span> (v == <span class="number">0</span>) &#123;</span><br><span class="line">                jedis.hmset(<span class="string">&quot;test:small:hash_&quot;</span> + k, map);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@AfterEach</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">tearDown</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (jedis != <span class="literal">null</span>) &#123;</span><br><span class="line">            jedis.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul>
<li>Key的最佳实践<ul>
<li>固定格式：[业务名]:[数据名]:[id]</li>
<li>足够简短：不超过44字节</li>
<li>不包含特殊字符</li>
</ul>
</li>
<li>Value的最佳实践：<ul>
<li>合理的拆分数据，拒绝BigKey</li>
<li>选择合适数据结构</li>
<li>Hash结构的entry数量不要超过1000</li>
<li>设置合理的超时时间</li>
</ul>
</li>
</ul>
<h2 id="批处理优化"><a href="#批处理优化" class="headerlink" title="批处理优化"></a>批处理优化</h2><h3 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h3><h4 id="我们的客户端与redis服务器是这样交互的"><a href="#我们的客户端与redis服务器是这样交互的" class="headerlink" title="我们的客户端与redis服务器是这样交互的"></a>我们的客户端与redis服务器是这样交互的</h4><p>单个命令的执行流程</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20220521151459880.png" alt="image-20220521151459880"></p>
<p>N条命令的执行流程</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20220521151524621.png" alt="image-20220521151524621"></p>
<p>redis处理指令是很快的，主要花费的时候在于网络传输。于是乎很容易想到将多条指令批量的传输给redis</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/image-20220521151902080.png" alt="image-20220521151902080"></p>
<h4 id="MSet"><a href="#MSet" class="headerlink" title="MSet"></a>MSet</h4><p>Redis提供了很多Mxxx这样的命令，可以实现批量插入数据，例如：</p>
<ul>
<li>mset</li>
<li>hmset</li>
</ul>
<p>利用mset批量插入10万条数据</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">testMxx</span><span class="params">()</span> &#123;</span><br><span class="line">    String[] arr = <span class="keyword">new</span> <span class="title class_">String</span>[<span class="number">2000</span>];</span><br><span class="line">    <span class="type">int</span> j;</span><br><span class="line">    <span class="type">long</span> <span class="variable">b</span> <span class="operator">=</span> System.currentTimeMillis();</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span>; i &lt;= <span class="number">100000</span>; i++) &#123;</span><br><span class="line">        j = (i % <span class="number">1000</span>) &lt;&lt; <span class="number">1</span>;</span><br><span class="line">        arr[j] = <span class="string">&quot;test:key_&quot;</span> + i;</span><br><span class="line">        arr[j + <span class="number">1</span>] = <span class="string">&quot;value_&quot;</span> + i;</span><br><span class="line">        <span class="keyword">if</span> (j == <span class="number">0</span>) &#123;</span><br><span class="line">            jedis.mset(arr);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">long</span> <span class="variable">e</span> <span class="operator">=</span> System.currentTimeMillis();</span><br><span class="line">    System.out.println(<span class="string">&quot;time: &quot;</span> + (e - b));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="Pipeline-1"><a href="#Pipeline-1" class="headerlink" title="Pipeline"></a>Pipeline</h4><p>MSET虽然可以批处理，但是却只能操作部分数据类型，因此如果有对复杂数据类型的批处理需要，建议使用Pipeline</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">testPipeline</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">// 创建管道</span></span><br><span class="line">    <span class="type">Pipeline</span> <span class="variable">pipeline</span> <span class="operator">=</span> jedis.pipelined();</span><br><span class="line">    <span class="type">long</span> <span class="variable">b</span> <span class="operator">=</span> System.currentTimeMillis();</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span>; i &lt;= <span class="number">100000</span>; i++) &#123;</span><br><span class="line">        <span class="comment">// 放入命令到管道</span></span><br><span class="line">        pipeline.set(<span class="string">&quot;test:key_&quot;</span> + i, <span class="string">&quot;value_&quot;</span> + i);</span><br><span class="line">        <span class="keyword">if</span> (i % <span class="number">1000</span> == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="comment">// 每放入1000条命令，批量执行</span></span><br><span class="line">            pipeline.sync();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">long</span> <span class="variable">e</span> <span class="operator">=</span> System.currentTimeMillis();</span><br><span class="line">    System.out.println(<span class="string">&quot;time: &quot;</span> + (e - b));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="集群下的批处理"><a href="#集群下的批处理" class="headerlink" title="集群下的批处理"></a>集群下的批处理</h3><p>如MSET或Pipeline这样的批处理需要在一次请求中携带多条命令，而此时如果Redis是一个集群，那批处理命令的多个key必须落在一个插槽中，否则就会导致执行失败。大家可以想一想这样的要求其实很难实现，因为我们在批处理时，可能一次要插入很多条数据，这些数据很有可能不会都落在相同的节点上，这就会导致报错了</p>
<p>这个时候，我们可以找到4种解决方案</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/1653126446641.png" alt="1653126446641"></p>
<p>第一种方案：串行执行，所以这种方式没有什么意义，当然，执行起来就很简单了，缺点就是耗时过久。</p>
<p>第二种方案：串行slot，简单来说，就是执行前，客户端先计算一下对应的key的slot，一样slot的key就放到一个组里边，不同的，就放到不同的组里边，然后对每个组执行pipeline的批处理，他就能串行执行各个组的命令，这种做法比第一种方法耗时要少，但是缺点呢，相对来说复杂一点，所以这种方案还需要优化一下</p>
<p>第三种方案：并行slot，相较于第二种方案，在分组完成后串行执行，第三种方案，就变成了并行执行各个命令，所以他的耗时就非常短，但是实现呢，也更加复杂。</p>
<p>第四种：hash_tag，redis计算key的slot的时候，其实是根据key的有效部分来计算的，通过这种方式就能一次处理所有的key，这种方式耗时最短，实现也简单，但是如果通过操作key的有效部分，那么就会导致所有的key都落在一个节点上，产生数据倾斜的问题，所以我们推荐使用第三种方式。</p>
<h4 id="串行化执行代码实践"><a href="#串行化执行代码实践" class="headerlink" title="串行化执行代码实践"></a>串行化执行代码实践</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">JedisClusterTest</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> JedisCluster jedisCluster;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@BeforeEach</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">setUp</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 配置连接池</span></span><br><span class="line">        <span class="type">JedisPoolConfig</span> <span class="variable">poolConfig</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JedisPoolConfig</span>();</span><br><span class="line">        poolConfig.setMaxTotal(<span class="number">8</span>);</span><br><span class="line">        poolConfig.setMaxIdle(<span class="number">8</span>);</span><br><span class="line">        poolConfig.setMinIdle(<span class="number">0</span>);</span><br><span class="line">        poolConfig.setMaxWaitMillis(<span class="number">1000</span>);</span><br><span class="line">        HashSet&lt;HostAndPort&gt; nodes = <span class="keyword">new</span> <span class="title class_">HashSet</span>&lt;&gt;();</span><br><span class="line">        nodes.add(<span class="keyword">new</span> <span class="title class_">HostAndPort</span>(<span class="string">&quot;127.0.0.1&quot;</span>, <span class="number">7001</span>));</span><br><span class="line">        nodes.add(<span class="keyword">new</span> <span class="title class_">HostAndPort</span>(<span class="string">&quot;127.0.0.1&quot;</span>, <span class="number">7002</span>));</span><br><span class="line">        nodes.add(<span class="keyword">new</span> <span class="title class_">HostAndPort</span>(<span class="string">&quot;127.0.0.1&quot;</span>, <span class="number">7003</span>));</span><br><span class="line">        nodes.add(<span class="keyword">new</span> <span class="title class_">HostAndPort</span>(<span class="string">&quot;127.0.0.1&quot;</span>, <span class="number">8001</span>));</span><br><span class="line">        nodes.add(<span class="keyword">new</span> <span class="title class_">HostAndPort</span>(<span class="string">&quot;127.0.0.1&quot;</span>, <span class="number">8002</span>));</span><br><span class="line">        nodes.add(<span class="keyword">new</span> <span class="title class_">HostAndPort</span>(<span class="string">&quot;127.0.0.1&quot;</span>, <span class="number">8003</span>));</span><br><span class="line">        jedisCluster = <span class="keyword">new</span> <span class="title class_">JedisCluster</span>(nodes, poolConfig);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">testMSet</span><span class="params">()</span> &#123;</span><br><span class="line">        jedisCluster.mset(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;Jack&quot;</span>, <span class="string">&quot;age&quot;</span>, <span class="string">&quot;21&quot;</span>, <span class="string">&quot;sex&quot;</span>, <span class="string">&quot;male&quot;</span>);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">testMSet2</span><span class="params">()</span> &#123;</span><br><span class="line">        Map&lt;String, String&gt; map = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;(<span class="number">3</span>);</span><br><span class="line">        map.put(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;Jack&quot;</span>);</span><br><span class="line">        map.put(<span class="string">&quot;age&quot;</span>, <span class="string">&quot;21&quot;</span>);</span><br><span class="line">        map.put(<span class="string">&quot;sex&quot;</span>, <span class="string">&quot;Male&quot;</span>);</span><br><span class="line">        <span class="comment">//对Map数据进行分组。根据相同的slot放在一个分组</span></span><br><span class="line">        <span class="comment">//key就是slot，value就是一个组</span></span><br><span class="line">        Map&lt;Integer, List&lt;Map.Entry&lt;String, String&gt;&gt;&gt; result = map.entrySet()</span><br><span class="line">                .stream()</span><br><span class="line">                .collect(Collectors.groupingBy(</span><br><span class="line">                        entry -&gt; ClusterSlotHashUtil.calculateSlot(entry.getKey()))</span><br><span class="line">                );</span><br><span class="line">        <span class="comment">//串行的去执行mset的逻辑</span></span><br><span class="line">        <span class="keyword">for</span> (List&lt;Map.Entry&lt;String, String&gt;&gt; list : result.values()) &#123;</span><br><span class="line">            String[] arr = <span class="keyword">new</span> <span class="title class_">String</span>[list.size() * <span class="number">2</span>];</span><br><span class="line">            <span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; list.size(); i++) &#123;</span><br><span class="line">                j = i&lt;&lt;<span class="number">2</span>;</span><br><span class="line">                Map.Entry&lt;String, String&gt; e = list.get(<span class="number">0</span>);</span><br><span class="line">                arr[j] = e.getKey();</span><br><span class="line">                arr[j + <span class="number">1</span>] = e.getValue();</span><br><span class="line">            &#125;</span><br><span class="line">            jedisCluster.mset(arr);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@AfterEach</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">tearDown</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (jedisCluster != <span class="literal">null</span>) &#123;</span><br><span class="line">            jedisCluster.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="Spring集群环境下批处理代码"><a href="#Spring集群环境下批处理代码" class="headerlink" title="Spring集群环境下批处理代码"></a>Spring集群环境下批处理代码</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"> <span class="keyword">void</span> <span class="title function_">testMSetInCluster</span><span class="params">()</span> &#123;</span><br><span class="line">     Map&lt;String, String&gt; map = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;(<span class="number">3</span>);</span><br><span class="line">     map.put(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;Rose&quot;</span>);</span><br><span class="line">     map.put(<span class="string">&quot;age&quot;</span>, <span class="string">&quot;21&quot;</span>);</span><br><span class="line">     map.put(<span class="string">&quot;sex&quot;</span>, <span class="string">&quot;Female&quot;</span>);</span><br><span class="line">     stringRedisTemplate.opsForValue().multiSet(map);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">     List&lt;String&gt; strings = stringRedisTemplate.opsForValue().multiGet(Arrays.asList(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;age&quot;</span>, <span class="string">&quot;sex&quot;</span>));</span><br><span class="line">     strings.forEach(System.out::println);</span><br><span class="line"></span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>

<p><strong>原理分析</strong></p>
<p>在RedisAdvancedClusterAsyncCommandsImpl 类中</p>
<p>首先根据slotHash算出来一个partitioned的map，map中的key就是slot，而他的value就是对应的对应相同slot的key对应的数据</p>
<p>通过 RedisFuture<String> mset = super.mset(op);进行异步的消息发送</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> RedisFuture&lt;String&gt; <span class="title function_">mset</span><span class="params">(Map&lt;K, V&gt; map)</span> &#123;</span><br><span class="line"></span><br><span class="line">    Map&lt;Integer, List&lt;K&gt;&gt; partitioned = SlotHash.partition(codec, map.keySet());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (partitioned.size() &lt; <span class="number">2</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">super</span>.mset(map);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Map&lt;Integer, RedisFuture&lt;String&gt;&gt; executions = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (Map.Entry&lt;Integer, List&lt;K&gt;&gt; entry : partitioned.entrySet()) &#123;</span><br><span class="line"></span><br><span class="line">        Map&lt;K, V&gt; op = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">        entry.getValue().forEach(k -&gt; op.put(k, map.get(k)));</span><br><span class="line"></span><br><span class="line">        RedisFuture&lt;String&gt; mset = <span class="built_in">super</span>.mset(op);</span><br><span class="line">        executions.put(entry.getKey(), mset);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> MultiNodeExecution.firstOfAsync(executions);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="服务器端优化"><a href="#服务器端优化" class="headerlink" title="服务器端优化"></a>服务器端优化</h2><h3 id="持久化配置"><a href="#持久化配置" class="headerlink" title="持久化配置"></a>持久化配置</h3><p>Redis的持久化虽然可以保证数据安全，但也会带来很多额外的开销，因此持久化请遵循下列建议：</p>
<ul>
<li>用来做缓存的Redis实例尽量不要开启持久化功能</li>
<li>建议关闭RDB持久化功能，使用AOF持久化</li>
<li>利用脚本定期在slave节点做RDB，实现数据备份</li>
<li>设置合理的rewrite阈值，避免频繁的bgrewrite</li>
<li>配置no-appendfsync-on-rewrite = yes，禁止在rewrite期间做aof，避免因AOF引起的阻塞</li>
<li>部署有关建议：<ul>
<li>Redis实例的物理机要预留足够内存，应对fork和rewrite</li>
<li>单个Redis实例内存上限不要太大，例如4G或8G。可以加快fork的速度、减少主从同步、数据迁移压力</li>
<li>不要与CPU密集型应用部署在一起</li>
<li>不要与高硬盘负载应用一起部署。例如：数据库、消息队列</li>
</ul>
</li>
</ul>
<h3 id="慢查询优化"><a href="#慢查询优化" class="headerlink" title="慢查询优化"></a>慢查询优化</h3><h4 id="什么是慢查询"><a href="#什么是慢查询" class="headerlink" title="什么是慢查询"></a>什么是慢查询</h4><p>并不是很慢的查询才是慢查询，而是：在Redis执行时耗时超过某个阈值的命令，称为慢查询。</p>
<p>慢查询的危害：由于Redis是单线程的，所以当客户端发出指令后，他们都会进入到redis底层的queue来执行，如果此时有一些慢查询的数据，就会导致大量请求阻塞，从而引起报错，所以我们需要解决慢查询问题。</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/1653129590210.png" alt="1653129590210"></p>
<p>慢查询的阈值可以通过配置指定：</p>
<p>slowlog-log-slower-than：慢查询阈值，单位是微秒。默认是10000，建议1000</p>
<p>慢查询会被放入慢查询日志中，日志的长度有上限，可以通过配置指定：</p>
<p>slowlog-max-len：慢查询日志（本质是一个队列）的长度。默认是128，建议1000</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/1653130457771.png" alt="1653130457771"></p>
<p>修改这两个配置可以使用：config set命令：</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/1653130475979.png" alt="1653130475979"></p>
<h4 id="如何查看慢查询"><a href="#如何查看慢查询" class="headerlink" title="如何查看慢查询"></a>如何查看慢查询</h4><p>知道了以上内容之后，那么咱们如何去查看慢查询日志列表呢：</p>
<ul>
<li>slowlog len：查询慢查询日志长度</li>
<li>slowlog get [n]：读取n条慢查询日志</li>
<li>slowlog reset：清空慢查询列表</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/1653130858066.png" alt="1653130858066"></p>
<h3 id="命令及安全配置"><a href="#命令及安全配置" class="headerlink" title="命令及安全配置"></a>命令及安全配置</h3><p> 安全可以说是服务器端一个非常重要的话题，如果安全出现了问题，那么一旦这个漏洞被一些坏人知道了之后，并且进行攻击，那么这就会给咱们的系统带来很多的损失，所以我们这节课就来解决这个问题。</p>
<p>Redis会绑定在0.0.0.0:6379，这样将会将Redis服务暴露到公网上，而Redis如果没有做身份认证，会出现严重的安全漏洞.<br>漏洞重现方式：<a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1039000">https://cloud.tencent.com/developer/article/1039000</a></p>
<p>为什么会出现不需要密码也能够登录呢，主要是Redis考虑到每次登录都比较麻烦，所以Redis就有一种ssh免秘钥登录的方式，生成一对公钥和私钥，私钥放在本地，公钥放在redis端，当我们登录时服务器，再登录时候，他会去解析公钥和私钥，如果没有问题，则不需要利用redis的登录也能访问，这种做法本身也很常见，但是这里有一个前提，前提就是公钥必须保存在服务器上，才行，但是Redis的漏洞在于在不登录的情况下，也能把秘钥送到Linux服务器，从而产生漏洞</p>
<p>漏洞出现的核心的原因有以下几点：</p>
<ul>
<li>Redis未设置密码</li>
<li>利用了Redis的config set命令动态修改Redis配置</li>
<li>使用了Root账号权限启动Redis</li>
</ul>
<p>所以：如何解决呢？我们可以采用如下几种方案</p>
<p>为了避免这样的漏洞，这里给出一些建议：</p>
<ul>
<li>Redis一定要设置密码</li>
<li>禁止线上使用下面命令：keys、flushall、flushdb、config set等命令。可以利用rename-command禁用。</li>
<li>bind：限制网卡，禁止外网网卡访问</li>
<li>开启防火墙</li>
<li>不要使用Root账户启动Redis</li>
<li>尽量不是有默认的端口</li>
</ul>
<h3 id="Redis内存划分和内存配置"><a href="#Redis内存划分和内存配置" class="headerlink" title="Redis内存划分和内存配置"></a>Redis内存划分和内存配置</h3><p>当Redis内存不足时，可能导致Key频繁被删除、响应时间变长、QPS不稳定等问题。当内存使用率达到90%以上时就需要我们警惕，并快速定位到内存占用的原因。</p>
<p><strong>有关碎片问题分析</strong></p>
<p>Redis底层分配并不是这个key有多大，他就会分配多大，而是有他自己的分配策略，比如8,16,20等等，假定当前key只需要10个字节，此时分配8肯定不够，那么他就会分配16个字节，多出来的6个字节就不能被使用，这就是我们常说的 碎片问题</p>
<p><strong>进程内存问题分析：</strong></p>
<p>这片内存，通常我们都可以忽略不计</p>
<p><strong>缓冲区内存问题分析：</strong></p>
<p>一般包括客户端缓冲区、AOF缓冲区、复制缓冲区等。客户端缓冲区又包括输入缓冲区和输出缓冲区两种。这部分内存占用波动较大，所以这片内存也是我们需要重点分析的内存问题。</p>
<table>
<thead>
<tr>
<th><strong>内存占用</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td>数据内存</td>
<td>是Redis最主要的部分，存储Redis的键值信息。主要问题是BigKey问题、内存碎片问题</td>
</tr>
<tr>
<td>进程内存</td>
<td>Redis主进程本身运⾏肯定需要占⽤内存，如代码、常量池等等；这部分内存⼤约⼏兆，在⼤多数⽣产环境中与Redis数据占⽤的内存相⽐可以忽略。</td>
</tr>
<tr>
<td>缓冲区内存</td>
<td>一般包括客户端缓冲区、AOF缓冲区、复制缓冲区等。客户端缓冲区又包括输入缓冲区和输出缓冲区两种。这部分内存占用波动较大，不当使用BigKey，可能导致内存溢出。</td>
</tr>
</tbody></table>
<p>于是我们就需要通过一些命令，可以查看到Redis目前的内存分配状态：</p>
<ul>
<li>info memory：查看内存分配的情况</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/1653132073570.png" alt="1653132073570"></p>
<ul>
<li>memory xxx：查看key的主要占用情况</li>
</ul>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/1653132098823.png" alt="1653132098823"></p>
<p>接下来我们看到了这些配置，最关键的缓存区内存如何定位和解决呢？</p>
<p>内存缓冲区常见的有三种：</p>
<ul>
<li>复制缓冲区：主从复制的repl_backlog_buf，如果太小可能导致频繁的全量复制，影响性能。通过replbacklog-size来设置，默认1mb</li>
<li>AOF缓冲区：AOF刷盘之前的缓存区域，AOF执行rewrite的缓冲区。无法设置容量上限</li>
<li>客户端缓冲区：分为输入缓冲区和输出缓冲区，输入缓冲区最大1G且不能设置。输出缓冲区可以设置</li>
</ul>
<p>以上复制缓冲区和AOF缓冲区 不会有问题，最关键就是客户端缓冲区的问题</p>
<p>客户端缓冲区：指的就是我们发送命令时，客户端用来缓存命令的一个缓冲区，也就是我们向redis输入数据的输入端缓冲区和redis向客户端返回数据的响应缓存区，输入缓冲区最大1G且不能设置，所以这一块我们根本不用担心，如果超过了这个空间，redis会直接断开，因为本来此时此刻就代表着redis处理不过来了，我们需要担心的就是输出端缓冲区</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/1653132410073.png" alt="1653132410073"></p>
<p>我们在使用redis过程中，处理大量的big value，那么会导致我们的输出结果过多，如果输出缓存区过大，会导致redis直接断开，而默认配置的情况下， 其实他是没有大小的，这就比较坑了，内存可能一下子被占满，会直接导致咱们的redis断开，所以解决方案有两个</p>
<p>1、设置一个大小</p>
<p>2、增加我们带宽的大小，避免我们出现大量数据从而直接超过了redis的承受能力</p>
<h3 id="集群优化-集群-or-主从"><a href="#集群优化-集群-or-主从" class="headerlink" title="集群优化 集群 or 主从"></a>集群优化 集群 or 主从</h3><p>集群虽然具备高可用特性，能实现自动故障恢复，但是如果使用不当，也会存在一些问题：</p>
<ul>
<li><p>集群完整性问题</p>
</li>
<li><p>集群带宽问题</p>
</li>
<li><p>数据倾斜问题</p>
</li>
<li><p>客户端性能问题</p>
</li>
<li><p>命令的集群兼容性问题</p>
</li>
<li><p>lua和事务问题</p>
</li>
<li><p><em>问题1、在Redis的默认配置中，如果发现任意一个插槽不可用，则整个集群都会停止对外服务：</em>* </p>
</li>
</ul>
<p>大家可以设想一下，如果有几个slot不能使用，那么此时整个集群都不能用了，我们在开发中，其实最重要的是可用性，所以需要把如下配置修改成no，即有slot不能使用时，我们的redis集群还是可以对外提供服务</p>
<p><img src="https://pub-9e727eae11e040a4aa2b1feedc2608d2.r2.dev/PicGo/1653132740637.png" alt="1653132740637"></p>
<p><strong>问题2、集群带宽问题</strong></p>
<p>集群节点之间会不断的互相Ping来确定集群中其它节点的状态。每次Ping携带的信息至少包括：</p>
<ul>
<li>插槽信息</li>
<li>集群状态信息</li>
</ul>
<p>集群中节点越多，集群状态信息数据量也越大，10个节点的相关信息可能达到1kb，此时每次集群互通需要的带宽会非常高，这样会导致集群中大量的带宽都会被ping信息所占用，这是一个非常可怕的问题，所以我们需要去解决这样的问题</p>
<p><strong>解决途径：</strong></p>
<ul>
<li>避免大集群，集群节点数不要太多，最好少于1000，如果业务庞大，则建立多个集群。</li>
<li>避免在单个物理机中运行太多Redis实例</li>
<li>配置合适的cluster-node-timeout值</li>
</ul>
<p><strong>问题3、命令的集群兼容性问题</strong></p>
<p>有关这个问题咱们已经探讨过了，当我们使用批处理的命令时，redis要求我们的key必须落在相同的slot上，然后大量的key同时操作时，是无法完成的，所以客户端必须要对这样的数据进行处理，这些方案我们之前已经探讨过了，所以不再这个地方赘述了。</p>
<p><strong>问题4、lua和事务的问题</strong></p>
<p>lua和事务都是要保证原子性问题，如果你的key不在一个节点，那么是无法保证lua的执行和事务的特性的，所以在集群模式是没有办法执行lua和事务的</p>
<p><strong>那我们到底是集群还是主从</strong></p>
<p>单体Redis（主从Redis）已经能达到万级别的QPS，并且也具备很强的高可用特性。如果主从能满足业务需求的情况下，所以如果不是在万不得已的情况下，尽量不搭建Redis集群</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E7%BC%93%E5%AD%98/" rel="tag"># 缓存</a>
              <a href="/tags/redis/" rel="tag"># redis</a>
              <a href="/tags/%E5%93%88%E5%B8%8C%E6%8F%92%E6%A7%BD/" rel="tag"># 哈希插槽</a>
              <a href="/tags/%E9%9B%86%E7%BE%A4/" rel="tag"># 集群</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2024/08/13/redis-source-code/" rel="prev" title="Redis 数据结构 网络模型">
                  <i class="fa fa-angle-left"></i> Redis 数据结构 网络模型
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2024/08/14/redis-nginx-cache/" rel="next" title="NGINX 多级缓存">
                  NGINX 多级缓存 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2023 – 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">碎梦</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/scatteredream" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
